#+TITLE: Course on Homotopy Type Theory
#+DESCRIPTION: Notes following the course on homotopy type theory by Robert Harper

#+SETUPFILE: math-en.setup
#+SETUPFILE: html.setup
#+SETUPFILE: essay.setup
#+LANGUAGE: en
#+OPTIONS: toc:nil
#+TODO: TODO WIP | CHECK DONE

* Lecture 1: Intuitionistic Type Theory
** Intuitionistic Type Theory (TT),
The *Intuitionistic Type Theory* is based on the work of Per
Martin-Löf on the 1970s.  It is an analysis and expansion of Brouwer's
intuitionism.

** Intensional Type Theory (ITT)
The *Intensional Type Theory* will be our base theory. Other forms of
type theory are extensions of this one.

** Extensional Type Theory (ETT)
The *Extensional Type Theory* has the core of ITT plus the principles
of equality reflection (ER) and uniqueness of the identity proofs
(UIP).

This is the intuitionistic theory of sets in which NuPRL is based.
It is a form of constructive set theory, developed by Bishop; where
types are treated as sets.

** Homotopy Type Theory (HoTT)
The *Homotopy Type Theory* is an elaboration of ITT with higher
inductive types (HIT) and the univalence axiom (UA).

It is an intuitionistic theory of weak $\infty\text{-groupoids}$. Here types
are spaces in an abstract sense.
** Brower's program
The *Brower's program* is a philosophy of mathematics based on the
following ideas
 
 1. mathematics is a human social activity. The focus is on the /language/
    as a tool for communication of mathematical concepts.

 2. the fundamental human capability is the understanding an execution
    of /algorithms/ for performing /constructions/. Proofs are forms
    of construction.

In this setting, the only way to describe infinite things is by
communicate them with an algorithm. 

*** Proof relevance
From the second point, arises the principle of *proof relevance*.
Proofs are mathematical objects that we can see an manipulate. In
other foundations of mathematics, only a limiting enumerable set of
formal proofs can be viewed as proofs.

*** Proof relevance in HoTT
In HoTT, our proofs will be paths in a space. This conception
will provide a synthetic way of working with homotopy which is a
cleaner, shorter and mechanizable way writting proofs.

*** Synthetic perspective in mechanized reasoning
Synthetic geometry is what Euclides did; analytic geometry is what
Descartes did. The traditional formulation of Homotopy Theory, using
euclidean spaces and topology, is an analytic one. Synthetic
formulations of Homotopy Theory are based on Quillen model categories or
HoTT.

This distinction of synthetic and analytical is due to Lawvere.

/Twelf vs Coq is another example/
** Type Theory
Type theory is an analysis and codification of Brower's intuitionism
drawning on Gentzen's proof theory. Types classify the admisible
constructions. A type is defined by

 * *introduction rules*, showing how to make a construction.
 * *elimination rules*, showing how to use a construction.

linked by the *inversion principle*, or principle of conservation of
proofs; stating that the introduction is inverse to the elimination.
This inversion principle is the basis for the computational content
of our language.

** Axiomatic freedom of constructive mathematics
In the Hilbert/Brouwer debate, Hilbert believed that Brouwer was negating
everything that has been done so far; but, as fewer assumptions lead to
stronger results, the exclusion of certain principles leads only to axiomatic
freedom.

For example, the law of excluded middle is not negated on constructive
mathematics, they are simply independent of it; but it can still be
taken as an hypothesis on certain subfields.

We can now include certain assumptions locally, and so, the
constructivity is not a limitation.
** Computational aspect
Type theory acts as an unified theory of computation. Programming
languages and computation are particular manifestations of this
unified theory.

** Computational trinitarianism

\[\begin{tikzcd}[row sep=huge, col sep=tiny]
& \begin{matrix}\text{Type}\\ \text{Theory}\end{matrix} \drar[to-to]\dlar[to-to] & \\
\text{Logic}\arrow[rr,to-to] & & \begin{matrix}\text{Category}\\ \text{Theory}\end{matrix}
\end{tikzcd}\]

There is a complete correspondence between the three theories.
** Intuitionistic logic
*Intuitionistic logic* is based on the principles of intuitionism.
It has the following judgements

 1. $A$ is a proposition.
 2. $A$ is a true proposition, it has a proof.

We do not expect that a proposition is either provable or refutable.
We assume also /open-endedness/, we cannot write all the proofs in a
systematic way.

** Negative fragment of intuitionistic propositional logic
We will write a grammar of proofs.

 * The trivially true proposition, this is the *truth-formation*
   rule

   \begin{prooftree}
   \RightLabel{(T-form)}
   \AxiomC{}
   \UnaryInfC{T prop}
   \end{prooftree}

   this trivially true proposition is true

   \begin{prooftree}
   \RightLabel{(T-intro)}
   \AxiomC{}
   \UnaryInfC{T true}
   \end{prooftree}

   but there is no truth elimination rule, as we are not using any
   information when we write this proposition.

 * Conjunction formation

   \begin{prooftree}
   \RightLabel{($\wedge$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\wedge$ B prop}
   \end{prooftree}

   conjunction introduction

   \begin{prooftree}
   \RightLabel{($\wedge$-intro)}
   \AxiomC{A true}
   \AxiomC{B true}
   \BinaryInfC{A $\wedge$ B true}
   \end{prooftree}
   
   we will use two elimination rules to extract the two pieces 
   of information that went into that fact.

   \begin{prooftree}
   \RightLabel{($\wedge$-elim$_1$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{A true}
   \RightLabel{($\wedge$-elim$_2$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}

 * Implication formation

   \begin{prooftree}
   \RightLabel{($\supset$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\supset$ B prop}
   \end{prooftree}

   and implication introduction, which uses only entailment

   \begin{prooftree}
   \RightLabel{($\supset$-intro)}
   \AxiomC{A true $\vdash$ B true}
   \UnaryInfC{A $\supset$ B true}
   \end{prooftree}

   in the Hilbert formulations of logic, we supress the difference
   between entailment and implication. The logical entailment is prior
   to the implication, it is a map of proofs; while the implication only
   captures that into the logic. The elimination rule is the modus ponens

   \begin{prooftree}
   \RightLabel{($\supset$-elim)}
   \AxiomC{A $\supset$ B true}
   \AxiomC{A true}
   \BinaryInfC{B true}
   \end{prooftree}

* Lecture 2: Intuitionistic Propositional Logic
** Negative fragment of intuitionistic propositional logic
We have talked about

 * the Gentzen principle of conservation of evidence.
 * the truth value.
 * the conjunction.
 * the implication.

Why are these "correct" rules? We are keeping a correspondence between
introduction and elimination rules; that is the beauty of the Gentzen
system and what gives rise to the computational interpretation.

These are not arbitrary rules, there is a coherence that is being kept.
** Structural properties of entailment
The concept of *logical entailment* is a compound judgement. It express
the idea of a conclusion derived from a set of assumptions

\[\underbrace{
A_1 \text{ true},
A_2 \text{ true},
\dots,
A_n \text{ true}}_{\Gamma}
\vdash
A
\]

Logical entailment is a mapping between propositions.
The properties of logical entailment (aka hypothetical judgement) are
the following properties
 
 1. Reflexivity (R), $A \text{ true} \vdash A \text{ true}$.
 2. Transitivity (T),
    
    \begin{prooftree}
    \RightLabel{(T)}
    \AxiomC{$\Gamma_1 \vdash A$ true}
    \AxiomC{$\Gamma_2,A$ true $\vdash B$ true}
    \BinaryInfC{$\Gamma_1,\Gamma_{2} \vdash B$ true}
    \end{prooftree}

    in presence of the weakening, contraction, and exchange properties,
    this can be rewritten using only a $\Gamma$.

 3. Weakening (W),
    
    \begin{prooftree}
    \RightLabel{(W)}
    \AxiomC{$\Gamma$ $\vdash A$ true}
    \UnaryInfC{$\Gamma,B$ true $\vdash A$ true}
    \end{prooftree}

    where the two first properties are fundamental, and this third is
    not as fundamental. You can consider deniying this principle, and
    you will arrive at the notion of /relevant entitlement/, where every
    assumption has to be used in the entitlement.

 4. Contraction (C), 
    
    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma,A$ true,$A$ true $\vdash B$ true}
    \UnaryInfC{$\Gamma, A$ true $\vdash B$ true}
    \end{prooftree}

    in certain logics, we may will want to keep an accounting of
    how many times have we used a lemma; we will have to deny this
    property.

 5. Exchange (E), the order of the assumptions does not matter

    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma \vdash A$ true}
    \UnaryInfC{$\pi(\Gamma) \vdash A$ true}
    \end{prooftree}

    where $\pi$ is any permutation.

When any of these properties fail, we talk of substructural entailment.

** Local form
We are writing the rules in local form. They can be used in the same
way on the presence of assumptions. A $\Gamma$ could be added to all
the rules to obtain the global form. It is implied in our rules.

There are certain scenarios in which we will want $\Gamma$ to be explicitely
empty.

** Order-theoretic formulation
Let us define $A \leq B$, an order on propositions, meaning that
$A \text{ true} \vdash B \text{ true}$.

*** Preorder
This is a preorder,

  * it is reflexive,

    \begin{prooftree}
    \RightLabel{($\leq$-refl)}
    \AxiomC{}
    \UnaryInfC{$A \leq A$}
    \end{prooftree}


  * it is transitive,

    \begin{prooftree}
    \RightLabel{($\leq$-trans)}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \leq C$}
    \end{prooftree}

  * we have a greatest, final element

    \begin{prooftree}
    \RightLabel{($\leq_\top$)}
    \AxiomC{}
    \UnaryInfC{$A \leq \top$}
    \end{prooftree}
   
  * we have meets given by conjunction. That is, there is a lower
    bound

    \begin{prooftree}
    \RightLabel{($\leq,\wedge_1$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq A$}
    \RightLabel{($\leq,\wedge_2$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

    which is also universal

    \begin{prooftree}
    \RightLabel{($\leq,\wedge$-bound)}
    \AxiomC{$C \leq A$}
    \AxiomC{$C \leq B$}
    \BinaryInfC{$C \leq A \wedge B$}
    \end{prooftree}

Those follow from the properties of entailment. We can draw those
properties with Hasse diagrams, where we can see a similarity with
a product diagram on category theory

\[\begin{tikzcd}[column sep=tiny]
& C \dar[dashed] \ar[ddr,bend left]\ar[ddl, bend right] & \\
& A \wedge B \drar\dlar & \\
A & & B &.
\end{tikzcd}\]

*** Antisymmetry and equivalence
We have now a lower semilattice. Sometimes, lower semilattices are
defined to be partial orders, where we have antisymmetry

    \begin{prooftree}
    \RightLabel{}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq A$}
    \BinaryInfC{$A = B$}
    \end{prooftree}

but we are going to work without antisymmetry. We haven't talked yet
about equality, but we are going to introduce the univalent principle.
We could define $A \simeq B$ when $A \leq B$ and $B \leq A$, they are not equal,
but equivalent. We could also work with equivalence classes $[A]_{\simeq}$ here.
Univalence will imply the equality of equivalent propositions.

** Positive fragment of IPL
Now we write the grammar of the positive fragment

 * The false proposition, this is the *false-formation* rule

   \begin{prooftree}
   \RightLabel{($\bot$-form)}
   \AxiomC{}
   \UnaryInfC{$\bot$ prop}
   \end{prooftree}

   there is no introduction rule, only an elimination rule

   \begin{prooftree}
   \RightLabel{($\bot$-elim)}
   \AxiomC{$\bot$ true}
   \UnaryInfC{A true}
   \end{prooftree}

   since there is no introduction rule and this never happens,
   this preserves the coherence principle.

 * Disjunction formation

   \begin{prooftree}
   \RightLabel{($\vee$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\vee$ B prop}
   \end{prooftree}

   disjunction introduction

   \begin{prooftree}
   \RightLabel{($\vee$-intro$_{1}$)}
   \AxiomC{A true}
   \UnaryInfC{A $\vee$ B true}
   \RightLabel{($\vee$-intro$_{2}$)}
   \AxiomC{B true}
   \UnaryInfC{A $\vee$ B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}
   
   we will use an elimination rule to extract the piece of
   of information that went into that fact as in

   \begin{prooftree}
   \RightLabel{($\vee$-elim)}
   \AxiomC{A $\vee$ B true}
   \AxiomC{A true $\vdash$ C true}
   \AxiomC{B true $\vdash$ C true}
   \TrinaryInfC{C true}
   \end{prooftree}

** Order-theoretical properties
We have now a least or initial element,
 
    \begin{prooftree}
    \RightLabel{($\leq$-$\bot$)}
    \AxiomC{}
    \UnaryInfC{$\bot \leq A$}
    \end{prooftree}

and joins or upper bounds

    \begin{prooftree}
    \RightLabel{($\leq,\vee_1$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \RightLabel{($\leq,\vee_2$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

where the bound is the least upper bound

    \begin{prooftree}
    \RightLabel{($\leq,\vee$-bound)}
    \AxiomC{$A \leq C$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \vee B \leq C$}
    \end{prooftree}

Note that those bounds are unique up to equivalence, as they follow
also a categorical universal diagram, in this case, the coproduct
diagram

\[\begin{tikzcd}[column sep=tiny]
A \drar\ar[ddr, bend right] & & B \dlar\ar[ddl, bend left] \\
& A \vee B \dar[dashed] & \\
& C  & &.
\end{tikzcd}\]

This is a lattice, that has all finite meets and joins.

** Order-theoretic formulation of the implication
We have an exponential $B^A$ whenever $A \supset B$, this is defined
as the property

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$A\wedge (A \supset B) \leq B$}
\end{prooftree}

and the exponential is the universal element with this property

\begin{prooftree}
\AxiomC{$A \wedge C \leq B$}
\UnaryInfC{$C \leq A \supset B$}
\end{prooftree}

** Heyting algebra
A *Heyting algebra* is a lattice with exponentials.

*** Yoneda Lemma
The Yoneda Lemma on lattices says that

$a \leq b \iff \left(\forall x: x \leq a \implies x \leq b\right)$.

It is trivial by transitivity and identity. This is
an instance of a more general fact.
** Negation
We define $\neg A := A \supset \bot$. It is the largest proposition inconsistent
with $A$, the largest proposition such that $A \wedge \neg A \leq \bot$.

** Complement
We define $\overline{A}$ as the universal element with the property that $\top \leq A \vee \overline{A}$
and $\overline{A} \wedge A \leq \bot$.

We have a complement distributive algebra (a boolean algebra!) and such thing
has exponentials.

\begin{prooftree}
\AxiomC{$\top \leq A \vee C$}
\UnaryInfC{$\overline{A} \leq C$}
\end{prooftree}

** Boolean algebra
A *boolean algebra* is a complemented distributive lattice. Therefore, it has
exponentials, defined as $B^A := \overline{A} \vee B$.

** Completeness theorem
If $A \leq B$ in every Heyting algebra, it must be deducible that $A \vdash B$.
If something is valid in all models, in all Heyting algebras, it must be
provable.

This logic is complete for Heyting algebras, but it is not going to be
complete for boolean algebras. $A \vee \neg A$ is not going to be provable in
our logic.

*** Proof
If something is provable in every Heyting algebra, you can construct the
propositional *Lindenbaum algebra*; and this is used to show completenaess.
If $A \leq B$ holds in every Heyting algebra, then $A \text{ true} \vdash B \text{ true}$. We
need to interpret the propositions as elements on a Heyting algebra.

*** Converse
If something is provable, it holds in every Heyting algebra. 

** Issue: negation and complement
In a boolean algebra, $A \vee \neg A \simeq \top$.

* Lecture 3: Propositions as Types
** Last week
Last week we saw IPL from a provability perspective. $A$ is true if it
has a proof, and $A$ is false if it has a refutation. We got the
structure of Heyting algebra (a lattice (partial order with all finite
meets and joins) and exponentials). Every Heyting algebra is
distributive. We defined the negation.

*** Soundness incompleteness result
$\Gamma \vdash A$ true iff $\Gamma^{\ast} \leq A^{\ast}$ in every Heyting algebra.

*** Boolean and Heyting algebras
Not every boolean algebra is a Heyting algebra, but every Heyting
algebra is a boolean algebra.

*** DeMorgan Duality
$\overline{A \wedge B} = \overline{A} \vee \overline{B}$ and $\overline{A \vee B} = \overline{A} \wedge \overline{B}$.

** Claim
In IPL, not all instances of LEM are provable. We cannot prove
in general that $A \vee \neg A \text{ true}$.

*** Idea
The disjunction property says that if $A \vee B \text{ true}$, then $A$ true
or $B$ true. This would imply that LEM gives us a proof or a
refutation of every element.

** There exists a Heyting algebra which is not a boolean algebra
We need only a countermodel, a Heyting algebra where $\top \leq A \vee \neg A$
does not hold. It will show that this is not provable in general
in IPL.

** Decidable proposition
A proposition is *decidable* iff $A \vee \neg A \text{ true}$. There are decidable
propositions even if LEM does not hold.

*** Example
Two decidable propositions are $\bot$ and $\top$.

Equality on natural numbers will be decidable, but equality on reals
will not.
** Stable proposition
A proposition is *stable* iff $(\neg \neg A) \supset A \text{ true}$.

** Negation of the negation of LEM
We can prove $\neg \neg (A \vee \neg A)$. This proves that not every proposition
is stable as a corollary.

*** Proof
We will assume $\neg (A \vee \neg A)$ and arrive at a contradiction. If we
assume $A$, we have $A \vee \neg A$, and then a contradiction, so it must
be the case that $\neg A$. We know now that $A \vee \neg A$, arriving at a
contradiction.

** Prove the disjunction property for IPL
We interpret the rules of IPL as an inductive definition of
the entailment relation.

We have finitary derivation trees of every $\Gamma \vdash A$.

*** Disjunction property: formal statement
If $\varnothing \vdash A \vee B \text{ true}$, then $\varnothing \vdash A \text{ true}$ or $\varnothing \vdash B \text{ true}$.

**** Counterexample if the context were not empty
If we take $A \vee B$ as an assumption, this would trivially
not hold.
*** Disjunction property: draft of a proof
We will use an induction on derivations. We examine all possible
derivations $\varnothing \vdash A \vee B \text{ true}$ and show that there are derivations of
$A$ or $B$ also.

The last step of a derivation of $A \vee B$ should be an introduction
$\vee-I_{1}$ or $\vee-I_2$; so there should be a derivation of $A$ or $B$ in
the previous step. The assumption rule is also not applicable.
Conjunction introduction is not applicable, and the same hold for
true introduction and implication introduction. Elimination rules
are our real problem here. For example, implication elimination should
be proved.

To prove this for the implication elimination rule, we suppose that
we have the derivations for $\vdash C$ and $C \vdash (A \vee B)$, and then we could
inline the first derivation using transitivity of entailment to get
a derivation of $\vdash A \vee B$. Note that this is not a complete proof! the
derivation of $C \supset (A \vee B)$ could have be done by other elimination
rules and we should prove that for them too.
** Structural properties are admissible
*Weakening is admissible*, if $\Gamma \vdash_{IPL} B\text{ true}$, then $\Gamma,A \text{ true} \vdash_{IPL} B \text{ true}$.
If you give a derivation of the first, you can get a derivation of the
second one.

*** Why is weakening admissible
Because the rules are polymorphic! They do not depend of Gamma. We
could inductively weaken every step $\Gamma \mapsto \Gamma,A\text{ true}$, and then, reapplying
the rules, would give us the same conclusion.

*** Similarly
You could do exchange or contraction. But reflexivity is a primitive rule!
Transitivity for $\text{IPL}^{-}$ is homework.
*** We have now defined a good logic
It is not simply a bunch of rules, they follow a criteria. The
structural properties should hold. There are substructural logics,
but those are not our topic of interest.
** Gentzen's insight
Our previous idea to prove the disjunction property uses crucially an
inversion principle between implication introduction and implication
elimination.

*ELIM is post-inverse to INTRO.*

We are saying something like the following for introductions, eliminations
and derivations.

 * $(\wedge E_1 \circ \wedge I)({\cal D}_1,{\cal D}_2) = {\cal D}_1$

This gives rise to a dynamics of proof! We do not only look at provability,
we look at the proofs per se.

** II. Proof relevant logic
We will write a grammar of proofs. $M : A$ means that $M$ is a proof
of $A$. In correspondence with the assumptions, there is the concept
of variables

\[ x_1:A_1, \dots , x_n:A_n \vdash M : A.\]

Transitivity now reads as a substitution rule

\begin{prooftree}
\AxiomC{$\Gamma, x : A\vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$[N/x]M : B$}
\end{prooftree}

and reflexivity is only a use of a variable

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:A \vdash x : A$}
\end{prooftree}

We will write this derivations as mappings on a bicartesian closed category

\[M : A_1 \times \dots \times A_n \to A.
\]

Proof-relevant logic will give rise to Type Theory and Category Theory.
* Lecture 4: Proof Reduction and Equivalence
We first saw logic from the point of view of provability. We are going
to look at the idea of logic with proofs. From the first, we got Heyting
Algebras; from the second, we are going to get bicartesian closed categories.

We going to define equivalence of proofs $M \equiv N : A$.

** Proof terms
We will need a grammar of proofs to construct proof terms.
The structural properties are now properties for this grammar.

 * Reflexivity is now the introduction of a variable.
 * Transitivity is now the substitution of a variable.
 * Weakening is now the ability to discard variables.
 * Contraction is now a replication of variables.
 * Exchange is a permutation of variables.

** Logic
Now the negative fragment of our logic can be written as

\begin{prooftree}
\RightLabel{$(\top_{I})$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge-I)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge_{E1})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) : A$}
\RightLabel{$(\wedge_{E2})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{snd}(M) : B$}
\noLine
\BinaryInfC{}
\end{prooftree}


\begin{prooftree}
\RightLabel{$(\supset_{I})$}
\AxiomC{$\Gamma, x:A \vdash M:B$}
\UnaryInfC{$\Gamma \vdash \lambda x . M : A \supset B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\supset_{E})$}
\AxiomC{$\Gamma \vdash M . A \supset B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash M(N) : B$}
\end{prooftree}

** Gentzen's Inversion principle
** Definitional equality
In first order logic, no one draws a distinction between propositional
equality and definitional equality.

*Definitional equality* is the least congruence closed under the following
rules
 
 * it is a equivalence relation.
 * it is compatible with the rules.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M' : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) \equiv \text{fst}(M') : A$}
\end{prooftree}

Now the inversion principle can be written on proof terms.
Simplifications such as $\text{fst}\left\langle M,N \right\rangle \equiv M$ are now useful if we
interpret this as a running program with proof dynamics.

Those are called Beta rules.
The inversion principle on conjunction is now

\begin{prooftree}
\RightLabel{$(\beta\wedge_1)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{fst}\left\langle M,N \right\rangle \equiv M : A$}
\RightLabel{$(\beta\wedge_2)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{snd}\left\langle M,N \right\rangle \equiv N : B$}
\noLine
\BinaryInfC{}
\end{prooftree}

The inversion principle on implication is inlining

\begin{prooftree}
\RightLabel{$(\beta\supset_1)$}
\AxiomC{$\Gamma,x:A \vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash (\lambda x. M)(N) \equiv [N/x]M : B$}
\end{prooftree}

Now we can compute by calculation with closed terms written
as $M \equiv N$.

** Gentzen's Unicity Principles
Those are $\eta$ rules.

\begin{prooftree}
\RightLabel{$(\eta\top)$}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\eta\wedge)$}
\AxiomC{$\Gamma\vdash M: A \wedge B$}
\UnaryInfC{$M \equiv \left\langle \text{fst}(M),\text{snd}(M) \right\rangle$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge\supset)$}
\AxiomC{$\Gamma\vdash M:A \supset B$}
\UnaryInfC{$\Gamma\vdash M \equiv \lambda x. Mx : A \supset B$}
\end{prooftree}

** Propositions as types
The inversion and unicity principles will make a very strong
correspondence on categories.

\begin{tabular}{c|c|c|c}
Latticces & Propositions & Types & Categories \\
\hline
greatest & $\top$ & $1$ & final object \\
meets & $A \wedge B$ & $A \times B$ & finite products \\
exponential & $A \supset B$ & $A \to B$ & exponential \\
minimum & $\bot$ & $0$ & initial object \\
joins & $A \vee B$ & $A+B$ & coproducts
\end{tabular}

** Category
A *category* is a generalized preoder with evidence.
The difference between preorder and partial order is
related to univalence

\begin{prooftree}
\AxiomC{$A \leq B$}
\AxiomC{$B \leq A$}
\BinaryInfC{$A \equiv B$}
\end{prooftree}

where this is an instance of univalence. 

In a category we have the structure of a preorder

 1) Reflexivity, $\mathrm{id} : A \to A$.
 2) Transitivity; if $f: A \to B$ and $g : B \to C$ then
    $g \circ f : A \to C$.

Those have to satisfy some coherence conditions, which are 
the following unit laws

 * $\mathrm{id_B}\circ f = f = f \circ \mathrm{id_A}$
 * $f \circ (g \circ h) = (f\circ g)\circ h$

The equality here is interesting. We could think of this structure
representing two paths and an homotopy between two paths on a 2-cell;
some kind of transformation. We are going to talk of a deformation
given by an associator

\[
\alpha : f \circ (g \circ h) \to (f \circ g) \circ h.
\]

And those notions of evidence (which act as natural transformations) need
also a notion of equivalence and a higher dimensional map between them. But 
this process could be repeated to infinity!

We are going to express the relation of types and terms in categorical terms.

** Terminal object
Definition of final object

\begin{prooftree}
\AxiomC{$$}
\UnaryInfC{$\left\langle\right\rangle : A \to 1$}
\AxiomC{$M : A \to 1$}
\RightLabel{$(\eta{\top})$}
\UnaryInfC{$M = \left\langle  \right\rangle : 1$}
\noLine
\BinaryInfC{}
\end{prooftree}

this was, in our old notation, $A \vdash \left\langle  \right\rangle : 1 = \top$.

** Product objects
There are maps

 1) $\mathrm{fst} : A \times B \to A$
 2) $\mathrm{snd} : A \times B \to A$

satisfying

\[\begin{tikzcd}[column sep=tiny]
& D \ar[bend left]{ddr}{M}\ar[swap,bend right]{ddl}{N}\dar[dashed]{\exists!} & \\
& A \times B \drar[swap]{\mathrm{fst}} \dlar{\mathrm{snd}} & \\
A && B
\end{tikzcd}\]

Pairing is the function taking two functions and returning
the function to the product

\begin{prooftree}
\AxiomC{$M : D \to A$}
\AxiomC{$N : D \to B$}
\BinaryInfC{$\left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

algebraically,

 * $\mathrm{fst}\circ \left\langle M,N \right\rangle = M : D \to A$
 * $\mathrm{snd}\circ \left\langle M,N \right\rangle = N : D \to B$

and there is a uniqueness condition; given

\begin{prooftree}
\RightLabel{$(\eta \times)$}
\AxiomC{$P : D \to A \times B$}
\AxiomC{$\mathrm{fst} \circ P = M$}
\AxiomC{$\mathrm{snd} \circ P = N$}
\TrinaryInfC{$P = \left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

the uniqueness can be seen as the existence of homotopy between
any two functions making the product diagram commute.

In particular, $\left\langle  \mathrm{fst}\circ P, \mathrm{snd} \circ P  \right\rangle = P$. Or we can say that $\left\langle \mathrm{fst}, \mathrm{snd} \right\rangle = \mathrm{id}$
or $\left\langle M,N \right\rangle \circ P = \left\langle M\circ P,N \circ P \right\rangle$.

Lawvere and Lambek first saw those connections on the 70s.
** Exponentials
The exponential $B^A$, gives the application map with the universal
diagram

\[\begin{tikzcd}
C \dar[dashed,swap]{\exists! \lambda(h)} & 
C \times A \ar{dr}{h}\dar[dashed,swap]{\lambda(h) \times id_A} & \\
B^{A} & B^{A} \times A \rar[swap]{app} & B \\
\end{tikzcd}\]

If we write that on syntax, that is equal to

 * $app(\lambda(h) \times \mathrm{id}) = ap \circ \left\langle \lambda(h) \circ \mathrm{fst}, \mathrm{snd} \right\rangle = h$.
 * if there is any $g$ such that $ap \circ (g \times \mathrm{id}) = h$, then $g = \lambda(h)$.

We get the $\eta\text{-rule}$ of

\[
g = \lambda(\mathrm{ap} \circ (g \times \mathrm{id}))
  = \lambda(\mathrm{ap} \circ \left\langle g \circ \mathrm{fst}, \mathrm{snd} \right\rangle).
\]

The essence of all this is

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash h : B$}
\UnaryInfC{$\Gamma \vdash \lambda x. h: B^A$}
\end{prooftree}

** DeBruijn indices
If we write contexts as $A_{n-1}\times \dots \times A_{1}$, and we refer to the
variables using $\mathrm{snd}(\mathrm{fst}(\mathrm{fst}\dots))$.
* Lecture 5: Universal properties
In the previous weeks we talked about

 * logic via provability and truth.
 * the entailment relation.
 * an order theoretic interpretation.
 * a logic for proofs with proof terms.
 * a notion of equality for proofs.

** Gentzen's inversion principle
Represented on the $\beta$ principles, rules such as

 * $\mathtt{fst} \left\langle M,N \right\rangle \equiv M$
 * $\mathtt{snd} \left\langle M,N \right\rangle \equiv N$
 * $(\lambda x. M)(N) \equiv [N/x]M$
 * $\mathtt{case}(\mathtt{inl}(M), x.P, y.Q) \equiv [M/x]P$
 * $\mathtt{case}(\mathtt{inr}(M), x.P, y.Q) \equiv [M/y]Q$

they act as rules for proof simplification and can be interpreted as
a dynamics for proofs. Proofs are programs.

** Gentzen's unicity principles
Represented on $\eta$ principles.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \langle\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle \mathtt{fst}(M),\mathtt{snd}(M) \right\rangle : A \wedge B$}
\end{prooftree}

there is another way of saying this

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\AxiomC{$\Gamma \vdash \mathtt{fst}(M) \equiv P : A$}
\AxiomC{$\Gamma \vdash \mathtt{snd}(M) \equiv Q : B$}
\TrinaryInfC{$\Gamma \vdash M \equiv \left\langle P,Q \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \supset B$}
\UnaryInfC{$\Gamma \vdash M \equiv \lambda x. M(x) : A \supset B$}
\end{prooftree}

** Categorical interpretation
A derivation

\[
x_1:A_1,\dots,x_n:A_n \vdash M : A
\]

is interpreted as a morphism

\[
M : A_1 \times \dots \times A_n \to A\]
\[M \equiv N : A_1 \times \dots \times A_n \to A
\]

The product diagram relates

 * the existence with the introduction.
 * the uniqueness with the $\eta$ rules.
 * the commutativity with the $\beta$ rules.

** Unicity principle for the disjunction [40:00]
It is more difficult to see how the disjunction property should be
written. An inspiration is the notion of Shannon expansion: the type
of booleans can be written as $\top \vee \top$; then $\mathtt{case}$ acts as a binary decision 
diagram. The Shannon expansion is a substitution using booleans where
 
 * $\mathtt{inl} \left\langle  \right\rangle \equiv true$
 * $\mathtt{inl} \left\langle  \right\rangle \equiv false$

then

\[
[M/x]P \equiv \text{ if } M \text{ then } [true/x]P \text{ else } [false/x]P.
\]

and, in particular,

\[
P \equiv \text{ if } x \text{ then } [true/x]P \text{ else } [false/x]P.
\]

The eta rule for disjunction is then

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \vee B$}
\AxiomC{$\Gamma, z:A \vee B \vdash P : C$}
\BinaryInfC{$\Gamma \vdash [M/z]P \equiv \mathrm{case}(M; x : [\mathtt{inl}(x)/z]P; y : [\mathtt{inr}(y)/z]P) : C$}
\end{prooftree}

like a generalized Shannon expansion. As an special case, we
get that $M \equiv \mathtt{case}(M, x . \mathtt{inl}(x), y . \mathtt{inr}(y))$.

** Remark
We could have defined the relationship on variables $x \equiv \left\langle \mathtt{fst}(x), \mathtt{snd}(x) \right\rangle$, but
to derive the general rule from there, we would have needed another property
to get a correct substitution rule.

** Coproduct
We write the coproduct as $A + B$, and its diagram as

\[\begin{tikzcd}[column sep=tiny]
& C  & \\
& A+B  \uar[dashed]{\exists! \left\{ P,Q \right\}}  & \\
A\ar[bend left]{uur}{P}       \urar[swap]{\mathtt{inl}} &&
B\ar[swap,bend right]{uul}{Q} \ular{\mathtt{inr}}
\end{tikzcd}\]

where

\[
\left\{ P,Q \right\} \equiv \mathtt{case} ( - , x.P, y.Q) 
\]

And the unicity simply says that

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash [ \mathtt{inl}(x)/z ]M \equiv P : C$}
\AxiomC{$\Gamma, y:B \vdash [ \mathtt{inr}(y)/z ]M \equiv Q : C$}
\BinaryInfC{$\Gamma, z : A+B \vdash M \equiv \mathtt{case}(z,x:P,y:Q) : C$}
\end{prooftree}

This is an induction principle. We can caracterize the behaviour of $M$ simply
by giving its behaviour on the $\mathtt{inl}$ and the $\mathtt{inr}$.
** Beta/eta rules
The beta rules are analytic judgements. Self-evident.
The eta rules are synthetic judgements. They require proof.

The beta rules correspond to definitional equality and the 
eta rules correspond to propositional equality; it will be
expressed typically by a type. The definitional equality, on
the other hand, is simply a judgement and it is also called
a judgmental equality.
* Lecture 6: Dependency, families of types
So far, we have seen a propositions/types correspondence.
We will add a type of natural numbers, and look for its correspondence
in intuitionistic logic.

** Gödel's T
We will call Gödel's T to the system we have developed so far plus
a natural numbers type. This is not exactly Gödel's T in the literature,
where it is defined only with function types.

\begin{prooftree}
\RightLabel{(Nat$_{I-0}$)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash 0 : Nat$}
\RightLabel{(Nat$_{I-S}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\UnaryInfC{$\Gamma \vdash s(M) : Nat$}
\noLine
\BinaryInfC{}
\end{prooftree}

The elimination form is just definition by recursion

\begin{prooftree}
\RightLabel{(Nat$_{E}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma \vdash P : A$}
\AxiomC{$\Gamma, x:A \vdash Q:A$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}(P,x.Q)(M) : A$}
\end{prooftree}

We need now two beta rules to comply with the inversion principle.

 * $\mathtt{rec}(P,Q)(0) \equiv P$
 * $\mathtt{rec}(P,Q)(s(M)) \equiv [ \mathrm{rec}(P,Q)(M)/x ]Q$

so, if $\overline{n} = s(\dots s(0)\dots)$, $\mathtt{rec}(P,Q)(\overline{n}) \equiv Q(Q(\dots (Q(P))\dots)$.

There is also a eta rule, that was not considered by Gödel at the moment.
Suppose an $M$ acting the same way on the $0$ and the $s$, then it is the
recursor.

\begin{prooftree}
\AxiomC{$\Gamma,z : Nat \vdash M : A$}
\AxiomC{$\Gamma \vdash [0/z] M \equiv P:A$}
\AxiomC{$\Gamma, z:Nat \vdash [ S(z)/z ]M \equiv [M/x]Q$}
\TrinaryInfC{$\Gamma,z:Nat \vdash M \equiv \mathtt{rec}(P,Q)(z)$}
\end{prooftree}

*** Special case on the recursor
Plugging naturals on the recursor

$z : Nat \vdash \mathtt{rec}(0,y.s(y))(z) \equiv z : Nat$

*** Commuting conversion

$\Gamma, z:Nat \vdash [ \mathtt{rec}(0,y.s(y))(z)/z  ]M \equiv \mathtt{rec}([0/z]M, y.[s(y)/z]M)(z)$

** Natural numbers object in a category
The natural numbers object is the universal object in the following
diagram

\[\begin{tikzcd}[column sep=huge]
1 \rar{0}\drar[swap]{P} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \rar{s}\dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} \\
&
A &
A \rar[swap]{Q}&
A
\end{tikzcd}\]

** Reorging the NNO into an initial algebra
This is equivalent to this universality property

\[\begin{tikzcd}[column sep=60pt]
1+\mathbb{N} \dar[swap]{\left\{ 0,s \right\}} \rar[dashed]{ id + \mathtt{rec}(P,Q) } & 
1+A \dar{\left\{ P,Q \right\}} \\
\mathbb{N} \rar[dashed]{\mathtt{rec}(P,Q)}  & 
A
\end{tikzcd}\]

where $f+g : A+B \to A'+B'$ is defined componentwise on the coproduct.

** Initial algebras
This is an instance of a more general phenomenon, where a functor $F$ satisfies
the diagram with the initial object $I$.

\[\begin{tikzcd}
F(I)\rar{F(!)} \dar[swap]{i} & F(A) \dar{f} \\
I\rar{(!)} & A
\end{tikzcd}\]

This is called an *initial algebra*.

** Defining addition
We can define addition on the second argument

$\mathtt{plus} := \lambda x. \lambda y. \mathtt{rec}(x;z.s(z))(y)$

and we can check that $\mathtt{plus}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$. But we also can
define addition on the first $\mathtt{q}:= \lambda x.\lambda y. \mathtt{p}\ y\ x$, and this also
implements addition: $\mathtt{q}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$.

Be we cannot prove

\[
x:Nat, y:Nat \vdash \mathtt{p}\ x\ y \equiv \mathtt{q}\ x\ y  \equiv \mathtt{p}\ y\ x
\]

as these are NOT definitionally equal! It can be proved that it is
not provable using only beta rules. This would require a proof by
induction: to show something for all the numerals is the same thing
as to show it for any numeral variables.

** Extensional and intensional equality
Those are *extensionally* equal, but they are not intensionally equal
(definitional equality). They represent a different algorithm. In the
*sense of Frege*, they have the same reference, but not the same sense.
They have the same IO but different algorithms.

 * Extensional equality is analytic, it does not require proof.
 * Intensional equality is synthetic, does requires proof.

Extensional equality on $(\mathbb{N}\to \mathbb{N})\to(\mathbb{N}\to \mathbb{N})$ has a high quantifier
complexity. A bunch of nested forall and exist.

** Extensional equality
Intensional equality is an inductive defined judgment, whereas
Extensional equality is a proposition such as

\[ \mathtt{p}\ x\ y =_{Nat} \mathtt{q}\ x\ y
\]

that is an atomic proposition. By the propositions as types
principle, extensional equality is a family of types.

\[
x: Nat, y:Nat \vdash x = y \text{ type}
\]

sometimes $x=y$ is written as $Id_{Nat}(x,y)$. It is a propositional
function or a binary relation.

This family can be instantiated by substitution

\[
Id_{Nat}(M,N) \text{ type}
\]

whenever $M,N:Nat$.

** Example of extensional equality
We can define the finite sequence of naturals of length $x:Nat$

\[
x : Nat \vdash Seq(x) \text{ type.}
\]

In this case, $Seq(p\ \overline{m}\ \overline{n}) \equiv Seq(q\ \overline{m}\ \overline{n})$ because of the fact that
$p\ \overline{m}\ \overline{n} \equiv q\ \overline{m}\ \overline{n}$. But

\[
x:Nat, y:Nat \vdash Seq(p\ x\ y) \not\equiv Seq(q\ x\ y)
\]

will not be definitionally equal. But they are isomorphic! In some
sense, they should be equivalent. $A \simeq B$ should mean that for some
$f,g$, we should get

\[\begin{aligned}
\alpha :&\quad g \circ f = \mathrm{id} \\
\beta :&\quad f \circ g = \mathrm{id}
\end{aligned}\]

but again, we are we meaning here by equality? In this case we are
talking about propositional equality. There should be transformations
$\alpha,\beta$ between the compositions and the identities.

** Univalence axiom
In some sense, we expect them to be equal. Univalence says that $A=B \iff A \simeq B$.
There will be an equivalence between those two types.
** Setup for dependent types
Context/closed types. We have judgements
 
 * $\Gamma \text{ ctx}$
 * $\Gamma \equiv \Gamma'$

Open types/families

 * $\Gamma \vdash A \text{ type}$
 * $\Gamma : A \equiv A'$

Elements of types

 * $\Gamma \vdash M : A$
 * $\Gamma \vdash M \equiv M' : A$

We will have a notion of empty context and the notion of adding anything
to a context

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \text{ ctx}$}
\AxiomC{$\Gamma \text{ ctx}$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A \text{ ctx}$}
\noLine
\BinaryInfC{}
\end{prooftree}

and the equality

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \equiv \cdot$}
\AxiomC{$\Gamma \equiv \Gamma'$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma, x:A \equiv \Gamma, x:A'$}
\noLine
\BinaryInfC{}
\end{prooftree}

we can take variables

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma,x:A,\Delta \vdash x :A $}
\end{prooftree}

here it is necessary a weakening rule

\begin{prooftree}
\AxiomC{$\Gamma,\Delta \vdash J$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A, \Delta \vdash J$}
\end{prooftree}

and a substitution

\begin{prooftree}
\RightLabel{(substitution/transitivity)}
\AxiomC{$\Gamma, x:A, \Delta \vdash J$}
\AxiomC{$\Gamma \vdash M:A$}
\BinaryInfC{$\Gamma [M/x]\Delta \vdash [M/x]J$}
\end{prooftree}

and the principle of functionality

\begin{prooftree}
\AxiomC{$\Gamma, x:A, \Delta \vdash N:B$}
\AxiomC{$\Gamma\vdash M\equiv M' :A$}
\BinaryInfC{$\Gamma [M/x] \Delta \vdash [M/x]N \equiv [M'/x]N : [M/x]B$}
\end{prooftree}

another simpler rule is

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M:A'$}
\end{prooftree}

and similarly

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M':A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M\equiv M':A'$}
\end{prooftree}

All this is written on the section 2 of the appendix of HoTT.

*** Exercise
Consider exchange and contraction
** Formation rules
The identity type is constructed as

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash N:A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

iterated identity types can be defined $Id_{Id_A(M,N)}$ to any dimension.
The introduction rule should be

\begin{prooftree}
\RightLabel{(Id-I)}
\AxiomC{$\Gamma \vdash M:A$}
\UnaryInfC{$\Gamma \vdash \mathrm{refl}(M) : Id_A(M,M)$}
\end{prooftree}

being a witness of the fact that $M$ is equal to itself.
* Lecture 7: Dependent Types
** Last week
The basic judgements are

 1) $\Gamma \text{ ctx}$
 2) $\Gamma \equiv \Gamma'$
 3) $\Gamma \vdash A \text{ type}$
 4) $\Gamma \vdash A \equiv A'$
 5) $\Gamma \vdash M:A$
 6) $\Gamma \vdash M \equiv M' :A$

and they follow structural properties. For example, typing respect definitional
equivalence

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M : A'$}
\end{prooftree}

We left open the exact formulation.

*** Example
An example of dependent type is $x : Nat \vdash Seq(x) \text{ text}$.

\begin{prooftree}
\AxiomC{$M \equiv M' : Nat$}
\UnaryInfC{$Seq(M) \equiv Seq(M')$}
\end{prooftree}

But we do not get $x,y : Nat \not\vdash Seq(x+y) \equiv Seq(y+x)$. The
reason is that $x + y \not\equiv y + x$, they are only intensionally equivalent.
To apply $\eta$ you need to establish an invariant about a candidate $M$,
and the $\eta$ rule would not be enough to write a proof of induction of
that fact. We do not want an induction eta-rule.

** Proof-relevance
An element $P : Id_A(M,N)$ can be seen as

 1) a proof that $M$ is $N$.
 2) an identification of $M$ with $N$.
 3) a path from $M$ to $N$.

This $x =_A y$ is called propositional equality.

** Generalization to dependent types
We will review the initial structure of types to generalize the
propositional negative connectives to their dependent forms.
For example, $A \times B$ will generalize to a sigma type $\sum_{x:A}B_x$;
and $A \supset B$ generalizes to $\prod_{x:A}B_{x}$.

\[
\prod_{x:Nat} \sum_{y:Nat} Id_{Nat}(y, \mathtt{succ}(x))
\]

They will represent logical conectives as

\[
\forall x:Nat. \exists y:Nat.\quad y = \mathtt{succ}(x).
\]

** Pi Types
Formation rules

\begin{prooftree}
\RightLabel{($\pi$-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x : A \vdash B_x \text{ type}$}
\BinaryInfC{$\Gamma \vdash \prod_{x:A}B_{x} \text{ type}$}
\end{prooftree}

introductory rules

\begin{prooftree}
\RightLabel{($\pi$-I)}
\AxiomC{$\Gamma, x:A \vdash M_{x} : B_{x}$}
\UnaryInfC{$\Gamma \vdash \lambda x. M_x : \prod_{x:A}B_{x}$}
\end{prooftree}

elimination rules

\begin{prooftree}
\RightLabel{($\pi$-E)}
\AxiomC{$\Gamma \vdash M : \prod_{x:A}B_x$}
\AxiomC{$\Gamma \vdash N:A$}
\BinaryInfC{$\Gamma \vdash MN : [N/x]B$}
\end{prooftree}

There is a beta-rule

\[
(\lambda x.M)N \equiv [N/x]M
\]

and an eta-rule

\[
(\lambda x.M x)\equiv M.
\]
** Particular case
$A \supset B$ is a particular case of a pi-type where $B$ does
not depends on $A$.

** Sigma type
*** Formation

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash B_{x} \text{ type}$}
\BinaryInfC{$\Gamma \vdash \sum_{x:A}B_x \text{ type}$}
\end{prooftree}

*** Introduction
This is constructive existence, you are required to show evidence
of a particular case where it does hold

\begin{prooftree}
\AxiomC{$\Gamma \vdash M :A $}
\AxiomC{$\Gamma \vdash N : [M/x]B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : \sum_{x:A} B_x$}
\end{prooftree}

*** Particular case
The product of types is a particular case where $B_x$ is
independent from $x:A$.

*** Elimination
Will not be the same as in the HoTT book.

\begin{prooftree}
\RightLabel{($\Sigma_{E_1}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{fst}(M) : A$}
\RightLabel{($\Sigma_{E_2}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{snd}(M) : [ \mathtt{fst}(M)/x]B_x$}
\noLine
\BinaryInfC{}
\end{prooftree}

*** Beta/eta rules
Beta rules

 * $\mathtt{fst}\left\langle M,N \right\rangle \equiv N$,
 * $\mathtt{snd}\left\langle M,N \right\rangle \equiv N$

and an eta-rule

 * $\left\langle \mathtt{fst}(M), \mathtt{snd}(M) \right\rangle \equiv M$.
 
** Constructive logic
Can be seen as a refinment of classical logic, not as anything opposite
to it.
** Positive fragment
In the positive fragment, we have $(0,A+B,Nat,\dots)$. But are not
going to change the types. Issue: the positive elims reach into
arbitrary types.

For example, the elim of $+$ was

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma,x:A \vdash N:C$}
\AxiomC{$\Gamma, y:B \vdash P:C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case}(M,x.N,y.P) : C$}
\end{prooftree}

but here there is no dependency. $C$ captures the join point of two
branches; or proof by cases.

*** Example: induction
Let $2 := 1 + 1$, $tt := \mathtt{inl}\langle\rangle$ and $ff := \mathtt{inr}\langle\rangle$. We define

\[ \mathtt{if}(M,N,P) := \mathtt{case}(M,-.N,-.P)
\]

and we want to prove that every element of $2$ is one of those

\[
\prod_{x:2} \left( Id_2(x, \mathtt{tt}) + Id_2(x, \mathtt{ff}) \right).
\]

We have to prove both

 * $Id_2(\mathtt{tt}, \mathtt{tt}) + Id_2(\mathtt{tt}, \mathtt{ff})$
 * $Id_2(\mathtt{ff}, \mathtt{tt}) + Id_2(\mathtt{ff}, \mathtt{ff})$

So we use

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma, z:A+B \vdash C_{z}$ type}
\AxiomC{$\Gamma, x:A \vdash N: [\mathtt{inl}(x)/z] C$}
\noLine
\UnaryInfC{$\Gamma, y:B \vdash P: [\mathtt{inr}(y)/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case} [z.C] (M;x.N;y.P) : [M/z]C$}
\end{prooftree}

where $[z.C]$ is called the *motive* (term by Connor McBride). In this
particular case

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : 2$}
\AxiomC{$\Gamma, z:2 \vdash C_{z}$ type}
\AxiomC{$\Gamma\vdash N: [\mathtt{tt}/z] C$}
\noLine
\UnaryInfC{$\Gamma\vdash P: [\mathtt{ff}/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{if}(M;N;P) : [M/z]C$}
\end{prooftree}

This is a rule of induction.

*** Example
We have the expression

$\mathtt{if}(M,17, \mathtt{tt}) : \mathtt{if} (M,Nat,2)$

but, it is a well-typed expression? not yet. We cannot type
those as types.

** Induction on naturals
\begin{prooftree}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma, z:Nat \vdash C \text{ type}$} 
\AxiomC{$\Gamma \vdash N : [0/z]C$}
\noLine
\UnaryInfC{$\Gamma,x:Nat, y:[x/z]C \vdash P:[s(x)/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}[z.C](M,N;x,y.P) : [M/z]C$}
\end{prooftree}

with the two beta rules

 * $\mathtt{rec}[z.C](0,N; x,y.P) \equiv N$
 * $\mathtt{rec}[z.C](s(M), N; x,y.P) \equiv [M, \mathtt{rec}[z.C](M,N;x,y.P)/x,y]P$

It has an eta rule which is not useful.

*** Exercise

$\prod_{x:Nat} \left(Id(s(x),0) \to \bot\right)$

we will use

\[
\lambda x. \mathtt{rec}[-](x; -,-)
\]

*** Hard exercise
We cannot solve this yet

$\prod_{x,y : Nat} (Id_{Nat}(sx,sy) \to Id_{Nat}(x,y))$
** The other form of product types, sigma variant
Idea: elimination as pattern-matching.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \Sigma_{x:A}B_x$}
\AxiomC{$\Gamma, z : \Sigma_{x:A}B_x \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A, y:B \vdash P : [\langle x,y \rangle/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{split}[z.C](M;x,y.P) : [M/z]C$}
\end{prooftree}

the beta rule is

 * $\mathtt{split}[z.C](\left\langle M_1,M_2 \right\rangle; x,y.P) \equiv [M_1,M_2/x,y]P$

and the eta rule is similar to previous $\eta$ rules. Anything like split is split.

*** Exercise
Define =split= from fst,snd.
Define =fst=, =snd= from split. (Not yet)
* Lecture 8: Identity types
** Polarity
Negative and positive fragments. The difference here is
if the type is based on the elimination or the introduction
rule; the other part of the rule is determined by this first
rule. In category theory, it corresponds to the universal
property mapping /in/ or /out/ the definition of the type.

\begin{tabular}{c|cc}
            & negative    & positive     \\
\hline
type theory & elimination & introduction \\
category theory & UP mapping in & UP mapping out
\end{tabular}

For example, $A\times B$ is /negative/. We write the elimination rule:
given a product, we have =fst= and =snd=. The introduction rule is
a pair, needing an $A$ and a $B$.
** Last week
Dependent formulations of 

 1) negatives $\Pi,\Sigma$.
 2) positives, the type does not change, but the elimination forms do;
    they become induction principles

Elim for the booleans is an example of branching. Today

 * identity types
 * universes
 * ITT. Limitations and peculiarities

** Identity types
They have this rule of formation

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

if we read this type propositionally, this is the type of proofs of
equality between $M$ and $N$. As a notation we use $M =_A N$.

\begin{prooftree}
\RightLabel{(Id-T)}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash \mathtt{refl}_A(M) : Id_A(M,M)$}
\end{prooftree}

In ITT, this would be the only intro rule. We can think of $Id$ as an
inductively generated family of types. 

** Elimination rule for identity types
The elimination rule would then work as

\begin{prooftree}
\RightLabel{(Id-E)}
\AxiomC{$\Gamma \vdash P: Id_{A}(M,N)$}
\AxiomC{$\Gamma, x:A, y:A, z:Id_A(x,y) \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash Q: [x,x,\mathtt{refl}(x)/x,y,z]C$}
\TrinaryInfC{$\Gamma \vdash J[x,y,z.C](P;x.Q) : [M,N,P/x,y,z]C$}
\end{prooftree}

This principle is called *path induction*, where a path is an element
of the identity type. The beta rule is then

 * $J[x,y,z.C]( \mathtt{refl}(M), x.Q) \equiv [M/x]Q : [M,M, \mathtt{refl}(M)/x,y,z]C$

This $J$ is the computational content of the proofs by path induction.
** Equivalence relation of identity
The identity type should be an equivalence relation

 1) it is reflexive by definition, $Id_A(M,M) \text{ true}$.
 2) it is symmetric showing that there is a function

    \[ \mathtt{sym}_A : \prod_{x,y:A}Id_A(x,y) \to Id_A(y,x)
    \]

 3) it is transitive with

    \[ \mathtt{trans}_A:
    \prod_{x,y,z:A} Id_A(x,y) \to Id_A(y,z) \to Id_A(x,z)
    \]

To define symmetry, we will take

\[ \mathtt{sym}_A :=
\lambda x,y:A.\quad \lambda z:Id_A(x,y).\quad
J[x,y, - : Id_A(y,x)}](z;x. \mathtt{refl}_A(x))
\]

Note that $\mathtt{sym}(M)(M)(\mathtt{refl}(M)) \equiv \mathtt{refl}(M)$ due to the beta rule for $J$.

To define transitivity 

\[ \mathtt{trans}_A :=
\lambda m,n,p. \ \lambda u{:}Id_A(m,n).\ \lambda v{:} Id_A(n,p).\  
(J[x,y, -:Id_A(y,p) \to Id(x,p) ](u; x.\lambda w.w))(v)
\]

# It would be better to stop using lambdas for the parameters and
# write the arguments as arguments.

Note that, in particular, $\mathtt{trans}(M)(M)(P)(\mathtt{refl_A(M)})(Q) \equiv Q$.

*** Exercise
Find two other proofs, not definitionally equivalent, of transitivity.
Hint: double induction.
** Simple functionality
Suposse $x:A\vdash F:B$ where $A,B$ are types. We have $F\colon A \to B$.
We would like to have a way to prove that maps preserve equality

\[
x,y{:}A, u{:}Id_A(x,y) \vdash Id_B(Fx,Fy)
\]

We will define $\mathtt{ap}\ F\ u$, also called $F(|u|)$; the functorial action

\[ \mathtt{ap}\ F\ u = 
J[x,y, -:Id_B(Fx,Fy)](u, x. \mathtt{refl}_B(F\ x))
\]

** Transportation property
Suposse $x:A \vdash B \text{ type}$, two pictures are useful

 1) Assigning $a{:}A \mapsto B[a]$ should be functorial.
 2) $\int_{A} B$ should have a display map with fibers sending elements
    on $B[a]$ to $a$.

In some sense, $a = a'$ must imply $B[a] \simeq B[a']$. Transportation could
be thought as functionality for families.

We would want to have 

\[
m,m':A, u:Id_A(m,m'), v : [m/x]B \vdash \mathtt{tr}[x.B](u)(v) : [m'/x]B
\]

the notation for $\mathtt{tr}[x.B](u)(v)$ is $u_{\ast}(v)$.

# Diagram of the lifting property [1:19:50]

This should be defined using path induction

\[ \mathtt{tr}[x.B](u)(v) :=
J\Big[x,y, -:[x/z]B \to [y/z]B\Big](u; z. \lambda w.w)(v)
\]

** Exercise
Find a map 

\[
x,y{:}Nat \vdash  -{:} Seq(x+y) \to Seq(y+x)
\]

To do this we need

 1) to find a path $x,y{:} Nat \vdash -{:}x+y =_{Nat} y+x$.
 2) transport along that path.
* Lecture 9: Universes
** Last week
Maps preserve proofs of identity (functionality)

 * if $F \colon A \to B$ and $p : Id_A(a,a')$, then $\mathtt{ap}\ f\ p : Id_B(f(a),f(a'))$.
   If $a = a'$ is true, $f(a) = f(a')$ is true.

The transportation creates isomorphisms between families of types.

 * If $x:A\vdash B$ is a type and $p : Id_A(a,a')$, then
   $\mathtt{tr}[x.B](p) : B[a] \to B[a']$. This is family functionality.
   If $a=a'$, then $B[a] \iff B[a']$.
** Universes and large elims
Last notion on ITT.

*** Example
We defined $\mathtt{if}(M,N;P) : B[M]$, and we would want to write things like
$\mathtt{if}(M;17;\mathtt{tt}) : \mathtt{if}(M; Nat,Bool)$; a type depending on a boolean. But we cannot
write it because those are types instead of terms.

*** Large eliminations (ad hoc)
We simply introduce a new type

\begin{prooftree}
\AxiomC{$M:Bool$}
\AxiomC{$A$ type}
\AxiomC{$B$ type}
\TrinaryInfC{$IF(M,A,B)$ type}
\end{prooftree}

where

 * $IF(\mathtt{tt},A,B) \equiv A$
 * $IF(\mathtt{ff},A,B) \equiv B$

Those are called *large eliminations*.

*** Universes of types
A *universe* is a type of types.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U}$ type}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U} \equiv {\cal U}$}
\end{prooftree}

where the introduction rules are the previous formation rules.
For example,

\begin{prooftree}
\RightLabel{(UI-Id)}
\AxiomC{$A: {\cal U}$}
\AxiomC{$M,N:A$}
\BinaryInfC{$Id_A(M,N) : {\cal U}$}
\end{prooftree}

The universe should be closed to type formation, for example, closed
to pi-types, sigma-types, 0, 1, sum of two types...

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}$}
\end{prooftree}

But we do NOT postulate that ${\cal U} : {\cal U}$. Its formation rule is the unique
formation rule that is not translated. In other way, the Burali-Forte
Paradox could be reproduced.

*** Solving the problem with universes
Now, we could form $\mathtt{if}(M,Nat,Bool) : {\cal U}$; except we should define some
elimination rules.

Universes allow us to prove

 * injectivity of succ.
 * define =fst=, =snd= from =split=.

If we were to have large elims, we could write things like $\mathtt{If}(M,U,U\to U)$; but
not with the universal type, where is not true that $U : U$.

** Hierarchy of universes
To solve previous problems, we could write a cumulative hierarchy of
universes. We have a family of rules

\begin{prooftree}
\RightLabel{(U-I)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i : {\cal U}_{i+1}$}
\RightLabel{(U-$\equiv$)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i \equiv {\cal U}_{i}$}
\noLine\BinaryInfC{}
\end{prooftree}

defining ${\cal U}_1,{\cal U}_2,\dots$ with a trivial definitional equality and closure
properties for every universe, for example

\begin{prooftree}
\AxiomC{$A : {\cal U}_i$}
\AxiomC{$x:A \vdash B:{\cal U}_i$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}_i$}
\end{prooftree}

and the *principle of cumulativity*

\begin{prooftree}
\RightLabel{(cumulativity)}
\AxiomC{$A:{\cal U}_i$}
\UnaryInfC{$A : {\cal U}_{i+1}$}
\RightLabel{(cumulativity-$\equiv$)}
\AxiomC{$A \equiv B : {\cal U}_{i}$}
\UnaryInfC{$A \equiv B : {\cal U}_{i+1}$}
\noLine\BinaryInfC{}
\end{prooftree}

This architecture is forced on us by the Burali-Forte paradox. This
corresponds to the idea of inaccesible cardinals; to a size hierarchy.
** Dimension
There will be another different notion (on a different axis) than
size (universes). Dimensions are new in HoTT.

** Formation rules in HoTT
In the HoTT book, formation rules are written as introductions to
the universal type

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B : {\cal U}$}
\end{prooftree}

This uses *typical ambiguity*, ${\cal U}$ can be ${\cal U}_i$. The type inference algorithms
of proof assistants solve these constraints, specifying the level in which
we are working. Is a kind of Universe Polymorphism: it let you pretend
${\cal U} : {\cal U}$.

It is very difficult to write something where it is not possible to get an
error at the time of inferring universes. The Burali-Forte paradox cannot be
written in this setting.

** ITT
At this point, we have introduced ITT with Nats, Sigma, Pi, Identity and
Universes. [Martin-Löf 73]

*** Theorem of Choice in ITT
When $C$ is a total relation, we can pick up a canonical representative of
the elements to which $x$ is related to.

\[
\left(\prod_{x:A} \sum_{y:B} C(x,y)\right) \to \sum_{f:A\to B}\prod_{x:A} C(x,f(x))
\]

where $f$ is called the choice function.

In set theory, this is indepent of the axioms of sets; but in type
theory, it is a theorem because of proof-relevance.

\[
\lambda F.\ 
\left\langle \lambda x. \mathtt{fst}(F(x)) , \lambda x. \mathtt{snd}(F(x)) \right\rangle
\]

where $\mathtt{snd}(F(x)) = C(x, \mathtt{fst}(F(x)))$. 

*** Axiom of choice on sets
How about translating this proof to set theory? We would need for the proof
to be a parametrized object! Proof relevance is key to prove the theorem of
choice. If we cannot look inside the first proof, we could not prove the
theorem.

** Martin-Lof theorem
If $p:Id_A(M,N)$ for any closed $M,N,A$; without hypothesis (a theorem),
then $M \equiv N : A$.

*** Example
If we have that 

$A = Nat \to Nat \to Nat$
$M = \lambda x. \lambda y.\ x+y$
$N = \lambda x. \lambda y.\ y+x$
$M \not\equiv N$

There is no proof $p : Id(M,N)$, no term of that type. Yet, given $x,y,z: Nat$,
there exists a proof of $p : Id(x+y,y+x)$. The axiom of extensionality fails
here. It is NOT true that

\begin{prooftree}
\AxiomC{$x : A \vdash p:Id_{B}(fx,gx)$}
\UnaryInfC{\vdash -:Id$_{A\to B}(f,g)$}
\end{prooftree}

So the ordinary notion of function is not true here anymore. We cannot
even prove that $\lambda x.fx = \lambda x.gx$. This is a weakness of ITT.

*** Function extensionality as an axiom
If we introduce extensionality as an axiom, we would have introduced another
intro for identity types, and $J$ should have to be redefined.

In HoTT, we can construct this from the axioms, and this makes very difficult
the task of giving it a meaningful computational interpretation.

** Extensional theory of types (ETT)
In ETT (Extensional here has another meaning), the only identifications are
=refl=. We have the principle of *identity reflection*

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$M \equiv N : A$}
\end{prooftree}

and the only possible proof of identity is =refl=

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$p \equiv \mathtt{refl}(M): Id_A(M,N)$}
\end{prooftree}

In this case, the problem is solved. $Id_B(fx,gx)$ gives us $fx \equiv gx$,
so $\lambda x. fx \equiv \lambda x. gx$, and by eta-reduction, $f \equiv g$. This implies function
extensionality and obviates the need for a rule of transport, we can in fact
show that $B[a] \equiv B[a']$. NuPRL was based on ETT, Coq is based on ITT.

** The disadvantage of ETT
$M:A$ is decidable (not feasible) in ITT, while $M : A$ is undecidable in ETT.
We need arbitrary theorem proving to decide the equality on ETT. It is instead
decidable if a derivation is a valid one.

* Lecture 10: Groupoid structure of types
** Last week
We considered ITT vs ETT. ETT has advantages

 * in ETT, there is no necessity for transport.
 * ETT is similar to standard mathematics, in that there is "just
   equality".
 * function extensionality is implied from the rules.

And disadvantages

 * type checking is no longer decidable; judgmental equality
   is not decidible and it involves proof search and arbitrary theorem
   proving.

A *setoid* in ITT is a set with a given equivalence relation chosen to
have properties like function extensionality. So, the alternative to ETT
is to work with setoids on ITT.

Types are (limited to) sets (aka hsets). The reason why ETT looks like standard
mathematics is because we are working with Sets, where the only paths/identifications
are reflexivities. A sufficient condition for being discrete is decibility of equality.

** Groupoids
Types in ITT, in contrast, are more general. They are $\infty\text{-groupoids}$, 
and they have richer path structure. Paths can be composed

 * $p : Id_A(a,b)$
 * $q : Id_A(b,c)$

When ITT was introduced, it had power to use gropoids. At the very
beginning, no one realized this feature. ETT works for set-level 
mathematics and it is easier.

*** Strict/weak refl
In ETT we can have two views of refl. NuPRL uses strict sets.

*** HoTT
ITT + axioms introducing new paths. Examples of new types are the
interval.

\[\begin{tikzcd}
I : & \underset{0}\cdot \rar[no head] & \underset{1}\cdot 
\end{tikzcd}\]

which is different from boolean types in that it has a nontrivial path

\[\begin{tikzcd}
Bool : & \underset{0}\cdot & \underset{1}\cdot 
\end{tikzcd}\]

There elements $0,1 : I$ and $seg : \mathrm{Id}_I(0,1)$. The booleans have a mapping
out property where a function $f : Bool \to A$ is defined by

 * $f(0) : A$
 * $f(1) :A$

on intervals, to create a function $f : I \to A$, you must also specify what the
function does on the segment

 * $f(\mathtt{seg}) : f(0) = f(1)$

just intuitively, we want some free structure on the data defining the type,
so that if we want to map out a type, we are required to define how to get
from a type to another on all constructors. $f : I \to A$, for example, picks
a path in $A$.
** How does J deal with new paths?
Where do you get off adding axioms to type theory? In type theory, 
we have introductions, eliminations, and the Gentzen's inversion/unicity
principle gives us computation by beta rules. Everything has a beta-normal
form.

But when we add axioms, we get into trouble. What should we do on these cases

 * $J[\ ](\mathtt{seg}, x.Q) \equiv ?$
 * $J[\ ](\lambda x.p, y.Q) \equiv ?$

the principal problem with HoTT is how to recover constructivity/computation on
HoTT. We can here express non set-level math. If every equalities are decidable,
we have to be working with sets.

** I. types are infinite-groupoids
Types are $\infty\text{-groupoids}$. 

Recall that $id_A(M) := \mathtt{refl}_A(M) : Id_A(M,M)$ and that
$p: Id_A(M,N) \vdash p^{-1} : Id_A(N,M)$ was defined by $J$. We also
had composition of paths (transitivity). =trans(p,q)= is defined
by $J$; so we have an equivalence relation.

We have to write code to prove that this is, in fact, an equivalence
relation. Those paths follow the groupoid laws.

*** Groupoid laws
In a groupoid, these laws has to be satisfied

  * $p \cdot p^{-1} \equiv \mathrm{id}$, could be an option, but we usually will accept
    equality on a weaker sense $p \cdot p^{-1} =_{\mathrm{Id}_A(M,N)} \mathrm{id}$.

So we would have elements giving us

  * $\mathtt{unitr} : Id_{Id_A(M,N)}(pp^{-1}, \mathrm{id}(M))$
  * $\mathtt{unitl} : p^{-1}p = \mathrm{id}(N)$
  * $\mathrm{idr} : p \cdot \mathrm{id}(N) = p$
  * $\mathrm{idl} : \mathrm{id}(M) \cdot p = p$

And associativity

  * $\mathtt{assoc} : (p \cdot q) \cdot r = p \cdot ( q \cdot r)$

All of those paths are definible from $J$, they are implicit on the
structure of types and they are called higher-coherences. If we consider only
paths from $M$ to $M$, we would get a higher-group.

*** Defining groupoid laws from J
The groupoid laws can be proven from J.

** II. Maps are functors
If $f : A \to B$ and $p: M = M'$, we get $\mathrm{ap}_f(p) : fM = fM'$. 
That is the principle of equality functionality. This is written using
$J$ again. We know that $\mathrm{ap}(\mathtt{refl}(M)) \equiv \mathtt{refl}(f(M))$. $\mathtt{ap}$ preserves
identities in this sense. Does it preserve all the groupoid structure?

We can prove that $\mathtt{ap}$ preserves all the structure, it gives us a principle
of *equality functoriality*; it is functorial.

* Lecture 11: Functoriality
** Last week
It is a generalization of the structure given by the equivalence
relation on paths. Path satisfy the groupoid laws with the
concatenation of paths. The data associated to every path can be
thought as a higher dimensional path.

For $f : A \to B$, we have

\[ \mathtt{ap}_f : Id(M,N) \to Id(fM, fN)
\]

and it is a functorial application, respecting the groupoid structure
due to the eta-rules for $J$ as

 * $ap(id) = id$
 * $ap(p^{-1}) = ap(p)^{-1}$
 * $ap(p\cdot q) = ap(p) \cdot ap(q)$

and having also that $ap_{id} = id$ and $ap_{f \circ g} = ap_g \circ ap_f$. Suppose $f : \prod_{x{:}A}B_x$,
we would like to have the path

\[ Id_A(M,N) \to Id_B(fM,fN)
\]

but $fM : [M/x]B$ and $fN:[N/x]B$ are not of the same type! But we could use
the transport property to get $p_{\ast} : [M/x]B \to [N/x]B$. If we apply the transport
property to the inversed path, we get the inverted path $B[N] \to B[M]$. We would
get different proofs of the lemma if we use $p_{\ast}$ or $p_{\ast}^{-1}$.

** Path-over-path
The lemma we want to do is

\[
M =_A N \longrightarrow f(M) =_p^{x:B_{x}} f(N)
\]

this is a notation that says that $f(M)$ and $f(N)$ are correlated by
$p$ on the fiber $x:B_x$. We will be able to send $p$ to a
path-over-path $q : f(M) =_p^{x:B_x} f(N)$.

#+begin_definition
Given $x : A \vdash B : {\cal U}_x$ and $p : M =_A N$,

\[
\Big(Q =_p^{x:B} R \Big)
:=
\Big(p_{\ast} Q =_{[N/x]B} R\Big)
\]
#+end_definition

It is possible to prove a lot of lemmas about this type. We can
state reflexivity, symmetry properties and so on.
** Equivalence of types: motivation
Equivalence vs definitional and propositional equality of types as
elements of the universe.

 * In an informal treatment of classical logic, we mix $\iff$ and $=$.
   Nothing can distinghish between them. In classical logic there are
   only two propositions, so it is difficult to distingish.
 * Equality should be the relationship respected by everything inside
   the language.
 * But when we are working on a proof relevance setting, there could
   be many different proofs of two propositions, and two implications
   do not have to be inverses!
 * Isomorphisms of sets work on a similar way. It is not important to
   distinghish between two isomorphic sets given any isomorphism $f,f^{-1}$.

We could write bijections like $\omega = \omega^2$, but there are
contexts where we want to make a difference between the two. Set theory
allows us to ask nonsensical things like $0 \in 1$.

The condition of bijection on types can be translated as a function
$f : A \to B$ with a $g : B \to A$ such that

In ITT, let's suppose a set of functions $N \to N$ and a non-trivial 
bijection to itself.

 * $F(f) = f'$ and $G(f') = f$
 * $F(g) = g'$ and $G(g') = g$

but what do those equalities mean? 

 * $F(f)(x) = f'(x)$ and $G(f)(y) = f(y)$ would be an interpretation.
   Those would be extensionally equal, but different functions.

The notion of bijection is not very useful when working on higher-order
types.
** Equivalence on types involving a universe
The elements of ${\cal U}$ have structure, each one of them is a groupoid.
The idea of bijection $FG(A) = A$ is not workable; we are interested
in nontrivial isomorphisms, in an equivalence rather than equality
$FG(A) \simeq A$.

This is similar to isomorphisms and equivalence of categories. We want
$FG(A) \cong A$, we do not need $FG(A) = A$. Equivalence is isomorphism up
to isomorphism.

And when we have a universe of universes, the same question repeats
itself. We need another level of comparison now. We would get the
higher-group structure of a type.

Isomorphism here is not a proposition but a structure.
** Equivalence
Given $f : A \to B$, a quasiinverse of $f$ is given by
$(g,\alpha,\beta)$ such that

 * $g : B \to A$
 * $\alpha : \prod_{a:A} g(f(a)) =_A a$
 * $\beta : \prod_{b:B} f(g(b)) =_B b$

The type of *quasiinverses* is

\[
QI(f)_{A\to B} := \sum_{g : B \to A} 
\left(
\left(\prod_{a:A} g(f(a)) = a\right)
\times
\left(\prod_{b:B} f(g(b)) = b\right)
\right)
\]

*** Another version
In ITT, this is different from

 * $\alpha' : g \circ f = id_A$
 * $\beta' : f \circ g = id_B$

this uses two paths instead of two homotopies.
Function extensionality is now

\[
(f =_{A \to B} g) \simeq
\left( \prod_{a:A}f(a)=_B g(a) \right)
\]

saying that every homotopy defines an equation. Those
two types of proofs are equivalent.

** Univalence axiom
There is an equivalence between equivalence and equality.

\[
(A \simeq B) \simeq (A = B)
\]

Equivalences are given by

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g = id_B \times g \circ f = id_A \right)  \times \text{ some coherence condition }
\]

to avoid the function extensionality issue, we can write
homotopies instead

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g \sim id_B \times g \circ f \sim id_A \right) \times \text{ some coherence condition }
\]

but we are going to have function extensionality.
* Lecture 12: Equivalence of Types
** Equivalence of types
We write the equivalence of $A \simeq B$. We say that $f : A \to B$ 
is an *equivalence* if there exists

\[
\left( \sum_{g:B\to A} f \circ g \sim id_B \right) \times
\left( \sum_{h:B\to A} h \circ f \sim id_A \right)
\]

the type of equivalences is

\[
A \simeq B := \sum_{f:A\to B} \mathrm{isequiv}(f)
\]

** Elements of the equivalence
An equivalence is defined whenever those functions
exist

 1. $f : A \to B$
 2. $g:B\to A$
 3. $\alpha: \prod_{y:B} f(g(y)) =_B y$
 4. $h : B\to A$
 5. $\beta : \prod_{x:A} h(f(x)) =_A x$

** Quasiinverse
Quasiinverses are defined as

\[ \mathrm{quasiinverse}(f) :=
\sum_{g:B\to A} f\circ g \sim id_B \times g \circ f \sim id_{A}
\]

There are three important properties

 1. $qinv(f) \to isequiv(f)$
 2. $isequiv(f) \to qinv(f)$
 3. $isequiv(f)$ expresses an HPROP, it has at most one proof up
    to higher homotopy.

we can transform the data from a quasiinverse to a equivalence.
from  $H : f \sim_{A \to B} g$ we get $\prod_{x:A} Id_B(f x, gx)$. $H$ is functorial in
$x:A$; in the sense that this diagram commutes for any $p : a = a'$

\[\begin{tikzcd}
f(a)\rar[no head]{H(a)} \dar[swap,no head]{ap_f(p)} & g(a) \dar[no head]{ap_g(p)} \\
f(a')\rar[no head]{H(a')} & g(a')
\end{tikzcd}\]

Homotopy is natural (or /polymorphic/) in $x$.

** Funtion extensionality

 1) definable if $\mathtt{happly}: f =_{A \to B} g \to f \sim g$.
 2) the axiom of funtion extensionality says that the
    above map is an equivalence.

In the presence of function extensionality, we could write $\alpha$
and $\beta$ as $f \circ g \sim id$ and $h \circ f \sim id$. Once you
have function extensionality, you can write the homotopy as
an equality

 * $\prod_{y:B} f(g(y)) = y$
 * by definition of homotopy, $f\circ g \sim id$
 * by function extensionality, $f \circ g = id_{B}$

** Exercises

 1) $id : A \to A$ is an equivalence, give the four parts of the
    equivalence.
 2) if $f$ is an equivalence, $f^{-1}$, given by the quasiinverse, is
    an equivalence.
 3) if $f$ and $g$ are equivalences, then so is $g \circ f: A \to C$.

** Structure of paths in types
For example, if we take $Id_{A \times B}(-,-)$, the identity type seems invariant
to the way the type has been constructed; but a structure can be deduced
from the types.

There is a function $f$ with the type $Id_{A \times B}(x,y) \to Id_A(\pi_1x, \pi_2y) \times Id_B( \pi_2x, \pi_2y)$
that we can define as

\[
f := \lambda p. \left\langle \mathrm{ap}_{\pi_1}(p), \mathrm{ap}_{\pi_2}(p) \right\rangle
\]

And we can prove that $f$ is an equivalence

\[
Id_A(x,y) \simeq Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x, \pi_2y)
\]

because it suffices to exhibit a quasiinverse for $f$.

 * $g : Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x,\pi_2y) \to Id_{A \times B}(x,y)$
 * $\alpha : g(f(p)) =_{Id_{A\times B}(x,y)} p$
 * $\beta : f(g(q)) =_{Id_A(-,-) \times Id_B(-,-)} q$

we use pattern matching

\[
g := \lambda (p,q). ap^2_{pair}\ p\ q
\]

where $pair = \lambda x,y. (x,y)$, and $ap^2_f\ p\ q : Id(f x y, f x' y')$ where
$p: Id(x,x')$ and $q : Id(y,y')$.
** Products
We need to show the following for the quasi-inverse

 * $\eta :\prod_p (ap^2_{pair} \left(ap_{\pi_1}(p), ap_{\pi_2}(p)) = p\right)$
 * $\beta_1 : \prod_p\prod_q ap_{\pi_1}(ap^2_{pair}\ p\ q) = p$
 * $\beta_2 : \prod_p\prod_q ap_{\pi_2}(ap^2_{pair}\ p\ q) = p$

We need by path induction $x : A \times B \vdash - : ap^2_{pair}\ (ap_{\pi_1}(refl(x))\ ap_{\pi_2}(refl(x)) = refl(x)$

 * $ap_{\pi_1}(refl(x)) \equiv refl(\pi_1(x))$
 * $ap_{\pi_2}(refl(x)) \equiv refl(\pi_2(x))$

Note that the type checking will depend on the computation rules, and
this is antimodular. If you change anything on the code, everything that
relies on it could break.

 * $ap^2_{pair}\ (refl(\pi_1 x))\ (refl(\pi_2 x)) \equiv refl(\pi_1(x),\pi_2(x)) \equiv refl(x)$
** Nullary case

\[
Id_{1}(x,y) \simeq 1
\]

** Coproducts
In coproducts, we would like to prove that

 * $Id_{A+B}(inl(a),inl(a')) \simeq Id_A(a,a')$
 * $Id_{A+B}(inr(b),inr(b')) \simeq Id_B(b,b')$
 * $Id_{A+B}(inl(a),inr(b)) \simeq 0$
 * $Id_{A+B}(inr(b),inl(a)) \simeq 0$

If we were to find a map from

 * $x : Id_{A+B}(inl(a),inl(a')) \vdash -:Id_A(a,a')$

using path induction on $p$, we would have to find a motive $C = ?$
and the conclusion should be $C(inl(a),inl(a'), p)$, where $J[C](p,\dots)$
would be the induction on paths. But how do we get rid of the $inl$?
We should define a motive as

\[
D(u,v) = Id_{A}(outl(u), outl(u))
\]

but there are not $outl$ functions! We want the motive to be

\[
F : (A+B) \times (A+B) \to {\cal U}
\]

such that
 
 * $F(inl(a),inl(a')) \equiv Id_A(a,a')$
 * $F(inr(b),inl(b')) \equiv Id_A(b,b')$
 * $F(inl(-),inr(-)) \equiv 0$
 * $F(inr(-),inr(-)) \equiv 0$

Exercise: define such an $F$ by double induction.

The critical lemma is $x : A+B \vdash -:F(x,x)$, which we need to
use path induction.

\[ \mathtt{case}[z.F(z,z)](x; m:A. refl(m) ; n:B. refl(n) ) : F(x,x)
\]

where $[inl(m)/z]F(z,z) \equiv F(inl(n),inl(n))$.
* Lecture 13: Path structure of Types
** Last week
We characterized paths in coproducts.

*** Lemma
$x : A +B \vdash -:F(x,x)$

we use induction on $x$

 * $a:A \vdash refl(a) : F(inl(a),inl(a))$
 * $b:B \vdash refl(b) : F(inr(b),inr(b))$

what we want to define a quasiinverse 

\[
f : \prod_{x,x' : A+B} Id_A(x,x') \to F(x,x')
\]

\begin{aligned}
f := \lambda x. \lambda x'. \mathtt{case}(x;\ a:A.\ \mathtt{case}( & \\
& x'; a':A. \lambda p:Id_A(inl(a),inl(a')) . J[F](p; z.F(z,z), \\
& \dots )
\end{aligned}

*** Quasiinverse
Now we have to define

\[
g : \prod_{x,x':A+B} F(x,x') \to Id_{A+B}(x,x')
\]

as

\[
g := \lambda x,x',z:F(x,x')\ \text{cases on }\ x\ x'
\]

and now we want to show

 * $z:F(x,x') \vdash \alpha(z) : f(g(z)) = z$
 * $z:Id_{A+B}(x,x') \vdash \beta(z) : g(f(z)) = z$

** Positive types
We work with coproducts as examples of positive types. We will
characterize $Id_0(-,-)$ and the path structure of $\mathbb{S}^1$.

\[
Id_{s'}(b,b) = \Omega_b(S') \simeq \mathbb{Z}
\]

We are doing synthetic homotopy theory.

** Characterizing paths on identity types
Given a type $A$, we consider $Id_{Id_{\dots_A}}(-,-)$. We cannot say much, because
it includes as special cases the spheres $\Omega(S^n)$.

If $f : A \to B$ is an equivalence, then so is $ap_f : a =_A a' \to f(a) = f(a')$.
What we have is $f : A \to B$, so $\alpha : \prod_{a:A}f^{-1}(f(a)) =_A a$ and $\beta : \prod_{b:B}f^{-1}(f(b)) =_B b$.
because it has quasiinverses. To prove this, we define

\[ ap^{-1}_f := \alpha(a)^{-1} \cdot ap_{f^{-1}} \cdot \alpha(a')
\]

now we need

 * $\alpha' : \prod_{p:a =_A a'} ap^{-1}_f(ap_f(p)) =_{a = a'} p$
 * $\beta' : \prod_{q:f(a) =_B f(a')} ap_f(ap_{f}^{-1}(q)) =_{f(a) = f(a')} q$

and both can be proved by path induction.
** Identity types are homs in an (infinite,1)-category
The type $Id_A(x,y)$ is similar to $Hom_A(x,y)$. $Id_A(-,-)$ is a family
of types, and hence a fibration.

We look at the transport/fibration properties taking
the notation $E(x,y) := Id(x,y)$

  1) fix $x_{0}:A$, consider $\lambda y:A.E(x_0,y)$,

     \[
     tr[y.E(x_0,y)](q) : E(x_0,y) \to E[x_0,y']
     \]

     it maps $p:E(x_0,y) \mapsto p \cdot q$

  2) fix $y_0 : A$, consider $x . E(x,y_0)$,

     \[
     tr[x.E(x,y_0)](p) : E(x,y_0) \to E(x',y_0)
     \]

     mapping $q \mapsto p^{-1}\cdot q$.

  3) for $p : x = x'$, $q : E(x,x)$; $tr[x.E(x,x)](p) : q \mapsto p^{-1} \cdot q \cdot p$.

It can be checked by path induction. This show that they behave like
Hom's and that they exhibit the infinity-groupoid structure.
** Recall: identity elimination rule
The idea is that, in ITT, this can be thought of as an induction
principle arising from taking the Id to be the least reflexive
relation, because the only introduction rule says so; and the 
elimination works as that.

\begin{prooftree}
\AxiomC{$\Gamma \vdash p:Id_A(M,N)$}
\noLine
\UnaryInfC{$\Gamma,x:A,y:A,z:Id(x,y) \vdash F : {\cal U}$}
\AxiomC{$\Gamma, x:A \vdash q : F(x,x,refl) $}
\BinaryInfC{$\Gamma \vdash J[F](p,x.q) : F(M,N,p)$}
\end{prooftree}

For doing set-level mathematics, this works. In HoTT, we interpret the
identities as paths in $A$, not as inductive types. We conclude things
about non-trivial paths only reasoning about reflexivity!
* Lecture 14: Identity elimination
** Last week exercise
If $ - : qinv(f)$, then $-: ap_f$.

 1) $ap_f^{-1} = ap_{f^{-1}}$
 2) $\alpha : \prod_{p : a=_A a'} \dots$
 3) $\beta : \prod_{q : f(a) = (a')} ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$

the (2) is proved by path induction, but (3) is not so easy. If we use
path induction there, we will get $F[f(a),f(a'),q]$ as motive, which should
be then $ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$. Recall that, for coproducts,

 * $F[inl(a),inl(a')] \equiv (a = a')$

but here, we cannot do that, we would need to define it such that
$F[f(a),f(a'),q] =_{{\cal U}} \left(ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q\right)$. If $M:A$ and
$p : A =_{{\cal U}} A'$, then $p_{\ast}(M) : A'$. So you use the fact that

 * $f^{-1}(f(a)) =_A a$, and
 * $(f^{-1},\alpha,\beta) : qinv(f)$.
** Justifying the J operator
The J operator has different meanings in ITT and HoTT

 1. In ITT, J expresses an induction principle on proofs of identity,
    of which there is exactly one.

 2. In HoTT (or ITT + FUNEXT), the situation is less clear,

    \[J[\ ](refl(M), x.Q) \equiv [M/x]Q\]
    
    but then, we have the problem

    \[J[\ ](funext(H); x.Q) \equiv ?
    \]

    where the Gentzen's principle does not hold. How should apply
    $J$ with the Univalence Axiom or to other defined equalities?

    * $J[\ ](UA(E), x.id) \equiv ?$
    * $J[\ ](seg, x.id) \equiv ?$
    * $J[\ ](loop, x.id) \equiv ?$

 3. In ETT, it does not work like this. Equality reflection allows us
    to replace to equalities; we do not need J at all. We get FUNEXT
    without special arrangement. It has a computational interpretation.
    You end using a theory of realizability.

 4. In OTT, we can have FUNEXT without special arrangement. It has a
    computational interpretation.

In HoTT, we give up on computation; but maybe we can recover one. We
justify the theory by interpretation into the classical ZF using
simplicial sets.
** Solving (partially) the problem
Idea: have $x:A \vdash Q : C[x,x,refl(x)]$ where the motif
$x:A,y:A,z: x=y \vdash C : {\cal U}$. We want to get $- : C[M,N,P]$ 
where $M,M':A,P: M=M'$. This is what the J-rule is saying. 

We know that $[M/x]Q : C[M,M,refl(M)$, and $Q$ depends functorially
on $x$. The logic in HoTT is integrated with the whole structure of
maps. There is a continuous dependency from $Q$ to $A$. So we also
know that $[P/x]Q : [M/x]Q =_p^{C(-,-,refl(-))} [N/x]Q$ (in an abuse of language)
and $ - : p_\ast [M/x]Q =_{C(M',M',refl(M'))} [M'/x]Q$.

Since $refl(M) : M = M and $p : M = M'$, now it suffices to find
$\alpha : refl(M) =^{Id(-,-)}_{(refl(M),p)} p$, wich is to say that

\[
\alpha : \left\langle refl(M),p \right\rangle(refl(M)) = p
\]

the triple $(refl,p,\alpha)$ would take $C(M,M,refl(M))$ into $C(M,M',p)$.

\[ tr[x.Id(x,x)](p)(q) = p^{-1}\cdot q \cdot p\]

it works choosing $refl_{Id_{A}(M,M')}(p)$. $C$ does the work! A priori, $C$ respects
whatever it is that $Id$ internalizes!

** The identity type
The equality is respected by all the theory, that is why the identity
type has those special properties. In HoTT, $Id$ internalizes homotopy
equivalence, and, by univalence, everything respects homotopy
equivalence. In contrast, in ITT, $Id$ internalizes definitional
equality.

The identity type does not define homotopy equivalence, it only 
internalizes the notion.
** Homotopy types
The slogan is that Homotopy (Type Theory) is (Homotopy Type) Theory.
# Así que debe traducirse por teoría de tipos homotópicos o
# por teoría de tipos homotópica.

#+begin_definition
A type $A$ is a *set*, aka 0-type, iff for all $p,q : x =_{A} y$, we have
that $p=q$.
#+end_definition

\[ \mathrm{isSet}(A) :=
\prod_{x,y:A}\prod_{p,q: x=y} p = q
\]

it is a discrete groupoid up to higher homotopy. The only paths are
the reflexivities, but up to higher-homotopy! There can be other loops,
but they are homotopic to the reflexivity.

You can form a type theory there every type is a set.
* Lecture 15: Sets and propositions
** Last week
We saw a justification for the J-rule and the interaction with
the functioriality of $C$ and the inductive analysis of J.

** The Interval Type
Formation rule

\begin{prooftree}
\RightLabel{$(I-F)$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash I : {\cal U}$}
\end{prooftree}

Introduction rules

\begin{prooftree}
\RightLabel{(iI0)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  0 : I$}
\RightLabel{(iI1)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  1 : I$}
\noLine
\BinaryInfC{}
\end{prooftree}

And another introduction rule

\begin{prooftree}
\RightLabel{(iIseg)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash seg : Id_I(0,1)$}
\end{prooftree}

This is an inductive definition of the type. The type should be
freely generated by these constructors.

\begin{prooftree}
\AxiomC{$\Gamma, x:I \vdash C[x] : {\cal U}$}
\AxiomC{$\Gamma \vdash M_0 : C[0]$}
\noLine
\UnaryInfC{$\Gamma \vdash M_1 : C[1]$}
\AxiomC{$\Gamma \vdash p : M_0 =_{seg}^{x:C} M_1$}
\TrinaryInfC{$\Gamma, x:I \vdash \mathrm{rec}_I[x.C](x;M_0,M_1 )  : C[x]$}
\end{prooftree}

where it is defined as

 * $rec[x.C](0;M_0,M_1, -) \equiv M_0 : C[0]$
 * $rec[x.C](1;M_0,M_1, -) \equiv M_1 : C[1]$
 * $dap(\lambda x . rec[x.C](0;M_0,M_1,p)) \equiv p : M_0 =^{x:C}_{seg} M_1$

the $dap$ map should be functorial

\[ dap : \prod_f \prod_{x:A}B \longrightarrow \prod_{p:Id(x,y)} Id(fx,fy)
\]

** The total path space of a type
The total path space are the morphisms from the interval

\[
\sum_{x:A}\sum_{y:A} Id(x,y) \simeq (I \to A)
\]

*** Proof
The rec function goes from left to right

$\lambda x,y,p. \lambda t. rec[-:A](t;x,y,p)$

And the description of the path goes the other way

\[ \lambda h. (h(0),h(1), ap(seg)).
\]

** Conclusion on the total path space
A path between functions is an homotopy, a path between
every pair of points

\begin{align*}
\int Id_{A \to B} &
\simeq I \to (A \to B) \\&
\simeq (I \times A) \to B \\&
\simeq (A \times I) \to B \\&
\simeq A \to (I \to B) \\&
\simeq A \to \int Id_{B}
\end{align*}

Function extensionality says that

\[
Id(f,g) \simeq \prod_{x:A}Id_{A \to B}(fx,gx)
\]

which can be proved by definition and taking the right-to-left
direction as an axiom.
** Sets
A type is a set if it is homotopically discrete.

\[
\mathrm{isSet}(A) \equiv \prod_{x,y:A}\prod_{p,q : x=y} p=q
\]

up to higher homotopy, the only equality is reflexivity.
Pure ITT is a theory of sets. All of the constructs of ITT
preserve the property of being a set

 1) $1$ is a set.
 2) if $A,B$ are sets, $A \times B$ is a set.
 3) if $A,B[x:A]$ are sets, $\sum_{x:A} B$ is a set.
 4) if $A,B$ are sets, $A+B$ is a set.
 5) $Nat$ is a set.
 6) if $A,B$ are sets, $A \to B$ is a set.
 7) if $A,B[x:A]$ are sets, $\prod_{x:A} B$ is a set.

In the NPS book, they use the terminology =Sets=.
** Problems interpreting ITT as a theory of sets
Why are the identities sets? Why is the universe a set?

ETT is also a set theory, and it is easier to work with it. In
ITT, we have to pay the price of higher dimensionality without
using it.

** Is universe a set?
Are the elements of ${\cal U}$ codes (names of types) or types? We can
introduce the elements of ${\cal U}$ inductively. The codes will form a
set.

NuPRL and HoTT take the elements to be types; but NPS take the
elements to be codes and to form a set, using ITT as a set theory.
* Lecture 16: ITT
All of the basic constructs of ITT preserve the relation of being a Set.
Up to higher homotopy, there is at most one proof of equality of any two
elements.

${\cal U}$ is rigged to be a set and it is a set of codes; an inductively defined
set.

** The identity type is a set
$Id_A(x,y)$ is a set if $A$ is a set

*** Proof
Assume that $A$ is a set

\[
H : \prod_{x,y:A}\prod_{p,q:Id_A(x,y)}Id_{Id_A(x,y)}(p,q)
\]

and we want to show that $Id(x,y)$ is a set. Assume $u,v : A$,
$r,s:Id(u,v)$ and $\alpha,\beta : Id(r,s)$. We have to show that

\[
Id_{Id_{Id_A(u,v)}(r,s)}(\alpha,\beta)
\]

We specialize $H' := H(u)(v)(r) : \prod_{q:Id_A(u,v)} Id(r,q)$; and we are going
to exploit the functoriality of $H'$. So

\[ apd_{H'} : \prod_{q,q': Id_A(u,v)} \prod_{\gamma : Id(q,q')} Id(\gamma_{\ast}(H'(q)),H'(q')
\]

being a path-over scenario. Here,

\[
apd_{H'}(r,s,\alpha) : Id(\alpha_{\ast}(H'(r)), H'(s))
\]

and, similarly

\[
apd_{H'}(r,s,\beta) : Id(\beta_{\ast}(H'(r)), H'(s)).
\]

So, we can conclude that I can get an element of the identity
$Id(\alpha_{\ast}(H'(r)), \beta_{\ast}(H'(r)))$. What this is telling us is that, by
post-composition given by transport in the identity, $Id(H'(r)\alpha, H'(r)\beta)$.

We have that $H'(r)\cdot \alpha = H'(r)\cdot \beta$, so I can multiply by the inverses
to get

\[
H'(r)^{-1}H'(r)\alpha = H'(r)^{-1}H'(r)\beta
\]

and then $\alpha = \beta$. We have used here the groupoid structure.
** ETT
ETT is also a set theory because ITT is a set theory. ETT is easier to
use when working with sets than ITT. HoTT adds the univalence axiom
and Higher Inductive Types. Here, homotopy can be thought as a branch
of logic. 

** ITT+UA
But ITT+UA is *not* a set theory; not all types are sets! In particular,
${\cal U}$ is a proper groupoid; there are non-trivial paths between elements.

For example, we will show two non-related paths between $1+1=2$ and
$2 = 1+1$. We know that

\[ UA: (A = B) \simeq (A \simeq B)
\]

and we are going to use it to create two different paths.

 * $ud(id)$
 * $ud(not)$

and $id \neq not : 2 \to 2$ by function extensionality; they are two different
equivalences. We also have $refl(tt) : tt =_2 tt$; and by transport if the
two paths were the same up to higher homotopy, $tr('') : ff = tt$, which is 
falsable.

** H-props
Start with $n \geq -2$. 

#+begin_definition
A type $A$ is an *h-prop* or prop iff

\[ \mathrm{IsProp(A)} :\equiv
\prod_{x,y:A} Id(x,y)
\]
#+end_definition

It is a subsingleton and it has at most one element up to higher
homotopy. The problem with this naming is that this collides with
the idea that propositions are types! It is better to call them
*h-props* instead of *props*.

The truth of these propositions is proof-irrelevant for types that
are called h-props.

*** Example: NuPRL and Markov's principle
In NuPRL, the types were specifications, and proofs where programs.
If we want to look for a zero on a sequence

\[s : \left( \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but here there is a solution in constant time! The $i$ is part of the
specification, we provided too much information on the input. The
problem here is proof-relevance. How could we suppress this information
in a type?

The first idea is an observation by *Brower*: we can change the specification
to use double negation

\[s : \left(\neg\neg \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but now, should a while terminate? *Markov's principle* says that, if you
can prove that a machine can't fail to halt, then it must halt. This is a
very contentfull statement in a constructivist setting. This is a very
strong axiom, the characteristic of the Russian school of constructivism.
(Markov, Kolmogorov).

*** Double negation and computational content
In NuPRL, we do not have Markov's principle. We would change $Nat \to Nat$ to
$FinSeq(k)$ in order to have a bound. Double negation kill computational,
proof relevant content.

#+begin_proposition
For any $A$, $\mathrm{IsProp}(\neg \neg A)$.
#+end_proposition

It has a simple proof.

*** Gödel's double negation translation
The idea of Gödel was to embed classical into constructive logic.
Here, classical logic is just a particular case of constructive
logic. This is called /squashing/

 * $\|1\| = 1$
 * $\|A \wedge B\| = \|A\| \wedge \|B\|$
 * $\|0\| = 0$
 * $\|A \vee B\| = \neg\neg(\|A\| \vee \|B\|)$

For implication, we have to choices

 * if we only want to just squash, $\|A \supset B\| = \|A\|\supset \|B\|$, suffices.
 * but if we want to recover classical logic, $\|A\| \supset (\neg\neg \|B\|)$.

Classical logic is constructive + double negation elimination; the
notion of $\neg\neg A \supset A$.

 * with the first option, $\|\neg\neg A \supset A\| = \neg\neg A \supset A$.
 * with the second one, $\|\neg\neg A \supset A\| = \neg\neg A \supset \neg\neg A$, which is true!

This is called the CTS transform for compilers. Where $\neg A$ is interpreted
as a countinuation for compilers. This is the type of a continuation

\[
(\|A\| \times (\|B\| \to 0)) \to 0
\]

With this technique, classical logic can be recovered from the constructivistic
logic.

** Propositional truncation
We will abstract the idea of squasing into truncation; the idea is
to quotient by the full relation. You take a type and a relation where
you quotient by all the relationships. The notion of subsingleton is
also useful to do proof-irrelevance.

The idea of a subquotient does not work well with set theories. In
HoTT we will use the idea of a quotient.

** Hedberg's theorem
A type with decidable equality is a set.

If $\prod_{x,y:A} Id(x,y) \vee \neg Id(x,y)$, then $isSet(A)$.

*** Corollary
Classical logic destroy the higher-homotopy structure! If you
postulate excluded-middle, everything is now gone.

*** Proof
 1) Decidable equality implies stable equality.

    \[
   \neg \neg Id(x,y) \to Id(x,y)
   \]

 2) Stability implies sethood.
* Lecture 17: Hedbergs theorem, truncation
** Last week
A type is a set if any two proofs of equality are equal. In other
words, if the equality is a proposition. A proposition is a type such
that any two elements of it are equal.

** The negations are propositions
The negation of any type is a proposition.

*** Proof
If $x,y : A \to \bot$, then $x = y$, as we have function extensionality;
and given any $a : A$, we could use ex falso quodlibet, $\mathtt{abort}(xa) : xa = ya$.
# Check this line on agda with hott

** Hedberg's theorem
A type with decidable equality is a set. Decidable equality
can be written as

\[
\prod_{x,y : A} Id(x,y) \vee \neg Id(x,y)
\]

and a type is a set if

\[
\prod_{x,y: A} \prod_{p,q : x=y} p = q.
\]

*** Proof 1: Decidable equality implies Stable equality
Stable equality, by definition, is

\[
\prod_{x,y : A} \neg \neg Id(x,y) \to Id(x,y).
\]

In general, what we know is that if $A \vee \neg A$, then $\neg\neg A \to A$. This
is only an instance of that.

*** Proof 2: Stable equality implies Sethood
Suppose that the equality on $A$ is stable, $h :\prod_{x,y: A} \neg \neg (x = y) \to (x = y)$.
It suffices to show that every $p : x = x$ is $p = \mathtt{refl}$. We can apply the
path to get, by transport

\[
p_{\ast}(h(x)(x)) =_{\neg\neg x = x \to x = x} h(x)(x)
\]

so we know that, for any $r: \neg\neg (x = x)$, we know that

\[
p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r).
\]

And Lemma 2.9.6 from HoTT book is a technical result, saying that

\[
h(x)(x)(r)(p) = h(x)(x)(p_\ast r)= p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r) = h(x)(x)(r),
\]

where we use that negated types are propositions.

*** Example: N is a set
By double induction, we can show the decidability of equality on this
type.
** Every proposition is a set
In general, we will get that any n-type is a n+1-type. If
$\prod_{x,y : A} x = y$, then $\prod_{x,y:A}\prod_{p,q:x=y} p = q$. Suppose a function given
with $f : \prod_{x,y:A} x = y$; then we can fix $x_0:A$ and let $g(y) \equiv f(x_0)(y)$.

By functioriality, if we have $p : y = y'$, then $apd(p) : p_{\ast}(g(y)) = g(y')$.
And if $q : y = y'$ and $q = g(y^{-1})g(y')$, so $p = q$.

** The statement of anything being a proposition or a set is a proposition

 * $isProp(isProp(A))$
 * $isProp(isSet(A))$

In the book, there is a chapter on when is a proposition an equivalence of
two types. $isProp(isEquiv(A)(B))$? In the case of the definition by quasiinverses,
it is not a proposition. A function can has many quasiinverses.

*** First proof
Given $f,g : isProp(A)$, we will show that they are equal. It suffices to show that
$x,y:A \vdash - : f(x)(y) =_{x=y} g(x)(y)$. Since $isProp(A)$ implies $isSet(A)$, the desired
equation holds.

*** Second proof
We can use a similar argument.
** Propositional truncation, aka "squashing"
When we worked in the Godel double negation translation,

\[
\|A \to B\| = \|A\| \to \neg\neg \|B\|
\]

A more abstract notion of truncation is do the squashing and not to
worry about recovering classical logic. What you do is to introduce
the type $\|A\|_{-1}$ of a truncation of $A$. It has the introduction form

\begin{prooftree}
\RightLabel{($\|\cdot\|$-I)}
\AxiomC{$M:A$}
\UnaryInfC{$|M| : \|A\|$}
\end{prooftree}

and the rule that any two elements are going to be the same up to higher
homotopies

\begin{prooftree}
\AxiomC{$M:A$}
\AxiomC{$N:A$}
\BinaryInfC{$- : Id_{\|A\|}(|M|,|N|)$}
\end{prooftree}

This is the quotient of $A$ by the full relation. The elimination form has
to be, then

\begin{prooftree}
\RightLabel{$\|\cdot\|$ - E}
\AxiomC{$M : \|A\|$}
\AxiomC{$x : A \vdash N : B$}
\AxiomC{$p : isProp(B)$}
\TrinaryInfC{$\mathtt{trunc}(M, x.N, p):B$}
\end{prooftree}

the requirement of $B$ to be a proposition, ensures that N's behaviour is
independent of the choice of representative of the suplied equivalence
class. We could relax the condition to a weaker one requiring only this.
** Contractibility
A type is contractible if it has an element and every other element is
equal to it

\[
isContr(A) = \sum_{x:A}\prod_{y:A} x=y
\]

*** Lemma

\[
isProp(A) \iff
\prod_{x,y:A} isContr(x=y)
\]

** n-types
Something is a -2type iff it is contractible. And something is an
n+1-type iff for all $x,y$, $x=y$ is a n-type.

 * A proposition is a -1 type
 * A set is a 0 type
 * A groupoid is a type
 * A 2-groupoid is a 2-type
 * and so on

Any n-type is also an n+1-type. It is a *cumulative hierarchy*.

** Not any type is an n-type
Not any type is an n-type for some n! There are types with a higher structure
up to infinity.

* Lecture 18: Homotopy n-types, contractability
** Last week
We defined contractability using centers of contraction.
It expresses the idea of unique existence $\exists!$. It is sometimes
written as $\Sigma!$.

Something is contractible if it is a proposition and it has
one element.

** Fact of contractability
If you fix any point $a : A$; you can consider the neighborhood of $A$
and we can consider the star of $A$ and that is contractible.
We can prove that

\[
isContr\left(\sum_{x:A} a = x\right)
\]

given $a : A$.
** The special case of the propositional truncation
We are going to call propositional truncation as -1-truncation.
We can write it as $\|A\|_{-1}$. It will be useful to define other
truncations. The idea is to have

\[
isProp(\|A\|)
\]

for any $A : {\cal U}$. That is to say that the equality type of this type
is contractible as

\[
\prod_{x,y:\|A\|} isContr(x = y).
\]

The intuition is that

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash |M| : \|A\| $}
\end{prooftree}

and in the elimination rule, we should prevent proofs for depending on
the witness of the inhabitation.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x : \|A\|, y: \|A\| \vdash \mathtt{squash}(x,y) : x = y$}
\end{prooftree}

The eliminator was defined as

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \|A\|$}
\AxiomC{$\Gamma, x : A\vdash N : B$}
\AxiomC{$\Gamma \vdash p : isProp(B)$}
\TrinaryInfC{$\Gamma \vdash elim[B](M,x.N,p) : B$}
\end{prooftree}

by using that $B$ was a proposition, we were sure that the result did not
depend on the representative of $A$.

** Gentzen and squash
Squash is another case of a new primitive equality. By Gentzen's principle,
we would need a beta and an eta rule

 * $elim[B](|M|; x.N, p) \equiv [M/x]N : B$

we would like to have a rule such as

 * $ap(\lambda z. elim[B](z;x.N,p))(squash(|M|,|N|)) \equiv (|M| =|N|)$

this is problematic. (?) If you are using a $J$ and the argument is a
squash, what should that be definitionally equal to?
** Revisit the axiom of choice
The Axiom of Choice $AC_{\infty}$ has a formulation as

\[
\prod_{A : {\cal U}}
\prod_{B : A \to {\cal U}}
\prod_{C : \prod_{x:A} B \to {\cal U}}
\left(
\prod_{x:A}\sum_{y:B_x} C(x,y)
\overset{\simeq}\longrightarrow
\sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x))
\right)
\]

and we can check in fact that this is a definable *equivalence*. It is
not an axiom! it is a theorem. The theorem of choice. We use crucially
the proof relevance to prove it.

*** Proof
From left to right

\[
\lambda F. \left(
 \lambda x. \mathtt{fst}(F x),
 \lambda x. \mathtt{snd}(F x)
\right)
\]

and from right to left

\[
\lambda \left\langle f,g\right\rangle . \lambda x .(f x, gx)
\]

and those are mutually inverses. We will need eta rules for products and
eta rules for sums.
*** It is a theorem
It is not saying exactly what the axixom of choice says usually.
** Versions of the axiom of choice
If we use propositional truncations we get the actual axiom of choice,
that we will call $AC_{-1}$.

\begin{aligned}
AC_{-1} : 
  \prod_{A :{\cal U}} isSet(A) \to 
  \prod_{B : A \to {\cal U}} \prod_{x : A} isSet(B(x)) \to
  \prod_{C : \prod_{x:A} B \to {\cal U}} \prod_{x:A} \prod_{y:B} isProp(C(x,y)) \to \\
  \left(
    \left( \prod_{x:A} \| \sum_{y:B} C(x,y) \| \right) \to
    \left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\|
  \right)
\end{aligned}

And this is *not* a theorem. We are using truncation and this is expressing the idea
that there is no functional dependency but we can, nevertheless, build a function.

*** NuPRL
Using squashing, we can express this also on the NuPRL system.
*** Expressivity
The constructive setting is more expressive than the classical one. We can choose,
by introducing identifications, to work on the classical setting.
*** Restatement
If we use the equivalence from before, we can write that

\[
\left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\| \simeq
\left\| \prod_{x:A}\sum_{y:B} C(x,y)  \right\|
\]

and that means that we can restate the axiom of choice using

\[
    \left( \prod_{x:A} \left\| \sum_{y:B} C(x,y) \right\| \right) \to
    \left\| \prod_{x : A} \sum_{y:B} C(x,y) \right\|
\]

instead. And we can reduce this to a simpler form as

\[
\prod_{x:X}\|Y(x)\| \to
\left\| \prod_{x:A} Y(x)  \right\|
\]

which can be read as "the product of a family of inhabited sets
is an inhabited set". This is also an equivalence.

This version of the axiom of choice is false if $X$ is not constrained
to be a set.
** Quasiinverses
Recall that a quasiinverse was

\[ \mathtt{qinv}( f : A \to B) :\equiv
  \sum_{g : B\to A} f \circ g \sim id \times g \circ f \sim id
\]

in the presence of function extensionality, we can replace $\sim$ with
$=$. We will show that $qinv$ is not necessarily a -1-type (a proposition).

*** Characterization of quasiinverses
If $f : A \to B$ and $e : qinv(f)$ then 

\[
qinv(f) \simeq \prod_{x:A} x = x
\]

sometimes we write $x =_{A} x \equiv \Omega(A,x)$. This uses univalence.

*** Existence of a not-proposition
There is a type $X$ such that

\[
\prod_{x : X} x=_Xx
\]

is not a proposition. An example of this is $X = \pi(\mathbb{S}) \simeq \mathbb{Z}$, which
will be a set. Another one is $X = K(G,1)$, a space with its fundamental
group being $G$.

As a corollary, $qinv(f)$ need not be a proposition.

** A good definition of equivalence
The criterion is that it should be a proposition, so the quasiinverses
definition does not qualify. We create new definitions

 * $isContr(f)$
 * $isBiequiv(f)$, we have a left inverse and a right inverse.
 * $isHalfAdjoint(f)$, defined by quasiinverses plus a coherence condition.

all these definitions are equivalent. And these are all propositions.

** Contractability definition of equivalence
For $f : A \to B$,

\[
isContr(f) :\equiv
\prod_{y:B} isContr(fibers_f(y))
\]

where

\[
fibers_f(y) \equiv \sum_{x:A} f(x) = y
\]

the things that are sent by $f$ to $y$. The total "sum of fibers" is
the total $A$.

*** Voevodsky's definition of equivalence
The definition can be stated as that exists a unique

\[
\prod_{y:B}\sum_{z: fib_f(y)} \prod_{z' : fib_f(y)} z = z'
\]

so the function is a bijection up to homotopy.
* Exercises
** Homework 1: Heyting algebra and IPL [5/6]
*** DONE Task 1
#+begin_statement
Show that $A \wedge (B \vee C) \leq (A \wedge B) \vee (A \wedge C)$ in any Heyting algebra.
Hint: use the Yoneda Lemma.
#+end_statement

The Yoneda Lemma in this setting says that the statement is equivalent
to say that, for all $D$, if $(A \wedge B) \vee (A \wedge C) \leq D$, then $A \wedge (B \vee C) \leq D$.
In this case we have

 * $A \wedge B \leq D$
 * $A \wedge C \leq D$

and crucially using the definition of exponential

 * $B \wedge C \leq B,C \leq A \supset D$.

*** DONE Task 2
#+begin_statement
Show that in any Heyting algebra, $A \supset \bot$ is one of the largest elements
inconsistent with $A$, and is equivalent to any largest inconsistent one.
#+end_statement

By definition, $A \wedge (A \supset \bot) \leq \bot$, and for any other element $C$ such that
$A \wedge C \leq \bot$, $C \leq (A \supset \bot)$. Any other largest inconsistent element should
satisfy $(A \supset \bot) \leq C$.

*** DONE Task 3
#+begin_statement
Show that, in any Boolean algebra (complemented distributive lattice),
$\overline{A} \vee B$ is a valid implementation of $A \supset B$. That is, it satisfies all
properties of $A \supset B$.
#+end_statement

We know that

\[
A \wedge (\overline{A}\vee B) \leq 
(A \wedge \overline{A}) \vee (A \wedge B) \leq
(A \wedge B) \leq B
\]

and if $A \wedge C \leq B$, then

\[
C \leq
C \wedge (A \vee \overline{A}) \leq
B \vee (C \wedge \overline{A}) \leq \overline{A} \vee B.
\]
*** TODO Task 4
#+begin_statement
Show that IPL is transitive, which is to say ...
#+end_statement

*** DONE Task 5
#+begin_statement
Show that for any Heyting algebra and any evaluation function on
atoms, if $\Gamma \vdash P$ true then $\Gamma^+\leq P^{\ast}$. You only have to consider the
cases in which the last rule applied is $(\supset I)$ or $(\supset E)$.
#+end_statement

  * In the first case, $(\supset I)$, we know that $\Gamma, A \vdash B$. By induction,
    we know that $\Gamma^{+} \wedge A^{\ast} \leq B^{\ast}$, and then $\Gamma^{ +} \leq (A^{\ast} \supset B^{\ast})$.
  * In the second case, we know by induction that $\Gamma^{ +} \leq A^{\ast} \supset B^{\ast}$ and
    $\Gamma^{+} \leq A^{\ast}$, so $\Gamma^{ +} \leq A^{\ast} \wedge (A^{\ast} \supset B^{\ast}) \leq B^{\ast}$.

*** DONE Task 6
#+begin_statement
Consider the Lindembaum algebra of IPL where the elements are all
propositions in IPL (with the translation $(-)^{\ast}$ being the identity function) 
and the relationship $\leq$ is defined by provability in IPL. That is, $A\leq B$ 
iff $A \text{ true} \vdash B\text{ true}$. Show that this is a Heyting algebra. You only have to
prove the transitivity. You may assume weakening and exchange of IPL,
or cite previous tasks as lemmas.
#+end_statement

If $A \leq B$ and $B \leq C$, we know that, by weakening, $A \text{ true},B \text{ true} \vdash C \text{ true}$.
We now can apply transitivity to $A \text{ true} \vdash B \text{ true}$ and the previous formula
to obtain $A \text{ true} \vdash C \text{ true}$.
** Homework 2: Kindom of Kittens [0/7]
*** TODO Task 1
#+begin_statement
Weite down a suitable morphism in terms of the primitive constructs and
the morphisms immediately available in each subtask. The primitive
constructs include $\mathrm{id}$, $f \circ g$, $\left\langle f,g \right\rangle$, $\mathtt{fst}$, $\mathtt{snd}$, $\mathtt{inl}$, $\mathtt{inr}$, $\left\{ f,g \right\}$, $\lambda(f)$ and $\mathtt{map}$.

 * *Reflexivity*, write down a morphism from $\Gamma^+ \times P^{\ast}$ to $P^{\ast}$.
 * *Contraction*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of
   a morphism $f \colon (\Gamma^{ +}\times P^{\ast})\times P^{\ast} \to Q^{\ast}$.
 * *Weakening*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of a
   morphism $f \colon \Gamma^{ +} \to Q^{\ast}$.
 * *Exchange*, write down a morphism from $(\Gamma^{ +}\times Q^{\ast}) \times P^{\ast}$ to $R^{\ast}$ in terms
   of a morphism $f \colon (\Gamma^{ +}\times P^{\ast}) \times Q^{\ast} \to R^{\ast}$.
 * *Substitution*, write down a morphism from $\Gamma^{ +}$ to $Q^{\ast}$ in terms of two 
   morphisms $f \colon \Gamma^{ +}\to P^{\ast}$ and $g\colon \Gamma^{ +}\times P^{\ast} \to Q^{\ast}$.
#+end_statement

*** TODO Task 2
*** TODO Task 3
*** TODO Bonus Task 1
*** TODO Task 4
*** TODO Task 5
*** TODO Task 6
* Bibliography
 * Awodey, Category theory.
 * Programming in Martin-Löf Type theory.
 * Homotopy Type Theory book.
