#+TITLE: Math
#+DESCRIPTION: My math notes and exercises
#+TODO: TODO WIP | CHECK DONE WONTFIX
#+SETUPFILE: setup/ejerciciomodelos.setup

** Header                                                           :ignore:
#+latex_header: \setcounter{secnumdepth}{0}
#+latex_header: \setlength{\parindent}{0pt}
#+latex_header: \usepackage{physics}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{amsmath}
#+latex_header: \usepackage{stmaryrd}
#+latex_header: \usepackage{mathtools}
#+latex_header: \usepackage{color}
#+latex_header: \usepackage{bussproofs}\EnableBpAbbreviations{}
#+latex_header: \usepackage{tikz-cd}

#+latex_header: \DeclareMathOperator{\im}{Im}
#+latex_header: \DeclareMathOperator{\coker}{Coker}
#+latex_header: \DeclareMathOperator{\spec}{Spec}
#+latex_header: \DeclarePairedDelimiter\bbk{\llbracket}{\rrbracket}
#+latex_header: \newcommand{\vertiii}[1]{{\left\vert\kern-0.25ex\left\vert\kern-0.25ex\left\vert #1 \right\vert\kern-0.25ex\right\vert\kern-0.25ex\right\vert}}

#+latex_header: \newcommand\id{\mathrm{id}}
#+latex_header: \newcommand\Id{\mathrm{Id}}
#+latex_header: \newcommand\hom{\mathrm{hom}}
#+latex_header: \newcommand\Nat{\mathrm{Nat}}
#+latex_header: \newcommand\Grp{\mathsf{Grp}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\todot{\xrightarrow{.}}
#+latex_header: \usepackage{mathtools}
#+latex_header: \DeclarePairedDelimiter\pair{\langle}{\rangle}

*** Macros on HoTT                                                 :ignore:
#+latex_header: \newcommand\ap{\mathsf{ap}}
#+latex_header: \newcommand\apd{\mathsf{apd}}
#+latex_header: \newcommand\refl{\mathsf{refl}}
#+latex_header: \newcommand\id{\mathsf{id}}
#+latex_header: \newcommand\transport{\mathsf{transport}}
#+latex_header: \newcommand\happly{\mathsf{happly}}
#+latex_header: \newcommand\funext{\mathsf{funext}}
#+latex_header: \newcommand\proj{\mathsf{pr}}
#+latex_header: \newcommand\rec{\mathsf{rec}}
#+latex_header: \newcommand\pr{\mathsf{pr}}
#+latex_header: \newcommand\idtoeqv{\mathsf{idtoeqv}}
#+latex_header: \newcommand\ua{\mathsf{ua}}
#+latex_header: \newcommand\isSet{\mathsf{isSet}}
#+latex_header: \newcommand\isProp{\mathsf{isProp}}
#+latex_header: \newcommand\Set{\mathsf{Set}}
#+latex_header: \newcommand\Prop{\mathsf{Prop}}
#+latex_header: \newcommand\fnot{\mathsf{not}}
#+latex_header: \newcommand\LEM{\mathsf{LEM}}
#+latex_header: \newcommand\trunc[1]{\left\lVert#1\right\rVert}
#+latex_header: \newcommand\isContr{\mathsf{isContr}}
#+latex_header: \newcommand\ishae{\mathsf{ishae}}
#+latex_header: \newcommand\qinv{\mathsf{qinv}}
#+latex_header: \newcommand\fib{\mathsf{fib}}
#+latex_header: \newcommand\biinv{\mathsf{biinv}}
#+latex_header: \newcommand\linv{\mathsf{linv}}
#+latex_header: \newcommand\rinv{\mathsf{rinv}}
#+latex_header: \renewcommand\succ{\mathsf{succ}}
#+latex_header: \newcommand\isequiv{\mathsf{isequiv}}
#+latex_header: \newcommand\isHinit{\mathsf{isHinit}}
#+latex_header: \newcommand\isEmbedding{\mathsf{isEmbedding}}
#+latex_header: \newcommand\isSurjective{\mathsf{isSurjective}}
#+latex_header: \newcommand\pair{\mathsf{pair}}
#+latex_header: \newcommand\inl{\mathsf{inl}}
#+latex_header: \newcommand\inr{\mathsf{inr}}
#+latex_header: \newcommand\seg{\mathsf{seg}}
#+latex_header: \newcommand\base{\mathsf{base}}
#+latex_header: \newcommand\N{\mathsf{N}}
#+latex_header: \newcommand\conn{\mathsf{conn}}
#+latex_header: \newcommand\code{\mathsf{code}}
#+latex_header: \newcommand\encode{\mathsf{encode}}
#+latex_header: \newcommand\decode{\mathsf{decode}}
#+latex_header: \renewcommand\S{\mathsf{S}}
#+latex_header: \newcommand\merid{\mathsf{merid}}
#+latex_header: \newcommand\isCut{\mathsf{isCut}}
#+latex_header: \newcommand\apart{\mathbin{\#}}
#+latex_header: \newcommand\istype[1]{\mathop{\mbox{$\mathsf{is}$-$#1$-$\mathsf{type}$}}}
*** Logic macros                                                   :ignore:
#+latex_header: \newcommand\land{\wedge}
#+latex_header: \newcommand\lor{\vee}
#+latex_header: \newcommand\model{\mathfrak{M}}
#+latex_header: \newcommand\entail{\models}
#+latex_header: \newcommand\seq{\Rightarrow}
*** Analysis                                                       :ignore:
#+latex_header: \newcommand\oy{\overline{y}}
* Books
** Categories for the working mathematician - MacLane
# Exports using config.setup, essay.setup

*** I. Categories, Functors and Natural Transformations
**** I.1. Axioms for categories
***** Metagraph
A *metagraph* consists of objects $a,b,c,\dots$ and arrows $f,g,h,\dots$, with two 
operations:

  - *domain*, $dom(f) = a$, and
  - *codomain*, $cod(f) = b$,

that we write as $f : a \to b$.

***** Metacategory
A *metacategory* is a metagraph with two additional operations:

  - *Identity*: $id_a : a \to a$
  - *Composition*: for a pair of arrows $dom(g) = cod(f)$, it defines a
    new arrow $g \circ f : dom(f) \to cod(g)$.

    \[\begin{tikzcd}
    & b \drar{g} & \\
    a \arrow{rr}{g\circ f} \urar{f} & & c
    \end{tikzcd}\]

Subject to the following axioms:

  - *Associativity*: Given objects and arrows in this configuration:
    
    $a \overset{f}\to b \overset{g}\to c \overset{k}\to d$

    We have the equality: $k \circ (g \circ f) = (k \circ g) \circ f$.

  - *Unit law*: composition with the identity arrow is neutral.

****** Metacategory of Sets
****** Metacategory of Groups
****** Arrow-only axioms
**** I.2. Categories
***** Category
An interpretation of a metacategory within set theory.

****** Diagram scheme (directed graphs)
A category is a graph with identity and composition functions.

***** Examples of categories
****** Basic examples
******* The empty category
******* 1, the category with one object and one identity
******* 2, the category a -> b with two objects
******* 3, a triangle category
******* Parallel arrows

****** Discrete categories
Where every arrow is an identity.

****** Monoids and groups
A category with one object.

****** Matrices
Objects: positive integers.
Arrows: $m\times n$ matrices.

****** Sets of sets
****** Preorder
******* Partial orders
******* Linear orders
****** Ordinal numbers
****** Simplicial category
****** Large categories
**** I.3. Functors
***** Functor
A morphism of categories. A functor $T : {\cal C} \to {\cal B}$ is given by:

  - The *object function*, $T : Obj({\cal C}) \to Obj({\cal B})$.
  - The *arrow function*, $T : (c \to c') \to (Tc \to Tc')$

With the axioms:

  - $T(1_c) = 1_{Tc}$
  - $T(f\circ g) = Tg \circ Tf$

***** Examples
****** The powerset functor
****** Homology groups
****** General linear group
****** Commutators
****** Forgetful functors
***** Composition of functors, the metacategory Cat
We can define composition of functors, and also functors as isomorphisms.

****** Isomorphisms
A functor is an isomorphism iff there is a functor $S : B \to C$ for 
which both composites are the identity $S \circ T = Id = T \circ S$.

****** Full functor
Every $g : c \to c'$ of $B$ is of the form $Tf : Tc \to Tc'$. In other words,
the arrow function (the map!) is injective.

****** Faithful functor
The equality $Tf_1 = Tf_2$ implies $f_1 = f_2$. In other words, the arrow
function is surjective.

****** Subcategories
A subcategory gives us an inclusion functor.

**** I.4. Natural transformations
***** Natural transformation
Given two functors $S,T : C \to B$, a natural transformation $\tau : S \xrightarrow{.} T$
is a function assigning every $c \in C$ an arrow $Sc \to Tc$ and yielding
a commutative diagram:

\[\begin{tikzcd}
c \dar{f} & & Sc \rar{\tau_c}\dar{Sf} & Tc \dar{Tf} \\
c' & & Sc' \rar{\tau_{c'}} & Tc'
\end{tikzcd}\]

We say that $\tau_c$ is natural in $c$.

****** Translation of pictures
A natural transformation translates a diagram from $S$ to $T$.

\[\begin{tikzcd}
a \arrow{dd}{h}\drar{f} &   & & S a \arrow{dd}{S h}\drar{S f} \arrow{rrr}{\tau a} &     & & T a \arrow{dd}{T h}\drar{T f} &     \\
  & b \dlar{g} & &     & S b \dlar{S g} \arrow{rrr}{\tau b} & &     & T b \dlar{T g} \\
c &   & & S c \arrow{rrr}{\tau c} &     & & T c &     \\
\end{tikzcd}\]

***** Natural isomorphisms
A natural transformation is a morphism of functors. We call 
*natural isomorphism* to a natural transformation where every 
component $\tau_c$ is invertible. We write it as:

$\tau : S \cong T$

The inverses form another natural transformation.

***** Examples
****** Determinant
Natural transformation between two functors
$GL, {\cal U}() : \mathtt{CRng} \longrightarrow \mathtt{Grp}$.

****** Identity and factor-commutator functor

****** Double character group
Defined as $D(G) = Hom(G, \mathbb{R}/\mathbb{Z})$, it is a contravariant functor when 
we define $(Df) t = t \circ f$. But the twice iterated functor $D^2$ is a 
covariant one.

There is a natural transformation between $Id$ and $D^2$.

\[
\tau_G(g) t = t(g)
\]

It is easy (with lambda calculus, for example) to check that this
diagram commutes.

****** Double dual of a finite vectorial space

****** Inclusion and cardinality of ordinals

**** I.5. Monics, epis and zeros
***** Isomorphism
An arrow $e : a \to b$ is an isomorphism if there is an arrow $e^{-1} : b \to a$
such that $e'e = 1$ and $ee' = 1$.

****** Isomorphic objects
Two objects are isomorphic if there is an isomorphism between them.

***** Monic and epi
An arrow is *monic* if it is left cancellable, it is *epi* if it is
right cancellable.

****** Retractions and sections
A left inverse is called a *retraction*, while a right inverse is
called a *section*.

***** Splits and idempotents
When $gh = 1$, $g$ is a split epi, $h$ is a split monic and the composite
$hg$ is an idempotent. An arrow is *idempotent* if $f^2 = f$, and it is said
to split when there exist arrows $g$ and $h$ such that $f = hg$ and $gh = 1$.

***** Terminal objects and initial objects
An object $t$ is terminal if for every $a$ there is exactly one arrow $a \to t$.
An object $s$ is initial if for every $a$ there is exactly one arrow $s \to a$.
An object $z$ is null if it is both initial and terminal.

****** Zero arrow
There is an unique arrow $a \to z \to b$ called the *zero* arrow. Any 
composite with it is itself a zero arrow.

***** Groupoids
A category where every arrow is invertible.

****** The fundamental groupoid
****** Group of homomorphisms
In a groupoid, each object determines a group, $hom(x,x)$.
If there is an arrow $f : x \to x'$, the groups $hom(x,x)$ and $hom(x',x')$
are isomorphic under conjugation $g \mapsto fgf^{-1}$.

****** Connected groupoid
A *connected groupoid* is deteremined by a group and the set of
all objects.

**** I.6. Foundations
***** Universe
An universe is a set $U$ with the closure properties:

  1. $x \in u \in U \implies x \in U$.
  2. e$u,v \in U \implies \{u,v\},(u,v),u\times v \in U$.
  3. $x \in U \implies {\cal P}x, \cup x \in U$.
  4. $\omega \in U$ where $\omega = \{0,1,2,\dots\}$.
  5. $f : a \to b$ surjective and $a \in U$, $b \subseteq U$ implies $b \in U$.

***** Small sets
Fixed an universe, we call a set $u \in U$ a *small set*. The universe is
the set of all small sets. $\mathtt{Set}$ denotes the category of small sets.

****** Small structures
A small group is a small set with a group structure. $\mathtt{Grp}$ denotes the
category of small groups.

***** Small categories
A category is small if the set of its arrows and objects are both small
sets. $\mathtt{Set}$ is not a small category.

**** I.7. Large categories
***** Abelian groups
***** Rings
***** Modules over a ring
***** Bimodules
***** Topological spaces with continuous maps
***** Topological spaces with homotopy classes
***** Pointed sets
***** Binary relations
***** Concrete categories
**** I.8. Hom-Sets
***** Hom-set
For objects $a,b \in C$, the *hom-set* is the set of all arrows between them:

\[
hom(a,b) = \{ f \mid f : a \to b \}
\]

****** Redefinition of a category
A small category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set between two objects $hom(a,b)$
  3. Composition function $hom(b,c)\times hom(a,b) \to hom(a,c)$
  4. Identity function for every object, $id \in hom(a,a)$

The distributivity can be seen as commutativity of the following
diagram:

\[\begin{tikzcd}
hom(c,d)\times hom(b,c)\times hom(a,b) \rar\dar &
hom(b,d)\times hom(a,b) \dar \\
hom(c,d)\times hom(a,c) \rar &
hom(a,d)
\end{tikzcd}\]

***** Preadditive category
A category $A$ where each hom-set $hom(a,b)$ is an additive abelian group
for which composition is bilinear:

\[
(g+g')\circ(f+f') = g\circ f + g\circ f' + g' \circ f + g' \circ f'
\]

***** Preadditive category as an enriched category
A preadditive category is given by:

  1. Set of objects $a,b,\dots$
  2. Hom-set, an abelian group between two objects $hom(a,b)$
  3. A bilinear composition $hom(b,c) \otimes hom(a,b) \to hom(a,c)$
  4. Identity morphism for every object, $\mathbb{Z} \to hom(a,a)$

We can see the similitude with the definition of a category by hom-sets.
Categories created in this way are called *enriched categories*.

*** II. Constructions on categories
**** II.1. Duality
***** Elementary theory of an abstract category (ETAC)
A theory with statements involving:

  - Domains: $a = dom(f)$
  - Codomains: $b = codom(f)$
  - Composition: $h = g \circ f$

A *sentence* is a statement with all variables quantified, using
the logical connectives and quantifiers.

****** Dual of an statement
A dual is formed by making the following replacements:

  - $a = dom(f)$ changes to $a = codom(f)$
  - $h = g \circ f$ changes to $h = f \circ g$
  - Logic is unchanged.

****** Table of dualities
\begin{tabular}{l|r}
Statement & Dual statement \\
\hline
$f : a \to b$ & $f : b \to a$ \\
$a = \operatorname{dom} f$ & $a = \operatorname{cod} f$ \\
$h = g \circ f$ & $h = f \circ g$ \\
$f$ mono & $f$ epi
\end{tabular}

***** Duality principle
The dual of each of the axioms for a category is also an axiom. Therefore,
if $\Sigma$ is a consequence of the axioms, so is its dual statement.

***** Duality and functors
The elementary theory of one functor has the axioms of two categories
$A,B$, and the properties of a functor $T$ between them. The duality for
a statement involving several categories reverses the arrows in each
category, but does not reverse the functors.

**** II.2. Contravariance and opposites
***** Opposite category
The *opposite category*, $C^{op}$, is defined with the objects of $C$; for each 
arrow $f : a \to b$ of $C$, the corresponding $f^{op} : b \to a$ is defined with the 
composition

\[
f^{op} \circ g^{op} = (g\circ f)^{op}.
\]

****** Opposite functors
If $T : C \to B$ is a functor, we can create an opposite functor
$T^{op} : C^{op} \to B^{op}$. The assignment $C \to C^{op}$ defines a covariant functor
$\mathtt{Cat} \to \mathtt{Cat}$.

***** Contravariant functors
A functor $S : C^{op} \to B$ can be seen as a *contravariant* functor $S : C \to B$,
knowing that

\[
S(f^{op}\circ g^{op}) = (Sf^{op})(Sg^{op}) = S((g\circ f)^{op}).
\]

****** Examples: Hom-sets
For each object $a \in C$, the *contravariant hom-functor* $hom(a,-)$ and
the *covariant hom-functor* $hom(-,a)$ are defined.

****** Examples: Sheafs
Given $X$, a topological space. Its open sets define a category by 
inclusion, $\mathtt{Open}(X)$. Let ${\cal C}(U)$ denote the set of continuous functions
$h : U \to \mathbb{R}$, the assignment $h \mapsto h|_V$ is a function ${\cal C}(U)\to{\cal C}(V)$ for
each $V \subset U$; and this gives us a contravariant functor.

****** Examples: R-Modules
$\mathtt{ModR} : \mathtt{Rng} \to \mathtt{Cat}$ is a contravariant functor. If $\rho : R \longrightarrow S$ is a morphism
of rings, given $B$ an S-module, we can define $(Mod\rho) B = B\rho$ by pull-back.

**** II.3. Products of categories
***** Product of two categories
We define the *product* $B \times C$ as the category with:

  - pairs of objects $(b,c)$ as objects,
  - pairs of arrows $(f,g)$ as arrows,

with the composition given by the composites in $B$ and $C$

\[
(f',g') \circ (f,g) = (f' \circ f,g' \circ g).
\]

We can define projection functors $P : B\times C \to B$, $Q : B\times C \to C$. Given
any category $D$ and two functors $B \overset{R}\longleftarrow D \overset{T}\longrightarrow C$, there is an unique 
functor $F : D \to B\times C$ with $PF = R, QF = T$.

\[\begin{tikzcd}
& D \drar{T}\dlar[swap]{R} \dar[dashed]{\exists! F} & \\
B & B\times C \rar[swap]{Q}\lar{P} & C
\end{tikzcd}\]

***** Product of functors
Two functors $U : B \to B'$, $V : C\to C'$ have a product:

\[
U\times V : B\times C \to B'\times C'
\]

That can be described as the unique functor making the following
diagram commutative:

\[\begin{tikzcd}
B \dar{U} &
B \times C  \rar{Q}\lar[swap]{P} \dar[dashed]{U \times V}&
C \dar{V} \\
B' &
B' \times C' \rar[swap]{Q'}\lar{P'}&
C'
\end{tikzcd}\]

****** Product as a functor
The product of categories can be seen as a functor:

\[
\times : \mathtt{Cat} \times \mathtt{Cat} \to \mathtt{Cat}
\]

****** Bifunctors
Our definition of product category gives an automatic definition for
a *bifunctor*, a functor of two variables.

***** Bifunctor determined by its currifications
Let $B,C,D$ be categories. For all objects $c \in C, b \in B$, let $L_c : B \to D$
and $M_b : C \to D$ be functors such that $M_b(c) = L_c(b)$.

There exists a bifuctor $S : B\times C \to D$ such that $S(-,c) = L_c$
and $S(b,-) = M_b$ iff for every pair of arrows:

\[
M_{b'}g \circ L_c f = L_{c'}f \circ M_b g
\]

so we can define the value of $S(f,g)$ uniquely.

****** TODO Proof

***** Natural transformations between bifunctors
Given bifunctors $S,S'$, the function $\alpha$ is a natural transformation
$\alpha : S \Rightarrow S'$ iff $\alpha(b,c)$ is natural in $b$ and natural in $c$.

****** TODO Proof

**** II.4. Functor categories
***** Composition of natural transformations
Given functors $R,S,T : C \to B$ and natural transformations $\tau : S\to T$
and $\sigma : R \to S$, their compositions define composite arrows which are
the components of the composite natural transformation $\tau \cdot \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90]{(\tau \circ \sigma)_c} &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90]{(\tau\circ\sigma)_{c'}} \\
Sc \rar{Sf}\dar{\tau_c}  &
Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf}  &  Tc' 
\end{tikzcd}\]

****** Proof
Naturality of the external square follows from the commutativity of the
two internal squares.

***** Functor category
Given categories $B,C$, let $B^C = \mathrm{Funct}(C,B)$ be the *functor category*,
with objects the functors $T\colon C \to B$ and morphisms the natural 
transformations

\[ \mathrm{Nat}(S,T) = \left\{ \tau\mid \tau\colon S \dot\to T \right\}.
\]

****** Example: Category of arrows
The category $\mathrm{Funct}(B,2)$ is called the *category of arrows* of $B$. Its
objects are arrows $f\colon a \to b$ and its morphisms are commutative squares

\[\begin{tikzcd}
a\rar{h} \dar[swap]{f} & a' \dar{f'} \\
b\rar{k} & b'
\end{tikzcd}\]

****** Example: Actions on a set
If $M$ is a monoid, $\mathrm{Funct}(M, \mathtt{Set})$ is the category with objects the actions
of $M$ on some sets and arrows the morphisms of such actions.

****** TODO Example: Group with operators
***** Example: Group representations
Given $K$ a commutative ring, the functor category $\mathrm{Funct}(G, K\mathtt{-mod})$ is the 
category of linear representations of $G$.

****** Objects
Every functor $T \colon G \to K\mathtt{-mod}$ is determined by a $K\text{-module}$ $V$ and
a morphism of groups $T\colon G \to \text{Aut}(V)$.

****** Natural transformations
A natural transformation $\sigma\colon T \to S$ is given by a single module
homomorphism $\sigma\colon V \to V'$, such that

\[\begin{tikzcd}
V\rar{\sigma} \dar[swap]{Tg} & V' \dar{T'g} \\
V\rar{\sigma} & V'
\end{tikzcd}\]

and it is called an *intertwining* operator.

**** II.5. The category of all categories
***** Identity natural transformations
The identity functor is the identity for the horizontal and vertical
compositions. We can use the symbol of the functor to denote it like
$S \colon S \dot\to S$.

***** Horizontal composition of natural transformations
Given functors $S,T \colon C \to B$ and $S',T'\colon B \to A$ and natural transformations

\[\begin{tikzcd}
C 
\rar[shift left=7pt, ""{name=UL, below}]{S} 
\rar[shift right=7pt, ""name=LL][swap]{T\vphantom{'}} &
B 
\rar[shift left=7pt, ""{name=UR, below}]{S'}
\rar[shift right=7pt, ""name=LR][swap]{T'} &
A\\
\ar[from=UL, to=LL, "\tau", shorten <= -2pt, shorten >= -2pt]
\ar[from=UR, to=LR, "\tau\smash{'}", shorten <= -2pt, shorten >= -2pt]
\end{tikzcd}\]

we can define the *horizontal composite* $\tau' \circ \tau \colon S'S \to T'T$ as the diagonal
of the commutative square

\[\begin{tikzcd}
S'Sc\rar{\tau'_{Sc}} \dar[swap]{S'\tau_c} & T'Sc \dar{T' \tau_c} \\
S'Tc\rar{\tau'_{Tc}} & T'Tc
\end{tikzcd}\]

explicitly, as $\tau' \circ \tau = T' \tau \circ \tau' = \tau' \circ S'\tau$. It is a natural transformation.

****** Alternative notation
With identity notation, we can then define the horizontal composition
as

\[
\tau'\circ \tau = 
(T' \circ \tau) \cdot (\tau'\circ S) =
(\tau' \circ T) \cdot (S'\circ \tau).
\]

****** Proof
It is natural as the following diagram is the composition of two
naturality squares

\[\begin{tikzcd}
S'Sc \rar{S'\tau} \dar{S'Sf} &
S'Tc \rar{\tau'}  \dar{S'Tf} &
T'Tc \dar{T'Tf} \\
S'Sb \rar{S'\tau} &
S'Tb \rar{\tau'} &
T'Tb
\end{tikzcd}\]

defined respectively by the naturality of $S'\tau$ and $\tau'$.

***** Interchange law
Given three categories and four transformations

\[\begin{tikzcd}
C 
\rar[shift left=15pt, ""{name=UL, below}]{} 
\rar[""name=L]
\rar[shift right=15pt, ""name=LL][swap]{} &
B 
\rar[shift left=15pt, ""{name=UR, below}]{}
\rar[""name=R]
\rar[shift right=15pt, ""name=LR][swap]{} &
A\\
\ar[from=UL, to=L, "\sigma", shorten <= -2pt, shorten >= -2pt]
\ar[from=L, to=LL, "\tau", shorten <= 2pt, shorten >= -2pt]
\ar[from=UR, to=R, "\sigma\smash{'}", shorten <= -2pt, shorten >= -2pt]
\ar[from=R, to=LR, "\tau\smash{'}", shorten <= 2pt, shorten >= -2pt]
\end{tikzcd}\]

the vertical and horizontal composites follow the interchange law

\[
(\tau'\cdot \sigma') \circ (\tau \cdot \sigma) = 
(\tau'\circ \tau) \cdot (\sigma'\circ \sigma).
\]

****** Proof
In this diagram, where every internal square is commutative by
naturality

\[\begin{tikzcd}
G_1F_1x \dar{G_1\sigma} \rar{\sigma'} \drar{\sigma'\circ\sigma} 
\ar[bend left]{rr}{\tau'\cdot\sigma'}
\ar[bend right=60,swap]{dd}{G_1(\tau \cdot \sigma)} & 
G_2F_1x \dar{G_2\sigma} \rar{\tau'} &
G_3F_1x \dar{G_3\sigma} \ar[bend left=60]{dd}{G_3(\tau \cdot \sigma)}\\
G_1F_2x \dar{G_1\tau} \rar{\sigma'} &
G_2F_2x \dar{G_2\tau} \rar{\tau'}  \drar{\tau'\circ\tau} &
G_3F_2x \dar{G_3\tau} \\
G_1F_3x \rar{\sigma'} \ar[bend right,swap]{rr}{\tau'\cdot\sigma'} &
G_2F_3x \rar{\tau'} &
G_3F_3x \\
\end{tikzcd}\]

we know, by definition, that the big diagonal must be $(\tau'\cdot \sigma') \circ (\tau\cdot\sigma)$.

***** Double category
A *double category* is a set of arrows for two different compositions
which together satisfy the [[*Interchange law][interchange law]].

***** 2-category
A *2-category* is a double category in thich every identity for the
first composition is also an identity for the second one.

****** Counterexample: commutative squares in Set
The category of commutative squares in Set is a double category but
not a 2-category.

***** Interchange law for operations
Two binary operations $\cdot,\circ$ are said to satisfy the interchange law when

\[
(a' \cdot b') \circ (a \cdot b) = (a' \circ a) \cdot (b'\circ b).
\]

****** Example: matrices
The usual product of matrices $\circ$ satisfies the interchange law with the
square-composition of matrices

\[
\tau \cdot \sigma = \begin{pmatrix}
\tau & 0\\
0 & \sigma
\end{pmatrix}.
\]

******* Proof
Trivial by definition.

***** Functor category as a functor
The functor category can be regarded as a functor

\[\mathrm{Func} \colon \mathtt{Cat}^{op}\times \mathtt{Cat} \to \mathtt{Cat}.
\]

sending an arrow, consisting of two functors $F,G$, to $F^{G}$, a functor
defined as

  * $F^GS = F \circ S \circ G$, on objects.
  * $F^{G}\tau = F \circ \tau \circ G$, on arrows.

****** Analogue with the hom-functor
Note that this is the categorical analogue of the hom-functor

\[\mathrm{Hom} \colon \mathtt{Set}^{op}\times \mathtt{Set} \to \mathtt{Set}.
\]

**** II.6. Comma categories
***** Category of objects under an object
Given $b \in C$, the category of *objects under* it, $(b \downarrow C)$, is the category
with objects all pairs $(f\colon b \to c, c)$, and arrows $h\colon (f,c) \to (f',c')$ for those
arrows such that $h\circ f = f'$.

****** Displayed notation
Objects are of the form

\[\begin{tikzcd}
b \rar{f} & c
\end{tikzcd}\]

morphisms are of the form

\[\begin{tikzcd}
& c \arrow[dd, "h"] \\[-15pt]
b \urar{f}\drar[swap]{f'}& \\[-15pt]
& c'
\end{tikzcd}\]

and the composition is the composition of two commutative triangles
in that form.

***** Category of objects over an object
The category of *objects over* $a$, $(C \downarrow a)$ can be defined similarly in
displayed notation as objects of the form

\[\begin{tikzcd}
c \rar{f} & a
\end{tikzcd}\]

and morphisms

\[\begin{tikzcd}
c \arrow[dd, "h"] \drar{f} &  \\[-15pt]
& b \\[-15pt]
c' \urar[swap]{f'} &
\end{tikzcd}\]

***** Comma category
Given categories and functors $E \overset{T}\longrightarrow C \overset{S}\longleftarrow D$, the comma category
$(T\downarrow S)$ has objects

\[\begin{tikzcd}
Te \rar{f} & Sd
\end{tikzcd}\]

and arrows commutative squares

\[\begin{tikzcd}
Te\rar{Tk} \dar[swap]{f} & Te' \dar{f'} \\
Sd\rar{Sh} & Sd'
\end{tikzcd}\]

The composite is the yuxtaposition of squares.

****** Categories of objects under/over and object
Those are particular cases when the object is seen as a functor
from the unital category $b \colon 1 \to C$.

**** II.7. Graphs and free categories
***** TODO Forgetful functor from categories to graphs
***** Free category
Let $G$ be a small graph. There is a small category $C$ called its free
category satisfying the following universal property

\[\begin{tikzcd}
G \rar{P} \drar[swap]{D} & UC\dar[dashed]{\exists! UD'} \\
& UB
\end{tikzcd}\]

which is equivalent to $P\colon G \to UC$ being initial in $(G \downarrow U)$.

**** TODO II.8. Quotient categories
*** III. Universals and Limits
**** III.1. Universal arrows
***** Universal arrow
A *universal arrow* from $c$ to $S$ is an arrow $u \colon c \to Sr$ such that
for every $c \to Sd$ exists a unique $r \to d$ making this diagram commute

\[\begin{tikzcd}
& Sd & d \\
c \rar[swap]{u}\urar{g} & Sr \uar[swap,dashed]{Sf} & r \uar[dashed]{\exists! f} &.
\end{tikzcd}\]

**** III.2. The Yoneda lemma
***** Universal arrows as natural bijections
The arrow $u \colon c \to Sr$ is universal iff $f \mapsto Sf \circ u$ is a bijection
$\mathrm{hom}(r,d) \cong \mathrm{hom}(c,Sd)$ natural in $d$. Any natural bijection of this
kind is determined by a unique universal arrow.

****** Proof
Bijection follows from the definition of [[*Universal arrow][universal arrow]], and
naturality follows from $S(gf)\circ u = Sg \circ Sf \circ u$.

Given a bijection $\varphi$, we define $u = \varphi(\mathrm{id}_r)$. By naturality we have
the bijection $\varphi(f) = Sf \circ u$, every arrow is written in this way.

***** Representation
A *representation* of $K \colon D \to \mathtt{Set}$ is a natural isomorphism

\[
\psi\colon \mathrm{hom}_{D}(r,-) \cong K.
\]

A functor is /representable/ if it has a representation. An object $r$ is
called a /representing object/. $D$ must have small hom-sets.

***** Representations from universal arrows
If $u \colon \ast \to Kr$ is a universal arrow for a functor $K\colon D \to \mathtt{Set}$, then
$f \mapsto K(f)(u\ast)$ is a representation. Every representation is obtained
in this way.

****** Proof
We know that $\mathrm{hom}(\ast, X) \xrightarrow{.} X$ is a natural isomorphism in $X$; in particular
$\mathrm{hom}(\ast, K-) \xrightarrow{.} K-$. Every representation is built then as

\[ \mathrm{hom}_{D}(r,-) \cong \mathrm{hom}(\ast,K-) \cong K, \]

for every natural isomorphism $D(r,-) \cong \mathtt{Set}(\ast,K-)$. But every natural
isomorphism of this kind is an [[*Universal arrows as natural bijections][universal arrow]].

***** Yoneda Lemma
For any $K\colon D \to \mathtt{Set}$ and $r \in D$, there is a bijection

\[
y \colon \mathrm{Nat}(\mathrm{hom}_{D}(r,-), K) \cong Kr
\]

sending the natural transformation $\alpha \colon \mathrm{hom}_{D}(r,-) \xrightarrow{.} K$ to the image of
the identity, $\alpha_r1_r$.

****** TODO Proof

***** Corollary to Yoneda Lemma
Given $r,s \in D$, any natural transformation $\mathrm{hom}(r,-) \xrightarrow{.} \mathrm{hom}(s,-)$ has
the form $h_{\ast}$ for a unique $h\colon s \to r$.

****** Proof
Using Yoneda Lemma, we know that

\[ \mathrm{Nat}(\mathrm{hom}_D(r,-), \mathrm{hom}_D(s,-)) \cong \mathrm{hom}_D(s,r),
\]

sending the natural transformation to a morphism $\alpha(id_r) = h \colon s \to r$. The
rest of the natural transformation is determined as $h_{\ast}$ by naturality.

***** Addendum to the Yoneda Lemma
The bijection on the [[*Yoneda Lemma][Yoneda Lemma]] is a natural isomorphism between
two $\mathtt{Set}^D \times D \to \mathtt{Set}$ functors.

***** Yoneda functor
In the conditions of [[*Yoneda Lemma][Yoneda Lemma]], the *Yoneda functor* is a full and
faithful functor $Y \colon D^{op} \to \mathtt{Set}^{D}$ defined with the arrow function

\[
\left(f \colon s \to r\right) \mapsto 
\Big(D(f,-) \colon D(r,-) \to D(s,-)\Big).
\]

****** TODO Proof
**** III.3. Coproducts and colimits
***** Diagonal functor
The *diagonal functor* $\Delta \colon C \to C \times C$ is defined by $\Delta(c) = (c,c)$ on objects
and by $\Delta(f) = (f,f)$ on arrows.

***** Coproduct diagram
A *coproduct diagram* of a pair $(a,b)$ is a universal arrow from $(a,b)$ to
the diagonal functor $\Delta$. The object defining this universal arrow up to
isomorphism is called the *coproduct object* and written as $a \amalg b$.

\[\begin{tikzcd}
 & (d,d) \\
(a,b) \rar[swap]{(i_a,i_b)} \urar{(f,g)} & 
(a\amalg b, a\amalg b) \uar[swap]{(f \amalg g, f \amalg g)} & .
\end{tikzcd}\]

****** Diagram rewriting
This universal property can be rewritten as

\[\begin{tikzcd}
a \rar{i}\drar[swap]{f} & a \amalg b \dar[dashed]{\exists! h} & b \lar{j}\dlar{g} \\
& d &  & .
\end{tikzcd}\]

****** Bijection rewriting
This universal arrow is a bijection $\mathrm{hom}(a,d) \times \mathrm{hom}(b,d) \cong \mathrm{hom}(a \amalg b,d)$
natural in $d$.

***** Coproduct functor
In a category $C$ where every pair has a coproduct, the coproduct bifunctor
$\amalg \colon C \times C \to C$ is defined on arrows as the unique arrow

\[\begin{tikzcd}
a \dar[swap]{f}\rar{i} & a \amalg b \dar[dashed]{\exists! f\amalg g} & b \dar{g}\lar[swap]{j} \\
a' \rar[swap]{i'} & a' \amalg b' & b \lar{j'}
\end{tikzcd}\]

making this diagram commute.

***** Infinite coproducts
A *coproduct* of objects of $C$ indexed by a discrete category $X$ is a
universal arrow to the indexed diagonal functor $\Delta \colon C \to C^{X}$. We write
the coproduct object as $\coprod_{x \in X} a_x$.

****** Bijection rewriting
This universal arrow is a bijection

\[\mathrm{hom}\left( \coprod_{x \in X}a_x, c \right)
\cong \prod_{x \in X} \mathrm{hom}(a_x,c)
\]

natural in $c$.

***** Copowers
A *copower* is a coproduct where all the factors are equal. It is written
as 

\[\coprod_{x\in X} b \cong X \cdot b.\]

***** Coequalizers
A *coequalizer* of two arrows $f,g \colon a \to b$ is $u \colon b \to e$ such that $uf = ug$; and
for every other $u'$ with the same property factorizes through it.

***** Pushout
**** III.5. Categories with finite products
***** Category with finite products
A category *has finite products* if to any finite number of objects exists
a product diagram. In particular, it has a terminal object.

***** Binary products define finite products
A category having binary products has finite products. There is then a
product bifunctor, an isomorphism

\[
\alpha \colon a \times (b \times c) \cong (a \times b) \times c
\]

natural in $a,b,c$; and isomorphisms

\[
\lambda \colon t \times a \cong a,
\qquad
\varrho\colon a \times t \cong a,
\]

both natural in $a$.

****** TODO Proof
We will prove that $a \times (b \times c)$ is a product of $a,b,c$; due to its universal
property we know it has the universal property of the product of $a,b,c$

\[\begin{tikzcd}[row sep=small]
& & b \\
a & a \times (b \times c) \rar\lar\urar\drar & b \times c \dar \uar \\
& & c
\end{tikzcd}\]

and, by the same reasoning, $(a \times b) \times c$ is also a product. They are
isomorphic due to universality.

# Why is it natural?

**** III.6. Groups in categories
***** A group has a group hom functor
In a category with finite products, $c$ is a group iff $\mathrm{hom}(c,-)$ is a group
in the functor category $\mathtt{Set}^{C^{op}}$.

****** TODO Proof

**** III.7. Colimits of representable functors
***** Representation as colimits
*** IV. Adjoints
**** IV.1. Adjunctions
***** IV.1.0. Adjunction
An *adjunction* from categories $X$ to $A$ is a pair of functors
$F\colon X \to A$, $G\colon A \to X$ with a natural bijection

\[
\varphi \colon \mathrm{hom}(Fx,a) \cong \mathrm{hom}(x,Ga),
\] 

natural in both $x\in X$ and $a \in A$. We write it as $F \dashv G$.

***** IV.1.1. Unit and counit
An adjunction determines a *unit* and a *counit*

 1) A natural transformation made with universal arrows $\eta\colon I \xrightarrow{.} GF$, where
    the right adjoint of each $f \colon Fx \to a$ is

    \[
    \varphi f = Gf \circ \eta_x \colon x \to Ga.
    \]

 2) A natural transformation made with universal arrows $\varepsilon \colon FG \xrightarrow{.} I$, where
    the left adjoint of each $g \colon x \to Ga$ is

    \[\varphi^{-1}g = \varepsilon \circ Fg \colon Fx \to a.\]

that follow the /triangle identities/ $\eta G \circ G \varepsilon = \mathrm{id}$ and $F\eta \circ \varepsilon F = \mathrm{id}$.

***** IV.1.2. Characterization of adjunctions
Each adjunction is completely determined by any of

 1) functors $F,G$ and $\eta\colon 1 \xrightarrow{.} GF$ where $\eta_x\colon x \to GFx$ is universal to $G$.
 2) functor $G$ and universals $\eta_x \colon x \to GF_0 x$, creating a functor $F$.
 3) functors $F,G$ and $\varepsilon\colon FG \xrightarrow{.} 1$ where $\varepsilon_a\colon FGa \to a$ is universal from $F$.
 4) functor $F$ and universals $\varepsilon_a\colon FG_0a \to a$, creating a functor $G$.
 5) functors $F,G$, with units and counits satisfiying the triangle
    identities $\eta G \circ G \varepsilon = \mathrm{id}$ and $F\eta \circ \varepsilon F = \mathrm{id}$.

**** IV.3. Reflective subcategories
**** IV.4. Equivalence of categories
***** Equivalence of categories
A *equivalence of categories* is a pair of functors $S,T$ which are
inverses, $S \circ T = I$. Their domain and codomain are called /equivalent/ 
/categories/.

***** Skeleton of a category
A *skeleton* is a full subcategory where every isomorphism class has
exactly one representative.

**** IV.5. Adjoints for preorders
***** Galois connections are adjoint pairs
Let $L\colon P \to Q^{op}$ and $R\colon Q^{op} \to P$ two order preserving functions. They
are adjoints iff for every two objects

\[
Lp \geq q \iff p \leq Rq.
\]

The adjunction is unique and

\[
Lp \geq LRLp \geq Lp, \qquad Rq \leq RLRq \leq Rq.
\]

**** IV.6. Cartesian closed categories
***** Cartesian closed category
A *cartesian closed category* is a category with all finite products where
the functors

\[\begin{tabular}{ccc}
$C \to 1$, & 
$C \to C \times C$, & 
$C \to C$, \\
$c \mapsto 0$, &
$c \mapsto (c,c)$, &
$c \mapsto c \times b$;
\end{aligned}\]

have specified adjoints

\[\begin{tabular}{ccc}
$0 \mapsto t$, &
$(a,b) \mapsto a \times b$, &
$c \mapsto c^b$.
\end{aligned}\]

***** TODO Evaluation map

**** IV.7. Transformations of adjoints
***** Map of adjunctions
Given two adjunctions $\varphi\colon F \dashv G$ and $\varphi'\colon F' \dashv G'$; we define a *map of adjunctions*
as two functors $K \colon A \to A'$ and $L \colon X \to X'$ such that

\[\begin{tikzcd}
A \dar{K}\rar{G} & X \dar{L} \\
A' \rar{G'} & X'
\end{tikzcd}
\quad
\begin{tikzcd}
X \dar{L}\rar{F} & A \dar{K} \\
X' \rar{F'} & A' &
\end{tikzcd}\]

commute and such that, knowing that $KF = F'L$ and $LG = G'K$,

\[\begin{tikzcd}
\mathrm{hom}(Fx,a) \rar{\varphi} \dar[swap]{K} & \mathrm{hom}(x,Ga) \dar{L} \\
\mathrm{hom}(F'Lx,Ka) \rar{\varphi'} & \mathrm{hom}(Lx,G'Ka)
\end{tikzcd}\]

commutes.

****** Equivalence for units and counits
Given the first property, the condition on hom-sets is equivalent
to $L\eta = \eta'L$ and $\varepsilon'K = K\varepsilon$.

******* TODO Proof

***** TODO Conjugate natural transformations

**** IV.9. Subsets and characteristic functions
***** Subobject classifier
A *subobject classifier* for ${\cal C}$ with a terminal object $1$ is a monomorphism
$t \colon 1 \to \Omega$ such that for every monomorphism $m$ exists a unique square

\[\begin{tikzcd}
S\rar{} \dar[swap,hook]{m} & 1 \dar[hook]{t} \\
X\rar[dashed]{\Psi_{S}} & \Omega &,
\end{tikzcd}\]

which is at the same time a pullback.

**** IV.10. Categories like sets
***** Elementary topos
An *elementary topos* is a category $E$ which

 1) has all finite limits,
 2) has a subobject classifier,
 3) is cartesian closed.

***** Presheaves
A *presheaf* is a set-valued contravariant functor on a small category.

*** V. Limits
**** V.1. Creation of limits
***** V.1.0. Small-complete category
A category is *small-complete* when all small diagrams have limits in it.

***** V.1.1. Completeness of Set
$\mathsf{Set}$ has all small limits. Given $J$ small, $F \colon J \to \mathtt{Set}$ has limit $\mathrm{Cone}(\ast,F)$,
the set of all cones $\sigma\colon \ast \to F$; with the functions $v_j\colon \sigma \mapsto \sigma_j(\ast)$.

****** Proof
As $J$ is small, $\mathrm{Cone}(\ast,F)$ is an object of $\mathsf{Set}$. We prove that it is a
cone; for any given $u \colon j \to k$ in $J$,

\[
(Fu)v_j(\sigma) = (Fu)\sigma_j = \sigma_k = v_k(\sigma).
\]

And we prove that it is universal. Given any cone $\tau \colon X \todot F$, for any
$x \in X$ we have a $\mathrm{Cone}(\ast,F)$, so there is a unique function
$h \colon X \to \mathrm{Cone}(\ast,F)$.

****** Adjunction
This can be written as the following adjunction

\[
\Nat(\Delta X,F) \cong \hom(X, \mathrm{Cone}(\ast,F)).
\]

***** TODO V.1.1. Example: p-adic numbers
***** V.1.2. Creation of limits in Grp
If a small $H \colon J \to \Grp$ can be forgot into $\Set$ with a limiting cone $v \colon L \todot UH$,
there is exactly one group structure on $L$ making each $v_i$ a homomorphism;
$L$ is a limit of $H$ with this structure.

****** Proof
We take $L = \mathrm{Cone}(\ast,UH)$ and define a group structure with $(\sigma\tau)_j = \sigma_j\tau_j$
and $(\sigma^{-1})_j = (\sigma_j)^{-1}$; making each $v$ a homomorphism. These are cones because
the functions $UHj$ are homomorphisms. Any other structure making each $v$ a
homomorphism should in particular satisfy these equations; so this structure
is unique.

Given any other group cone $\lambda \colon G \todot H$, then $U\lambda \colon UG \todot UH$ is a set cone
and there exists a unique $h \colon UG \to L$ making the diagram commute; this is
a homomorphism of groups

\[
(h(g_1g_2))_j = \lambda_j(g_1g_2) = \lambda_j(g_1)\lambda_j(g_2) = (hg_1)_j(hg_2)_j.
\]

***** V.1.2. Creation of limits
The functor $V\colon A \to X$ *creates limits* for $F\colon J \to A$ when

 1) for any con $\tau\colon x \xrightarrow{.} VF$ exists $\sigma\colon a \to F$ with $Va = x$ and $V\sigma = \tau$.
 2) this $\sigma$ is a limiting cone.

***** V.1.3. The forgetful Groups to Sets functor creates limits
The forgetful functor $U \colon \Grp\to \Set$ creates limits.

****** Proof
Rereading of the [[*V.1.2. Creation of limits in Grp][previous theorem]].

**** V.2. Limits by products and equalizers
***** V.2.1. Existence of limits from products and equalizers
If ${\cal C}$ has all equalizers and all products indexed by the sets of objects
and arrows of $J$, it has every limit $F\colon J \to {\cal C}$.

****** TODO Proof

***** TODO V.2.2. Limits from products and equalizers
***** TODO V.2.2. Finite limits from products and equalizers
If a category ${\cal C}$ has all finite products and all equalizers, it
has all finite limits.

**** TODO V.3. Limits with parameters
**** V.4. Preservation of limits
***** V.4.0. Preservation of limits
A functor $H\colon C \to D$ *preserves limits* $J \to C$ when every limiting
cone $v$ in $C$ yields a limiting cone $Hv$ in $D$.

***** V.4.0. Continuous functor
A functor is *continuous* if it preserves all small limits.

***** V.4.1. Hom-functors preserve all limits
In ${\cal C}$ with small hom-functors, each $\hom(c,-)$ preserves all limits.

****** TODO Proof

**** TODO V.5. Adjoints on limits
***** V.5.1. Right adjointa preserve all limits
If $G \colon A \to X$ has a left adjoint and the diagram $T\colon J \to A$ has a
limiting cone $\tau \colon a\todot T$, then $GT$ has the limiting cone $G\tau \colon Ga \todot GT$
in $X$.

****** Proof
As $G$ is a functor, $G\tau$ is already a cone. Given any other cone $\sigma \colon x \todot GT$,
we can take adjoints on every component and, by naturality of the adjoint,
we have a cone $\sigma_{\ast} \colon Fx \todot T$. This cone uniquely factorizes throught $\tau$ with
$h \colon Fx \to a$, naturality preserves this unique factorization in $h_{\ast} \colon x \to Ga$,

\begin{prooftree}
\AXC{\begin{tikzcd}[fragile,ampersand replacement=\&] 
x \rar{h_\ast}\& Ga \rar{G\tau} \& Gi  \end{tikzcd}}
\doubleLine
\UIC{\begin{tikzcd}[fragile,ampersand replacement=\&]
Fx \rar{h}\& a \rar{\tau} \& i \end{tikzcd}}
\end{prooftree}

so $G\tau$ is universal.

**** V.6. Freyd's adjoint functor theorem
***** V.6.1. Existence of an initial object
In ${\cal D}$ small-complete with small hom-sets, there exists an initial object
if and only if it satisfies

 - solution set condition :: there exists a small family $\left\{ k_i \right\}_{i \in I}$ such that
      for each $d \in D$ exists an arrow $k_i \to d$.

****** Proof
If it has an initial object, it trivially satisfies the condition with that
object.

We take $w = \prod k_i$ and we have at least one arrow $w \to d$ for each $d$, given
by projections. We can construct the equalizer of all $\hom(w,w)$, which is
small

\begin{tikzcd}
v \rar{e} & w \rar[bend left] \rar[bend right] & w
\end{tikzcd}

For each $d$ there exists at least one $v \to d$, if there were two $f,g \colon v \to d$,
we take the equalizer of both, $u$, and

\[\begin{tikzcd}
u \rar{e_1} & v \dlar[swap]{e}\dar{e}\rar[bend left]{f}\rar[bend right]{g} & d \\
w \uar[dashed]{s}\rar{ee_1s} & w \rar & k_i \uar
\end{tikzcd}\]

we know that a $s \colon w \to u$ must exist; as $ee_1se = e$ and $e$ is an equalizer
(and thus, a monomorphism), $e_1se =\id$. Then, $e_1$ has a right inverse and
it is also a monomorphism, so it has to be an isomorphism, $f = g$.

***** V.6.2. Lemma to Freyd I: creation of products by adjoints
Given $G \colon A \to X$ preserving all small products, the projection
$Q \colon (x \downarrow G) \to A$, $(x \to Ga) \mapsto a$ from the comma category creates
all small products.

****** Proof
Given $\left\{ f_j\colon x \to Ga_j \right\}$ an indexed family of objects in $(x \downarrow G)$ such
that $p_k \colon \prod a_j \to a_k$ exists in $A$; we know that $Gp_k \colon G\prod a_j \to Ga_j$
is a product, so there is a unique $f \colon x \to G\prod a_j$ with $(Gp_j)f=f_j$,

\[\begin{tikzcd}
\Pi a_j \dar{p_j} & & G\Pi a_j \dar{Gp_j} \\
a_j & x \rar[swap]{f_j}\urar[dashed]{f} & Ga_j \\
\end{tikzcd}\]

We can now verify that these $p_j$ create a product in the comma category.

***** TODO V.6.2. Lemma to Freyd II: creation of equalizers by adjoints
***** V.6.2. The Freyd adjoint functor theorem
A functor $G \colon A \to X$ from a locally small category has
left-adjoint iff it preserves all small limits and satisfies the

 - solution set condition :: for each object $x \in X$ there is a small set $I$
      and a family of arrows $\left\{ f_i \colon x \to Ga \right\}_{i \in I}$ such that every $h \colon x \to Ga$
      can be written as $h = Gt \circ f_i$ for some $i$ with some $t \colon a_i \to a$.

****** Proof
******* First implication
If $G$ has a left-adjoint, it preserves all limits; the unit 
$\eta \colon x \to GFx$ satisfies the solution set condition.

******* Second implication
By [[*IV.1.2. Characterization of adjunctions][characterization of adjoints]], it suffices to create a universal
arrow $x \to Ga$ for each $x$; that is, a initial object in the comma
category $(x \downarrow G)$; the solution set condition gives us the conditions
of [[*V.6.1. Existence of an initial object][existence of an initial object]]. We only need to prove that $(x \downarrow G)$
is small-complete; but $G$ preserving small products makes the projection
create all [[*V.6.2. Lemma to Freyd I: creation of products by adjoints][products]] and create all [[*V.6.2. Lemma to Freyd II: creation of equalizers by adjoints][equalizers]].

***** V.6.3. The representability theorem

**** TODO V.7. Subobjects and generators
**** TODO V.8. The special adjoint functor theorem
**** TODO V.9. Adjoints in topology
*** VI. Monads and algebras
**** VI.1. Monads in a category
***** Monad
A *monad* is a functor $T\colon X \to X$ with natural transformations

 * $\eta\colon I \xrightarrow{.} T$, called /unit/
 * $\mu \colon T^2 \xrightarrow{.} T$, called /multiplication/

such that

\[\begin{tikzcd}
T^3 \rar{T\mu}\dar{\mu T} & T^2\dar{\mu} \\
T^2 \rar{\mu} & T
\end{tikzcd}
\qquad
\begin{tikzcd}
IT \rar{\eta T}\drar[swap]{\cong} & T^2\dar{\mu} & \lar[swap]{T\eta}\dlar{\cong} TI \\
& T & &.
\end{tikzcd}\]

***** Each adjunction defines a monad
Given $F \dashv G$, $GF$ is a monad.

****** Proof
We take the unit of the adjunction as the monad unit. We define the
product as $\mu = G\varepsilon F$. Associativity follows from these diagrams

\[\begin{tikzcd}
FGFG\rar{FG\varepsilon} \dar[swap]{\varepsilon FG} & FG \dar{\varepsilon} \\
FG\rar{\varepsilon} & I
\end{tikzcd}
\qquad
\begin{tikzcd}
GFGFGF\rar{GFG\varepsilonF} \dar[swap]{G\varepsilon FGF} & GFGF \dar{G\varepsilonF} \\
GFGF\rar{G\varepsilonF} & GF &,
\end{tikzcd}\]

where the first is commutative by the [[*Interchange law][interchange law]] and the second
is obtained by applying functors $G$ and $F$. Unit laws follow from
the [[*Unit and counit][triangular identities]] after applying $F$ and $G$.

***** Comonad
A *comonad* is a functor $L\colon X \to X$ with natural transformations

 * $\varepsilon\colon L\to I$, called /counit/
 * $\delta\colon L \to L^2$, called /comultiplication/

such that

\[\begin{tikzcd}
L\rar{\delta} \dar[swap]{\delta} & L^{2} \dar{L\delta} \\
L^{2}\rar{\delta L} & L^{3}
\end{tikzcd}
\qquad
\begin{tikzcd}
& L \dar{\delta} \dlar[swap]{\cong} \drar{\cong} & \\
IL & 
L^2 \lar{\varepsilon L}\rar[swap]{L \varepsilon} & 
LI
&.
\end{tikzcd}\]

***** TODO Each adjunction defines a comonad
**** VI.2. Algebras for a monad
***** T-algebra
For a monad $T$, a $T\text{-algebra}$ is an object $x$ with an arrow $h \colon Tx \to x$ called 
/structure map/ making these diagrams commute

\[\begin{tikzcd}
T^{2}x \rar{Th}\dar[swap]{\mu} & Tx \dar{h} \\
Tx\rar{h} & x &.
\end{tikzcd}\]

***** Morphisms of T-algebras
A morphism of T-algebras is an arrow $f\colon x \to x'$ making the following square
commute

\[\begin{tikzcd}
Tx \dar[swap]{Tf}\rar{h} & Tx \dar{f} \\
Tx' \rar[swap]{h'} & Tx' &.
\end{tikzcd}\]

***** Category of T-algebras
The set of all $T\text{-algebras}$ and their morphisms form a category $X^{T}$.

****** Proof
Given $f\colon x \to x'$ and $g\colon x'\to x''$, $T\text{-algebra}$ morphisms, their composition
is also a $T\text{-algebra}$ morphism, due to the fact that this diagram

\[\begin{tikzcd}
Tx \rar{h}\dar[swap]{Tf} & 
x \dar{f}\\
Tx' \dar[swap]{Tg} \rar{h'} &
x' \dar{g}\\
Tx'' \rar{h''}&
x''
\end{tikzcd}\]

commutes.

***** Every monad is defined by its T-algebras
The monad defined by the adjunction $F^{T} \dashv G^{T}$ is $T$, where the functors
are defined as

\[F^{T}\colon \begin{tikzcd}
x \dar{f} \\
x'
\end{tikzcd} \mapsto \begin{tikzcd}
(Tx,\mu) \dar{Tf} \\
(Tx',\mu)
\end{tikzcd}
\qquad
G^{T}\colon  \begin{tikzcd}
(x,h) \dar{f} \\
(x',h')
\end{tikzcd} \mapsto
\begin{tikzcd}
x \dar{Tf} \\
x' &
\end{tikzcd}\]

knowing that $(Tx,\mu)$ is always a $T\text{-algebra}$.

****** TODO Proof

**** VI.3. The comparison with algebras
***** Comparison of adjunctions with algebras
Given $F \dashv G$ with the monad $T$, there is a unique $K\colon A \to X^T$ with
$G^TK = G$ and $KF = F^T$.

****** TODO Proof

**** TODO VI.4. Words and free semigroups
**** TODO VI.5. Free algebras for a monad
*** VII. Monoids
**** VII.1. Monoidal categories
***** VII.1.0. Strict monoidal category
A *strict monoidal category* ${\cal B}$ is a category with a bifunctor $\otimes \colon {\cal B} \times {\cal B} \to {\cal B}$
which is associative

\[
\otimes(\otimes \times 1) = \otimes (1 \times \otimes) \colon {\cal B} \times {\cal B}\times {\cal B} \to {\cal B}
\]

and with a *unit* object,

\[
\otimes(e \times \Id) = \Id_{{\cal B}} =\otimes(\Id \times e).
\]

***** VII.1.0. Monoidal category
A *monoidal category* ${\cal B}$ is a category with a bifunctor $\otimes \colon {\cal B} \times {\cal B} \to {\cal B}$
and three natural isomorphisms

 * $\alpha \colon a \otimes (b \otimes c) \cong (a \otimes b) \otimes c$

 * $\lambda \colon e \otimes a \cong a$

 * $\rho \colon a \otimes e \cong a$

such that the pentagonal diagram commutes

\begin{tikzcd}
a \otimes (b \otimes (c \otimes d)) \dar{1 \otimes \alpha} \rar{\alpha}& 
(a \otimes b) \otimes (c \otimes d) \rar{\alpha}& 
((a \otimes b) \otimes c) \otimes d \dar{\alpha \otimes 1}\\
a \otimes ((b \otimes c) \otimes d) \ar[rr, "\alpha"] & & 
(a \otimes (b \otimes c)) \otimes d
\end{tikzcd}

and the following triangular diagram commutes

\[\begin{tikzcd}[row sep=tiny]
& a \otimes (e \otimes c) \ar[dd, "\alpha"]\dlar[swap]{1 \otimes \lambda}\\ 
a \otimes c &\\
& (a \otimes e) \otimes \ular{\rho \otimes 1}
\end{tikzcd}\]

*** IX. Special limits
**** IX.1. Filtered limits
***** Directed preorder
A preorder $P$ is *directed* when any two elements have an upper bound.

***** Filtered category
A category ${\cal C}$ is *filtered* when

 1) for any $a,b \in {\cal C}$ there exists a $c$ with arrows $a \to c$, $b \to c$.
 2) for any $u,v \colon a \to b$ exists a $w\colon b \to c$ such that $wu=wv$.

In a filtered category, every finite diagram is base of at least one cone.

*** Exercises [35/52]
**** I. Categories, functors and natural transformations [19/23]
***** I.3. Functors
****** CHECK Exercise I.3.1
#+begin_statement
Show how each of the following constructions can be regarded as a functor:

 - the field of quotients of an integral domain.
 - the Lie algebra of a Lie group.
#+end_statement

******* Field of quotients
Given two integral domains and a ring homomorphism $f : R \to S$, we
define an homomorphism between its fields of quotients as:

\[
\widetilde{f}\left(\frac{a}{b}\right)
=
\frac{f(a)}{f(b)}
\]

We can prove it is well-defined using that $ab=cd$ implies
$f(a)f(b) = f(c)f(d)$, and then:

\[
\widetilde{f}\left(\frac{a}{b}\right)
=
\frac{f(a)}{f(b)}
=
\frac{f(c)}{f(d)}
=
\widetilde{f}\left(\frac{c}{d}\right)
\]

And it respects sums and products:

\[
\widetilde{f}\left(\frac{a}{b} + \frac{c}{d}\right)
=
\widetilde{f}\left(\frac{ad+cb}{bd}\right)
=
\frac{f(a)f(d)+f(c)f(d)}{f(b)f(d)}
=
\frac{f(a)}{f(b)}+\frac{f(c)}{f(d)}
\]

\[
\widetilde{f}\left(\frac{ac}{bd}\right) =
\frac{f(a)f(c)}{f(b)f(d)}
\]

So it is a field homomorphism.

******* TODO Lie algebra
Given $\phi : G \to H$, a Lie group homomorphism, we can compute its first
derivative at the identity $\phi^*$.
****** DONE Exercise I.3.2
#+begin_statement
Show that functors $1 \to C$, $2 \to C$, and $3 \to C$ correspond respectively to
objects, arrows, and composable pairs of arrows in $C$.
#+end_statement

A functor $F\colon 1 \to C$ is determined by $F1$. A functor $F\colon 2 \to C$ is determined
by $F(1\leq 2)\colon F1 \to F2$. A functor $F\colon 3 \to C$ is determined by $F(1\leq 2)$ and
$F(2\leq 3)$, which must be composable in $F2$.

****** DONE Exercise I.3.3
#+begin_statement
Interpret "functor" in the following special types of categories:

  1. A functor between two preorders is a function $T$ which is monotonic
     (i.e. $p \leq p'$ implies $Tp \leq Tp'$).
  2. A functor between two groups (one-object categories) is a morphism
     of groups.
  3. If $G$ is a group, a functor $G \to \mathtt{Set}$ is a permutation representation
     of $G$, while $G \to Matr_K$ is a matrix representation of $G$.
#+end_statement

******* First statement
A functor must be a monotonic function, as it has to send $(p\leq p')$ into
a morphism between $Tp$ and $Tp'$. This morphism exists if and only if 
$Tp \leq Tp'$.

******* Second statement
It respects the identity and the group operation, as functors respect
the identity and the composition.

******* Third statement
A functor $F\colon G \to \mathtt{Set}$ is determined by $FG$ and the assignment of every
element of $G$ to a set automorphism, that is, an element of the permutation
group of the set.

The functor $F\colon G \to \mathtt{Matr}_K$ selects a dimension $n$, and sends every element
of the group to an invertible matrix $M_{n\times n}$.

****** DONE Exercise I.3.4
#+begin_statement
Prove that there is no functor $\mathtt{Grp} \to \mathtt{Ab}$ sending each group $G$ to its
center. (Consider $S_2 \to S_3 \to S_2$, the symmetric groups).
#+end_statement

A functor must preserve identities and composition. We have the following
diagram in $\mathtt{Grp}$,

\[\begin{tikzcd}
S_2 \rar[hook]\arrow[rr,bend left, "id"] & S_3 \rar & S_2
\end{tikzcd}\]

that cannot be translated into $\mathtt{Ab}$ by this functor

\[\begin{tikzcd}
S_2 \rar & \{id\} \rar &  S_2
\end{tikzcd}\]

as we know that the identity is not the zero morphism.

****** DONE Exercise I.3.5
#+begin_statement
Find two different functors $T : \mathtt{Grp} \to \mathtt{Grp}$ with object function $T(G) = G$
the identity for every group $G$.
#+end_statement

The identity functor and a functor sending every morphism to the zero 
morphism.

***** I.4. Natural transformations
****** DONE Exercise I.4.1
#+begin_statement
Let $S$ be a fixed set, and $X^S$ the set of all functions $h : S \longrightarrow X$.
Show that $X \mapsto X^S$ is the object function of a functor $\mathtt{Set} \longrightarrow \mathtt{Set}$,
and that evaluation $e_X : X^S \times S \longrightarrow X$ defined by $e(h,s) = h(s)$, the
value of the function $h$ at $s \in S$ is a natural transformation.
#+end_statement

We define the functor $\_^S$ on arrows as follows. Given a $f : X \to Y$
and a $g : S \longrightarrow X$:

\[
f^S(g) = f \circ g
\]

And it follows the functor laws.

We can see that evaluation is a natural transformation with the
naturality square:

\[\begin{tikzcd}
X^S \times S \dar{e_X}\rar{f^S,id} & Y^S \times S \dar{e_Y}\\
X \rar{f} & Y
\end{tikzcd}\]

Which commutes on its elements:

\[\begin{tikzcd}
(f,s) \dar{e_X}\rar{g^S,id} & (g\circ f, s) \dar{e_Y}\\
f(s) \rar{f} & g(f(s))
\end{tikzcd}\]

****** DONE Exercise I.4.2
#+begin_statement
If $H$ is a fixed group, show that $G \mapsto H \times G$ defines a functor
$H \times - \colon \mathtt{Grp}\to \mathtt{Grp}$ and that each morphism $f \colon H \to K$ of groups defines
a natural transformation $H \times -\; \dot\to \; K \times -$.
#+end_statement

The functor will send a morphism $f \colon G \to G'$ to $\mathrm{id}\times f\colon H\times G \to H \times G'$.
The naturality condition is satisfied if the following diagram commutes

\[\begin{tikzcd}
H \times G \dar{\mathrm{id}\times f} \rar{g\times\mathrm{id}} & 
K \times G \dar{\mathrm{id}\times f} \\
H \times G' \rar{g\times\mathrm{id}} & 
K \times G'
\end{tikzcd}\]

but it is trivial to check commutativity.

****** DONE Exercise I.4.3
#+begin_statement
If $B$ and $C$ are groups (regarded as categories with one object each) and
$S,T \colon B \to C$ are functors (homomorphisms of groups), show that there is a
natural transformation $S \dot\to T$ if and only if $S$ and $T$ are conjugate; i.e.
if and only if there is an element $h \in C$ with $Tg = h(Sg)h^{-1}$ for all
$g \in B$.
#+end_statement

If the only object in $B$ is $b$, then $Sb = Tb = c$ must be the only object
in $c$. Naturality gives us

\[\begin{tikzcd}
c\rar{\varphi} \dar[swap]{Sf} & c \dar{Tf} \\
c\rar{\varphi} & c
\end{tikzcd}\]

so we know that $Sf \circ \varphi = \varphi \circ Tf$, and this is the conjugate condition.

****** DONE Exercise I.4.4
#+begin_statement
For functors $S,T \colon C \to P$ where $C$ is a category and $P$ a preorder, show
that there is a natural transformation $S \dot\to T$ (which is then unique) if
and only if $Sc \leq Tc$ for every object $c \in C$.
#+end_statement

To define a natural transformation, we must have a familiy of morphisms

\[
Sc \to Tc \quad\forall c \in C,
\]

but this morphism exists if and only if $Sc \leq Tc$ for every object. If the
morphisms exist, the naturality condition is trivial, as there will be
an unique morphism between two objects and all squares will commute.

****** DONE Exercise I.4.5
#+begin_statement
Show that every natural transformation $\tau\colon S \dot\to T$ defines a function
(also called $\tau$) which sends each arrow $f\colon c \to c'$ of $C$ to an arrow
$\tau f\colon Sc \to Tc'$ of $B$ in such a way that $Tg \circ \tau f = \tau(gf) = \tau g\circ Sf$ for
each composable pair $(g,f)$. Conversely, show that every such function $\tau$ 
comes from a unique natural transformation with $\tau_c = \tau(1_c)$. (This gives 
an arrows only description of a natural transformation.)
#+end_statement

Given $f\colon c \to c'$, we apply the naturality condition and take $\tau$ to be the
diagonal

\[\begin{tikzcd}
Sc \drar{\tau f} \rar{\tau} \dar[swap]{Sf} & Tc \dar{Tf} \\
Sc'\rar{\tau} & Tc'
\end{tikzcd}\]

i.e. we have defined $\tau f = Tf\circ \tau_c = \tau_{c'} \circ Sf$. The condition holds now 
trivially, as we know that

\[
Tg \circ \tau f = Tg\circ Tf\circ \tau_c = \tau(gf) = \tau_{c'}\circ Sg\circ Sf
= \tau g \circ Sf.
\]

****** TODO Exercise I.4.6
#+begin_statement
Let $F$ be a field. Show that te category of all finite-dimensional vector
spaces over $F$ (with morphisms all lineal transformations) is equivalent
to the category $\mathtt{Matr}$.
#+end_statement
***** I.5. Monics, epis and zeros
****** DONE Exercise I.5.1
#+begin_statement
Find a category with an arrow which is both epi and monic, but not 
invertible (e.g., dense subset of a topological space).
#+end_statement

In the $\mathtt{Top}$ category of topological spaces with continuous functions,
we can include a dense subset in its base space. This inclusion will
be a monomorphism (as it is injective) and an epimorphism as we know
that, if $i \colon U \subset V$ is our inclusion,

\[ f\circ i = i \circ g \implies f|_{U} = g|_{U},\]

and because it is a dense subset, by continuity, $f = g$.

But it has not to be an isomorphism. In fact, it won't be if $U$ is a
proper subset.

****** DONE Exercise I.5.2
#+begin_statement
Prove that the composite of monics is monic, and likewise for epis.
#+end_statement

If $f,g$ are monics, we can apply the definition twice to get

\[
f \circ g \circ a = f \circ g \circ b \implies
g \circ a = g\circ b \implies
a = b.
\]

The same proof can be applied in reverse.

****** DONE Exercise I.5.3
#+begin_statement
If a composite $g\circ f$ is monic, so is $f$. Is this true of $g$?
#+end_statement

No, $f$ could be a zero morphism and $g$ could still give $g\circ h = g\circ h'$ for
two $h \neq h'$.

****** DONE Exercise I.5.4
#+begin_statement
Show that the inclusion $\mathbb{Z} \to \mathbb{Q}$ is epi in the category $\mathtt{Rng}$.
#+end_statement

If $f \circ i = g \circ i$, then $f|_{\mathbb{Z}} = g|_{\mathbb{Z}$, and we can extend the morphisms uniquely
to the ring $\mathbb{Q}$, as the ring morphisms have to preserve inverses.

****** TODO Exercise I.5.5
#+begin_statement
In $\mathtt{Grp}$ prove that every epi is surjective (Hint. If $\varphi\colon G\to H$ has image
$M$ not $H$, use the factor group $H/M$ if $M$ has index 2. Otherwise, let
$\mathrm{Perm}\ H$ be the group of all permutations of the set $H$, choose three
different cosets $M,Mu$ and $Mv$ of $M$, define $\sigma \in \mathrm{Perm}\ H$ by
$\sigma(xu) = xv$, $\sigma(xv) = xu$ for $x \in M$, and $\sigma$ otherwise the identity.
Let $\psi\colon H \to \mathrm{Perm}\ H$ send each $h$ to left multiplication $\psi_h$ by $h$, while
$\psi'_h = \sigma^{-1}\psi_h\sigma$. Then $\psi\varphi = \psi'\varphi$, but $\psi \neq \psi'$).
#+end_statement

****** DONE Exercise I.5.6
#+begin_statement
In $\mathtt{Set}$, show that all idempotents split.
#+end_statement

Given $f \colon A \to A$ idempotent, we can define the set $\mathrm{img}\ f$, and two functions
$g \colon A \to \mathrm{img}\ f$, $h\colon \mathrm{img}\ f \to A$ defined naturally and satisfiying the conditions.
Notice that $g$ is an epimorphism and $h$ a monomorphism.

****** DONE Exercise I.5.7
#+begin_statement
An arrow $f \colon a \to b$ in a category $C$ is /regular/ when there exists an arrow
$g\colon b \to a$ such that $fgf = f$. Show that $f$ is regular if it has either a left or
a right inverse, and prove that every arrow in $\mathtt{Set}$ with $a \neq \varnothing$ is regular.
#+end_statement

If $f$ has either a right or a left inverse, it is trivial that it is regular.

If $a \neq \varnothing$, we can take $x_y \in \left\{ x \in a \mid f(x) = y \right\}$, a representative of the class
of elements that are mapped onto $y$, and $u \in a$ an arbitrary element, and define

\[
g(y) = \left\{\begin{array}{ll} 
x_y & \mbox{if } y \in \mathrm{img}(f)  \\
u & \mbox{otherwise }
\end{array} 
\right.
\]

and this morphism makes the $f$ regular. (Have we used the choice axiom to define
the representatives?)

****** DONE Exercise I.5.8
#+begin_statement
Consider the category with objects $\left\langle X,e,t \right\rangle$, where $X$ is a set, $e \in X$, and
$t \colon X \to X$, and with arrows $f\colon \left\langle X,e,t \right\rangle \to \left\langle X',e',t' \right\rangle$ the functions $f$ on $X$ to $X'$
with $fe=e'$ and $ft = tf'$. Prove that this category has an initial object in
which $X$ is the set of natural numbers, $e=0$, and $t$ is the successor function.
#+end_statement

We will prove that $\left\langle \mathbb{N},0,S \right\rangle$ is the initial object. For every object $\left\langle X,e,t \right\rangle$,
we only can define a function $f$, its image on zero is determined by the
first arrow condition $f(0) = e$, and its image in every other natural is
determined as

\[
f(n) = f(S \circ \overset{n}\dots \circ S(0)) = t\circ \overset{n}\dots \circ t(f(0)).
\]

****** DONE Exercise I.5.9
#+begin_statement
If the functor $T \colon C \to B$ is faithful and $Tf$ is monic, prove $f$ monic.
#+end_statement

If $f\circ g = f \circ h$, we have $Tf\circ Tg = Tf\circ Th$. $Tf$ is monic and $T$ is faithful, so
we get $g = h$.

***** I.6. Foundations
****** CHECK Exercise I.6.1
#+begin_statement
Given a universe $U$ and a function $f \colon I \to b$ with domain $I \in U$ and
with every value $f_i$ an element of $U$, for $i \in I$, prove that the usual
cartesian product $\prod_i f_i$ is an element of $U$.
#+end_statement

An element of the cartesian product will be a function $g \colon I \to \bigcup f_i$,
where $g(i) \in f_i$ for every $i \in I$. Our cartesian product is defined as

\[
\left\{ x \in {\cal P}\left( I \times \bigcup f_i \right) \;\middle|\; 
\left( \forall (i,b) \in x \colon b \in f_i \right) \wedge
\left( \forall j \in I\colon \exists! (i,b) \in x\colon j = i \right)
\right\}.
\]

Notice that the powerset and the union of elements in $U$ are elements
in $U$.

****** TODO Exercise I.6.2
#+begin_statement
(a) Given a universe $U$ and a function $f \colon I \to b$ with domain $I \in U$, show
that the usual union $\bigcup_i f_i$ is a set of $U$.

(b) Show that this one closue property of $U$ may replace condition (v) and the
condition $x \in U$ implies $\bigcup x \in U$ in the definition of a universe.
#+end_statement
**** II. Constructions on categories [6/11]
***** II.3. Products of categories
****** DONE Exercise II.3.1
#+begin_statement
Show that the product of categories includes the following known special
cases: The product of monoids (categories with one object), of groups,
of sets (discrete categories).
#+end_statement

The product of two monoids or groups has only one object, and so it is
a monoid or group. Every pair of isomorphisms has an inverse given by
the pair of inverses, and because of that, we know that the product of
two groups is in fact a group.

The product of two sets has no nontrivial morphisms and only pairs of
objects as objects.

****** DONE Exercise II.3.2
#+begin_statement
Show that the product of two preorders is a preorder.
#+end_statement

The product of two preorders gives the product preorder, where $(a,b) \leq (a',b')$
if and only if $a \leq a'$ and $b\leq b'$. That pair of morphisms is witness of the 
order.

****** DONE Exercise II.3.3
#+begin_statement
If $\left\{ C_i \mid i \in I \right\}$ is a family of categories indexed by a set $I$, describe the
product $C= \prod_iC_i$, its projections $P_i\colon C \to C_i$, and establish the universal
property of these projections.
#+end_statement

An object in this category is a function assigning $i \mapsto c_i \in C_i$. A morphism
between it and $i \mapsto d_i \in C_i$ is a function assigning $i \mapsto (f_i \colon c_i \to d_i)$ and
componentwise composition. Its projections are only the functors given by
evaluation on any element in $I$.

Given any other family of functors $D \to C_i$, we can define a functor to $C$
componentwise, being the unique functor making a product diagram commute.

****** TODO Exercise II.3.4
#+begin_statement
Describe the opposite of the category $\mathtt{Matr}_K$.
#+end_statement

****** DONE Exercise II.3.5
#+begin_statement
Show that the ring of continuous real-valued functions on a topological
space is the object function of a contravariant functor on $\mathtt{Top}$ to $\mathtt{Rng}$.
#+end_statement

We are going to define the functor $T \colon \mathtt{Top}\to \mathtt{Rng}$ taking $Tf$ to be
$(\circ f) \colon \mathrm{hom}_{\mathtt{Top}}(Y,\mathbb{R}) \to \mathrm{hom}_{\mathtt{Top}}(X,\mathbb{R})$ for any given $f \colon X \to Y$. It is 
trivially a functor, as it preserves composition.

We know that the composition of two continuous functions is
continuous, and we have to prove that $(\circ f)$ is a ring homomorphism,
but it is trivial that

\[\begin{aligned}
(g\cdot h) \circ f &= (g \circ f) \cdot (h \circ f) \\
(g + h) \circ f &= (g \circ f) + (h \circ f). \\
\end{aligned}
\]

***** II.4. Functor categories
****** TODO Exercise II.4.1
#+begin_statement
For $R$ ring, describe $R\text{-Mod}$ as a full subcategory of the functor category
$\mathtt{Ab}^R$.
#+end_statement

****** TODO Exercise II.4.2
#+begin_statement
Describe $B^X$, for $X$ a finite set (a finite discrete category).
#+end_statement

****** TODO Exercise II.4.3
#+begin_statement
Let $\mathbb{N}$ be the discrete category of natural numbers. Describe the functor
category $\mathtt{Ab}^{\mathbb{N}}$ (commonly known as the category of graded abelian groups). 
#+end_statement

***** II.5. The category of all categories
****** TODO Exercise II.5.1
#+begin_statement
For small categories $A$, $B$ and $C$ establish a bijection

\[ \mathrm{hom}(A \times B, C) \cong \mathrm{hom}(A, C^B),
\]

and show it natural in $A$, $B$ and $C$. Hence show that $-\times B \colon \mathtt{Cat}\to \mathtt{Cat}$ has
a right adjoint.
#+end_statement

***** II.6. Comma categories
****** DONE Exercise II.6.1
#+begin_statement
If $K$ is a commutative ring, show that the comma category $(K \downarrow \mathtt{CRng})$ is
the usual category of all small commutative $K\text{-algebras}$.
#+end_statement

A $K\text{-algebra}$ can be defined as an inclusion from $K$ on a ring, morphisms
of algebras must preserve this inclusion.

# A more detailed proof would be interesting.

****** DONE Exercise II.6.2
#+begin_statement
If $t$ is a terminal object in $C$, prove that $(C \downarrow t)$ is isomorphic to $C$.
#+end_statement

By definition of terminal object, there will be only an arrow 
$\ast \colon u \to t$ for any $u \in C$. Every morphism will create a commutative 
diagram because of the unicity of the morphisms.

**** III. Universals and limits [9/16]
***** III.1. Universal arrows
****** DONE Exercise III.1.1
#+begin_statement
Show how each of the following familiar constructions can be interpreted
as a universal arrow:

 * The integral group ring of a group (better, of a monoid).
 * The tensor algebra of a vector space.
 * The exterior algebra of a vector space.
#+end_statement

******* The integral group ring (monoid)
The integral group ring $\mathbb{Z}G$ is defined as the initial object of $(G \downarrow {\cal U})$,
where ${\cal U}$ is the functor that takes a ring and returns its group of units.

******* The tensor algebra of a vector space
The tensor algebra $T(V)$ is defined as the initial object of $(V \downarrow U)$,
where $U\colon \mathtt{Alg}_k \to \mathtt{Vect}_k$ is the forgetful functor.

******* The exterior algebra of a vector space
The same construction as above can be performed on the full subcategory of
external algebras.

****** DONE Exercise III.1.2
#+begin_statement
Find a universal element for the contravariant power set functor
${\cal P} \colon \mathtt{Set}^{op} \to \mathtt{Set}$.
#+end_statement

The universal arrow for $A$ will be its inclusion in ${\cal P}{\cal P}A$ as

\[
i(a) = \left\{ U \in {\cal P}A \mid a \in U \right\}.
\]

Given a morphism $f \colon A \to {\cal P}B$, we define $g \colon B \to {\cal P}A$ as

\[
g(b) = \left\{ a \in A \mid b \in f(a) \right\}.
\]

And its image when the functor is applied is

\[
{\cal P}g(\mathbb{A}) = g^{-1}(\mathbb{A})
= \left\big\{ b \in B \mid \left\{ a \mid b \in f(a) \right\} \in \mathbb{A} \right\big\}.
\]

The $g$ is unique, as it is defined by $x \in f(a) \iff a \in g(x)$.

****** DONE Exercise III.1.3
#+begin_statement
Find (from any given object) universal arrows to the following forgetful
functors: $\mathtt{Ab} \to \mathtt{Grp}$, $\mathtt{Rng}\to \mathtt{Ab}$ (forget the multiplication), $\mathtt{Top} \to \mathtt{Set}$,
$\mathtt{Set}_{\ast} \to \mathtt{Set}$.
#+end_statement

******* Abelian groups to groups
The universal arrow defines the [[https://en.wikipedia.org/wiki/Commutator_subgroup][abelianization]] of the group. A morphism
from a group to an abelian group must have the commutator subgroup in 
its kernel

\[f(aba^{-1}b^{-1}) = f(a)f(b)f(b)^{-1}f(a)^{-1} = 1.\]

Thus, every morphism can be factorized in $G/[G,G]$, giving

\[\begin{tikzcd}
g \rar[hook]{i}\drar[swap]{f} & G/[G,G]\dar[dashed]{\widetilde f} \\
  & h & .
\end{tikzcd}\]

******* WIP Rings to abelian groups
A tensor Z-algebra over the abelian group.

******* Topological spaces to sets
The inclusion on the discrete topology over the set is an universal
arrow. If we define any application $f\colon A \to O$, there is an unique 
continuous function $\widetilde f \colon (A,\tau_d) \to (O,\tau)$ defined by $\widetilde f(x) = f(x)$. It is
trivially continuous, as $\tau_d$ is the discrete topology.

******* Pointed sets to sets
Trivially, the inclusion on $(S \cup \left\{ \ast \right\}, \ast)$ defines an universal arrow.

****** TODO Exercise III.1.4
#+begin_statement
Use only universality (of projections) to prove the following isomorphisms of
group theory:

 1) For normal subgroups $M,N$ of $G$ with $M \subset N$, $(G/M)(N/M) \cong (G/M)$.
 2) For subgroups $S$ and $N$ of $G$, $N$ normal, with join $SN$, $SN/N \cong S/S\cap N$.
#+end_statement

****** TODO Exercise III.1.5
#+begin_statement
Show that the quotient $K\text{-module}$ $A/S$ ($S$ a submodule of $A$) has a description
by universality. Derive isomorphism theorems.
#+end_statement

****** TODO Exercise III.1.6
#+begin_statement
Describe quotients of a ring by a two-sided ideal by universality.
#+end_statement

****** TODO Exercise III.1.7
#+begin_statement
Show that the construction of the polynomial ring $K[x]$ in a indeterminate $x$
over a commutative ring $K$ is a universal construction.
#+end_statement

***** III.2. Yoneda Lemma
****** DONE Exercise III.2.1
#+begin_statement
Let functors $K,K' \colon D \to \mathtt{Set}$ have representations $\left\langle r,\psi \right\rangle$ and $\left\langle r',\psi' \right\rangle$, 
respectively. Prove that to each natural transformation $\tau\colon K \overset{\cdot}\to K'$,
there is a unique morphism $h \colon r' \to r$ of $D$ such that

\[
\tau\circ \psi = \psi' \circ D(h,-) \colon D(r,-) \overset{\cdot}\to K'.
\]
#+end_statement

The following natural transformation

\[\begin{tikzcd} 
\mathrm{hom}(r,-) \rar{\psi}&
K \rar{\tau}&
K' \rar{\psi'^{-1}}& 
\mathrm{hom}(r',-),
\end{tikzcd}\]

[[*Corollary to Yoneda Lemma][must]] have the form $h_{\ast}$ for a unique $h\colon r' \to r$, so $\tau \circ \psi = \psi' \circ h_{\ast}$.

****** TODO Exercise III.2.2
#+begin_statement
State the dual of the Yoneda Lemma ($D$ replaced by $D^{op}$).
#+end_statement

***** III.3. Coproducts and colimits
****** DONE Exercise III.3.1
#+begin_statement
In the category of commutative rings, show that $R \to R \otimes S \gets S$, with maps
$r \mapsto r \otimes 1$, $s \mapsto 1\otimes s$, is a coproduct diagram.
#+end_statement

Given $\alpha\colon R \to T$ and $\beta\colon S \to T$; the unique homomorphism making the diagram
commute must be defined by

\[f(r\otimes s) = f(r\otimes 1)f(1 \otimes s) = \alpha(r) \beta(s).\]
***** III.4. Products and limits
****** DONE Exercise III.4.1
#+begin_statement
In $\mathtt{Set}$, show that the pullback of $f\colon X \to Z$ and $g \colon Y \to Z$ is given
by the set of pairs $\left\{ (x,y) \mid x \in X, y \in Y, fx = gy \right\}$. Describe pullbacks
in $\mathtt{Top}$.
#+end_statement

Let $h_x,h_y$ be two functions such that $f(h_x(c)) = g(h_y(c))$. Then the only
possible $\phi \colon C \to P = \left\{ (x,y) \mid fx =gy \right\}$ is $\Phi(c) = (h_xc,h_yc) \in P$.

In $\mathtt{Top}$, the pullback is similar: it is a subspace of the product given
by $\left\{ (x,y) \mid fx = gy \right\}$.

****** DONE Exercise III.4.4
#+begin_statement
In any category, prove that $f\colon a \to b$ is epi if and only if the following
square is a pushout

\[\begin{tikzcd}
a\rar{f} \dar[swap]{f} & b \dar{1} \\
b\rar{1} & b &.
\end{tikzcd}\]
#+end_statement

The usual definition of epimorphism is equivalent to the universal
property.

****** DONE Exercise III.4.5
#+begin_statement
In a pullback square, show that $f$ monic implies $q$ monic.
#+end_statement

If $n,m \colon c \to b \times d$, with $n\pi_2 = m\pi_{2}$; as we know that $n\pi_1 f = m\pi_1 f$, we
can use monicity to get $n\pi_1 = n\pi_2$. By universal property of the pullback
square, $n = m$.

***** III.5. Categories with Finite Products
****** DONE Exercise III.5.1
#+begin_statement
Prove that the diagonal $\delta_c \colon c \to c \times c$ is natural in $c$.
#+end_statement

We use the identity $\pi_1\delta_c = 1_c = \pi_2\delta_c$ to create the four commutative
triangles that we use in this diagram. The commutativity of the diagram
follows from the universal property of the product.

\[\begin{tikzcd}
& c\dar{\delta}\dlar[swap,bend right]{id}\drar[bend left]{id} & \\
c \dar{f} & c \times c\lar[swap]{\pi}\rar{\pi} \dar{f \times f} & c \dar{f} \\
d\drar[bend right]{\delta} & d \times d \lar[swap]{\pi}\rar{\pi}\dar{id} & 
d\dlar[bend left,swap]{\delta} \\
& d\times d \\
\end{tikzcd}\]

****** TODO Exercise III.5.5
#+begin_statement
If $B$ has (finite) products show that any functor category $B^C$ also has (finite)
products (calculated "pointwise").
#+end_statement
**** IV. Adjoints [1/2]
***** IV.1. Adjunctions
****** DONE Exercise IV.1.2
#+begin_statement
Given functors $G\colon A \to X$ and $F \colon X \to A$, show that each adjunction $\left\langle F,G,\varphi \right\rangle$ can
be described as an isomorphism $\theta$ of comma categories such that the following diagram
commutes

\begin{tikzcd}[column sep=none]
\theta\colon & (F \downarrow I_{A})\dar & \cong & (I_x \downarrow G)\dar \\
& X \times A & = & X \times A & &.
\end{tikzcd}

Here the vertical maps have components the projection functors $P$ and
$Q$ of II.6(5).
#+end_statement

Given an adjunction $\varphi \colon \mathrm{hom}(Fx,y) \cong \mathrm{hom}(x,Gy)$, we can define the isomorphism
in objects as $\theta(f \colon Fx \to y) = (\varphi f \colon x \to Gy)$. And the isomorphism on morphisms
as

\begin{tabular}{ccc}
\begin{tikzcd}
Fx \dar{f}\rar{Fk} & Fx' \dar{f'} \\
y \rar{h} & y'
\end{tikzcd} 
& \Longrightarrow &
\begin{tikzcd}
x \dar{\varphi f}\rar{k} & x' \dar{\varphi f'} \\
Gy \rar{Gh} & Gy'
\end{tikzcd}
\end{tabular}

where the commutativity of the second diagram follows from the commutativity of the
first one if we apply naturality of $\varphi$. This $\theta$ is bijective and respects composition
trivially. The given diagram commutes.

# Are all isomorphisms on this form adjunctions?

****** TODO Exercise IV.1.3
#+begin_statement
For the adjunction $\left\langle \Delta,\times,\varphi \right\rangle$, show that the unit $\delta_c : c \to c \times c$ for each object
$c \in C$ is the unique arrow such that the diagram

\[\begin{tikzcd}
& C\drar{1}\dlar[swap]{1}\dar[dashed]{\delta_c} & \\
c & c \times c \rar[swap]{q}\lar{p} & c
\end{tikzcd}\]

commutes. This arrow is often called the /diagonal arrow/ of $c$. If $C = \mathtt{Set}$, show
that $\delta_cx = \left\langle x,x \right\rangle$ for $x \in c$.
#+end_statement

** Homotopy type theory book - Univalent Foundations
*** Part I
**** I.1. Type theory
***** I.1.1. Type theory versus set theory
****** Judgements and rules
Set theory is not only about seta but also about the interplay between /sets/
and /propositions/ of first-order logic, the system where sets are formulated.
In contrast, type theory does not need to be formulated inside any 
superstructure such as first-order logic. It is its own deductive system.

First-order logic is based on only one kind of judgment: whether any
given proposition as a proof; but in type theory, the basic judgment
is $a : A$, where $a$ is an element of the type $A$. Although it could
be seen as an analogous to $a \in A$ in set theory, the difference
resides in that $a \colon A$ is not a proposition but a judgment of
the theory. In particular, we cannot disprove those judgements and we
cannot talk about an element $a$ without specifying its type.

****** Propositional equality
Equality here is not a proposition but a type. Given $a,b : A$, we can define
the type $a =_A b$; we say that $a$ and $b$ are *propositionally equal* when this
type is unhabited.

****** Judgmental equality
*Judgmental equality* or *definitional equality* is an equality judgment
given by definitions: it can be decided expanding out the definitions. 
We write it as $a \equiv b$ and we introduce definitions as $a :\equiv b$.

****** Judgments of type theory
Type theory will be a system based on two forms of judgement

 * $a : A$, meaning $a$ has type $A$.
 * $a \equiv b : A$, meaning that $a$ and $b$ are definitionally equal.

****** Contexts
A *context* is a collection of assumptions in which a judgment may depend on.

# It can be thougt as a parameter space (?)
# https://en.wikipedia.org/wiki/Parameter_space

****** Rules and axioms of type theory
Rules of type theory can be grouped into type formers, procedural ways
to construct types. Usually, no axioms are necessary in type theory.

***** I.1.2. Function types
****** Functions
Given types $A,B$, $A \to B$ is the type of *maps* or *functions* between them.
Functions are a primitive concept of type theory; given $f : A \to B$, it can
be applied to $a \colon A$ to obtain $f a : B$.

******* Constructing functions
Given $\Phi$, an expression of type $B$ assuming $x : A$; we can define a function
as

\[
f(x) :\equiv \Phi,
\]

and also as a \lambda-expression, written as

\[
(\lambda (x:A) . \Phi) : A \to B,
\quad
\text{ or even }
\quad
(x \mapsto \Phi) : A \to B.
\]

****** \beta-reduction
*\beta-reduction* is a computation rule defined by

\[
(\lambda x. \Phi) (a) \equiv \Phi',
\]

where every ocurrence of $x$ in $\Phi$ has been replaced by $a$ in $\Phi'$, in a way that
the binding structure is preserved; maybe renaming variables.

****** \eta-reduction
*\eta-reduction*, often called /uniqueness principle for function types/
is the computation rule defined by

\[
f \equiv (\lambda x. f(x)).
\]

****** Currying
*Currying* is a way to define multiple-input functions as functions returning
partially aplied functions. For example, $f : A \to (B \to C)$ can be applied
to two arguments as $(f\ a)\ b : C$.

***** I.1.3. Universes and families
****** Universes
A *universe* is a type whose elements are types.

******* Russell's paradox
As in set theory, a universe of all types including itself, ${\cal U}_{\infty} : {\cal U}_{\infty}$, is
unsound.

******* Hierarchy of universes
A cumulative hierarchy of universes is defined, where every universe
is an elemtn of the next universe, ${\cal U}_i : {\cal U}_{i+1}$; and all the elements of
a universe are elements of all the higher universes.

\[
{\cal U}_0 : {\cal U}_1 : {\cal U}_2 : \dots
\]

*Typical ambiguity* is the writing style where we omit the level unless
it is necessary.

****** Families of types
A *family of types*, is a collection of types varying over a type
variable $A$. They are functions whose codomain is a universe, $f : A \to {\cal U}$.

***** I.1.4. Dependent function types (\Pi-types)
****** Dependent function types
Given $A : {\cal U}$ and $B : A \to {\cal U}$, we construct the type of *dependent functions*
as $\prod_{(x:A)}B(x) : {\cal U}$.

******* Constructing dependent functions
Given $\Phi : B(x)$, a expression assuming $x : A$, we can use \lambda-abstraction
to write

\[
\lambda x . \Phi(x) : \prod_{(x:A)} B(x).
\]

******* Reductions
\beta and \eta-reductions still hold on dependent functions.

****** Polymorphic functions
A *polymorphic function* takes a type as one of its arguments, and acts on
elements of that type.

******* The identity function
The polymorphic identity function $\mathrm{id} : \prod_{(A:{\cal U})} A \to A}$ is defined as
$\mathrm{id} =& \lambda (A:{\cal U}) . \lambda (x:A) . x$.

***** I.1.5. Product types
****** Cartesian product
Given $A,B : {\cal U}$, the *cartesian product type* $A \times B : {\cal U}$ contains pairs
$(a,b) : A \times B$, where $a:A$ and $b:B$. A function on a product type is
defined by

\[
f((a,b)) :\equiv g(a)(b),
\]

where $g : A \to B \to C$.

****** Unit type
The *unit type* $1$ has a unique element $\star : 1$.

****** TODO Introducing new types
****** Product type recursor
The *recursor* for product types symbolizes the fact that we can define a 
function on a product type only by giving its value on pairs,

\[ \mathtt{rec}_{A \times B}(C,g,(a,b)) = g(a)(b),
\]

where it has type

\[ \mathtt{rec}_{A \times B} : \prod_{C : {\cal U}} (A \to B \to C) \to A \times B \to C.
\]

****** TODO Unit type recursor

****** TODO Product type dependent recursor
****** TODO Propositional uniqueness principle
****** Induction principle on product types
The induction principle on product types has type

\[ \mathtt{ind}_{A \times B} :
\prod_{C : A \times B \to {\cal U}}
\left( \prod_{(x:A)} \prod_{(y:B)} C((x,y)) \right) \to
\prod_{(x:A \times B)} C(x)
\]

and defining equation $\mathtt{ind}_{A \times B} (C,g,(a,b)) :\equiv g(a)(b)$.

****** TODO Induction principle on unit types

***** I.1.6. Dependent type pairs (\Sigma-types)
****** TODO Type-theoretic axiom of choice
****** Example: Magmas
We can define a *magma* as

\[ \mathtt{magma} :\equiv
\sum_{A : {\cal U}} A \to A \to A.
\]
***** I.1.7. Coproduct types
****** TODO Coproduct type
****** TODO Empty type
***** I.1.8. The type of booleans
****** TODO if-then-else
****** TODO Coproducts as dependent types
***** I.1.9. The natural numbers
****** TODO Natural numbers
****** Addition
We define $\mathsf{add} : \mathbb{N} \to \mathbb{N} \to \mathbb{N}$ as

 * $\mathsf{add}(0,n) \equiv n$,
 * $\mathsf{add}(\succ(m),n) \equiv \succ(\mathsf{add}(m,n))$.

****** TODO Associativity
***** I.1.10. Pattern matching and recursion
We would like to define a function only writing its /defining equations/.
An example of this is this =double= function

\[\begin{aligned} 
\mathtt{double}(0) &:\equiv 0 \\ 
\mathtt{double}( \mathtt{succ}(n) ) &:\equiv \mathtt{succ} (\mathtt{succ} (\mathtt{double} (n))).
\end{aligned}\]

This style is called *pattern matching*; it is similar to recursion but
it is limited in the recursive calls it can use. Explicitly, it can be used
only as a shorthand for writing a definition using the recursor. Given

\[\begin{aligned} 
f(0) &:\equiv \Phi_0 \\ 
f( \mathtt{succ}(n) ) &:\equiv \Phi_{s},
\end{aligned}\]

we need $\Phi_s$ to depend on $f$ only via $f(n)$ in order to be well-defined as

\[
f :\equiv \mathtt{rec}_{\mathbb{N}} (C,\Phi_0,\lambda n. \lambda r. \Phi'_{s}).
\]

***** I.1.11. Propositions as types
An element of the type corresponding to a proposition is a *witness* or 
a *proof* of the truth of that proposition. From this perspective, proofs
are mathematical objects per se.

# Cite Wadler

****** Falsity and negation

****** Constructive logic
The natural interpretation of propositions-as-types is /constructive/,
meaning that certain tautologies on classical logic, such as the 
*law of excluded middle* (LEM) do not hold.

The logic is still compatible with the presence of the LEM as an axiom.

***** I.1.12. Identity types

\[ \mathtt{refl} : \prod_{a:A} (a =_A a)
\]

**** I.2. Homotopy type theory
In homotopy type theory, each type has the structure of an
$\infty\text{-groupoid}$, arising from the induction principle for
identity types.

Homotopy type theory provides a /synthetic/ description of the spaces,
in contrast with the usual analytic approach of topology.

***** 2.1. Types are higher groupoids
****** 2.1.1. Path inverse
Given $x,y : A$, there is a function called *inverse*

\[
(-)^{-1} : (x = y) \to (y = x)
\]

such that $\refl^{-1} = \refl$.

******* Proof
Given $p : x = y$, we apply path induction and then provide $\refl : x = x$.

****** 2.1.2. Path composition
Given $x,y,z : A$, there is a function called *concatenation*

\[
\cdot : (x = y) \to (y = z) \to (x = z)
\]

such that $\refl \cdot \refl = \refl$.

******* First proof
Given $p \cdot q$, we apply path induction on $p$ and $q$. Definitionally,
we can provide an element of $x = x$,

\[
\refl \cdot \refl = \refl
\]

******* Second proof
We apply path induction over $p$, and provide $q$ as an element
of $x = z$. We have $\refl \cdot q \equiv q$.

******* Third proof
We apply path induction over $q$, and provide $p$ as an element
of $x = y$. We have $p \cdot \refl \equiv p$.

******* Proof-relevance and definitional equalities
These three proofs are not definitionally equal, and they provide
different functions with sightly different definitions. In particular,
we get three different definitional equalities

 1) $\refl \cdot \refl \equiv \refl$,

 2) $p \cdot \refl \equiv p$,

 3) $\refl \cdot q \equiv q$;

and, while doing informal mathematics, we will prefer the symmetry of
the first one.

****** TODO 2.1.4. Path operation properties

****** TODO 2.1.6. Eckmann-Hilton
****** 2.1.7. Pointed type
A *pointed type* is a type with a basepoint of that type. That is,
${\cal U}_{\bullet} :\equiv \sum_{A:{\cal U}} A$ is the type of pointed types.

****** 2.1.8. Loop spaces
Given a pointed type $(A,a)$, we define the *loop space* as

\[
\Omega(A,a) :\equiv ((a=a),\refl_a)
\]

and the *n-fold iterated loop space* recursively as

 * $\Omega^0(A,a) :\equiv (A,a)$,

 * $\Omega^{n+1}(A,a) :\equiv \Omega^n(\Omega(A,a))$.

***** 2.2. Functions are functors
****** 2.2.1. Definition of ap
Given $f: A \to B$, there is an operation

\[
\ap_f : x=y \to f(x) = f(y)
\]

such that $\ap_f(\refl) \equiv \refl_{f(x)}$.

******* Notation
We write $\ap_f(p)$ as $f(p)$.

******* Proof
Trivially defined by path induction.

****** 2.2.2. Functioriality of ap
Given $f : A \to B$ and $g : B \to C$ and paths $p : x = y$ and
$q : y = z$, we have

 1) $\ap_f(p \cdot q) = \ap_f(p) \cdot \ap_f(q)$
 2) $\ap_f(p^{-1}) = ap_f(p)^{-1}$
 3) $\ap_g(\ap_f(p)) = \ap_{g \circ f}(p)$
 4) $\ap_{id_A}(p) = p$

******* Proof
Trivial by path induction on $p$.

***** 2.3. Type families are fibrations
****** 2.3.1. Transport
Given $P : A \to {\cal U}$ and $p : x = y$, there exists a function

\[
p_{\ast} : P(x) \to P(y),
\]

such that $\refl_{\ast}$ is the identity.

******* Notation
Sometimes we notate transport as

\[
p_{\ast} \equiv \transport^P(p,-) : P(x) \to P(y).
\]

******* Proof
Applying path induction over $p$, $x \equiv y$ and $\id : P(x) \to P(x)$
is an inhabitant of the type.

****** 2.3.2. Path lifting property
Given $P : A \to {\cal U}$ and $u : P(x)$, for any $p : x = y$,

\[
\mathsf{lift}(u,p) : (x,u) = (y, p_{\ast}(u));
\]

in $\sum_{x:A}P(x)$ such that $\mathsf{pr}_1(\mathsf{lift}(u,p)) = p$.

******* Proof
The first component is given by $p$, the second one can be defined
applying path induction over $p$ and, knowing that $x \equiv y$ and thus,
$u \equiv p_{\ast}(u)$.

****** 2.3.4. Dependent map
Given $f : \prod_{x:A} P(x)$ there exists a map

\[
\apd_f : \prod_{p : x=y} p_{\ast}(f(x)) =_{P(y)} f(y)
\]

******* Proof
Path induction.

****** TODO 2.3.5. Constant transport
****** TODO 2.3.8. Constant plus dependent transport
****** 2.3.9. Transport composition lemma
Given $P : A \to {\cal U}$, $p : x = y$ and $q : y = z$, for $u : P(x)$ we have

\[
q_{\ast}(p_{\ast}(u)) = (p \cdot q)_{\ast} (u).
\]

******* Proof
Double path induction.

****** TODO 2.3.10. Transport precomposition lemma
****** TODO 2.3.11. Naturality of transport
***** 2.4. Homotopies and equivalences
****** 2.4.1. Homotopy
A *homotopy* between $f, g : \prod_{x:A} P(x)$ is a dependent function
of type

\[
(f \sim g) :\equiv \prod_{x:A} f(x) = g(x).
\]

****** 2.4.2. Homotopy is an equivalence relation
Homotopy is an equivalence relation on each dependent function
type $\prod_{x:A} P(x)$. We have elements of

 1) reflexivity

    \[
    \prod_{f:\prod_{x:A} P(x)} (f \sim f)
    \]

 2) symmetry

    \[
    \prod_{f,g : \prod_{x:A}P(x)} (f \sim g) \to (g \sim f)
    \]

 3) transitivity

    \[
    \prod_{f,g,h : \prod_{x:A} P(x)} (f \sim g) \to (g \sim h) \to (f \sim h)
    \]

******* Proof
Given any $f$ and $x$, $\refl$ is of type $f(x) = f(x)$.

Given any $f,g$ such that $f \sim g$, for every $x$, we have an inhabitant of
$f \sim g$. By path induction, it must be $\refl$, so $\refl : g(x) = f(x)$.
 
Given any $f,g,h$ such that $f \sim g$ and $g \sim h$, for every $x$, we
have $f(x) = g(x) = h(x)$, and, in particular $f(x) = h(x)$.

****** 2.4.3. Naturality of homotopies
Given $H : f \sim g$ and $p : x = y$, 

\[
H(x) \cdot g(p) = f(p) \cdot H(y).
\]

As a commutative diagram,

\[\begin{tikzcd}
f(x)\rar[equal]{f(p)} \dar[swap,equal]{H(x)} & 
f(y)\dar[equal]{H(y)} \\
g(x)\rar[equal]{g(p)} &
g(y)
\end{tikzcd}\]


******* Proof
By path induction, $p = \refl$, and $\ap$ computes on reflexivity.

****** 2.4.4. Endonaturality of homotopies
Given $H : f \sim \id_{A}$, for any $x : A$,

\[
H(f(x)) = f(H(x))
\]

******* Proof
By naturality, and knowing that $H(x) : f(x) = x$, 

\[\begin{tikzcd}
f(x)\rar[equal]{f(H(x))} \dar[swap,equal]{H(x)} & 
f(f(x))\dar[equal]{H(f(x))} \\
x\rar[equal]{H(x)} &
f(x)
\end{tikzcd}\]

thus,

\[
f(H(x)) \cdot H(x) = H(f(x)) \cdot H(x),
\]

and then $f(H(x)) = H(f(x))$.

****** 2.4.6. Quasi-inverse
A *quasi-inverse* of $f : A \to B$ is a triple $(g,\alpha,\beta)$ with homotopies
$\alpha : f \circ g \sim \id_B$ and $\beta : g \circ f \sim \id_A$.

\[
\mathsf{qinv}(f) = \sum_{g:B \to A} (f \circ g \sim \id) \times (g \circ f \sim \id).
\]

****** 2.4.9. Transport has a quasi-inverse
The transport $p : x = y$ for $P \colon A \to {\cal U}$,

\[
\mathsf{transport}^P(p,-) : P(x) \to P(y)
\]

has a quasiinverse $\transport^P(p^{-1},-)$.

***** 2.5. Higher groupoid structure of type formers

***** 2.6. Cartesian product types
****** 2.6.2. Cartesian product equalities
For any $x,y$, the function

\[
x = y \to (\proj_1(x) = \proj_1(y)) \times (\proj_2(x) = \proj_2(y))
\]

given by applying projections to the equality, is an equivalence.
We denote the quasiinverse as

\[
\mathsf{pair}^{=} :
(\proj_1(x) = \proj_1(y)) \times (\proj_2(x) = \proj_2(y))
\to
x = y.
\]

******* Proof
We will define a function in the other direction. By induction,
we assume $x \equiv (a,b)$ and $y \equiv (a',b')$; thus we have $a = a'$
and $b = b'$. We apply path induction to both paths and we
get that $(a,b) \equiv (a',b')$.

Now we have to prove that it is a quasiinverse. In one direction,
if we have $r : x = y$, we apply path induction and we get the
pair $(\refl_{\proj_1(x)}, \refl_{\proj_2(x)})$. If we apply induction to $x$, we
get $(\refl_a,\refl_{b})$; our inverse takes this to $\refl_{(a,b)}$.

In the other direction, if we have $p : a = a'$ and $q : b = b'$,
we apply induction to get $\refl_{(a,b)}$; applying a function to
reflexivity gives again $(\refl_a, \refl_b)$.

****** 2.6.4. Cartesian product transport
Given two type families $A,B : Z \to {\cal U}$ and a path $p : z = w$,
for every $x : A(z) \times B(z)$,

\[
p_{\ast}(x) = (\transport^A(p,\proj_1(x)), \transport^B(p,\proj_2(x)))
\]

******* Proof
By path induction, it remains to prove

\[
x = (\proj_1(x), \proj_2(x)),
\]

which is definitionally equal.

****** 2.6.5. Functoriality under cartesian products
Given $x,y : A \times B$, $p,q$ path between components. For every function
defined as $f(x) :\equiv (g(\proj_1(x)), h(\proj_2(x)))$, it holds that

\[
f(\mathsf{pair}^{=}(p,q)) = \mathsf{pair}^{ =}(g(p),h(q)).
\]

******* Proof
We first apply induction over $x$, and then path induction over
$p,q$. We get reflexivity in both sides.

***** 2.7. Sigma types
****** 2.7.2. Sigma type equalities
Given a type family $P : A \to {\cal U}$, there is an equivalence

\[
(w = w') \simeq \sum_{p : \proj_1(w) = \proj_1(w')} 
p_{\ast}(\proj_2(w)) = \proj_2(w'). 
\]

This can be seen as an introduction $\pair^{=}$ and elimination rules
for equalities between dependent pairs.

******* Proof
******** First component of the equivalence
We define the first part of the equivalence depending on
$w,w' : \sum_{x:A}P(x)$, of type

\[
f : \prod_{w,w' : \sum_{x:A}P(x)} 
\left(
(w=w') \to
\sum_{p:\proj_1(w) = \proj_1(w')} p_{\ast}(\proj_2(w)) = \proj_2(w')
\right)
\]

by induction on the path $w = w'$ as

\[
f(w,w,\refl) = (\refl_{\pr_1(w)}, \refl_{\pr_2(w)}).
\]

******** Second component of the equivalence
And we define the second part of the equivalence depending
again on both $w,w'$, of type

\[
g : \prod_{w,w' : \sum_{x:A}P(x)}
\left( \left(
\sum_{p:\pr_1(w) = \pr_1(w')}  
p_{\ast}(\pr_2(w)) = \pr_2(w')
\right)
\to (w = w')
\right)
\]

defined by induction on $w = (x,y)$ and $w' = (x',y')$ first and then on
$p : x = x'$ and $p_{\ast}(y) = y'$, to get

\[
g((x,y),(x,y),\refl,\refl) = \refl_{(x,y)}.
\]

******** First homotopy
Finally, we have to show that they form an equivalence. Given any $w,w'$ and

\[
r : \sum_{p:\pr_1(w) = \pr_1(w')} p_{\ast}(\pr_2(w)) = \pr_2(w'),
\]

we can apply induction over both $w = (x,y)$ and $w' = (x',y')$, and then over
$r$ to get paths $p : x = y$ and $p_{\ast}(y) = y'$. By path induction and the definition
of $f$ and $g$, we get the desired result, $f(g(r)) = r$.

******** Second homotopy
On the other hand, if we have $p : w = w'$, we can directly apply path induction
and use the definitions to get $g(f(p)) = p$.

****** 2.7.3. Sigma equality to its parts
For any $z : \sum_{x:A}P(x)$, we have $z = (\pr_1(z),\pr_2(z))$.

******* Proof
By induction on $z = (x,y)$, we trivially arrive at an
identity path.

# HoTT MAILING LIST !

******* Proof in HoTT book
Applying the [[*2.7.2. Sigma type equalities][previous lemma]], we only have to provide evidence
for the equality of both projections. We trivially have

\[
\pr_1(z) = \pr_1(\pr_1(z),\pr_2(z))
\]

and by judgmental equality, it is trivial that

\[
(\refl_{\pr_1(z)})_{\ast}(\pr_2(z)) = \pr_2(z) = \pr_2(\pr_1(z),\pr_2(z)).
\]

****** 2.7.4. Transport over sigma equalities
Given $P : A \to {\cal U}$ and

\[
Q : \left( \sum_{x:A} P(x) \right) \to {\cal U},
\]

for any path $p : x = y$, and $(u,z) : \sum_{u:P(x)} Q(x,u)$ we have

\[
p_{\ast}(u,z) = 
(p_{\ast}(u), \pair^{=}(p,\refl_{p_{\ast}(u)})_{\ast} (z)).
\]

***** 2.8. The unit type
****** Unit type equality
Given $x,y:1$, we have $(x = y) \simeq 1$.

******* Proof
A function $(x = y) \to 1$ is defined trivially; and given any $x, y : 1$
we now by induction that $x \equiv y$ and we can write a constant function
to $\refl_{\star}$.

Given an element $u : 1$, it is trivial that the composite is an element
of $1$, and therefore both are equal to $\star$. Given an element $p : x = y$,
we can apply path induction to get $p = \refl_{x}$ and induction over $x$ to
get $\refl_{\star}$. As a consequence, $p$ goes to $\refl_{\star}$.

***** 2.9. The function extensionality axiom
****** 2.9.2. happly
There exists a function

\[
\happly : (f = g) \to \prod_{x:A} f(x) = g(x)
\]

defined by path induction.

****** 2.9.3. Function extensionality axiom
The function $\happly$ is an equivalence. It has a quasi-inverse given
by

\[
\funext : \left(\prod_{x:A} f(x) = g(x)\right) \to (f = g).
\]

such that, for any $h : \prod_{x:A} f(x) = g(x)$,

\[
\happly(\funext(h), x) = h(x).
\]

****** TODO 2.9.4. Dependent identity, inverses and composition

****** 2.9.4. Rules for dependent transport
Given $f : A(x) \to B(x)$ and $p : x = y$,

\[
p_{\ast}(f) = p_{\ast}\circ f \circ p^{-1}_{\ast}.
\]

******* Proof
Path induction.

****** 2.9.6. Equivalence for the dependent function equality
Given $A,B : X \to {\cal U}$, $p : x = y$ and two functions $f : A(x) \to B(x)$
and $g : A(y) \to B(y)$, we have an equivalence

\[
(p_{\ast}(f) = g) \simeq \prod_{a:A(x)} p_{\ast}(f(a)) = g(p_{\ast}(a)).
\]

Moreover, given $q : p_{\ast}(f) = g$, we have

\[
\happly(q,p_{\ast}(a)) : (p_{\ast}(f))(p_{\ast}(a)) = g(p_{\ast}(a))
\]

equal to the composite

\[
p_{\ast}(f)(p_{\ast}(a)) = p_{\ast}(f(p^{-1}_{\ast}(p_{\ast}(a))))
= p_{\ast}(f(a)) = g(p_{\ast}(a)).
\]

******* Proof
By path induction on $p$, we arrive to function extensionality.
Computation rule for function extensionality gives us the value
of $\happly$.

****** TODO 2.9.7. Transport equivalence between families
***** 2.10. Universes and the univalence axiom
****** 2.10.1. idtoeqv
Given any types $A,B : {\cal U}$, there is a function

\[
\idtoeqv : (A = B) \to (A \simeq B).
\]

******* TODO Proof

****** 2.10.3. Voevodsky's Univalence Axiom
A universe is univalent if for any $A,B : {\cal U}$, $\idtoeqv$ is an equivalence.
All universes are univalent. There exists

\[\ua : (A \simeq B) \to (A = B),
\]

such that 

\[
\transport(\ua(f), x) = f(x).
\]

****** TODO 2.10.5. Transport and idtoeqv
***** 2.11. Identity type
****** 2.11.1. Aplication of equivalences is an equivalence
If $f : A \to B$ is an equivalence, so is

\[
\mathsf{ap}_f : (a = a') \to (f(a) = f(a')).
\]

******* Proof
Let $f^{-1}$ be a quasiinverse with homotopies

\[
\alpha : \prod_{b:B} f(f^{-1}(b)) = b
\quad\mbox{ and }\quad
\beta : \prod_{a:A}f^{-1}(f(a)) = a.
\]

the quasiinverse of $\ap_f$ will be $\ap_{f^{-1}}$ concatenated with $\beta^{-1}$ and $\beta$.
We will show that this is a quasiinverse. On one direction,

\[
\beta_a^{-1} \cdot \ap_{f^{-1}}(\ap_f(p)) \cdot \beta_{a'} = p
\]

is true by [[*2.4.4. Endonaturality of homotopies][endonaturality of the homotopy]] $\beta$ and functoriality
of the application $\ap_{f^{-1}} \circ \ap_f = \ap_{f^{-1} \circ f}$.

****** 2.11.2. Path transport
Given any $a : A$ with $p : x_1 = x_2$,

 1) for $q : a = x_1$, we have $\transport^{x \mapsto a=x}(p,q) = p_{\ast}(q) = q \cdot p$;
 2) for $q : x_1 = a$, we have $\transport^{x\mapsto x=a}(p,q) = p^{-1} \cdot q$;
 3) for $q : x_1 = x_1$, we have $\transport^{x\mapsto (x=x)}(p,q) = p^{-1} \cdot q \cdot p$.

******* Proof
By path induction on $p$, we get the composition rules for
reflexivity.

***** 2.12. Coproducts
****** 2.12.1. Characterization of equalities for coproducts
Given a coproduct type $A + B$, 

 * $(\inl(a_1) = \inl(a_2)) \simeq (a_1 = a_{2})$,
 * $(\inr(b_1) = \inr(b_2)) \simeq (b_1 = b_2)$,
 * $(\inl(a) = \inr(b)) \simeq 0$.

******* Proof
Given $a_0 : A$ we will characterize the family

\[
(x \mapsto (\inl(a_0) = x)) : A + B \to {\cal U},
\]

using the following type family

 * $\code(\inl(a)) :\equiv (a_0 = a)$,
 * $\code(\inr(a)) :\equiv 0$.

and proving that $(\inl(a_0) = x) \simeq \code(x)$ in the following
[[*2.12.5. Code for coproducts][lemma]]. An analogous family $(x \mapsto (\inr(b_0) = x))$ can be also
characterized.

****** 2.12.5. Code for coproducts
Given $a_0 : A$, for all $x:A+B$, we have $(\inl(a_0) = x) \simeq \code(x)$;
with the definition presented in the previous [[*2.12.1. Characterization of equalities for coproducts][proof]].

******* Proof
We first define a function

\[
\encode : \prod_{(x:A+B)} \prod_{(p : \inl(a_0) = x)} \code(x)
\]

using transport, as $\encode(\inl(a), p) = p_{\ast}(\refl_{a_0})$. Next, we define
a function

\[
\decode : \prod_{(x : A+B)}\prod_{(c : \code(x))} (\inl(a_0) = x)
\]

by induction on $x$ as

 * $\decode(\inl(a), c) :\equiv \ap_{\inl}(c)$,
 * $\decode(\inr(b),c) :\equiv \mathsf{abort}(c)$.

Now, we must prove that they form an equivalence. On the one hand, given
$x : A +B$ and $p : \inl(a_0) = x$, we must show that

\[
\decode(x,\encode(x,p)) = p;
\]

and this can be done by path induction on $p$. On the other hand, given
any $c : \code(x)$, we want to prove that

\[
\encode(x,\decode(x,c)) = c;
\]

and we can proceed by induction on $x$; if $x \equiv \inr(b)$, then we arrive at
a contradiction in $c$; in other case, $x \equiv \inl(a)$ so we can apply path
induction on $c$.

***** 2.13. Natural numbers
****** 2.13.0. Codes for identities on natural numbers
We define $\mathsf{code} \colon \mathbb{N} \to \mathbb{N} \to {\cal U}$ by double recursion as

 * $\code(0,0) :\equiv 1$,
 * $\code(\succ(m),0) :\equiv 0$,
 * $\code(0,\succ(n)) :\equiv 0$,
 * $\code(\succ(m),\succ(n)) :\equiv \code(m,n)$,

and trivially, a diagonal function $r : \prod_{n:\mathbb{N}} \code(n,n)$ by induction.

****** 2.13.1. Equivalence code-identity
We have $(n = m) \simeq \code(m,n)$.

******* Proof
******** Encode function
We define a function $\prod_{m,n \colon \mathbb{N}} (n = m) \to \code(m,n)$ by transport
and using the diagonal $r : \prod_{n:\mathbb{N}} \code(n,n)$.

******** Decode function
We define a function $\prod_{m,n\colon \mathbb{N}} \code(m,n) \to (n = m)$ by double induction
on $n$ and $m$.

 * On the case $n=m=0$, we define a function to $\refl_0$.
 * On the cases where only one of them is zero, we arrive a contradiction.
 * On the case were both are successors, we have an element $\code(m,n)$, so
   we can recursively apply the decode function to it to get $m = n$. Now
   it suffices to use $\ap_{\succ}$.

******** Quasiinverses I
We will show first that given any $p : m = n$,

\[
\decode(n,n,\encode(n,n,\refl)) = \refl,
\]

which is to show $\decode(n,n,r(n)) = \refl$. This can be done by induction
on $n$, where in the case $0$, we get reflexivity and in the successor case,
we use that $\ap(\refl) = \refl$.

******** Quasiinverses II
Given any $c : \code(m,n)$, we can apply double induction.

 * In the zero case, we have a unit type that remains the same after
   encoding.
 * In the only one successor case, we arrive a contradiction.
 * In the both successor cases, 
   \[\begin{aligned}
   \encode&(\succ(m),\succ(n),\decode(\succ(m),\succ(n),c)) \\
     &= \encode(\succ(m),\succ(n),\ap_{\succ}(\decode(m,n,c))) \\
     &= (\ap_{\succ}(\decode(m,n,c)))_{\ast} (r(\succ(m))) \\
     &= (\decode(m,n,c))_{\ast} (r(m)) \\
     &= \encode(m,n,\decode(m,n,c)) \\
     &= c
   \end{aligned}\]
   by induction.

In other words, we can prove that each code is a diagonal and then
apply induction over $\decode(m,n,c)$.

****** 2.13.2. Zero is not a successor
We have that zero is not the successor of any natural number,
in particular

\[
\encode(\succ(m),0) : (\succ(m) = 0) \to 0.
\]

******* Proof
Applying [[*2.13.1. Equivalence code-identity][decode-encode]] directly.

****** 2.13.3. Successor is injective
The sucessor function is injective, in particular

\[
(\succ(m) = \succ(n)) \to (m = n).
\]

******* Proof
We can apply $\encode$ to the equality and get a new code
to which apply $\decode$. Note that

$\encode(\succ(m),\succ(n)) : \code(m,n)$

is well-typed.

***** 2.14. Example: equality of structures
****** 2.14.1. Semigroup structures
The type of *semigroup structures* on $A$ is defined as

\[
\mathsf{SemigroupStr}(A) :\equiv \sum_{(m : A \to A \to A)} \prod_{(x,y,z : A)} m(x,m(y,z)) = m(m(x,y),z)
\]

and a *semigroup* is defined in general as

\[
\mathsf{Semigroup} :\equiv \sum_{A : {\cal U}} \mathsf{SemigroupStr}(A).
\]

****** 2.14.1. Induced structures
Given an equivalence $e : A \simeq B$, we can transport semigroup
structures

\[
(\ua(e))_{\ast} : \mathsf{SemigroupStr}(A) \to \mathsf{SemigroupStr}(B).
\]

Given $(m,a) : \mathsf{SemigroupStr}(A)$, we want to compute

\[
\ua(e)_{\ast} (m,a) : \mathsf{SemigroupStr}(B)
\]

and transporting over a [[*2.7.4. Transport over sigma equalities][coproduct]] is the same as transporting over its
components. We will get some $(m',a')$ where

 * $m'(b_1,b_2) :\equiv (\ua(e)_{\ast}(m))(b_1,b_2)$;

 * $a' :\equiv (\pair^{=}(\ua(e), \refl))_{\ast}\ a$.

By function extensionality, we only have to check the behaviour of
$m'$ given a pair of arguments. We have,
# UA is quasi-inverse to transport^(X \to X)

\[\begin{aligned}
m'(b_1,b_2) &=
\ua(e)_{\ast} (m (\ua(e)_{\ast}^{-1} b_1, \ua(e)_{\ast}^{-1} b_2)) \\
&= e(m(e^{-1}b_1,e^{-1}b_2))
\end{aligned}\]

It can be proved that the transported $a'$ works by algebraic
manipulation using this fact.

***** 2.15. Universal properties
****** 2.15.2. Universal property of the product
There is an equivalence

\[
(X \to A \times B) \simeq (X \to A) \times (X \to B);
\]

given by $f \mapsto (\pr_1 \circ f, \pr_2 \circ f)$.

******* TODO Proof

****** 2.15.5. Dependent universal property of the product
There is an equivalence

\[
\left( \prod_{x:X} A(x) \times B(x) \right) \simeq
\left( \prod_{x:X} A(x) \right) \times 
\left( \prod_{x:X} B(x) \right)
\]

given by $f \mapsto (\pr_1 \circ f, \pr_2 \circ f)$.

******* TODO Proof

****** 2.15.7. Theorem of choice
There is an equivalence

\[
\left( \prod_{x:X}\sum_{(a : A(x))} P(x,a) \right) \simeq
\left( \sum_{g : \prod_{x:X}A(x)} \prod_{x:X} P(x,g(x)) \right)
\]

trivially determined.

******* TODO Proof

****** 2.15.11. Pullbacks
Given $f : A \to C$ and $g : B \to C$, we define the *pullback* as

\[
A \times_C B :\equiv \sum_{(a:A)}\sum_{(b:B)}(f(a) = g(b)).
\]

**** I.3. Sets and logic
***** 3.1. Sets and n-types
****** 3.1.1. Sets
A type $A$ is a *set* if every two equalities $p,q : x =_A y$ are equal.

\[
\textsf{isSet}(A) \equiv \prod_{(x,y : A)} \prod_{(p,q : x = y)} p = q.
\]

****** 3.1.6. Dependent product of sets is a set
Given $A$ a set and $B : A \to {\cal U}$ such that each $B(x)$ is a set, $\prod_{x:A} B(x)$ 
is a set.

******* Proof
Suppose $f, g : \prod_{x:A} B(x)$ and $p, q : f = g$. Applying function
extensionality,

 * $p = \mathsf{funext}(\lambda x. \mathsf{happly}(p,x))$,
 * $q = \mathsf{funext}(\lambda x. \mathsf{happly}(q,x))$.

Since $B(x)$ is a set, 

 * $\mathsf{happly}(p,x) : f(x) = g(x)$
 * $\mathsf{happly}(q,x) : f(x) = g(x)$

must be equal. Thus, by function extensionality $(\lambda x. \mathsf{happly}(p,x)) = (\lambda x. \mathsf{happly}(q,x))$,
and applying $\mathsf{funext}$, $p = q$.

****** 3.1.7. 1-types
A type $A$ is a *1-type* if for all $x,y:A$ and $p,q : x = y$ and $r,s : p = q$,
we have $r = s$.

****** 3.1.8. Every set is a 1-type
Every set is a *1-type*.

******* Proof
If we have $x,y : A$, $p,q : x = y$ and $f : \isSet(A)$, then we
can define $g = f(x,y,p)$ by partial application, and

\[
g : \prod_{q : x = y}(p = q);
\]

we can now, given $r : q = q'$, use dependent application to get

\[
\apd_g(r) : r_{\ast}(g(q)) = g(q').
\]

By path transport, that means that $g(q) \cdot r = g(q')$. In particular,
given any two $r,s : p = q$;

\[
g(p) \cdot r = g(q) = g(p) \cdot s
\]

and $r = s$ by cancellation.

****** 3.1.9. Not all types are sets
The universe ${\cal U}$ is not a set.

******* TODO Proof
We take $2$ to be the type of the booleans. There exists a
function $\mathrm{not}\colon 2 \to 2$ which is an equivalence; by univalence,
there exists $\ua(\mathrm{not}) \colon 2 = 2$ which is not $\refl$. If it were
$\refl$, then, by univalence, $0_2 = 1_2$.

***** 3.2. Propositions as types?
****** 3.2.2. Negation of double negation
It is not true that $\neg(\neg A) \to A$ for each $A : {\cal U}$.

******* Proof
Given $f \colon \prod_{A:{\cal U}} \neg(\neg A) \to A$, we will arrive to a contradiction.

Let $p \colon 2 = 2$ be the non-trivial path of the booleans. We know
that $f(2) : \neg\neg 2 \to 2$ and

\[
\apd_f(p) : p_{\ast}(f(2)) = f(2),
\]

applying [[*2.9.4. Rules for dependent transport][rules for dependent transport]], we have

\[
p_{\ast}(f(2))(u) = (p_{\ast} \circ f(2) \circ p_{\ast}^{-1})(u).
\]

Every two $u,v : \neg\neg 2$ are equal by function extensionality; thus

\[
p^{-1}_{\ast}(u) = u
\]

and so

\[
p_{\ast}(f(2)(u)) = p_{\ast}(f(2))(u) = f(2)(u).
\]

We have now that $\fnot(f(2)(u)) = f(2)(u)$, and, at the same time,
it is obvious that $\prod_{x:2} \neg (\fnot(x) = x)$.

****** 3.2.7. Negation of LEM
It is not true that $A + (\neg A)$ for each $A \colon {\cal U}$.

******* Proof
An element of type $\prod_{A:{\cal U}} \neg\neg A \to A$ can be constructed from
an element of type $\prod_{A:{\cal U}} A + (\neg A)$.

***** 3.3. Mere propositions
****** 3.3.1. Mere proposition
A type $P$ is a *mere proposition* when

\[
\isProp(P) : 
\prod_{x,y : P} x = y
\]

is inhabited.

****** 3.3.2. Truth is the only true mere proposition
If $P$ is a mere proposition and $x_0 : P$, then $P \simeq 1$.

******* Proof
A trivial equivalence can be constructed.

****** 3.3.3. Equivalence of connected mere propositions
If $P$ and $Q$ are mere propositions, $P \to Q$ and $Q \to P$
imply $P \simeq Q$.

******* Proof
If $f : P \to Q$ and $g : Q \to P$, then $f(g(x)) = x$ and
$g(f(x)) = x$ because both are mere propositions.

****** 3.3.4. Mere propositions are sets
Every mere proposition is a set.

******* Proof
Given $f : \isProp(A)$, we fix $x : A$ and define $g(y) :\equiv f(x,y)$
of type $\prod_{y : A} x = y$. Given two $y,z : A$ with $p : y = z$, we
have

\[
\apd_g(p) : p_{\ast}(g(y)) = g(z)
\]

hence $g(y) \cdot p = g(z)$, or $p = g(y)^{-1} \cdot g(z)$; thus given $p,q : x = y$
we have $p = g(x)^{-1} \cdot g(y) = q$.

****** 3.3.5. isProp and isSet are mere propositions
Given any type $A$, the types $\isSet(A)$ and $\isProp(A)$ are mere
propositions.

******* Proof
If we have $f,g : \isProp(A)$, we know that $f(x,y) = g(x,y)$ because
$A$ is a mere proposition. By function extensionality, $f = g$.

If we have $f,g : \isSet(A)$ we know that $f(x,y,p,q) = g(x,y,p,q)$
because $x = y$ is a mere proposition from the fact that $A$ is a set.
By function extensionality, $f = g$.

***** 3.4. Classical vs. intuitionistic logic
****** 3.4.1. Law of excluded middle
We define the *law of excluded middle* as

\[
\LEM :\equiv \prod_{A : {\cal U}} \Big( \isProp(A) \to (A + \neg A) \Big)
\]

whereas the usual general law of excluded middle is renamed as

\[
\LEM_{\infty} :\equiv \prod_{A : {\cal U}} (A + \neg A).
\]

The law of excluded middle can be assumed as an axiom.

****** 3.4.3. Decidable types
1. A type is *decidable* if $A + \neg A$.

2. A type family is *decidable* if

   \[
   \prod_{a : A} B(a) + \neg B(a)
   \]

3. A type has *decidable equality* if
   
   \[
   \prod_{a,b : A} (a = b) + \neg (a = b)
   \]

The Law of excluded middle says that all mere propositions are
decidable.

***** 3.5. Subsets and propositional resizing
****** 3.5.1. Uniqueness of dependent sum of mere propositions
Given $P \colon A \to {\cal U}$ such that $P(a)$ is always a mere proposition;
if $u,v \colon \sum_{x:A}P(x)$ are such that $\proj_1(u) = \proj_1(v)$, then
$u = v$.

******* Proof
Given $p : \proj_1(u) = \proj_1(v)$, we only have to show that

\[
p_{\ast}(\proj_2(u)) = \proj_2(v)
\]

and this is true because both are members of $P(\proj_1(v))$, a
mere proposition.

****** 3.5.1. Subtypes
If $P$ is a family of mere propositions, we write

\[
\sum_{x:A} P(x) \equiv \left\{ x : A\mid P(x) \right\}
\]

and call this a *subtype*. We can define membership and subsets
analogously.

******* Subuniverses of sets and mere propositions
We define

 * $\Set_{{\cal U}} :\equiv \left\{ A : {\cal U} \mid \isSet(A) \right\}$,
 * $\Prop_{{\cal U}} :\equiv \left\{ A : {\cal U} \mid \isProp(A) \right\}$.

There are natural maps $\Set_{{\cal U}_i} \to \Set_{{\cal U}_{i+1}}$.

****** 3.5.2. Propositional resizing
*Propositional resizing* is the fact that the natural map
$\Prop_{{\cal U}_i} \to \Prop_{{\cal U}_{i+1}}$ is an equivalence.

Propositional resizing can be taken as an axiom.

******* Omega-indexation of propositions
From propositional resizing follows the existence of $\Omega$, a
type that indexes mere propositions. If propositional resizing
is true, $\Omega :\equiv \Prop_{{\cal U}_0}$.

******* Powersets
If propositional resizing is true, we can define

\[
{\cal P}(A) :\equiv (A \to \Omega),
\]

which is independent of the universe.
***** 3.6. Logic of mere propositions
****** TODO 3.6.1. Product of mere propositions is a mere proposition
****** TODO 3.6.2. Dependent functions to mere propositions are mere propositions
****** TODO 3.6.2. Sums of mere propositions are not mere propositions
***** 3.7. Propositional truncation
****** 3.7.0. Propositional truncation type
For any $A$ there is a *truncation type* $\trunc{A}$, with constructors

 * $|a| : \trunc{A}$ for any $a : A$;
 * $x=y$ for any $x,y : \trunc{A}$;

ensuring that it is a mere proposition.

******* Recursion principle
If $B$ is a mere proposition and $f : A \to B$, then there exists
$g : \trunc{A} \to B$ such that $g(|a|) \equiv f(a)$ for all $a:A$.

****** 3.7.1. Traditional logical notation
We define

 * $\top :\equiv 1$,

 * $\bot :\equiv 0$,

 * $P \land Q :\equiv P \times Q$,

 * $P \lor Q :\equiv \trunc{P + Q}$,

 * $P \Rightarrow Q :\equiv P \to Q$,

 * $P \Leftrightarrow Q :\equiv P = Q$,

 * $\neg P :\equiv P \to 0$,

 * $\forall (x:A). P(x) :\equiv \prod_{x:A} P(x)$,

 * $\exists (x:A).P(x) :\equiv \trunc{\sum_{x:A} P(x)}$.

****** 3.7.2. Traditional set notation
We define

 * $\left\{ x:A\mid P(x) \right\} \cap \left\{ x:A \mid Q(x) \right\} :\equiv \left\{ x:A \mid P(x) \wedge Q(x) \right\}$,
 * $\left\{ x:A \mid P(x) \right\} \cup \left\{ x:A \mid Q(x) \right\} :\equiv \left\{ x:A\mid P(x) \lor Q(x) \right\}$,
 * $A \setminus \left\{ x:A\mid P(x) \right\} :\equiv \left\{ x:A \mid \neg P(x) \right\}$.

Note how the latter are not complements in the absence of LEM.
***** 3.8. The axiom of choice
****** 3.8.1. The axiom of choice
Given a $X$ and type families $A : X \to {\cal U}$, $P : \prod_{x:X} (A(x) \to {\cal U})$
such that $X$ and $A(x)$ are always sets and $P(x,a)$ is always a
mere proposition; the *axiom of choice* asserts

\[
\left( \prod_{x:X} \trunc{\sum_{a:A(x)} P(x,a)} \right)
\to
\trunc{\sum_{(g: \prod_{x:X}A(x))} \prod_{(x:X)} P(x,g(x))}.
\]

In logical notation, this means,

\[
\bigg( \forall (x:X). \exists (a:A(x)). P(x,a) \bigg)
\Rightarrow
\left( \exists \bigg(g: \prod_{x:X}A(x)\bigg). \forall (x:X). P(x,g(x)) \right)
\]

****** 3.8.2. Simpler axiom of choice
The axiom of choice is equivalent to 

\[
\left( \prod_{x:X} \trunc{Y(x)} \right) \to
\trunc{ \prod_{x:X} Y(x) }
\]

for any $X$ and $Y(x)$ always sets.

******* TODO Proof

****** TODO 3.8.5. Counterexample to the simpler version

***** 3.9. The principle of unique choice
****** 3.9.1. Equivalence of mere propositions and truncations
If $P$ is a mere proposition, $P \simeq \trunc{P}$.

******* Proof
We apply the universal property to $\id$ to get $\trunc{P} \to P$;
and we have a $P \to \trunc{P}$ by definition. This [[*3.3.3. Equivalence of connected mere propositions][proves]] an
equivalence of mere propositions.

****** 3.9.2. The principle of unique choice
Given $P \colon A \to {\cal U}$ such that

 * $P(x)$ is always a mere proposition;
 * $\trunc{P(x)}$ is always true.

Then $\prod_{x:A}P(x)$.

******* TODO Proof

***** 3.10. When are propositions truncated?
***** 3.11. Contractibility
****** 3.11.1. Contractible type
A type $A$ is *contractible*, or *singleton* if there is a center of
contraction $a : A$ such that $a = x$ for all $x : A$.

\[
\isContr(A) :\equiv \sum_{a:A}\prod_{x:A}(a = x)
\]

****** 3.11.3. Characterization of contractibility
Given $A$, the following are equivalent

 1. $A$ is contractible,
 2. $A$ is a mere proposition, and there is a point $a:A$,
 3. $A$ is equivalent to $1$.

******* Proof
If $A$ is contractible, it has a point $a : A$ and every two other
points are equal to it.

If $A$ is an inhabited mere proposition, it is equivalent to $1$.

And $1$ is contractible.

****** TODO 3.11.4. Contr is a mere proposition
****** TODO 3.11.5. Contractibility of Contr
****** TODO 3.11.6. Dependent product of contractible types
****** TODO 3.11.7. Retracts and contractibility
****** TODO 3.11.8.
****** TODO 3.11.9.
****** 3.11.10. Mere propositions and contractibility
$A$ is a mere proposition iff for all $x,y : A$, the type $x = y$ is
contractible.

******* TODO Proof
If $A$ is a mere proposition, then $x = y$ must be true; it must be
also a set, so $x=y$ must be contractible.

If $x=y$ is contractible, it is inhabited, so $A$ is a mere
proposition.

**** I.4. Equivalences
***** 4.1. Quasi-inverses
****** 4.1.1. Characterization of the quasi-inverse type
If given $f : A \to B$, $\qinv{}(f)$ is inhabited,

\[
\qinv(f) \simeq \prod_{x:A}(x=x)
\]

******* TODO Proof
As $f$ is an equivalence, we apply univalence to get $p : A = B$.
Applying path induction, $p = \refl$ and $f = \id$. Then,

\[
\qinv(\id) \equiv \sum_{g : A \to A} (g \sim \id) \times (\id \sim g)
\]

which is equivalent by function extensionality to

\[
\sum_{g : A \to A} (g = \id) \times (g = \id)
\]

****** 4.1.2. Existence of center
Given $a : A$ and $q : a = a$ such that

 1. $a = a$ is a set,
 2. $\trunc{a = x}$ for all $x : A$,
 3. $p \cdot q = q \cdot p$ for all $p : a = a$,

there exists $f : \prod_{x:A}(x = x)$ such that $f(a) = q$.

******* TODO Proof
****** 4.1.3. qinv is not always a mere proposition
There exists a function such that $\qinv(f)$ is not a mere
proposition.

******* TODO Proof
***** TODO 4.2. Half adjoint equivalences
****** 4.2.1. Half adjoint equivalence
A function $f : A \to B$ is a *half adjoint equivalence* if

\[
\ishae(f) :\equiv
\sum_{(g : B \to A)}
\sum_{(\eta : g \circ f \sim \id_{A})}
\sum_{(\epsilon : f \circ g \sim \id_{B})}
\prod_{(x:A)}
f(\eta(x)) = \epsilon(f(x))
\]

that is, there exist two homotopies and a coherence condition
between them.

****** 4.2.2. Logical equivalence of half adjoint equivalences
Given $f : A \to B$ and $g : B \to A$ with homotopies $\eta : g \circ f \sim \id$ and
$\epsilon : f \circ g \sim \id$, the following two types are logically equivalent

 * $\prod_{x:A}f(\eta(x)) = \epsilon(f(x))$,

 * $\prod_{x:A} g(\epsilon(x)) = \eta(g(x))$.

******* Proof
We will prove the second homotopy from $\tau : \prod_{x:A}f(\eta(x)) = \epsilon(f(x))$;
simmetry gives us the other direction.

By [[*2.4.4. Endonaturality of homotopies][endonaturality of homotopies]] in $\epsilon$ we have

\[\begin{tikzcd}
fgfg(x) \rar[equal]{fg \epsilon(x)} \dar[swap,equal]{\epsilon fg(x)} & 
fg(x) \dar[equal]{\epsilon(x)} \\
fg(x) \rar[equal]{\epsilon(x)} &
x
\end{tikzcd}\]

and applying $g$ to the complete diagram renders

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{gfg\epsilon(x)} \dar[swap,equal]{g\epsilon fg(x)} & 
gfg(x) \dar[equal]{g\epsilon(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

applying now the homotopy $\tau(g(x))$, we get $g \epsilon fg(x) = gf \eta g(x)$;
and again by [[*2.4.4. Endonaturality of homotopies][naturality]], we have $gf \eta g(x) = \eta gfg(x)$, and the
diagram is

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{g fg\epsilon(x)} 
\dar[swap,equal]{\eta gfg(x)} & 
gfg(x) \dar[equal]{g\epsilon(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

Meanwhile, by naturality of $\eta$ between $gfgfg$ and $gfg$, we have that

\[\begin{tikzcd}
gfgfg(x) \rar[equal]{g fg\epsilon(x)} 
\dar[swap,equal]{\eta gfg(x)} & 
gfg(x) \dar[equal]{\eta g(x)} \\
gfg(x) \rar[equal]{g\epsilon(x)} &
gx
\end{tikzcd}\]

and joining both diagrams we get $\eta g(x) = g \epsilon(x)$.

****** 4.2.3. qinv implies ishae
It is obvious that $\ishae$ implies $\qinv$.
For any $f : A \to B$ we have $\qinv(f) \to \ishae(f)$.

******* Proof
Given a quasiinverse $(f,g,\eta,\epsilon)$, we will define a new tuple
$(f,g,\eta,\epsilon',\tau')$; taking $\epsilon'$ to be

\[
\epsilon'(b) :\equiv \epsilon fg(b)^{-1} \cdot f\eta g(b) \cdot \epsilon(b)
\]

so we need to find an homotopy

\[
\tau(a) : f\eta(a) = \epsilon fgf(a)^{-1} \cdot f \eta gf(a) \cdot \epsilon f(a)
\]

but we know by [[*2.4.4. Endonaturality of homotopies][endonaturality]] that $\eta gf(a) = gf \eta(a)$ and by
homotopy that

\[
f \eta gf(a) \cdot \epsilon f(a) = fgf\eta(a) \cdot \epsilon f(a) = \epsilon fgf(a) \cdot f\eta(a).
\]

****** 4.2.4. Fiber of a map
The *fiber* of $f : A \to B$ over a point is

\[
\fib_f(y) :\equiv \sum_{x:A}(f(x) = y).
\]

****** 4.2.5. Equality of fibers
Given $f : A \to B$ and $(x,p), (x',p') : \fib_f(y)$,

\[
((x,p) = (x',p'))
\simeq
\left( \sum_{\gamma : x = x'} f(\gamma) \cdot p' = p \right)
\]

******* TODO Proof
# Path lemmas

****** 4.2.6. Fibers of half-adjoint equivalences are contractible
If $\ishae(f)$ for $f : A \to B$, then $\fib_f(y)$ is contractible for any $y : B$.

******* TODO Proof

****** 4.2.7. Left and right inverses
Given $f : A \to B$ we define

 * its *left inverses*, $\linv(f) :\equiv \sum_{g : B \to A} (g \circ f \sim \id)$,

 * its *right inverses*, $\rinv(f) :\equiv \sum_{g \colon B \to A}(f \circ g \sim \id)$.

***** TODO 4.3. Bi-invertible maps
****** 4.3.1. Bi-invertible
A function $f : A \to B$ is *bi-invertible* if it
[[*4.2.7. Left and right inverses][has left and right inverses]]

\[
\biinv(f) :\equiv \linv(f) \times \rinv(f).
\]

****** 4.3.2. biinv is a mere proposition
The type $\biinv(f)$ is a mere proposition for any $f : A \to B$.

******* TODO Proof

****** 4.3.3. Equivalence biinv and ishae
Given $f : A \to B$, we have $\qinv(f) \simeq \ishae(f)$.

******* TODO Proof
***** TODO 4.4. Contractible fibers
****** 4.4.1. Contractible maps
A function $f : A \to B$ is *contractible* if $\fib_f(y)$ is contractible
for every $y : B$; that is, we define

\[
\isContr(f) :\equiv \prod_{y:B} \isContr(\fib_f(y)).
\]

****** 4.4.3. isContr implies ishae
For any $f : A \to B$, we have $\isContr(f) \to \ishae(f)$.

******* TODO Proof

****** 4.4.4. isContr is a mere proposition
For any $f$, the type $\isContr(f)$ is a mere proposition.

******* TODO Proof
****** 4.4.5. isContr is equivalent to ishae
For any $f : A \to B$, we have $\isContr(f) \simeq \ishae(f)$.

******* TODO Proof
***** 4.5. On the definition of equivalences
We have proved equivalent

\[
\isContr(f) \simeq \ishae(f) \simeq \biinv(f)
\]

so we choose $\isequiv{}(f) :\equiv \ishae(f)$.

***** 4.6. Surjections and embeddings
****** 4.6.0. Isomorphisms
When two sets are equivalent, we say that they is an *isomorphism*
or a *bijection*.

****** 4.6.1. Surjections and embeddings
A function $f : A \to B$ is

 * *surjective* if $\trunc{\fib_f(b)}$ for every $b : B$;
 * *embedding* if $\ap_f : (x=y) \to (f(x) = f(y))$ is an equivalence.

******* Split surjection
We say that a function $f : A \to B$ is a *split surjection* if

\[
\prod_{b:B}\sum_{a:A} f(a) = b.
\]

Note that it is a stronger assertion than being surjective, that
only asks for an inhabitant without constructive evidence.

******* Axiom of choice and split surjections
The [[*3.8.1. The axiom of choice][axiom of choice]] says exactly that every surjection between sets is
split.

****** 4.6.2. Characterization of embeddings
A function $f : A \to B$ between sets is an embedding if and only if

\[
\prod_{x,y:A} f(x) = f(y) \to x = y.
\]

And we say that it is an *injection*.

******* Proof
We apply that $f(x) = f(y)$ and $x = y$ are mere propositions to get
an equivalence from the logical implications.

****** 4.6.3. Equivalence is surjection and embedding
Any function $f : A \to B$ is an equivalence if and only if it is both
surjective and an embedding.

******* TODO Proof

****** 4.6.4. Equivalence is equivalent to surjection and embedding
For any $f : A \to B$,

\[
\isequiv(f) \simeq \isEmbedding(f) \times \isSurjective(f).
\]

***** 4.7. Closure properties of equivalences
****** 4.7.1. The 2-out-of-3 property
If any two $f,g,g\circ f$ are equivalences, so is the third.

******* Proof
Given $g \circ f$ and $g$ equivalences, we show that $(g \circ f)^{-1} \circ g$ is a
quasi-inverse to $f$ because

 * on the one hand,

   \[
   ((g \circ f)^{-1} \circ g) \circ f \sim \id_{A}
   \]

 * on the other hand,

   \[\begin{aligned}
   f \circ (g \circ f)^{-1} \circ g &\sim
   g^{-1} \circ g \circ f \circ (g \circ f)^{-1} \circ g \\
   &\sim g^{-1} \circ g \\
   &\sim \id.
   \end{aligned}\]

In a similar way, we can prove the other two pair of equivalences.

****** 4.7.2. Retracts
A function $g : A \to B$ is a *retract* of $f : X \to Y$ in

\[\begin{tikzcd}
A \rar{s}\dar{g} & X \rar{r}\dar{f} & A\dar{g} \\
B \rar{s'}& Y \rar{r'}& B
\end{tikzcd}\]

if

 * $R : s \circ r \sim \id$,
 * $R' : s' \circ r' \sim \id$,
 * $L : f \circ s \sim s' \circ g$,
 * $K : g \circ r \sim r' \circ f$.
 * a path $H(a)$ witnessing commutativity of

   \[\begin{tikzcd}
   grs(a) \dar[equal,swap]{g(Ra)}\rar[equal]{Ks(a)} & r'fs(a) \dar[equal]{r'(La)} \\
   g(a)  \rar[equal]{R'(ga)^{-1}} & r's'g(a) \\
   \end{tikzcd}\]

****** TODO 4.7.3. Retract of equivalence is equivalence
****** TODO 4.7.5. 
***** TODO 4.8. The object classifier
****** TODO 4.8.1. Fiber of a type family
****** TODO 4.8.2. 
****** 4.8.3. Object classifier
Given any type $B$ there is an equivalence

\[
\chi :
\left( \sum_{A:{\cal U}}(A \to B) \right) \simeq (B \to {\cal U}).
\]

******* TODO Proof
We can define 

 * $\chi((A,f),b) :\equiv \fib_f(b)$

 * $\psi(P) :\equiv \left( \left(\sum_{b:B} P(b) \right), \pr_1 \right)$

and now verify that this constitutes an equivalence.

***** 4.9. Univalence implies function extensionality
We do not assume function extensionality on this section.

****** 4.9.1. Weak function extensionality principle
The *weak function extensionality principle* asserts that,
for any family $P : A \to {\cal U}$,

\[
\left( \prod_{x:A} \isContr(P(x)) \right)
\to
\isContr \left( \prod_{x:A}P(x) \right).
\]

****** 4.9.2. Equivalence on slice objects
If ${\cal U}$ is univalent, $A,B,X : {\cal U}$ and $e : A \simeq B$, there is 
an equivalence

\[
(X \to A) \simeq (X \to B).
\]

******* TODO Proof

****** TODO 4.9.3. 
****** TODO 4.9.5. Weak function extensionality implies function extensionality
The weak function extensionality principle implies the axiom
of [[*2.9.3. Function extensionality axiom][function extensionality]].

******* Proof

**** I.5. Induction
***** 5.1. Introduction to inductive types
****** 5.1.1. Uniqueness of functions over the natural numbers
Given $f,g : \prod_{n:\mathbb{N}} E(x)$ with

\[
e_z : E(0)
\quad\text{ and }\quad 
e_s : \prod_{n:\mathbb{N}}E(n) \to E(\succ(n)) 
\]

such that $f(0) = e_z = g(0)$ and

 * $\prod_{n:\mathbb{N}} f(\succ(n)) = e_s(n,f(n))$,
 * $\prod_{n:\mathbb{N}} g(\succ(n)) = e_s(n,g(n))$;

then $f$ and $g$ are equal.

******* Proof
We apply induction on $n$ over the type family $f(n) = g(n)$.
In the base case, $f(0) = g(0)$; and in the successor case,
knowing that $f(n) = g(n)$,

\[
f(\succ(n)) = e_s(n,f(n)) = e_s(n,g(n)) = g(\succ(n)).
\]

****** TODO 5.2. Uniqueness of inductive types
***** TODO 5.3. W-types
***** 5.4. Inductive types are initial algebras
****** 5.4.1. N-algebra
A $\mathbb{N}\text{-algebra}$ is a type with two elements

\[
\mathbb{N}\text{alg} :\equiv \sum_{C:{\cal U}} C \times (C \to C).
\]

****** 5.4.2. N-homomorphism
A $\mathbb{N}\text{-homomorphism}$ between algebras is a function preserving
the zero and successor elements up to path equality

\[
\mathbb{N}\text{Hom}((C,c_0,c_s), (D,d_0,d_s)) :\equiv
\sum_{h \colon C \to D} (h(c_0) = d_0) \times \left( \prod_{c:C} h(c_s(c)) = d_s(h(c)) \right).
\]

****** 5.4.3. Homotopy initial N-algebra
An algebra is homotopy initial if the type of homomorphisms to any
other algebras is contractible; that is

\[
\isHinit_{\mathbb{N}}(I) :\equiv \prod_{C : \mathbb{N}\text{Alg}} \isContr(\mathbb{N}\text{Hom}(I,C)).
\]

****** TODO 5.4.4. Uniqueness of homotopy initial N-algebras

****** TODO 5.4.5. The naturals are an homotopy initial N-algebra
****** TODO 5.4.6. W-algebras
***** TODO 5.5. Homotopy-inductive types
**** I.6. Higher inductive types
***** 6.2. Induction principles and dependent paths
****** 6.2.1. Propositional equality by definition
In the case of higher inductive types, we give equalities by
definition that use non-fundamental parts of the type theory,
and so they are propositional instead of judgmental.

We write them as $f(\mathsf{loop}) := \ell$ to indicate this fact.

****** 6.2.2. Notation for dependent paths
We write dependent paths as

\[
(u =^P_p v) :\equiv \transport^P(p,u) = v.
\]

****** 6.2.5. Non-dependent computation rule of the circle
Given $a : A$ with $p : a = a$, there is a function $f : \mathbb{S}^1 \to A$ such
that

 * $f(\base) :\equiv a$,
 * $\ap_f(\mathsf{loop}) :\equiv p$.

******* TODO Proof

***** 6.3. The interval
****** 6.3.0. The interval
We denote $I$ to the type generated by

 * $0_I : I$, a start point,
 * $1_I : I$, an end point,
 * $\seg : 0_I = 1_I$, a segment between points.

******* TODO Induction principle of the interval
******* TODO Recursion principle of the interval
****** 6.3.1. The interval is contractible
The type $I$ is contractible.

******* Proof
We define a function of type $\prod_{i:I}(i = 1)$, by induction over the
interval

 * $f(0) :\equiv \seg$,
 * $f(1) :\equiv \refl_1$,

and $\apd_f(\seg) : \seg_{\ast}(\seg) = \refl$ can be defined knowing
that this type is equivalent to $\seg^{-1} \cdot \seg = \refl$, and
that path inverse is an inhabitant.

****** TODO 6.3.2. Extensionality from the interval type

***** TODO 6.4. Circles and spheres
***** 6.5. Suspensions
****** 6.5.0. Suspension of a type
The *suspension* of a type $A$ is a type $\Sigma A$ defined by the
generators

 * north, $\N : \Sigma A$;

 * south, $S : \Sigma A$;

 * and meridians, $\merid : A \to (\N = \S)$.

******* TODO Induction principle

****** 6.5.1. Circle as suspension
The circle can be seen as the suspension of the booleans,

\[
\Sigma 2 \simeq \mathbb{S}^{1}.
\]

******* TODO Proof

***** TODO 6.6. Cell complexes

***** TODO 6.7. Hubs and spokes
**** I.7. Homotopy n-types
***** 7.1. Definition of n-types
****** 7.1.1. is-n-type
We define $\istype{n} : {\cal U} \to {\cal U}$ as

\[
\istype{n}(X) :\equiv
\left\{\begin{array}{ll}
\isContr(X) & \mbox{if } n = -2, \\
\prod_{x,y:X} \istype{n'}(x = y) & \mbox{if } n = n' + 1.
\end{array}\right.
\]

****** TODO 7.1.4. Retraction of an n-type
****** TODO 7.1.5. Equivalence preserves n-types
***** 7.2. Uniqueness of identity proofs and Hedberg's theorem
****** TODO 7.2.0. Uniqueness of identity proofs (UIP)

****** 7.2.1. Axiom K
A type $A$ is a set if and only if it satisfies *Axiom K*, for
all $x:X$ and $p : x = x$, we have $p = \refl$.

******* TODO Proof

****** 7.2.2. Mere identity relations in sets
Given $R$ a reflexive mere relation on $X$ implying identity, $X$
is a set and $R(x,y) \simeq (x = y)$ for all $x,y :X$.

******* Proof
Given $\rho : \prod_{x:X}R(x,x)$ and $f : \prod_{x,y}R(x,y) \to (x = y)$, we have
that if $X$ is a set, $x = y$ is a mere proposition logically equivalent
to $R(x,y)$. On the other hand, if $x = y$ is equivalent to $R(x,y)$ and
it is a mere proposition, $X$ is a set.

We can give two proofs, either proving that $X$ is a set or that $R(x,y)$
is equivalent to $x = y$.

******** X is a set
Given $x:X$ and $p : x = x$, we consider

\[
\apd_{f(x)}(p) : p_{\ast}(f(x,x)) = f(x,x)
\]

which, by [[*2.9.6. Equivalence for the dependent function equality][path equalities for dependent functions]] gives us a path

\[
p_{\ast}(f(x,x,r)) = f(x,x,p_{\ast}(r)).
\]

Knowing that $R(x,x)$ is a mere proposition, $p_{\ast}(r) = r$; and transport
in the identity type is equal to concatenation, so

\[
f(x,x,r) \cdot p = f(x,x,r)
\]

and $p = \refl$, satisfying axiom K.

******** TODO R is equivalent to equality

****** 7.2.3. A type with double negation cancellation equality is a set
If $X$ has the property $\neg\neg (x=y) \to (x=y)$, it is a set.

******* Proof
We have $\neg\neg(x=y)$ as a reflexive mere relation implying identity,
so we can apply the previous [[*7.2.2. Mere identity relations in sets][lemma]].

****** 7.2.5. Hedberg's theorem
If a type has [[*3.4.3. Decidable types][decidable]] equality, it is a set.

******* TODO Proof.

****** TODO 7.2.6. Natural numbers form a set
The type of natural numbers has decidable equality, and hence is a set.

******* TODO Proof
Given $x,y : \mathbb{N}$, we proceed by induction in both arguments. In the first
case, $\refl_0$ proves the equality; in the case of a successor and a zero,
we can apply 

***** 7.5. Connectedness
****** 7.5.1. n-connected function
A function $f : A \to B$ is *n-connected* if $\trunc{\fib_f(b)}_n$ is
contractible for all $b : B$.

\[
\conn_n(f) :\equiv \prod_{b:B} \isContr(\trunc{\fib_f(b)}_n)
\]

A type $A$ is *n-connected* if the function $A \to 1$ is.

****** TODO 7.5.2. Surjectivity is (-1)-connectedness
A function is (-1)-connected iff it is [[*4.6.1. Surjections and embeddings][surjective]].

*** Part II
**** II.8. Homotopy theory
***** 8.0. Homotopy theory
****** 8.0.1. Homotopy groups
We define the *homotopy groups* of a pointed type $(A,a)$ as

\[
\pi_n(A,a) :\equiv \trunc{\Omega^n(A,a)}_{0}.
\]

***** 8.1. Fundamental group of the circle
****** 8.1.1. Universal cover of the circle
We define $\mathsf{code} : \mathbb{S}^1 \to {\cal U}$ by recursion as

 * $\mathsf{code}(\mathsf{base}) :\equiv \mathbb{Z}$,
 * $\mathsf{code}(\mathsf{loop}) :\equiv \ua(\succ)$.

****** 8.1.2. Lemma of code transport
We have that

 * $\transport^{\mathsf{code}}(\mathsf{loop},x) = x + 1$,
 * $\transport^{\mathsf{code}}(\mathsf{loop},x) = x -1$.

******* TODO Proof

****** 8.1.5. Encode
We define the function $\mathsf{encode} : \prod_{x:\mathbb{S}^1}(\base = x) \to \mathsf{code}(x)$ by

\[
\mathsf{encode}\ p :\equiv \transport^{\mathsf{code}}(p,0).
\]

****** 8.1.6. Decode
We can define a function $\mathsf{decode} : \prod_{x:\mathbb{S}^1} \mathsf{code}(x) \to (\base = x)$.

******* TODO Definition
****** 8.1.7. Encode-decode of a path
For all $x : \mathbb{S}^1$ and $p : \base = x$,

\[
\mathsf{decode}(\mathsf{encode}(p)) = p.
\]

******* TODO Proof

***** TODO 8.2. Connectedness of suspensions
**** II.9. Category theory
**** II.10. Set theory
**** II.11. Real numbers
***** 11.2.1. Dedekind reals
****** 11.2.1. Dedekind cuts
A *Dedekind cut* is a pair $(L,U)$ of mere predicates such that
it is

 1) /inhabited:/ $\exists (q : \mathbb{Q}). L(q)$ and $\exists (r : \mathbb{Q}) . U(r)$;

 2) /rounded:/ for all $q,r \in \mathbb{Q}$,

    * $L(q) \iff \exists (r : \mathbb{Q}). (q < r) \wedge L(r)$

    * $U(r) \iff \exists(q:\mathbb{Q}).(q < r) \wedge U(q)$

 3) /disjoint:/ $\neg (Lq \wedge Uq)$ for all $q:\mathbb{Q}$,

 4) /located:/ $(q < r) \implies Lq \vee Ur$ for all $q,r : \mathbb{Q}$.

We define $\isCut(L,U)$ as the mere proposition of the conjunction
of these conditions. The set of *Dedekind reals* is defined as

\[
\mathbb{R}_d :\equiv
\left\{ (L,U) : (\mathbb{Q} \to \Omega) \times (\mathbb{Q} \to \Omega)
\mid \isCut(L,U) \right\}. 
\]

****** 11.2.1. Rational embedding
To each rational $q$, we associate $L_q(r) :\equiv (r < q)$ and
$U_q(r) :\equiv (q < r)$.

****** 11.2.1. Algebraic structure
We define addition as

\[
L_{x+y}(r) :\equiv \exists (t,s :\mathbb{Q}),\quad L_x(t) \land L_y(s) \land (t + s = q)
\]

and multiplication

\[\begin{aligned}
L_{x\cdot y}(q) :\equiv \exists (a,b,c,d : \mathbb{Q}), &\quad
L_x(a) \land U_x(b) \land L_y(c) \land U_y(d) \land \\ 
& (q < \min(ac,ad,bc,bd))
\end{aligned}\]

This has structure of commutative ring.

****** TODO 11.2.1. Order
****** TODO 11.2.2. Order and cuts
****** 11.2.3. Weak linearity
Linearity, $(x < y) \lor (y \leq x)$, is valid only if we assume LEM. We
have *weak linearity* $(x < y) \to (x < z) \lor (z < y)$.

****** 11.2.3. Apartness
\[
(x \apart y) :\equiv (x < y) \lor (y < x)
\]

we have $(x \apart y) \to \neg (x = y)$, but the converse is not true.

******* TODO Apartness is cotransitive
****** 11.2.4. Invertibility
A real is invertible if and only if it is apart from 0.

****** 11.2.6. Archimedean principle for Rd
If $x,y : \mathbb{R}$ such that $x < y$, then there merely exists $q : \mathbb{Q}$
such that $x < q < y$.

****** TODO 11.2.8. Dedekind reals form an ordered archimedean field

***** 11.2.2. Dedekind reals are Cauchy complete
****** Cauchy sequence
A sequence $x : \mathbb{N} \to \mathbb{Q}$ is *Cauchy* if

\[
\prod_{(\epsilon : \mathbb{Q}_+)} \sum_{(n:\mathbb{N})}
\prod_{(m,k \geq n)} |x_m-x_k| < \epsilon
\]

note how we can get a modulus of convergence out of this explicit
existential by Theorem of Choice.

****** Cauchy approximation
A *Cauchy approximation* is a map $x \colon \mathbb{Q}_+ \to \mathbb{R}_d$ such that

\[
\forall (\delta,\epsilon : \mathbb{Q}_+), |x_{\delta} - x_{\epsilon}|
< \delta + \epsilon,
\]

and its *limit* is $l : \mathbb{R}_d$ such that

\[
\forall (\epsilon, \theta : \mathbb{Q}_+), |x_{\epsilon}- l| < \epsilon + \theta
\]

****** Completeness for Cauchy approximations
Every Cauchy approximation has a limit.

******* TODO Proof

****** TODO Completeness for Cauchy sequences
***** TODO 11.2.3. Dedekind reals are Dedekind complete
***** 11.3.0. Cauchy reals
***** 11.4. Comparison of Cauchy and Dedekind reals
***** 11.5. Compactness of the interval
****** Notions of compactness

 * *Metrically compact:* Cauchy complete and totally bounded.
 * *Bolzano-Weierstrass:* every sequence has a convergent subsequence.
 * *Heine-Borel:* every open cover has a finite subcover.

These are equivalent in classical mathematics.
***** 11.5. Metrical compactness
****** 11.5.1. Metric space
****** 11.5.2. Cauchy approximation
****** 11.5.2. Complete metric space
****** 11.5.3. e-nets
****** 11.5.3. Totally bounded space
****** 11.5.5. Uniform continuity
****** 11.5.6. Metrical compactness of the interval
***** 11.5. Bolzano-Weierstrass and Heine-Borel compactness
*** Exercises
**** 1. Exercises: Type theory [5/11]
***** DONE Exercise 1.1
#+begin_statement
Given functions $f : A \to B$ and $g : B \to C$, define their composite
$g \circ f : A \to C$. Show that we have $h \circ (g \circ f) \equiv (h \circ g) \circ f$.
#+end_statement

We define

\[
g \circ f :\equiv \lambda x.g(f(x))
\]

and thus

\[\begin{aligned}
h \circ (g \circ f) &:\equiv \lambda x. h((g \circ f)(x)) \\ 
&\equiv \lambda x. h((\lambda y.g(f(y)))(x)) \\
&\equiv \lambda x. h(g(f(x))) \\
&\equiv \lambda x. (\lambda y. h(g(y)))(f(x)) \\
&\equiv (h \circ g) \circ f.
\end{aligned}\]

***** TODO Exercise 1.2
***** TODO Exercise 1.3
***** TODO Exercise 1.4
#+begin_statement
Assuming as given only the iterator for natural numbers

\[
\mathsf{iter} : \prod_{C:{\cal U}} C \to (C \to C) \to \mathbb{N} \to C.
\]

with the defining equations

 * $\mathsf{iter}(C,c_0,c_s,0) :\equiv c_{0}$,
 * $\mathsf{iter}(C,c_0,c_s,\succ(n)) :\equiv c_s(\mathsf{iter}(C,c_0,c_s,n))$,

....
#+end_statement

***** TODO Exercise 1.5
***** DONE Exercise 1.10
#+begin_statement
Show that the Ackermann function $\mathsf{ack} : \mathbb{N} \to \mathbb{N} \to \mathbb{N}$ is definable using
only $\mathsf{rec}_{\mathbb{N}}$ satisfying the following equations

 * $\mathsf{ack}(0,n) \equiv \mathsf{succ}(n)$,

 * $\mathsf{ack}( \mathsf{succ}(m),0) \equiv \mathsf{ack}(m,1)$,

 * $\mathsf{ack}(\mathsf{succ}(m), \mathsf{succ}(n)) \equiv \mathsf{ack}(m, \mathsf{ack}(\succ(m),n)$.
#+end_statement

We can define

\[
\rec_{\mathbb{N}}\ \succ\ 
(\lambda m. \lambda a_m. 
\rec_{\mathbb{N}}\ (a_m\ 1)\ (\lambda n. \lambda a_{mn}. a_m\ a_{mn})
)
\]

where we can take $a_{m}$ to mean the $\mathsf{ack}$ function partially applied to $m$,
whereas we can take $a_{mn}$ to mean $\mathsf{ack}(m,n)$. With these definitions, we
have the base and successor equalities judgmentally.

***** DONE Exercise 1.11
#+begin_statement
Show that for any type $A$ we have $\neg\neg\neg A \to \neg A$.
#+end_statement

We write the function 

\[
\lambda f. \lambda a. f (\lambda h. h(a)) : \neg\neg\neg A \to \neg A
\]

where $f : \neg\neg\neg A$, $h : \neg A$ and $(\lambda h. h(a)) : \neg\neg A$.

***** DONE Exercise 1.12
#+begin_statement
Using the propositions as types interpretation, derive the
following tautologies

 1) if A, then (if B then A);
 2) if A, then not (not A);
 3) if (not A or not B), then not (A and B).
#+end_statement

We define the following terms

 * $\lambda a.\lambda b.a : A \to (B \to A)$;
 * $\lambda a.\lambda f.f(a) : A \to \neg\neg A$;
 * $\lambda u. \rec(u, \lambda f.\lambda (a,b).f(a), \lambda g.\lambda (a,b). g(b))$;

with the desired types.

***** DONE Exercise 1.13
#+begin_statement
Using propositions-as-types, derive the double negation of the principle
of excluded middle, i.e., prove /not (not (P or not P))/.
#+end_statement

We can define a function

\[
(\lambda f. f (\inr (\lambda p. f (\inl (p))))) 
\]

whose type is $\neg (\neg (P \vee \neg P))$ for any given $P$.

***** TODO Exercise 1.15
***** TODO Exercise 1.16
#+begin_statement
Show that addition of natural numbers is commutative,

\[
\prod_{i,j : \mathbb{N}} i + j = j + i.
\]
#+end_statement

We proceed by induction on $i$. In the first case, we have to
prove $\prod_{j : \mathbb{N}} 0 + j = j + 0$; and this can be done by induction
on $j$. In fact,

 * $\mathsf{commzero}(0) = \refl_0$,
 * $\mathsf{commzero}(S(n)) = \ap_{\succ}(\mathsf{commzero}(n))$.

**** 2. Exercises: Homotopy type theory [3/17]
***** TODO Exercise 2.1
#+begin_statement
Show that the three obvious proofs of Lemma 2.1.2 are pairwise equal.
#+end_statement

***** TODO Exercise 2.2
***** TODO Exercise 2.3
***** TODO Exercise 2.4
***** TODO Exercise 2.5
***** TODO Exercise 2.6
***** TODO Exercise 2.7
***** TODO Exercise 2.8
***** TODO Exercise 2.9
***** DONE Exercise 2.10
#+begin_statement
Prove that \Sigma-types are associative, in that for any $A : {\cal U}$ and
families $B : A \to {\cal U}$ and $C : \left(\sum_{x:A} B(x)\right) \to {\cal U}$, we have

\[
\left( \sum_{x:A}\sum_{y:B(x)} C(x,y) \right)
\simeq
\left( \sum_{p : \sum_{x:A}B(x)} C(p) \right)
\]
#+end_statement

We first define a function

\[
f : \left( \sum_{x:A}\sum_{y:B(x)} C(x,y) \right)
\to
\left( \sum_{p : \sum_{x:A}B(x)} C(p) \right)
\]

by induction on the argument, as

\[
f (x,y,c) :\equiv ((x,y),c).
\]

Now we have to prove that this is an equivalence with two homotopies,
with an inverse defined by induction

\[
g((x,y),c) :\equiv (x,y,c).
\]

In fact, given any $(x,y,c)$, or any $((x,y),c)$ it is trivial to check
that there exist two homotopies. Note how we use induction to get the
constructors of the pair.
***** TODO Exercise 2.11
#+begin_statement
A homotopy commutative square

\[\begin{tikzcd}
P\rar{h} \dar[swap]{k} & A \dar{f} \\
B\rar{g} & C
\end{tikzcd}\]

consists of functions $f,g,h$ and $k$ as shown, together with a path $f \circ h = g \circ k$.
Note that this is exactly an element of the pullback $(P \to A) \times_{(P \to C)} (P \to B)$
as defined in (2.15.11). A commutative square is called a (homotopy)
*pullback square* if for any $X$, the induced map

\[
(X \to P) \to (X \to A) \times_{(X \to C)} (X \to B)
\]

is an equivalence. Prove that the pullback $P :\equiv A \times_C B$ defined in (2.15.11)
is the corner of a pullback square.
#+end_statement

***** TODO Exercise 2.12
***** DONE Exercise 2.13
#+begin_statement
Show that $(2 \simeq 2) \simeq 2$.
#+end_statement

We have $(2 \simeq 2)$ with two possible elements determined by the function
given by $2 \to 2$. If we take $\id : 2 \to 2$, that is a trivial equivalence,
and if we take $\neg : 2 \to 2$ we have a different equivalence. 

Now, given any function $f : 2 \to 2$, we can apply induction to both
$f(1)$ and $f(0)$ and then, by function extensionality, assert that it
has to be a constant function or some of the previous equivalences.
We only have two possible equivalences then.

We declare a function taking $\id$ to $\mathsf{true}$ and $\neg$ to $\mathsf{false}$, the inverse
is trivially defined.

***** DONE Exercise 2.14
#+begin_statement
Suppose we add to type theory the equality reflection rule which says
that if there is an element $p : x = y$, then in fact $x \equiv y$. Prove that
for any $p : x = x$ we have $p \equiv \refl$.
#+end_statement

Given any $p : x = y$, we have $x \equiv y$, and we can prove the (well-typed!)
equality $p = \refl$ by path induction. Note that we have used the equality
reflection rule to prove that 

\[
\prod_{x,y : A}\prod_{p : x=y} p = \refl_x
\]

is actually well-typed.

***** TODO Exercise 2.15
***** TODO Exercise 2.16
#+begin_statement
Suppose that rather than function extensionality (Axiom 2.9.3),
we suppose only the existence of an element

\[
\mathsf{funext} : \prod_{A:{\cal U}} \prod_{B:A \to {\cal U}} \prod_{f,g : \prod_{x:A}B(x)} (f \sim g) \to (f = g).
\]
#+end_statement

***** TODO Exercise 2.18
#+begin_statement
State and prove a version of Lemma 2.4.3 for dependent functions.
#+end_statement

**** 3. Exercises: Sets and logic [2/8]
***** DONE Exercise 3.1
#+begin_statement
Prove that if $A \simeq B$ and $A$ is a set, then so is $B$.
#+end_statement

The equivalence gives us a pair of functions $f : A \to B$ and $g : B \to A$
with homotopies $\eta : g \circ f \sim \id$ and $\epsilon : f \circ g \sim \id$. By naturality of
$\eta$ we have, for any two paths $p,q : x =_B y$, that

\[\begin{tikzcd}
fg(x)\rar[equal]{fg(p)} \dar[swap,equal]{\eta_x} & 
fg(y)\dar[equal]{\eta_y} \\
x \rar[equal]{p} &
y
\end{tikzcd}\]

and

\[\begin{tikzcd}
fg(x)\rar[equal]{fg(q)} \dar[swap,equal]{\eta_x} & 
fg(y)\dar[equal]{\eta_y} \\
x \rar[equal]{q} &
y
\end{tikzcd}\]

but $g(p) = g(q)$ because $A$ is a set, so $fg(p) = fg(q)$ and therefore, $p=q$.

***** DONE Exercise 3.2
#+begin_statement
Prove that if $A$ and $B$ are sets, then so is $A + B$.
#+end_statement

Note that $A + B = \prod_{x:2} C(x)$ for some family $C$, and we know that the
[[*3.1.6. Dependent product of sets is a set][dependent product of sets is a set]].

***** TODO Exercise 3.3
***** TODO Exercise 3.4
#+begin_statement
Show that $A$ is a mere proposition if and only if $A \to A$ is
contractible.
#+end_statement

***** TODO Exercise 3.5
#+begin_statement
Show that $\isProp(A) \simeq (A \to \isContr(A))$.
#+end_statement

***** TODO Exercise 3.6
#+begin_statement
Show that if $A$ is a mere proposition, then so is $A + (\neg A)$. Thus,
there is no need to insert a propositional truncation in 3.4.1.
#+end_statement

***** TODO Exercise 3.9
#+begin_statement
Show that if $\LEM$ holds, then the type $\Prop :\equiv \sum_{A:{\cal U}} \isProp(A)$
is equivalent to $2$.
#+end_statement

***** TODO Exercise 3.21
#+begin_statement
Prove that $\isProp(P) \simeq (P \simeq \trunc{P})$.
#+end_statement

**** 4. Exercises: Equivalences [0/0]
** Algebra: chapter 0 - Aluffi
*** III. Anillos y mdulos
**** 7. Complejos y homologa
***** 7.1. Complejos y secuencias exactas.
 #+begin_definition
 *Complejo*. Un complejo es una serie de morfismos $d_i$ entre R-Mdulos:

 \[\dots \longrightarrow M_{i+1} \longrightarrow M_i \longrightarrow M_{i-1} \longrightarrow \dots\]

 tales que $d_i \circ d_{i+1} = 0$.
 #+end_definition

 Adems lo llamamos *exacto* cuando $im (d_{i+1}) = ker (d_i)$.

 #+begin_proposition
 *Exactitud de monomorfismos y epimorfismos*. Dos complejos de la forma:

 \[ \dots \longrightarrow 0 \longrightarrow L \overset{\alpha}\longrightarrow M \longrightarrow \dots \]
 \[ \dots \longrightarrow M \overset{\beta} \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]

 Son exactos en $L$ y $N$ ssi $\alpha$ y $\beta$ son monomorfismo y epimorfismo, 
 respectivamente.
 #+end_proposition

 #+begin_definition
 *Secuencia exacta corta*. Una secuencia exacta corta es un complejo de la forma:

 \[ 0 \longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \longrightarrow 0 \]
 #+end_definition

 El primer teorema de isomorfa nos dice que $N \cong \frac{M}{ker(\beta)} = \frac{M}{im(\alpha)}$ lo que nos 
 lleva a identificar   $N \cong \frac{M}{L}$. De hecho, cada monomorfismo da lugar a una 
 secuencia exacta corta:

 \[ 0 \longrightarrow \ker(\phi) \longrightarrow M \longrightarrow im(\phi) \longrightarrow 0 \]

***** 7.2. Secuencias exactas escindidas
 #+begin_definition
 *Secuencia escindida*. Una secuencia exacta corta:

 \[ 0 \longrightarrow M_1 \longrightarrow N \longrightarrow M_2 \longrightarrow 0 \]

 es escindida si es isomorfa a una secuencia de la forma siguiente:

 \[ \begin{tikzcd}
 0   \arrow{r}{} & 
 M_1 \arrow{d}{\sim}\arrow{r}{} & 
 N   \arrow{d}{\sim}\arrow{r}{} & 
 M_2 \arrow{d}{\sim}\arrow{r}{} & 
 0 \\
 0   \arrow{r}{} & 
 M_1 \arrow{r}{} & 
 M_1 \oplus M_2   \arrow{r}{} & 
 M_2 \arrow{r}{} & 
 0
 \end{tikzcd} \]

 Es decir, hay un isomorfismo entre secuencias.
 #+end_definition

 #+begin_theorem
 *Relacin entre secuencias escindidas e inversas*. Sea $\phi$ un homomorfismo;
 entonces tiene inversa izquierda ssi la secuencia siguiente escinde:

 \[ 0 \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow coker(\phi) \longrightarrow 0 \]

 Y tiene inversa derecha si la secuencia siguiente escinde:

 \[ 0 \longrightarrow ker(\phi) \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow 0 \]
 #+end_theorem

***** 7.3. Homologa, y el lema de la serpiente
 #+begin_definition
 *Homologa*. La i-sima homologa de un complejo,

 \[ \dots \longrightarrow M_{i+1} \overset{d_{i+1}}\longrightarrow M_i \overset{d_i}\longrightarrow M_{i-1} \longrightarrow \dots \]

 es el R-mdulo:

 \[H_i(M) = \frac{ker(d_i)}{im(d_{i+1})}\]
 #+end_definition

 La homologa mide lo que se aleja de ser exacto en un punto determinado, y
 es $0$ cuando el complejo es exacto. Puede verse como una generalizacin de
 kernel y cokernel; que los realiza en este caso extremo:

 \[ 0 \longrightarrow M_1 \overset{\phi}\longrightarrow M_0 \longrightarrow 0 \]

 En el que $H_1(M) \cong ker(\phi)$ y $H_0(M) \cong coker(\phi)$.

 #+begin_theorem
 *Lema de la serpiente*. Teniendo dos secuencias exactas en el diagrama 
 conmutativo siguiente:

 \[ \begin{tikzcd}
 0 \rar & L_1 \rar{\alpha_1}\arrow{d}{\lambda} & M_1 \rar{\beta_1}\arrow{d}{\mu} & N_1 \rar\arrow{d}{\eta} & 0 \\
 0 \rar & L_0 \rar{\alpha_0}                   & M_0 \rar{\beta_0}               & N_0 \rar                & 0
 \end{tikzcd} \]

 Existe una secuencia exacta de la forma:

 \[ 0 \overset{}\longrightarrow 
 ker(\lambda) \overset{}\longrightarrow 
 ker(\mu) \overset{}\longrightarrow 
 ker(\eta) \overset{\delta}\longrightarrow 
 coker(\lambda) \overset{}\longrightarrow 
 coker(\mu) \overset{}\longrightarrow 
 coker(\eta) \overset{}\longrightarrow 
 0\]
 #+end_theorem

 El diagrama desde el que se deduce todo esto, con columnas exactas, es
 el siguiente:

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(\lambda) \rar \dar  & ker(\mu) \rar \dar    & ker(\eta) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & L_1 \rar{\alpha_1} \dar{\lambda}  & M_1 \rar{\beta_1} \dar{\mu} & N_1 \rar \dar{\eta}        & 0 \\
 0 \rar & L_0 \rar{\alpha_0} \dar & M_0 \rar{\beta_0} \dar & N_0 \rar \dar        & 0 \\
	& coker(\lambda) \rar \dar & coker(\mu) \rar \dar  & coker(\eta) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

*** IV. lgebra lineal
**** 4. Presentaciones y resoluciones
***** 4.1. Torsin
 #+begin_definition
 *Torsin*. Un elemento $m \in M$ mdulo de $R$ es de *torsin* si $\{m\}$ es linealmente
 dependiente. Es decir,

   \[ \exists r \in R,\ r \neq 0\ :\ rm = 0 \]

 El conjunto de elementos de torsin se llama $Tor(M)$. Un mdulo es *libre de torsin*
 si $Tor(M) = 0$ y *de torsin* si $Tor(M)=M$.
 #+end_definition

 Un anillo conmutativo es libre de torsin sobre s mismo si y slo si es dominio de
 integridad. Cuando esto ocurre, $Tor(M)$ es siempre submdulo de $M$. Submdulos o
 sumas de mdulos libres de tensin sern libres de torsin, y por todo esto, los mdulos
 libres sobre dominios de integridad sern libres de torsin.

 #+begin_definition
 *Cclico*. Un mdulo es *cclico* cuando es generado por un elemento. Es decir,
 cuando $M \cong R/I$ para algn ideal.
 #+end_definition

 Cuando en un dominio de integridad todos sus
 mdulos cclicos son libres de torsin, es un cuerpo. Otra forma de pensar sobre un mdulo
 cclico es como aquel que admite un epimorfismo:

 \[ R \longrightarrow M \longrightarrow 0 \]

***** 4.2. Mdulos finitamente presentados y resoluciones libres
 #+begin_definition
 *Anulador.* El anulador de un mdulo $M$ es:

 \[Ann_R(M) = \{ r \in R\ |\ \forall m \in M, rm = 0 \}\]
 #+end_definition

 Es un ideal de $R$. Cuando $M$ es finitamente generado y $R$ es dominio de integridad,
 $M$ es de torsin si y slo si $Ann(M) \neq 0$.

 #+begin_definition
 *Mdulos finitamente generados y presentados*. Sabemos que todos los mdulos admiten un
 epimorfismo de la forma:

 \[ R^{\oplus A} \longrightarrow M \longrightarrow 0\]

 Cuando lo admiten con $A$ finito, se tiene $M$ *finitamente generado*. Un mdulo se dice
 *finitamente presentado* si hay una secuencia exacta de la forma:

 \[R^n \overset{\phi}\longrightarrow R^m \longrightarrow M \longrightarrow 0\]

 .
 #+end_definition

 Si $R$ es Noetheriano, todo mdulo finitamente generado es finitamente presentado.

 #+begin_definition
 *Resolucin*. Una resolucin de $M$ mediante mdulos libres finitamente generados es
 un complejo exacto:

 \[ \dots \rightarrow R^{m_3} \rightarrow R^{m_2} \rightarrow R^{m_1} \rightarrow R^{m_0} \rightarrow M \rightarrow 0 \]
 #+end_definition

 Aqu podemos entender que $R^{m_0}$ contiene los generadores, $R^{m_1}$ las relaciones
 entre los generadores, $R^{m_2}$ las relaciones entre relaciones, y as sucesivamente.

 Un dominio de integridad es *cuerpo si y slo si todos sus mdulos son finitamente generados*,
 esto es equivalente a tener:

 \[ 0 \longrightarrow R^m \longrightarrow M \longrightarrow 0 \]

 para cualquier mdulo.

 Un dominio de integridad es *PID si todas las resoluciones como finitamente generado 
 extienden a finitamente presentado*, de la forma:

 \[0 \longrightarrow R^{m_1} \longrightarrow R^{m_0} \overset{\pi}\longrightarrow M \longrightarrow 0\]

 esto equivale a pedir que $\ker(\pi)$ sea libre.

***** 4.3. Leyendo una presentacin
 Hemos visto que podemos estudiar un mdulo finitamente presentado por un
 morfismo $\phi: R^n \longrightarrow R^m$, donde $M = coker(\phi)$. Esto quiere decir que 
 podemos asignarle una matriz explcita.

 #+begin_theorem
 *Producto de mdulos en matrices*. Sean $M,N$ mdulos con matrices $A,B$.
 Tenemos $M \oplus N$ con matriz:

 \[\left(\begin{array}{c|c}
 A & 0 \\ \hline 0 & B 
 \end{array}\right)\]
 #+end_theorem

 Adems ntese que las *matrices equivalentes* representan el mismo 
 homeomorfismo, y por tanto el mismo mdulo.

 #+begin_theorem
 *Transformaciones de matrices de mdulos*. Una matriz representa el mismo mdulo
 tras las transformaciones de:
  - Permutar filas o columnas
  - Aadir filas o columnas linealmente dependientes
  - Multiplicar filas o columnas por una unidad
  - Quitar una fila y columna en la que slo queda una unidad
 #+end_theorem

 Las primeras son consecuencia de la equivalencia. La ltima puede colocarse como
 una parte de identidad en una matriz de la forma:

 \[A = \left(\begin{array}{c|c}
 u & 0 \\ \hline 0 & A' 
 \end{array}\right)\]

 Que no afecta al cokernel.

*** VII. Cuerpos
**** 1. Extensiones de cuerpos I
***** 1.1. Definiciones bsicas
****** Categora de los cuerpos
Los cuerpos forman la *categora $\mathtt{Fld}$* con los homomorfismos de 
anillos entre ellos. Todo homomorfismo de anillos entre cuerpos
es inyectivo y todo morfismo en esta categora es monomorfismo.

As, todo morfismo entre cuerpos en $Hom(k,K)$ es una extensin $K/k$.

****** Caracterstica de un cuerpo
      La *caracterstica* de $K$ es el generador de $ker(i)$ para 
      $i : \mathbb{Z} \longrightarrow K$. Las extensiones preservan la 
      caracterstica, as que podemos particionar la categora en categoras 
      $\mathtt{Fld}_p$.

****** Cuerpos primos
      El inicial de $\mathtt{Fld}_0$ es $\mathbb{Q}$, y el de $\mathtt{Fld}_p$ es $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z}$. Todos los
      cuerpos son extensiones de uno de estos llamados *cuerpos primos*.

****** Grado de una extensin
El *grado*, $[F : K]$, de una extensin es su dimensin como espacio
vectorial sobre la base. Es *finita* o *infinita* si lo es su grado.

***** 1.2. Extensiones simples
****** Extensin simple
Una extensin es *simple* si es de la forma $K(\alpha)$ donde 
$K(\alpha)$ es la interseccin de todos los subcuerpos de algn
$F$ conteniendo al cuerpo $K$ y el elemento $\alpha$.

****** Polinomio irreducible mnimo
Dada una extensin simple $K(\alpha)$, consideramos la evaluacin
$\epsilon : K[X] \longrightarrow K(\alpha)$ por casos:

 - Es *inyectiva* ssi es una *extensin infinita*. En este
   caso $K(\alpha) \cong K(X)$ es el cuerpo de funciones racionales.
 - No es *inyectiva*. Existe un nico polinomio mnico
   irreducible $p$ que genera el ncleo,

   \[ K(\alpha) \cong \frac{K[t]}{(p(t))}\]

   Se le llama *polinomio mnimo*.

****** TODO Extensin de isomorfismos a extensiones simples
Proposition 1.5
****** Automorfismos de una extensin
El *grupo de automorfismos* de una extensin $Aut_K(F)$, es el
grupo de los automorfismos de cuerpos que dejan fijo $K$.
****** Automorfismos y races
Sea $K(\alpha)$ con $p$ polinomio mnimo. Entonces $p$ tiene $|Aut_K(K(\alpha))|$ races
distintas en $K(\alpha)$. En particular,

\[ |Aut_K(K(\alpha))| \leq [K(\alpha):K] \]

y el caso de igualdad se tiene con $p$ factorizando en factores 
lineales sobre $F$.
***** 1.3. Extensiones finitas y algebraicas
****** Elementos algebraicos y trascendentes
Sea $F/K$ una extensin con $\alpha \in F$, entonces $\alpha$ es *algebraico*
cuando $K(\alpha)/K$ es finita, y *trascendente* si no. Una extensin
es *algebraica* si todos sus elementos lo son.

**** 6. Un poco de teora de Galois
***** 6.1. Correspondencia de Galois y extensiones de Galois
****** Cuerpo fijo
Sea $F/k$ extensin y $G \subseteq Aut_k(F)$. Llamamos *cuerpo fijo* de $G$ a:

\[ F^G = \{ \alpha\in F \mid \forall g \in G, g\alpha=\alpha\}\]

****** Correspondencia de Galois
Hay correspondencia entre los cuerpos intermedios de la extensin
y los subgrupos del grupo de automorfismos.

Dado $E$ cuerpo intermedio, lo enviamos a $Aut_E(F)$. Dado $G$ lo enviamos
a $F^G$.

****** Inclusin y correspondencia
Para cualesquiera subgrupo $G$ y cuerpo intermedio $E$:

 - $E \subseteq F^{Aut_E(F)}$
 - $G \subseteq Aut_{F^G}(F)$

Si llamamos $E_1E_2$ al menor subcuerpo de $F$ conteniendo $E_1,E_2$ y llamamos
$<G_1,G_2>$ al menor subgrupo de los automorfismos conteniendo $G_1,G_2$:

 - $Aut_{E_1E_2}(F) = Aut_{E_1}(F) \cap Aut_{E_2}(F)$
 - $F^{<G_1,G_2>} = F^{G_1} \cap F^{G_2}$

****** Extensiones de Galois
Sea $F/k$ extensin, equivalen:

 - $F$ es cuerpo de descomposicin de algn $f \in k[t]$.
 - $F/k$ es normal y separable.
 - $|Aut_k(F)| = [F : k]$.
 - La correspondencia de Galois es biyeccin.
 - $F/k$ separable y, si $E/F$ es algebraica con $\sigma \in Aut_k(E)$, $\sigma(F)=F$.

Llamamos a esto una *extensin de Galois*.
*** VIII. Vuelta al lgebra lineal
**** 1. Preliminares
***** 1.1. Funtores
 #+begin_definition
 *Funtor*. Un funtor covariante:

 \[{\cal F} : C \longrightarrow D\]

 Asigna a cada $A \in C$ un ${\cal F}(A) \in D$ y mapea los morfismos entre cada par de objetos:

 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]

 Respetando la identidad y la composicin de morfismos. 

 Un *funtor contravariante* es un funtor desde la categora opuesta:

 \[{\cal F} : C^{op} \longrightarrow D\]
 #+end_definition

 Los funtores preservan los diagramas conmutativos. Llamamos *prehaz* a un funtor
 contravariante $C \longrightarrow \mathtt{Set}$.

 #+begin_definition
 *Funtor aditivo*. Llamamos a un funtor 
 ${\cal F}: R-\mathtt{Mod} \longrightarrow S-\mathtt{Mod}$ *aditivo* cuando
 la funcin $Hom_{R}(A,B) \rightarrow Hom_{S}({\cal F}(A),{\cal F}(B))$ es homomorfismo de grupos.
 #+end_definition

***** 1.3. Equivalencia de categoras
 #+begin_definition
 *Funtores plenamente fieles*. Dada la funcin inducida:
 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]
 Un funtor es *fiel* si es inyectiva, *pleno* si es sobreyectiva y *plenamente fiel*
 si es biyectiva.
 #+end_definition

 #+begin_definition
 *Equivalencia de categoras*. Un funtor es una equivalencia de categoras si 
 es plenamente fiel y esencialmente sobreyectivo, es decir, para cada $Y \in D$,
 existe un $X \in C$ tal que $F(X) \cong Y$.
 #+end_definition

***** 1.4. Lmites y colmites

 #+begin_definition
 *Lmite*. Para un funtor ${\cal F}: {\cal I} \longrightarrow C$, su lmite es
 un objeto $L \in C$ con morfismos $\lambda_I: L \longrightarrow {\cal F}(I)$ tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L \arrow{dr}{\lambda_J} \arrow{dl}[swap]{\lambda_I} \\
 {\cal F}(I) \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J)
 \end{tikzcd} \]

 - $L$ es final en este diagrama.
 #+end_definition

 Ser esencialmente nico y puede notarse por $\varprojlim {\cal F}$.

 #+begin_theorem
 *Lmites sobre cadenas en R-Mod*. En R-Mod siempre existe un lmite llamado \(\varprojlim {\cal A}_i\) sobre una
 cadena de la forma:

 \[ \begin{tikzcd}
 & & A 
 \arrow{lld}[swap]{\phi_5}
 \arrow{ld}{\phi_4}
 \arrow{d}{\phi_3}
 \arrow{rd}[swap]{\phi_2}
 \arrow{rrd}{\phi_1} 
 & & \\
 \dots \arrow{r}[swap]{\phi_{45}}  &
 A_4 \arrow{r}[swap]{\phi_{34}} &
 A_3 \arrow{r}[swap]{\phi_{23}} &
 A_2 \arrow{r}[swap]{\phi_{12}} &
 A_1
 \end{tikzcd} \]
 #+end_theorem

 Este lmite es el submdulo de las /secuencias coherentes/ en $\prod_i A_i$, es decir, de
 aquellas tales que $a_i = \phi_{i,i+1}(a_{i+1})$; teniendo como morfismos $\phi_i$ las proyecciones
 cannicas


 #+begin_definition
 *Colmite*. La nocin dual de lmite es el *colmite*, es decir, para
 un funtor ${\cal F} : I \longrightarrow C$, su colmite es un objeto $L \in C$ con morfismos $\gamma_i : {\cal F}(I) \longrightarrow L$
 tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L  \\
 {\cal F}(I) \arrow{ur}{\gamma_I} \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J) \arrow{ul}[swap]{\gamma_J}
 \end{tikzcd} \]

 - $L$ es inicial en este diagrama.
 #+end_definition

***** 1.5. Comparando funtores
 #+begin_definition
 *Transformacin natural*. Una transformacin natural entre dos funtores ${\cal F} \Longrightarrow {\cal G}$ 
 consiste en morfismos $\upsilon_X : {\cal F}(X) \longrightarrow {\cal G}(X)$ tales que conmuta el diagrama:

 \[ \begin{tikzcd}
 {\cal F}(X) \arrow{r}{{\cal F}(\alpha)} \arrow{d}{\upsilon_X} & {\cal F}(Y) \arrow{d}{\upsilon_Y} \\
 {\cal G}(X) \arrow{r}{{\cal G}(\alpha)} & {\cal G}(Y)
 \end{tikzcd}
 \]

 para cualquier morfismo $\alpha$.

 Llamamos *isomorfismo natural* a una transformacin natural donde cada $\upsilon$
 es un isomorfismo.
 #+end_definition

 #+begin_definition
 *Funtor adjunto*. Llamamos ${F}$ y ${G}$ adjuntos si tenemos:

 \[ Hom_C(X,GY) \cong Hom_D(FX,Y) \]

 Isomorfismos naturales.
 #+end_definition

 Lo que nos da realmente un isormorfismo natural de $Hom_C(F-,-)$ con $Hom_D(-,G-)$,
 entendidos como funtores. Llamamos aqu adjunto izquierdo a $F$ y adjunto derecho a $G$.
 Tenemos ms sobre funtores adjuntos en la lista de reproduccin de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][The Catsters]].

 #+begin_theorem
 *Continuidad de adjuntos*. Los funtores adjuntos derechos son continuos, los adjuntos
 izquierdos son cocontinuos. Es decir, para $I : {\cal I}\longrightarrow D$, $J : {\cal J}\longrightarrow C$

 \[G(\varprojlim I) = \varprojlim (G \circ I)\]
 \[F(\varinjlim J) = \varinjlim (F \circ J)\]
 #+end_theorem

 Siempre que existan los lmites. La demostracin de esto se puede hacer aplicando los
 funtores en los diagramas conmutativos y usando las propiedades universales de los lmites.

 #+begin_definition
 *Funtor exacto*. Un funtor exacto respeta la exactitud de las secuencias. Es decir,
 siendo la siguiente secuencia exacta:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

 La siguiente secuencia ser exacta:

 \[ 0 \longrightarrow FA \overset{F\phi}\longrightarrow FB \overset{F\psi}\longrightarrow FC \longrightarrow 0\]
 #+end_definition

 En particular, lo llamamos /exacto a la izquierda/ si preserva la exactitud de:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C\]

 Y /exacto a la derecha/ si preserva la exactitud de:

 \[ A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

**** 2. Producto tensor y el funtor Tor
***** 2.1. Aplicaciones bilineales
 #+begin_definition
 *Aplicacin bilineal*. Una aplicacin $\phi:M\times N \longrightarrow P$ es bilineal si
 son lineales $\phi(\_,n)$ y $\phi(m,\_)$ para cualesquiera $m,n$.
 #+end_definition

 #+begin_definition
 *Producto tensor*. $M \otimes_R N$ es el producto tensor de $M$ y $N$ como mdulos de $R$
 si cualquier aplicacin bilineal factoriza de forma nica a travs de l:

 \[ \begin{tikzcd}
 M \times N \arrow{r}{\phi} \arrow{d}{\otimes} & P \\
 M \otimes N \arrow{ru}[swap]{\exists! \overline\phi} &
 \end{tikzcd} \]
 #+end_definition

 Usando universalidad podemos ver que $R \otimes N \cong N$ y que $M\otimes N \cong N\otimes M$. La construccin
 explcita del producto tensor se hace sobre el mdulo libre sobre $M \times N$ provocando un
 cociente sobre los submdulos generados por:

 \[(m,r_1n_1+r_2n_2) - r_1(m,n_1) - r_2(m,n_2)\]
 \[(r_1m_1+r_2m_2,n) - r_1(m_1,n) - r_2(m_2,n)\]

 Lo que nos permite actuar con ellos de forma bilineal. La demostracin se basa en usar
 la propiedad universal de la proyeccin sobre ese cociente.

***** 2.2. Adjuncin con Hom
 Dado un mdulo $N$ de $R$, tenemos un funtor covariante $\otimes_R N$, que ser *adjunto izquierdo*
 a $Hom_{R-mod}(N,-)$. Podemos observar simplemente que una aplicacin bilineal, al currificarse,
 determina una funcin que va de $M$ a $Hom(N,P)$, y que es lineal. Sabiendo esto, es trivial
 que:

 \[ Hom_R(M, Hom_R(N,P)) \cong Hom_R(M \otimes N, P)\]

 La naturalidad y el hecho de que es un isomorfismo se comprueban fcilmente. El hecho de
 que exista una adjuncin nos dice adems que $\otimes_R N$, o $N\otimes_R$ por la isomorfa anterior,
 son cocontinuos.

 #+begin_fact
 Para cualesquiera \(R\)-mdulos, se tiene:

 \[(M_1 \oplus M_2) \otimes N \cong (M_1 \otimes N) \oplus (M_2 \otimes N)\]

 \[N \otimes (M_1 \oplus M_2) \cong (N \otimes M_1) \oplus (N \otimes M_2)\]

 \[(\oplus_\alpha M_\alpha) \otimes N \cong \oplus_\alpha (M_\alpha \otimes N)\]
 #+end_fact

 Por cocontinuidad.

 #+begin_fact
 Para cualesquiera dos conjuntos $A,B$, se tiene:

 \[R^{\oplus A} \otimes R^{\oplus B} \cong R^{\oplus A \times B}\]
 #+end_fact

 Teniendo \(R^{\oplus n} \otimes R^{\oplus m} \cong R^{\oplus nm}\). De hecho, la base del espacio producto
 tensor la forman los vectores puros que emparejan elementos de las 
 bases de cada uno de los espacios.

 #+begin_theorem
 *Producto tensor de cocientes*. Dado un $N$ mdulo de $R$, e $I$ ideal,
 tenemos:

 \[\frac{R}{I}\otimes N \cong \frac{N}{IN}\]

 Y desde ah, aplicando adems el tercer teorema de isomorfa, tenemos:

 \[\frac{R}{I} \otimes \frac{R}{J} \cong \frac{R}{I+J}\]
 #+end_theorem

 Esto se deduce de aplicar el funtor $\_ \otimes N$ a la secuencia exacta del 
 ideal:

 \[I \longrightarrow R \longrightarrow \frac{R}{I} \longrightarrow 0\]
 
 \[I \otimes N \longrightarrow N \longrightarrow \frac{R}{I} \otimes N \longrightarrow 0\]

 Desde donde se obtiene $IN$ como inclusin de $I\otimes N$ en $N$.

***** 2.3. Exactitud y planitud
 #+begin_definition
 *Mdulo plano*. El mdulo $N$ es *plano* si el funtor $\_ \otimes N$ es un
 funtor exacto.
 #+end_definition

 Un *mdulo libre* ser siempre plano.

***** 2.4. Los funtores Tor
 #+begin_definition
 *El funtor Tor*. Lo que se aleja de la exactitud el funtor $\_ \otimes N$
 es medido por el funtor $Tor_1(\_,N)$. De hecho, si tenemos una secuencia
 exacta:

 \[0\longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0\]

 Obtenemos aplicando el funtor $\otimes N$ esta otra secuencia:

 \[Tor_1(C,N) \longrightarrow A \otimes N \longrightarrow B \otimes N \longrightarrow C \otimes N \longrightarrow 0\]

 Y de hecho, esta secuencia podr extenderse an ms con /funtores derivados/,
 que se definen como:

 \[Tor_i^R(M,N) = H_i(M_{\bullet} \otimes N)\]
 #+end_definition

 Aqu entendemos $M_\bullet \otimes N$ como el complejo que se obtiene tomando una resolucin
 libre de $M$:

 \[\dots \longrightarrow R^{\otimes S_2} \longrightarrow R^{\otimes S_1} 
 \longrightarrow R^{\otimes S_0} \longrightarrow M \longrightarrow 0}\]

 Y retirando $M$ y tensando sobre $N$, para tener:

 \[\dots \longrightarrow N^{\otimes S_2} \longrightarrow N^{\otimes S_1} 
 \longrightarrow N^{\otimes S_0} \longrightarrow 0}\]

 Todo esto se obtendr de manera natural aplicando el lema de la serpiente a una secuencia
 de resoluciones compatibles, algo que, si los mdulos fueran PID y tuvieran una resolucin
 de grado 2, sera de la forma:

 \[ \begin{tikzcd}
    & 0 \dar & 0 \dar & 0 \dar &   \\
 0 \rar & R^{\oplus a_1}\rar\dar & R^{\oplus b_1} \rar\dar & R^{\oplus c_1} \rar\dar & 0 \\
 0 \rar & R^{\oplus a_0}\rar\dar & R^{\oplus b_0} \rar\dar & R^{\oplus c_0} \rar\dar & 0 \\
 0 \rar & A\rar\dar & B \rar\dar & C \rar\dar & 0 \\
  & 0 & 0 & 0 & 
 \end{tikzcd} \]

 Tensando las dos filas superiores, que son libres, nos quedaran dos filas sobre las que aplicar
 el lema de la serpiente y obtener los funtores derivados tal y como los hemos definido.

**** 5. Funtor Hom y dualidad 
***** 5.1. Adjunciones, de nuevo
 Ya sabemos que el funtor $Hom(N,\_)$ es adjunto derecho a $\_\otimes N$, ahora
 estudiamos el funtor $Hom(\_,N)$.

 #+begin_theorem
 *Adjuncin de Hom contravariante*. El funtor $Hom(\_,N)$ es adjunto derecho
 de su funtor opuesto, $Hom^{op}(\_,N)$.
 #+end_theorem

 Aplicando currificacin tenemos trivialmente:

 \[Hom(L,Hom(M,N)) \cong Hom(M,Hom(L,N))\]

 Que, teniendo en cuenta que estamos usando la categora opuesta, prueba la
 adjuncin.

 #+begin_proposition
 *Exactitud de Hom*. Ambos funtores $Hom$ son adjuntos derechos y por tanto,
 exactos por la izquierda. Teniendo en cuenta que uno es contravariante, quiere
 decir que:

 \[ A \overset{}\longrightarrow B \overset{}\longrightarrow C \overset{}\longrightarrow 0\]

 Lleva a:

 \[ 0 \overset{}\longrightarrow Hom(C,N) \overset{}\longrightarrow 
 Hom(B,N) \overset{}\longrightarrow Hom(A,N)\]
 #+end_proposition

***** 5.2. Mdulos duales.
 #+begin_definition
 *Mdulo dual*. El dual de un R-mdulo $M$ es el mdulo $M^{\vee} = Hom_R(M,R)$.
 #+end_definition

 Tenemos que $Hom(M,R^n) \cong M^{\vee} \otimes R^n$.

**** 6. Mdulos proyectivos e inyectivos, y el funtor Ext
***** 6.1. Proyectividad e inyectividad
 #+begin_definition
 *Mdulos proyectivos e inyectivos*. Un R-mdulo es /proyectivo/ si $Hom(P,\_)$
 es exacto; e /inyectivo/ si $Hom(\_,P)$ es exacto.
 #+end_definition

 Esto es equivalente a decir que cada epimorfismo $M \longrightarrow N$ lleva un
 morfismo $P \longrightarrow N$ a $P \longrightarrow M$, en el caso de /proyectividad/:

 \[ \begin{tikzcd}
  & P \dlar[swap,dashed]{\exists p'} \dar[swap]{p} \drar{0} & \\
 M \rar & N \rar & 0
 \end{tikzcd} \]

 O que cada monomorfismo $L \longrightarrow M$ lleva un morfismo $L \longrightarrow Q$ a
 un monomorfismo $M \longrightarrow Q$, en el de la /inyectividad/:

 \[ \begin{tikzcd}
  & Q & \\
 0 \urar{0} \rar & N \rar \uar[swap]{q} & M \ular[dashed,swap]{\exists q'}
 \end{tikzcd} \]

 Adems, esto es equivalente a decir que un mdulo $P$ es /proyectivo/ si toda secuencia

 \[ 0 \overset{}\longrightarrow L \overset{}\longrightarrow M \overset{}\longrightarrow P \overset{}\longrightarrow 0 \]

 es escindida, y $Q$ es /inyectivo/ si toda secuencia:

 \[ 0 \overset{}\longrightarrow Q \overset{}\longrightarrow M \overset{}\longrightarrow N \overset{}\longrightarrow 0 \]

 es escindida.

***** 6.2. Mdulos proyectivos
 #+begin_theorem
 *Caracterizacin de proyectividad*. Un mdulo es proyectivo ssi es el sumando
 directo de un mdulo libre.
 #+end_theorem

 As, la suma directa de dos mdulos proyectivos es proyectiva; el producto tensor
 de dos mdulos proyectivos es proyectivo, y todo mdulo proyectivo es plano.

***** 6.3. Mdulos inyectivos
 #+begin_theorem
 *Caracterizacin de inyectividad*. Un mdulo es *inyectivo* ssi toda aplicacin
 $f : I \longrightarrow Q$ extiende a una aplicacin $\hat f : R \longrightarrow Q$, donde I es ideal de R.
 #+end_theorem

***** 6.4. El funtor Ext
 Existiran dos formas naturales de definir *Ext*, que coinciden no trivialmente:

 #+begin_definition
 *Funtor Ext*. Dado $M$ con una resolucin proyectiva:

 \[ \dots \overset{}\longrightarrow P_1 \overset{}\longrightarrow P_0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \]

 aplicamos el funtor contravariante $Hom(\_,N)$ eliminando $M$ para obtener:

 \[ 0 \overset{}\longrightarrow Hom(P_0,N) \overset{}\longrightarrow Hom(P_1,N) \overset{}\longrightarrow Hom(P_2,N) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomologa de este complejo $Hom(M_\bullet,N)$, dejando como definicin:

 \[Ext^i_R(M,N) = H^i(Hom(M_\bullet,N))\]
 #+end_definition

 #+begin_definition
 *Funtor Ext*. Dado $N$ con una resolucin inyectiva:

 \[ 0 \overset{}\longrightarrow N \overset{}\longrightarrow Q_0 \overset{}\longrightarrow Q_1 \overset{}\longrightarrow \dots \]

 aplicamos el funtor covariante $Hom(M,\_)$ eliminando $N$ para obtener:

 \[ 0 \overset{}\longrightarrow 
 Hom(M,Q_0) \overset{}\longrightarrow 
 Hom(M,Q_1) \overset{}\longrightarrow 
 Hom(M,Q_2) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomologa de este complejo $Hom(M,N_\bullet)$, dejando como definicin:

 \[Ext^i_R(M,N) = H^i(Hom(M,N_\bullet))\]
 #+end_definition

*** IX. lgebra homolgica
*** Complejos y homologa, de nuevo
**** 3.1. Recordatorio de definiciones bsicas
 #+begin_definition
 *Resolucin*. La /resolucin/ de un objeto $A$ es un complejo
 exacto excepto en un punto, donde es isomorfa a $A$.
 #+end_definition

 Esto es equivalente a tener un complejo exacto de la forma:

 \[ \dots \overset{}\longrightarrow 
 M_2 \overset{}\longrightarrow 
 M_1 \overset{}\longrightarrow 
 M_0 \overset{}\longrightarrow 
 A \longrightarrow
 0\]

**** 3.2. La categora de los complejos
 #+begin_definition
 *Categora de complejos de cocadenas*. La categora $C(A)$ tiene como objetos
 los complejos de cocadenas en una categora $A$; y como morfismos entre dos 
 cocadenas,   $Hom(M^\bullet,N^\bullet)$, los diagramas conmutativos entre ellas. Por ejemplo:

 \[ \begin{tikzcd}
 \dots \rar & M^{i-1} \rar\dar{\alpha^{i-1}} & M^{i} \rar\dar{\alpha^{i}} &  M^{i+1} \rar\dar{\alpha^{i+1}} & \dots \\
 \dots \rar & N^{i-1} \rar & N^{i} \rar & N^{i+1} \rar & \dots
 \end{tikzcd} \]

 representa el morfismo $\alpha_\bullet$.
 #+end_definition

 Esta es una categora abeliana. De ella definiremos adems dos variantes:

 - $C^+(A)$, subcategora plena de los complejos acotados por debajo.
 - $C^-(A)$, subcategora plena de los complejos acotados por arriba.
*** Exercises [20/62]
**** I. Preliminaries: Set theory and categories [1/1]
***** I.5. Universal properties
****** DONE Exercise I.5.12
#+begin_statement
Define notions of /fibered products/ and /coproducts/, as terminal objects of
the categories $C_{\alpha,\beta}$ and $C^{\alpha,\beta}$ considered in Example 3.10, by stating carefully
the corresponding universal properties.

As it happens, $\mathtt{Set}$ has both fibered products and coproducts. Define these
objects 'concretely', in terms of naive set theory.
#+end_statement

******* Fibered products
Given $\alpha\colon A \to C$ and $\beta \colon B \to C$, we take the objects of the category
to be commutative diagrams

\[\begin{tikzcd}[row sep=tiny]
 & A \drar{\alpha} & \\
Z\drar{g}\urar{f} && C\\
& B \urar{\beta} & &.
\end{tikzcd}\]

And morphisms to be of the form

\[\begin{tikzcd}[row sep=tiny]
& & A \drar{\alpha} & \\
Z' \rar{h}\ar[bend right]{drr}{g'} \ar[bend left]{urr}{f'} &
Z\drar{g}\urar{f} && C\\
& & B \urar{\beta} & &.
\end{tikzcd}\]

With the trivial identity $\mathrm{id}_Z \colon (Z,f,g) \to (Z,f,g)$. The terminal object
should be the one such that every other object's morphisms descompose
through it.

\[\begin{tikzcd}[row sep=tiny]
& & A \drar{\alpha} & \\
Z' \rar[dashed]{\exists! h}\ar[bend right]{drr}{g'} \ar[bend left]{urr}{f'} &
F\drar{\pi_{\beta}}\urar{\pi_{\alpha}} && C\\
& & B \urar{\beta} & &.
\end{tikzcd}\]

******* Fibered coproducts
The same idea can be applied to the dual construction

\[\begin{tikzcd}[row sep=tiny]
& & A \dlar{\iota_A}\ar[bend right]{lld}{f'} & \\
Z &
F \lar[dashed]{\exists! h} && 
C \ular{f}\dlar{g}\\
& & B \ular{\iota_B}\ar[bend left]{llu}{g'} & &.
\end{tikzcd}\]

******* In the category of sets
In $\mathtt{Set}$, the fibered product will be

\[
\left\{ (a,b) \in A \times B \mid \alpha(a) = \beta(b) \right\},
\]

as we can show using the product universal property. The fibered coproduct
is the coproduct divided by the equivalence relation generated by the
pairs $a \sim b$ such that $\exists c\colon a = f(c), b = g(c)$.

**** II. Groups, first encounter [16/28]
***** II.1. Definition of group
****** DONE Exercise II.1.1
#+begin_statement
Write a careful proof that every group is the group of isomorphisms of a
grupoid. In particular, every group is the group of automorphisms of some
object in some category.
#+end_statement

Given a group $(G,\bullet)$, we can define an object $G$ with morphisms the elements
of the group. Composition will be the binary operation of the group, and we
can check, using the group properties, that category axioms hold

 1. *Identity*, there is an identity element on $G$ which acts as the identity
    morphism: $e \circ a = a = a \circ e$.
 2. *Associativity* holds directly: $a \circ (b\circ c) = (a \circ b)\circ c$.

This only object defines a category which is also a grupoid, as every arrow
has an *inverse* by the last property of groups: every element of the group has
an inverse.

****** DONE Exercise II.1.2
#+begin_statement
Consider the 'sets of numbers' listed in 1.1, and decide which are made into 
groups by conventional operations such as $+$ and $\cdot$. Even if the answer is negative,
see if variations on the definition of these sets lead to groups.
#+end_statement

******* The empty set
It is not a group, as it has no identity.

******* Naturals
They form no group with addition, as not every element has an inverse.

******* Integers
They are a commutative group with the addition.

******* Rational numbers
They are a group with addition, and also a group with multiplication if we
consider $0$ out of the group.

******* Real numbers
They follow the same logic as the rationals.

******* Complex numbers
Same logic as the rationals.
****** TODO Exercise II.1.3
****** TODO Exercise II.1.4
****** TODO Exercise II.1.5
****** TODO Exercise II.1.6
****** TODO Exercise II.1.7
****** TODO Exercise II.1.8
****** TODO Exercise II.1.9
****** TODO Exercise II.1.10
****** TODO Exercise II.1.11
****** TODO Exercise II.1.12
****** DONE Exercise II.1.13
#+begin_statement
Give an example showing that $|gh|$ is not necessarily equal to $\mathrm{lcm}(|g|,|h|)$, even
if $g$ and $h$ commute.
#+end_statement

In $(\mathbb{Z}/\mathbb{Z}_4,+)$, we have $\mathrm{lcm}(|1|,|1|) = |1| = 4$, but $|1+1| = 2$.

****** DONE Exercise II.1.14
#+begin_statement
As a counterpoint to [[*Exercise II.1.13][Exercise 13]], prove that if $g$ and $h$ commute, 
and $\mathrm{gcd}(|g|,|h|) = 1$, then $|gh| = |g||h|$.
#+end_statement

We know that $|gh| = N \mid |g||h|$. If we divide to obtain $g^{N} = (h^{-1})^{N}$, we have

 * $1 = \left( g^{-1} \right)^{N|g|} = h^{N|g|}$
 * $1 = \left( h^{-1} \right)^{N|h|} = g^{N|h|}$

and then, $|h| \mid N|g|$ and they are coprimes, so $|h| \mid N$. Likewise, $|g| \mid N$.
Finally, $|gh| = \mathrm{lcm}(|h|,|g|) \mid N$.

****** DONE Exercise II.1.15
#+begin_statement
Let $G$ a commutative group, and let $g \in G$ be an element of maximal /finite/
order: that is, such that if $h \in G$ has finite order then $|h| \leq |g|$. Prove that
in fact if $h$ has finite order in $G$ then $|h|$ divides $|g|$.
#+end_statement

If $|h|$ does not divide $|g|$, then there is a prime $p$ such that

 * $|h| = p^{a+b}m$
 * $|g| = p^bn$, with $\mathrm{gcd}(n,p) = 1$.

then we know that $|h^m| = p^{a+b}$ and $|g^{p^b}| = n$. Using [[*Exercise II.1.14][exercise 14]] (we are in a
commutative group), we know that $|g^{p^b}h^m| = p^{a+b}n$, contradicting maximality.

***** II.2. Examples of groups
****** DONE Exercise II.2.2
#+begin_statement
Prove that if $d \leq n$, then $S_n$ contains elements of order $d$.
#+end_statement

The element $(1\;2\;\dots\;d)$ has order $d$.

****** TODO Exercise II.2.5
***** II.3. The category Grp
****** DONE Exercise II.3.1
#+begin_statement
Let $\varphi\colon G \to H$ be a morphism in a category $C$ with products. Explain why there
is a unique morphism

\[(\varphi\times\varphi)\colon G\times G \to H \times H.\]
#+end_statement

The real morphism is $(\varphi\circ \pi_1 \times \varphi \circ \pi_2)$, using the projections from $C$ as presented
in the following diagram

\[\begin{tikzcd}[column sep=small,row sep=tiny]
& G \times G\drar\dlar\ar[dashed]{dd}{\varphi\times\varphi} & \\
G\ar{dd} & & G\ar{dd} \\
& H \times H\drar\dlar & \\
H & & H \\
\end{tikzcd}\]

****** DONE Exercise II.3.8
#+begin_statement
Define a group $G$ with two generators $x,y$, subject (only) to the relations
$x^2=e$, $y^3=e$. Prove that $G$ is a coproduct of $C_2$ and $C_3$ in $\mathtt{Grp}$.
#+end_statement

Given any two morphisms $f\colon C_2 \to H$ and $g \colon C_3 \to H$, we define $h(x) = f(1)$ 
and $h(y) = g(1)$ as it should be to make the diagram commutative. There is
only a possible way to extend this morphism to $h \colon G \to H$.

***** II.4. Group homomorphisms
****** DONE Exercise II.4.3
#+begin_statement
Prove that a group of order $n$ is isomorphic to $\mathbb{Z}/n\mathbb{Z}$ if and only if it
contains an element of order $n$.
#+end_statement

If it contains $a$ of order $n$, then $e,a,a^2,\dots,a^{n-1}$ are $n$ different elements.
As the group is of order $n$, they constitute the whole group.

****** DONE Exercise II.4.8
#+begin_statement
Let $G$ be a group, and $g \in G$. Prove that the function $\gamma_g \colon G \to G$ defined
by $\gamma_g(a) = gag^{-1}$ is an automorphism of $G$. Prove that the function $G \to \mathrm{Aut}(G)$
defined by $g \mapsto \gamma_g$ is a homomorphism. Prove that this homomorphism is trivial
if and only if $G$ is abelian.
#+end_statement

The function $\gamma_g$ is trivially a homomorphism, and it has the inverse $\gamma_{g^{-1}}$.
We can check that $g\mapsto \gamma_g$ is a homomorphism, as

\[
\gamma_h\gamma_g(a) = hga(hg)^{-1} = \gamma_{hg}(a).
\]

If the homomorphism is trivial, $a = gag^{-1}$ for any $a,g \in G$; this is 
equivalent to abelianity.

****** DONE Exercise II.4.11
#+begin_statement
In due time, we will prove the easy fact that if $p$ is a prime integer then
the equation $x^d=1$ can have at most $d$ solutions in $\mathbb{Z}/p\mathbb{Z}$. Assume this fact,
and prove that the multiplicative group $G = (\mathbb{Z}/p\mathbb{Z})^{\ast}$ is cyclic.
#+end_statement

If the group is not cyclic there is no element of order $p-1$. So the element
of maximal order has order $d < p-1$, and every other element has a [[*Exercise II.1.15][divisor
of this order]] as its order. Then the equation $x^d = 1$ has more than $p-1$ roots,
contradicting the assumption.

****** TODO Exercise II.4.16
#+begin_statement
Prove /Wilson's theorem/: a positive integer $p$ is prime if and only if

\[(p-1)! \equiv -1  \mod p.
\]
#+end_statement

We are multiplying all elements of $(\mathbb{Z}/p\mathbb{Z})^{\ast} \cong (\mathbb{Z}/(p-1)\mathbb{Z})$

***** II.5. Free groups
****** DONE Exercise II.5.3
#+begin_statement
Use the universal property of free groups to prove that the map $j \colon A \to F(A)$ is
injective, for all sets $A$.
#+end_statement

If it were not injective, with $j(a) = j(b)$, every $f \colon A \to G$ should follow 
$f(a)=f(b)$, but given any two $a,b$ we can define $f \colon A \to \mathbb{Z}\times\mathbb{Z}$ by sending
$f(a) = (1,0)$, $f(b) = (0,1)$, and every other element to $0$.

****** DONE Exercise II.5.6
#+begin_statement
Prove that the group $F(\left\{ x,y \right\})$ is a coproduct $\mathbb{Z}\ast\mathbb{Z}$ of $\mathbb{Z}$ by itself in the
category $\mathtt{Grp}$.
#+end_statement

Given $d \colon \left\{ a,b \right\} \to G$, we use the coproduct inclusions on $\mathtt{Set}$ to define 
individual arrows

\[\begin{tikzcd}[column sep=tiny]
& G & \\
& \left\{ a,b \right\}\uar{d} & \\
\left\{ a \right\} \arrow[bend left]{uur} \urar{i} & & 
\left\{ b \right\} \arrow[bend right]{uul} \ular[swap]{i}
\end{tikzcd}\]

and then simply use the universal property of the free modules of one
element as follows

\[\begin{tikzcd}[column sep=small]
& G & \\
& \mathbb{Z}\ast\mathbb{Z} \uar[dashed] & \\
\mathbb{Z}\ar{ur}\ar[dashed,bend left]{uur} & & 
\mathbb{Z}\ar{ul}\ar[dashed,bend right]{uul} \\
& \left\{ a,b \right\} \ar[dashed]{uu} &\\
\left\{ a \right\}\urar \arrow[bend left=90]{uuuur}  \ar{uu} &&
\left\{ b \right\}\ular \arrow[bend right=90]{uuuul} \ar{uu}
\end{tikzcd}\]

****** DONE Exercise II.5.7
#+begin_statement
Extend the result of [[*Exercise II.5.6][Exercise 5.6]] to free groups $F(\left\{ x_1,\dots,x_n \right\})$ and to free
/abelian/ groups $F^{ab}(\left\{ x_1,\dots,x_n \right\})$.
#+end_statement

The same argument can be repeated $n$ times to obtain $\mathbb{Z}\ast \overset{n}\dots \ast\mathbb{Z}$ as free group.
As $\mathbb{Z}\oplus\mathbb{Z}$ is the abelian coproduct, $\mathbb{Z}\oplus\dots\oplus\mathbb{Z}$ is the free group.

***** II.6. Subgroups
****** DONE Exercise II.6.1
#+begin_statement
The group of invertible $n \times n$ matrices with entries in $\mathbb{R}$ is denoted $GL_n(\mathbb{R})$.
Similarly, $GL_n(\mathbb{C})$ denotes the group of $n \times n$ invertible matrices with complex
entries. Consider the following sets of matrices:

 * $SL_n(\mathbb{R}) = \left\{ M \in GL_n(\mathbb{R}) \mid \mathrm{det}(M)=1 \right\}$;
 * $SL_n(\mathbb{C}) = \left\{ M \in GL_n(\mathbb{C}) \mid \mathrm{det}(M)=1 \right\}$;
 * $O_n(\mathbb{R}) = \left\{ M \in GL_n(\mathbb{R}) \mid MM^t = M^tM = I_n \right\}$;
 * $SO_n(\mathbb{R}) = \left\{ M \in O_n(\mathbb{R}) \mid \mathrm{det}(M)=1 \right\}$;
 * $U(n) = \left\{ M \in GL_n(\mathbb{C}) \mid MM^{\dag} = M^{\dag}M = I_n \right\}$;
 * $SU(n) = \left\{ M \in U_n(\mathbb{C}) \mid \mathrm{det}(M) = 1 \right\}$;

Here $I_n$ stands for the $n \times n$ identity matrix, $M^t$ is the /transpose/ of $M$,
$M^{\dag}$ is the /conjugate transpose/ of $M$, and $\mathrm{det}(M)$ denotes the /determinant/
of $M$. Find all possible inclusions among these sets, and prove that in every
case the smaller set is a subgroup of the larger one.
#+end_statement

We are dealing with three different properties:

  1. The matrix has entries in $\mathbb{C}$.
  2. The matrix has its conjugate transpose as its inverse, $MM^{\dag}=I_n$.
  3. The matrix has determinant $1$, $\mathrm{det}(M) = 1$.

None of them implies the others. The three properties give rise to this 
three-dimensional cube

\[\begin{tikzcd}[column sep=tiny, every arrow/.append style={dash}]
&& GL(\mathbb{C}) & \\
& U(n) \urar & SL_n(\mathbb{C})\uar & GL(\mathbb{R})\ar{ul} \\
& SU(n) \uar\ar{ur} & O_n(\mathbb{R}) \ular\urar & SL_n(\mathbb{R}) \ular\uar\\
&& SO_n(\mathbb{R})\uar \urar\ular & & .
\end{tikzcd}\]

****** DONE Exercise II.6.3
#+begin_statement
Prove that every matrix in $SU(2)$ may be written in the form

\[\begin{pmatrix}
a+bi & c+di \\
-c+di & a-bi
\end{pmatrix}\]

where $a,b,c,d \in \mathbb{R}$ and $a^2+b^2+c^2+d^2 = 1$. (Thus, $SU(2)$ may be
realized as a three-dimensional sphere embedded in $\mathbb{R}^4$; in particular,
it is /simply connected/.)
#+end_statement

If we take $\alpha,\beta,\gamma,\delta \in \mathbb{C}$, and create a special unitary matrix, we have 
the relationships

 * $|\alpha|+|\beta| = 1$
 * $\alpha\delta-\beta\gamma = 1$
 * $\alpha\overline{\gamma} + \beta\overline{\delta} = 0$

that are solved by $\alpha = \overline{\delta}$ and $\beta = -\overline{\gamma}$, while the first one gives us the
sphere condition.

**** III. Rings and modules [3/15]
***** III.1. Definition of a ring
****** DONE Exercise III.1.1
#+begin_statement
Prove that if $0=1$ in a ring $R$, then $R$ is a zero-ring.
#+end_statement

By definition,

\[
r = 1r = 0r = 0r+0r = 0.
\]

***** III.5. Modules over a ring
****** DONE Exercise III.5.4
#+begin_statement
Let $R$ be a ring. A nonzero $R\text{-module}$ is /simple/ (or /irreducible/) if its
only submodules are $\left\{ 0 \right\}$ and $M$. Let $M,N$ be simple modules, and let
$\varphi \colon M \to N$ be a homomorphism of $R\text{-modules}$. Prove that either $\varphi = 0$, or
$\varphi$ is an isomorphism. (This rather innocent statement is known as *Schur's 
Lemma*.)
#+end_statement

The kernel and image of $\varphi$ will be submodules, they only can be the total
submodule or the zero submodule, as $M,N$ are simple modules. There are two 
cases

  - If $\operatorname{ker}\phi = \{0\}$, it is a monomorphism. Its image must be different
    from $0$, thus it must be $N$.

  - If $\operatorname{ker} \phi = M$, we have $\phi = 0$.

***** III.6. Products and coproducts in R-Mod
****** CHECK Exercise III.6.16
#+begin_statement
Let $R$ be a ring. A (left-)$R\text{-module}$ $M$ is /cyclic/ if $M = \left\langle m \right\rangle$ for
some $m \in M$. Prove that simple modules (cf. Exercise 5.4) are cyclic.
Prove that an $R\text{-module}$ $M$ is cyclic if and only if $M \cong R/I$ for some
(left-)ideal $I$. Prove that every quotient of a cyclic module is cyclic.
#+end_statement

******* Un mdulo simple es cclico
Tomemos un elemento suyo cualquiera y
creamos $<m>$. Ocurre que debe ser un submdulo y por ser simple, todo
el mdulo.

******* Un cociente por ideal es cclico.
 Sea $M = R/I$, un mdulo sobre $R$ podemos generarlo simplemente 
 por $<1>$, luego es cclico.
 Sea $M=<m>$ un mdulo cclico. Podemos tomar un isomorfismo que lleve
 $r \mapsto rm$ y definir $I = \{r\;|\;rm=0\}$. Por 1er Teorema de isomorfa:

 \[M \cong R/ker(\phi) \cong R/I\]

******* Todo cociente de cclico es cclico.
Usando el tercer teorema de isomorfa:

\[\frac{\frac{R}{I}}{J} \cong \frac{\frac{R}{I}}{\frac{I+J}{I}} \cong \frac{R}{I+J}\] (?)

***** III.7. Complexes and homology
****** TODO Exercise III.7.1. Exactitud entre ceros.

 \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \overset{}\longrightarrow \dots \]

 Tenemos que el ncleo de la segunda debe ser igual a la imagen de la primera y
 por tanto, cero. Eso slo es posible si $M=0$.

****** TODO Exercise III.7.2. Exactitud entre isomorfas
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow M \overset{}\longrightarrow M' \overset{}\longrightarrow 0 \longrightarrow \dots\]
 Tenemos por el primer 0 la funcin inyectiva y por el segundo la funcin 
 sobreyectiva. Debe ser por tanto isomorfismo.

****** TODO Exercise III.7.3. Kernel y cokernel en secuencia exacta
     \[ \dots \overset{}\longrightarrow 0 \overset{}\longrightarrow L \overset{}\longrightarrow M 
     \overset{\phi}\longrightarrow M' \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]
 Por el primer 0 tengo una inyeccin $i$ de $L$ en $M$, que lo identifica con
 $im(i) = ker(\phi)$. Del segundo 0 tengo que la imagen de la proyeccin $\pi$ de
 $M'$ en $N$ es todo $N$. Entonces, por teorema de isomorfa y por exactitud:

 \[N = im(\pi) \cong \frac{M'}{ker(\pi)} = \frac{M'}{im(\phi)} = coker(\phi)\]

****** TODO Exercise III.7.4. Hotel de Hilbert
 Dada una secuencia de enteros, podemos moverla un paso a la derecha:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,a_2,\dots)\] 

 Para tener el morfismo $\alpha$ que nos da la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\alpha}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi_1}\longrightarrow \mathbb{Z} \overset{}\longrightarrow 0 \]

 Dada una secuencia de enteros, podemos moverla a los sitios pares y hacer
 proyeccin de los impares luego:

 \[(a_1,a_2,a_3,\dots) \longrightarrow (0,a_1,0,a_2,0,a_3,\dots)\]

 Para tener los morfismos $\beta$ y $\pi$ que nos dan la secuencia exacta:

 \[ 0 \overset{}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\beta}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{\pi}\longrightarrow \mathbb{Z}^{\oplus \mathbb{N}} \overset{}\longrightarrow 0 \] 

****** TODO Exercise III.7.5. Exactitud entre noetherianos
 Tenemos la secuencia exacta:

 \[ \dots \overset{}\longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \overset{}\longrightarrow \dots \]

 Y supongamos $L,N$ noetherianos. Sea entonces una sucesin de ideales \(\{M_i\}\),
 tenemos que las sucesiones de ideales \(\{\alpha^{-1}(M_i)\}\) y \(\{\beta(M_i)\}\) se estabilizarn
 a partir de un cierto $j$. Tomando un $i > j$ tendremos que $M_i = M_{i+1}$ y por tanto,
 se estabilizar la secuencia inicial.

 Supongamos que existiera $x \in M_{i+1}$ pero $x \notin M_i$. Dividimos en dos casos:

 *Caso 1*. $x \in im(\alpha)$, tendramos que existira algn elemento 
 $a \in \alpha^{-1}(x) \subset \alpha^{-1}(M_{i+1}) = \alpha^{-1}(M_{i})$, pero por definicin entonces $x = \alpha(a) \in M_i$.

 *Caso 2*. $x \notin im(\alpha)$, tendramos $\beta(x) \in \beta(M_{i+1})$. Existe un $y \in M_i$ tal que 
 $\beta(y) = \beta(x)$, es decir, $x-y \in ker(\beta)$. Pero entonces $x-y \in im(\alpha)$ y por tanto,
 $x-y \in M_i$, llevando a $x\in M_i$.

****** TODO Exercise III.7.6. Epimorfismo escindido
 Sea una sucesin:

 \[ 0 \overset{}\longrightarrow ker(\phi) \overset{}\longrightarrow M \overset{\phi}\longrightarrow N \overset{}\longrightarrow 0 \]

 Supongamos que *escinde*, entonces $\phi$ es la proyeccin hacia $N$ y tiene
 como inversa derecha a la inclusin.

 Supongamos que *tiene inversa* derecha $\psi$, entonces buscamos un isomorfismo
 entre $M \cong ker(\phi) \oplus N$, que tenemos con estos dos morfismos:

 \[(k,n) \mapsto \psi n + k\]
 \[m \mapsto (m-\psi \phi m, \phi m)\]

****** TODO Exercise III.7.10. Lema corto de los cinco 
 Si en el lema de la serpiente son $\lambda$ y $\nu$ isomorfismos, tenemos la sucesin:

 \[0 \longrightarrow 0 \longrightarrow ker(\mu) \longrightarrow 0 \overset{\delta}\longrightarrow
   0 \longrightarrow coker(\mu) \longrightarrow 0 \longrightarrow 0\]

 Por tanto, el kernel y cokernel de $\mu$ son nulos y es isomorfismo.

****** TODO Exercise III.7.11. Todo morfismo de escisin es isomorfismo
 Directamente aplicando el ejercicio anterior, tenemos que $N \cong M_1 \oplus M_2$.

****** TODO Exercise III.7.12. Lema de los cuatro (1)
 Lo probamos por caza del diagrama. Primero tomamos un elemento en el ncleo
 de C y aplicamos:

 - Inyectividad de $\delta$. 
 - Exactitud de $BCD$.
 - Exactitud de $ABC$.
 - Sobreyectividad de $\alpha$.
 - Exactitud de $ABC$.

 Teniendo que el elemento es nulo.

****** TODO Exercise III.7.13. Lema de los cuatro (2)
 Volvemos a cazar diagramas. Tomamos un $c'$ en $coker(\gamma)$ y hacemos:

 - Exactitud de CDE.
 - Inyectividad en E.
 - Sobreyectividad de D.
 - Exactitud de CDE.

 Y as llegamos a un $z \in C$ que tiene como imagen un $z' \in C'$. Tomamos $c'-z'$,
 que tiene imagen nula en $D$ y aplicamos:

 - Exactitud de BCD.
 - Sobreyectividad en $B$.

 Y obtenemos un $x \in C$ que tiene como imagen a $c'-z'$. Finalmente: $\gamma(x+z) = c'$.

****** TODO Exercise III.7.14. Lema de los cinco
 Trivial uniendo ambos lemas de los cuatro.

**** VI. Linear Algebra [0/13]
***** VI.1. Free modules revisited
****** TODO Exercise VI.1.1. R y C son isomorfos como espacios vectoriales de Q
Sabemos que $C \cong R \oplus R$. Dada una base $B$ de $\mathbb{R}$, podemos ver que ser
infinita y por axioma de eleccin isomorfa a $B+B$, que ser a su
vez una base de $\mathbb{R}^2$. Luego $\mathbb{R} \cong \mathbb{R} \oplus \mathbb{R}$.

****** TODO Exercise VI.1.4. lgebras de Lie
 Demostramos que $[u,v] = -[v,u]$. Ya que tenemos:

 $$[u,v] + [v,u] = [u,v] + [u,u] + [v,v] + [v,u] = [u+v,v] + [u+v,u] = [u+v,u+v] = 0$$

 Para todas las K-lgebras, tomar $[v,w] = vw-wv$ nos da un lgebra de Lie.
 Podemos verlo porque cumple las tres primeras propiedades que se le piden a un
 lgebra de Lie y adems:

 \begin{align*}
 [[u,v],w] + [[v,w],u] + [[w,u],v] & = \\
 (uvw-vuw-wuv+wvu) &+\\
 (vwu-wvu-uvw+uwv) &+\\
 (wuv-uwv-vwu+vuw) &=\\
 0
 \end{align*}

****** TODO Exercise VI.1.5. Sistemas generadores e independientes en dominios de integridad
 Un sistema independiente puede no crecer a base y un sistema generador
 puede no reducirse a base en un dominio de integridad. Como ejemplos
 tenemos $\mathbb{Z}$ con: {2} como sistema independiente y $\{2,3\}$ como sistema generador.
 Ninguno puede crear base porque las nicas bases posibles seran $\{1\}$ y $\{-1\}$.

****** TODO Exercise VI.1.13. Un grupo abeliano con endomorfismos de caracterstica 0.
 Si tiene endomorfismos que forman un cuerpo de caracterstica 0, podemos
 identificar $\mathbb{Z}$ con los endomorfismos por propiedad universal y
 luego podemos extenderlo por contener $Q$ las inversas. De otro modo, 
 $Q$ es inicial en la categora de cuerpos de caracterstica 0, as, hay
 forma de identificarlo con endomorfismos del cuerpo.

 As, nuestro grupo $A$ es espacio vectorial sobre $Q$. Y es de dimensin 1,
 porque si tuviera dimensin mayor y una base de ms de un elemento, colapsar
 dos elementos de la base en uno sera un endomorfismo sin inversa.

****** TODO Exercise VI.1.14. La potencia de un isomorfismo estabiliza kernel e imagen.
 Tenemos que $ker(\phi^n) \subset ker(\phi^{n+1})$ y que dos subespacios contenidos de la misma
 dimensin deben ser iguales. Por tanto, la dimensin debe crecer o estabilizarse
 a cada paso. Si la dimensin es finita debe estabilizarse en algn punto.

 Por otro lado, tenemos que las imgenes deben estabilizarse en dimensin
 para tener $ker(\phi^n) \oplus im(\phi^{n+1}) = V$. Y entonces, para que el kernel no crezca,
 ninguno de los vectores que forman la base de $im(\phi^n)$ pueden tener como
 imagen algo que est en $ker(\phi)$, as que vuelven a tener como imagen algo en
 $im(\phi^{n+1})$, que debe estar contenido en $im(\phi^n)$ y ser de la misma
 dimensin.

***** VI.2. Homomorphisms of free modules I
****** TODO Exercise VI.2.1. Grupo isomorfo a la suma
 Tenemos que:

 \[
 \left( \begin{matrix} 1 & 0 \\ r & 1 \end{matrix} \right)
 \left( \begin{matrix} 1 & 0 \\ p & 1 \end{matrix} \right) =
 \left( \begin{matrix} 1 & 0 \\ r+p & 1 \end{matrix} \right)
 \]

 Luego la proyeccin del tercer elemento es un isomorfismo
 de grupos.

****** TODO Exercise VI.2.6. Row echelon form
 Cuando trabajamos en un cuerpo podemos pasar a /row echelon form/ usando
 los siguientes pasos:

  - Pasamos el primer elemento no nulo a la fila ms alta.
  - Lo hacemos uno con su inversa y reducimos toda la columna restante.
  - Hacemos lo mismo con la submatriz a la derecha y debajo de ese 1.

 Esto debe dejarnos slo ceros debajo y encima de los 1 pivotes.

***** VI.4. Presentations and resolutions
****** TODO Exercise VI.4.1. Tor(M) es submdulo de M cuando R es dominio de integridad.
 Tenemos $Tor(M) = \{ m | \exists r \in R : r \neq 0, rm = 0\}$, y siendo dos elementos $m,n$ en $Tor(M)$, 
 que cumplen que $rm = 0$ y $qn = 0$, podemos
 ver que su suma ser cerrada y que el producto por $r\in R$ ser cerrado cuando
 $R$ es conmutativo:

  - $rq(m+n) = rqm+qrn = 0+0 = 0$
  - $r(pm) = p(rm) = 0$

 Usando aqu que es dominio de integridad y por tanto $rq \neq 0$.

****** TODO Exercise VI.4.2. Hom(M,N) es libre de torsin cuando lo es N.
 Supongamos que no lo fuera, existira un $f \in Hom_R(M,N)$ tal que 
 $rf = 0$ para algn $r$ no divisor de $0$. Pero entonces, esto hara
 que en el anillo $N$ existiese $rf(m) = 0$ para cualquier $m$, y por 
 ser libre de torsin, se tendra $f(m) = 0$ para todo $m$.
 Luego $f=0$.

 En particular $Hom_R(M,R)$ es libre de torsin.

****** TODO Exercise VI.4.4. Propiedades del anulador
 Suponiendo $p,q \in Ann(R)$, tenemos que para todo $m \in M$ se tendr
 $pm=0$ y $qm=0$. Por lo tanto $(p+q)m=0$ y $rpm = 0$, hacindolo ideal.

******* M de torsin si y slo si el anulador es no nulo.
 Si $Ann(M) \neq 0$, existe un elemento de $R$ que anula todo $M$, como
 adems $R$ es dominio de integridad, este elemento no ser divisor de 0, y $M$
 ser torsin. Si $M$ es torsin y finitamente generado, tendr un elemento
 $r_i$ que anular cada uno de sus generadores $m_i$. Siendo $R$ conmutativo,
 el elemento producto estar en el anulador

                      \[
 \prod_{i} r_i
 \] 

 Ntese que si quitamos la condicin de que $M$ sea finitamente generado, existen
 mdulos como \(\mathbb{Z}_2 \oplus \mathbb{Z}_4 \oplus \mathbb{Z}_8 \dots\) que son torsin porque todo elemento se anula pero
 tienen anulador vaco porque no existen elementos que anulen todo el mdulo.

****** TODO Exercise VI.4.13. Complejo de Koszul

******* Es un complejo.
 Comprobamos que es un complejo viendo que las siguientes composiciones son $0$:

  - \(d_1 \circ d_2 (t) = bta - atb = 0\)
  - \(\pi \circ d_1 (r,s) = (ra+sb)\ mod(a,b)) = 0 \)

******* Es un complejo exacto cuando la secuencia es regular.
 Y comprobamos que es exacto en el caso en el que la secuencia es regular viendo
 que:

 - \(ker(d_2) = 0\), ya que $a$ no es divisor de cero.
 - \(ker(d_1) = <(b,-a)>\). Tenemos que $b$ no es divisor de cero mdulo $a$, as, para que
   sea linealmente dependiente con $a$ necesitamos algo que sea cero mdulo $a$. Este
   caso requiere $s$ mltiplo de $a$. Esto requiere estar dentro del ideal generado por
   $(b,-a)$.
 - Que la imagen de $d_1$ es el ncleo de $\pi$ y que la proyeccin es sobreyectiva
   es trivial.

****** TODO Exercise VI.4.14. Complejo de Koszul en el caso de 3 elementos
******* Es un complejo
 Volvemos a comprobar que las composiciones son nulas. Tenemos de hecho que:

 \[d_2 \circ d_1 = d_3 \circ d_2 = 0\]

 Y que la proyeccin coincide con el generado por $d_1$.

******* Es un complejo exacto cuando la secuencia es regular
 Otra vez, como $c$ no es divisor de cero mdulo $(a,b)$, tenemos que el kernel
 de $d_3$ es nulo. De la misma forma, se tiene que el $ker(d_2)=im(d_3)$, aplicando
 en cada caso el no ser divisor de cero. Vuelve a tenerse una ecuacin similar
 que demuestra $ker(d_1) = im(d_2)$. El caso de la proyeccin es trivial.
****** TODO Exercise VI.4.15. Resolucin de Z sobre Z[x,y]
 Podemos encontrar una resolucin como:

 \[0 \longrightarrow 
 \mathbb{Z}[x,y] \overset{\phi} \longrightarrow 
 \mathbb{Z}[x,y]^2 \overset{\delta} \longrightarrow 
 \mathbb{Z}[x,y] \overset{\pi} \longrightarrow 
 \mathbb{Z} \longrightarrow 0 \]

 Donde $\pi$ es un morfismo que cancela $x,y$. $\delta$ es un morfismo que lleva
 cada una de las copias del $1$ a $x$ e $y$. Finalmente, $\phi$ es monomorfismo
 que lleva $1$ a $(y,-x)$ que es generador de $ker(\delta)$.

**** VIII. Linear algebra, reprise [0/5]
***** VIII.1. Preliminaries, reprise
****** TODO Exercise VIII.1.2. Funtor plenamente fiel respeta isomorfas 
 Sea ${\cal F}(A) \cong {\cal F}(B)$, gracias a dos morfismos inversos $\alpha,\beta$. Como
 el funtor es pleno, existen dos morfismos preimagen de ambos
 llamados $\alpha',\beta'$ y tenemos que:

 \[{\cal F}(\alpha' \circ \beta') = \alpha \circ \beta = 1\]

 Por ser fiel, debemos tener $\alpha' \circ \beta' = 1$.
****** TODO Exercise VIII.1.3. Accin de grupo como funtor
 Sea $G$ un grupo. Su accin sobre un objeto $C$ ser un morfismo que
 enve cada elemento del grupo a un isomorfismo de $C$. Es decir, un
 homomorfismo de grupos:

 \[(G,\ast) \longrightarrow (Aut(C),\circ)\]

 Pero como podemos ver $G$ como un objeto tal que cada uno de sus elementos
 sea un isomorfismo, tenemos claramente un isomorfismo:

 \[(Aut(G),\circ) \cong (G,\ast) \longrightarrow (Aut(C),\circ)\]

 Y podemos definir el funtor que lleva $G$ a $C$ y que lleva cada endomorfismo
 de $G$ a uno de $C$.

****** TODO Exercise VIII.1.17. Complecin de un lgebra
 Tenemos que los $R/I^n$ son mdulos en R-Mod, por tanto, la cadena siguiente
 tendr lmite. Donde los morfismos sern las inclusiones naturales:

 \[\dots \longrightarrow R/I^3 \longrightarrow R/I^2 \longrightarrow R/I \]

 Ese lmite lo llamamos $R_I$, y es el submdulo de secuencias coherentes de $\prod_i R/I^i$.
 Es decir, un elemento suyo es una secuencia tal que cada elemento es la proyeccin
 del siguiente. Este submdulo es conmutativo porque lo es el producto de todos los mdulos.

 Podemos incluir $R$ en $R_I$ llevando el $1$ a $(1,1,1,\dots)$. Y esto conmutar con las
 proyecciones naturales que nos daba la propiedad universal.
 Para que $x$ se anule al incluirlo en $R_I$ desde $R$, necesitamos que todas las proyecciones
 de su imagen sean $0$, as que necesitamos que pertenezca a $I_n$ para cada $n$.

****** TODO Exercise VIII.1.19. Enteros p-dicos
 Llamamos enteros p-dicos al lmite $\mathbb{Z}_p = \varprojlim \mathbb{Z}/p^i\mathbb{Z}$, y nmeros p-dicos a su cuerpo de fracciones
 $\mathbb{Q}_p$. Por definicin, un entero p-dico es una secuencia de enteros $\{a_i\}$ tales que:

 \[ a_s \equiv a_r  \mod (p^s)\]

 Para cualesquiera $s \leq r$. De otra forma, cada entero tiene una expansin nica:

 \[ A = b_0 + b_1 p + b_2 p^2 + b_3 p^3 + \dots\]

 Donde $b_i < p$. Esto es as porque dada una secuencia $(a_i)$, tenemos la igualdad:

 \[b_0 = a_0\]
 \[b_i p^i + a_{i+1} = a_i\]

 Y se puede construir una desde la otra usando que $a_i - a_{i+1} \equiv_{p^i} 0$. 

 A partir de aqu podemos hacer aritmtica como usualmente desde estos desarrollos de los
 nmeros p-dicos.
***** VIII.2. Tensor products, and the Tor functors
****** TODO Exercise VIII.2.14. Tor en 0 es el producto tensor
 La definicin inicial de Tor es como:

 \[Tor^R_i(M,N) = H_i(M_\bullet \otimes N)\]

 Y como tenemos que el complejo $M_\bullet \otimes N$ es el siguiente,
 siendo $S_0$ una base de $M$, y $S_1$ base de las relaciones de $M$:

 \[ \dots \overset{}\longrightarrow N^{\oplus S_2} 
 \overset{\phi_2}\longrightarrow N^{\oplus S_1} 
 \overset{\phi_1}\longrightarrow N^{\oplus S_0} 
 \overset{}\longrightarrow 0 \]

 Que ha salido de tensar el siguiente complejo exacto:

 \[ \dots \overset{}\longrightarrow R^{\oplus S_1} \overset{\psi_2}\longrightarrow R^{\oplus S_0} \overset{\psi_1}\longrightarrow M \overset{}\longrightarrow 0 \]

 Tenemos que:

 \[H_i(M_\bullet \otimes N) \cong \frac{N^{\otimes S_0}}{im(\phi_1)} \cong 
 \frac{R^{\otimes S_0}}{im(\psi_2)} \otimes N \cong M \otimes N \]

 Donde usamos la exactitud de la segunda secuencia con el primer teorema de isomorfa
 y el hecho de que el functor $\otimes N$ respeta los colmites y por tanto el cociente, que puede
 verse como coecualizador.
** Sheaves in geometry and logic - MacLane, Moerdijk
*** 0. Categorical preliminaries
**** Adjoints
Adjoints functors are natural isomorphisms of the form 

\[
\theta \colon \mathrm{Hom}(X,GA) \cong \mathrm{Hom}(FX,A)
\]

with the naturality condition given by the equation

\[
\theta(G\alpha \circ f \circ \beta) = \alpha \circ \theta(f) \circ F\beta
\]

*** I. Categories of functors
**** I.1. The categories at issue
***** Examples of topoi
****** Sets
Small sets with functions between them.

****** n-Sets
Given $n \in \mathbb{N}$, the $n\text{-tuples}$ of sets with $n\text{-tuples}$ of functions between them.

****** G-Sets
Representations of a fixed group $\mu\colon X\times G \to X$, with morphisms preserving
the group action $f(x\cdot g) = f(x) \cdot g$.

****** M-Sets
Representations of a fixed monoid.

****** 2-Sets
Category of functions betweeen sets $\sigma\colon X \to X'$ and commutative squares
between them.

****** N-Sets
Category of sequences $X_0 \to X_1 \to X_2 \to \dots$ of sets and commutative squares
as morphisms.

****** Preseaves
Objects are presheaves $P\colon C^{op} \to \mathtt{Sets}$, and arrows natural transformations
$\theta\colon P \to P'$.

******* Yoneda embedding
$y \colon C \to \Set^{C^{op}}$ is full and faithful.

****** Comma category
Objects are functions $h \colon X \to J$ for a fixed $J$ and arrows
commuting triangles. Each object determines a family of sets

\[
H_j = h^{-1}(j) = \left\{ x \mid x \in X, h(x) = j \right\}
\]

and each function determines a family $f_j \colon H_j \to H'_j$. If we take
$J$ as a discrete category, each object of the comma category is a
functor from it and each morphism is a natural transformation.

That is, we can see the comma category inside a presheaf category
with this assignment

\[
L\colon \Set/J \to \Set^{J}
\]

while in the other direction, each functor provides an object $\bigsqcup H_j$
in the comma category; thus providing a complete equivalence of
categories.

/The comma category is equivalent to a presheaf category./

It is *not* an isomorphism because the composition of both
constructions may not be the identity (the disjoint union is only
unique up to isomorphism).

****** Sheaves over a topological space
Category of sheaves over a topological space.

****** Continuous G-Sets
Given $G$ a topological group, the continuous representations of the group
are the objects with the continuous homomorphisms of actions.

****** Simplicial sets
A *simplicial object* is a family of objects $\left\{ S_n  \right\} \in C$ satisfiying the
simplicial identities

******* TODO Simplicial identities
****** Finite sets
Finite sets and functions between them.

****** Presheaves to finite sets

***** Presheaves
Many of these examples can be seen in a way as examples of presheaf
categories.

**** I.2. Pullbacks
***** Pullback
A *pullback* of $X \to B \gets Y$ is the universal object and
projections making this diagram commute

\[\begin{tikzcd}
P\rar[dashed]{f'} \dar[dashed,swap]{g'} & Y \dar{g} \\
X\rar{f} & B &.
\end{tikzcd}\]

****** In sets
We have the set of pairs $\pair{x,y}$ such that $f(x)=g(y)$.

****** In inclusions
If we have that $g$ is an inclusion, $P$ is the inverse image $f^{-1}(Y)$,
included in $X$.

If both $f,g$ are inclusions, we have the intersection of two subsets.

****** Indexed sets
If $g\colon Y \to B$ is regarded as an indexed set $\left\{ G_b \right\}$ of inverse images
of each $b \in B$, the pullback is $\left\{ G'_x \right\} = \left\{ G_{fx} \right\}$.

***** Pullbacks always exist on a presheaf category
The pullback of any two presheaves exists on a preseaf category.

****** Proof
We know that the pullback of any two sets exists in $\mathtt{Set}$ as the
fibered product. Given two preseaves $X,Y$, we can construct a new 
pullback preseaf pointwise, taking $(X \times_B Y)C$ as the pullback 
of $XC$ and $YC$. In other words,

\[
(X \times_B Y)(C) \cong X(C) \times_{B(C)} Y(C).
\]

Given any $f\colon C \to D$, we take $Pf\colon PC \to PD$ as the unique universal arrow
making the two diagrams commute.
# ???

***** Kernel pair of a morphism
Pullback of $f$ with itself induces an equivalence relation of the
morphism with itself.

***** Pullback along a monic is monic
The pullback along a monic is always monic.

****** Proof
Diagram chasing using the fact that the first one is monic and then
using the universal property of pullbacks to prove uniqueness.

****** In Sets, the pullback of epi is epi

***** All finite limits are constructed by terminal object and pullbacks
A category with a terminal object and all pullbacks has all finite limits.

In presheaves, all finite limits are constructed pointwise. 
# Note that exponentials are NOT a finite limit.

****** Proof
All finite limits can be constructed from finite products and equalizers.
Binary products are pullbacks using the terminal object, which is also the
product of no factors. Equalizers are created from pullbacks $X \to Y \times Y \gets Y$ 
with the diagonal function.

***** TODO Pullbacks in continuous G-sets
**** I.3. Characteristic functions of subobjects
***** Subobject classifier
A *subobject classifier* is a monic $t\colon 1 \rightarrowtail \Omega$ such that for every monic $S \rightarrowtail X$
exists a unique $\Phi \colon X \to \Omega$ creating a pullback square

\[\begin{tikzcd}
S\rar{1} \dar[swap]{i} & 1 \dar{t} \\
X\rar[dashed]{\Phi} & \Omega
\end{tikzcd}\]

where the morphism $t$ is called /true/.

***** Set of subobjects
A subobject is an equivalence class of monics.

We call $\mathrm{Sub}_C(X)$ to the set of subobjects $S$ of $X$. It is
partially ordered under inclusion.

****** Subobject functor
A pullback

\[\begin{tikzcd}
S'\rar{} \dar[swap]{m'} & S \dar{m} \\
Y\rar{f} & X
\end{tikzcd}\]

defines a functor $\mathrm{Sub}\ f\colon \mathrm{Sub}(X) \to \mathrm{Sub}(Y)$.

***** Well-powered category
A category is *well-powered* when $\mathrm{Sub}_C(X)$ is isomorphic to a small set
for any $X$.

***** Existence of a subobject classifier in well-behaved categories
A category $C$ with finite limits and small hom-sets has a subobject classifier
if and only if there is a natural isomorphism

\[
\theta \colon \mathrm{Sub}_C(-) \cong \mathrm{Hom}_C(-,\Omega),
\]

and then, $C$ is also well-powered.

****** Proof
******* Given a subobject classifier
There exists a unique characteristic function for each equivalence
class of monics; an this is a bijection (from the characteristic
function, the monic can be recovered up to isomorphism).

To show that this is natural, given any $f \colon Y \to X$, we have to
prove that

\[\begin{tikzcd}
\mathrm{Sub}(X) \rar{\theta} \dar[swap]{f^{-1}} & \mathrm{hom}(X,\Omega) \dar{\circ f} \\
\mathrm{Sub}(Y) \rar{\theta} & \mathrm{hom}(Y,\Omega)
\end{tikzcd}\]

and this can be proved by the pullback theorem, by which two pullback
squares can be joint in a outer pullback square

\[\begin{tikzcd}
S'\rar{} \dar[swap]{} & S \dar{}\rar & 1\dar{\mathrm{true}} \\
Y\rar{f} & X \rar{\phi} & \Omega
\end{tikzcd}\]

${\cal C}$ is well-powered because all hom-sets are small

******* Given a natural bijection
The identity corresponds to some subobject $t_0 \colon \Omega_0 \to \Omega$. By naturality,
$S = \mathrm{Sub}(\phi)(\Omega_0)$ and every subobject is the pullback of some $\Omega_0$.

Now, we show that $\Omega_0$ is in fact the terminal object. The following
two squares are pullbacks because $t_0$ is monic

\[\begin{tikzcd}
X \rar[bend left]{\phi'} \rar[bend right]{\phi''} \dar[swap]{\mathrm{id}} & 
\Omega_{0} \dar{t_{0}} \\
X \rar[bend left]{t_{0}\phi'} \rar[bend right]{t_{0}\phi''} & \Omega
\end{tikzcd}\]

and by unicity, we have $t_0\phi' = t_0\phi''$ and $\phi' = \phi''$.

***** TODO G-bundles
**** I.4. Typical subobject classifiers
***** Examples of subobject classifiers
****** Classifier for Sets and Finite sets
The classifier $1 \to 2$.

****** Classifier for n-Sets
The classifier is a n-tuple of $1 \to 2$ functions. There are $2^n$
truth values.

****** Classifier for BG-Sets
The same classifier $1 \to 2$ works, $G$ acts trivially on both sets.

****** Classifier for BM-Sets
The same classifier for groups does not work, because complements need not
to be closed under the action of a monoid.

****** TODO Arrow category
****** TODO Time sets
****** TODO Subfunctors
**** I.5. Colimits
***** Colimits in functor categories
Colimits in functor categories can be computed pointwise
\[
(\varinjlim H)(C) = \varinjlim H(C).
\]

***** Every object is a colimit of representable objects
In a functor category $\mathtt{Sets}^{C^{op}}$, every object $P$ is
the colimit of a diagram of representable objects.

***** TODO Theorem 2
**** I.6. Exponentials
***** In sets
$(-)^{X}$ is the right adjoint of $- \times X$.

***** The representable functors category is cartesian closed
For any small category ${\cal C}$, the functor category $\mathtt{Sets}^{\mathcal{C}^{op}}$ is cartesian closed.

****** TODO Proof

**** I.7. Propositional calculus
***** TODO Sets and boolean algebras, open subsets and heyting algebras
***** Lattice
A *lattice* is a partially ordered set, which, interpreted as a category,
has all binary products and coproducts.

That is, $x \leq y$ if and only if $x \to y$.

A lattice with $0 \leq x \leq 1$ are the initial and terminal objects, and has all
finite limits and colimits.

***** TODO Equational definition of a lattice
***** TODO Complements on a lattice
***** TODO Boolean algebra
***** TODO Complete lattice
**** I.8. Heyting algebras
***** Heyting algebra
A Heyting algebra is a poset with all finite products and coproducts which is
cartesian closed.

***** TODO Properties of Heyting algebras

**** I.9. Quantifiers as adjoints
*** IV. First properties of Elementary topoi
**** IV.1. Definition of a topos
***** Elementary topos
****** Definition
A *topos* ${\cal E}$ is a category with

  * an object $\Omega$, called the *subobject classifier*;
  * a function ${\cal P}$ on objects, called the *powerset*;
  * two natural isomorphisms $\mathrm{Sub}_{{\cal E}}A \cong \mathrm{hom}_{{\cal E}}(A,\Omega)$ and
    $\mathrm{hom}_{{\cal E}}(B \times A,\Omega) \cong \mathrm{hom}_{{\cal E}}(A,{\cal P}B)$.

****** Alternative definition
A *topos* is a category with finite limits and a function on its
objects ${\cal P}$ such that
\[
\mathrm{Sub}_{{\cal E}}(B \times A) \cong \mathrm{Hom}_{{\cal E}}(A,{\cal P}B)
\]
is an natural isomorphism in $A$.

****** Definition: Elementary form
A *topos* is a category ${\cal E}$ such that

  1) pullbacks exist for every diagram of the form

     \[\begin{tikzcd}[column sep=small, row sep=small]
     X \drar  & & Y\dlar \\
        & B &
     \end{tikzcd}\]

  2) it has a terminal object $1$;

  3) it has a *subobject classifier* $\Omega$ with a monic arrow $\mathtt{true} \colon 1 \to \Omega$ such that
     for every monomorphism $m \colon S \to B$, there is a unique arrow $\mathrm{char}\ m$, called
     the *classifying map* of $m$ such that the following diagram is a pullback

     \[\begin{tikzcd}
     S \dar[swap]{m}\rar & 1 \dar{\mathrm{true}} \\
     B \rar[swap]{\mathrm{char}\ m} & \Omega
     \end{tikzcd}\]

  4) it has a function on objects ${\cal P}$ and an morphism $\in_B\colon B \times {\cal P}B \to \Omega$ such
     that for every $f \colon B \times A \to \Omega$, an unique $g \colon A \to {\cal P}B$ making the following
     diagram commute

     \[\begin{tikzcd}[row sep=small]
     A \ar[dashed]{dd}{g} & B \times A \drar{f}\ar[dashed,swap]{dd}{1 \times g} \\
     & & \Omega \\
     {\cal P}B & B \times {\cal P}B \urar[swap]{\in_B} &
     \end{tikzcd}\]

# Membership map is dinatural in B.

***** Generalized elements
****** Generalized and global elements
An arrow $b \colon X \to B$ is a *generalized element* of $B$ defined over $X$. The generalized
elements defined over the terminal object $1$ are the *global elements* of $B$.

****** Predicate
A morphism $\theta \colon B \to \Omega$ is called a *predicate*.

****** Subobjects
A subobject of $A$ has the following three descriptions

  1) $m \colon S \to A$ monomorphism, as an equivalence class of monics;

  2) $\phi\colon A \to \Omega$, as a predicate;

  3) $s \colon 1 \to {\cal P}A$, as a global element of the powerset.

we call $S = \left\{ a \mid \phi \right\}$ the *extension* of $\phi$; $\phi = \mathrm{char}\ S$ the *characteristic function*
of $S$ and $s = \lceil\phi\rceil$ the *name* of $\phi$.

****** Kronecker delta

****** Monicity of the transpose of the Kronecker delta
For all objects $B$ in a topos, $\left\{ \cdot \right\}$ is monic.

****** Bimorphisms are isomorphisms in a topos
In a topos, every monomorphism is an equalizer and every bimorphism
is an isomorphism.

***** Exponentials
****** Every topos is cartesian closed
Every topos has exponentials.

**** IV.8. Lattice and Heyting algebra objects in a topos
***** Internal lattice
An internal lattice in a category is an object $L$ with morphisms
\[
\bigwedge \colon L \times L \to L,
\qquad
\bigvee \colon L \times L \to L
\]

and commutative diagrams expressint the identities of a lattice

  * associativity,
  * commutativity,
  * idempotent laws,
  * absorption law.

Such a lattice object has a zero and a one if there are arrows
\[
\top \colon 1 \to L,
\qquad
\bot \colon 1 \to L,
\]
with the appropiate identities.

***** Internal Heyting algebra
Exists an implication $\Rightarrow \colon L \times L \to L$ satisfiying the diagrammatic version
of the identities of the implication.

***** Partial order on an internal lattice
We can define a subobject $\leq_L$ on the category as the following equalizer
\[\begin{tikzcd}
\leq_{L}\rar & 
L \times L \rar[shift left=.75ex]{\wedge}\rar[swap,shift right=.75ex]{\pi_1} & 
L.
\end{tikzcd}\]

****** Equivalent definition of internal Heyting algebra

***** External Heyting algebra
Given $A$ in a topos ${\cal E}$, $\mathrm{Sub}\ A$ is a Heyting algebra. The structure
is natural in $A$, in the sense that the pullback along any morphism
$k\colon A \to B$ induces a map $k^{-1}$ of Heyting algebras.

****** TODO Proof
***** Internal Heyting algebra
Given $A$ in a topos ${\cal E}$, ${\cal P}A$ is an internal Heyting algebra. Th structure
is natural in $A$, in the sense that that the any morphism $k\colon A \to B$
induces a map ${\cal P}k \colon {\cal P}A \to {\cal P}B$ of Heyting algebras.

The internal structure of ${\cal P}A$ makes $\mathrm{hom}(X,{\cal P}A)$ an external Heyting
algebra with the following isomorphism of Heyting algebras
\[
\mathrm{Sub}(A \times X) \cong \mathrm{Hom}(X,{\cal P}A).
\]

****** TODO Proof
*** VI. Topoi and logic
*** VI.1. The topos of sets
**** Natural numbers object
In an arbitrary topos ${\cal E}$, a *natural numbers object* is the object $\mathbb{N}$
with arrows

\[\begin{tikzcd}
1\rar{0} & \mathbb{N}\rar{s} & \mathbb{N}
\end{tikzcd}\]

which is universal in the sense that for any other object with the same
arrows, we can define a commutative diagram

e\[\begin{tikzcd}
1\rar{0}\dar{\cong} & \mathbb{N}\rar{s}\dar[dashed]{h} & \mathbb{N} \dar[dashed]{h}\\
1\rar{x} & X\rar{f} & X &.\\
\end{tikzcd}\]

***** Recursion as a universal property
Definition by recursion assumes the existence of this universal object.

**** Natural numbers by adjunction
Given ${\cal E}$ with a natural numbers object $\mathbb{N}$ and adjoints $g^{\ast} \dashv g_{\ast}$, the diagram

\[\begin{tikzcd}
1 \cong g^{\ast}(1) \rar{g^{\ast}(0)} &
g^{\ast}(\mathbb{N}) \rar{g^{\ast}(s)} &
g^{\ast}(\mathbb{N})
\end{tikzcd}\]

is a natural numbers object.

***** TODO Proof

**** Boolean topos
A topos ${\cal E}$ is *boolean* when the internal Heyting algebra $\Omega$ is an internal
boolean algebra.

*** Ejercicios [0/27]
**** I. Categories of Functors [0/11]
***** TODO Exercise I.1
#+begin_statement
Show that pullbacks of epis are epi for categories of each of
the types (i)-(ix).
#+end_statement

***** TODO Exercise I.2
#+begin_statement
Prove that $\mathtt{FinSets}^{\mathbb{N}}$ has no subobject classifier.
#+end_statement

***** TODO Exercise I.3
***** TODO Exercise I.4
***** TODO Exercise I.5
***** TODO Exercise I.6
***** TODO Exercise I.7
***** TODO Exercise I.8
***** TODO Exercise I.9
***** TODO Exercise I.10
***** TODO Exercise I.11
**** IV. First Properties of Elementary Topoi [0/16]
***** TODO Exercise I.1
***** TODO Exercise I.2
***** TODO Exercise I.3
***** TODO Exercise I.4
***** TODO Exercise I.5
***** TODO Exercise I.6
***** TODO Exercise I.7
***** TODO Exercise I.8
***** TODO Exercise I.9
***** TODO Exercise I.10
***** TODO Exercise I.11
***** TODO Exercise I.12
***** TODO Exercise I.13
***** TODO Exercise I.14
***** TODO Exercise I.15
***** TODO Exercise I.16
** Lecture notes on the lambda calculus - Salinger
*** 1. Introduction
*** 2. The untyped lambda calculus
**** 2.5. Formal definitions of \beta-reduction and \beta-equivalence
***** \beta-equivalence
The \beta-equivalence $M =_{\beta} M'$ is the symmetric transitive closure
of the \beta-reduction $\rightarrow_{\beta}$.

*** 3. Programming in the untyped lambda calculus
*** 4. The Church-Rosser Theorem
**** 4.1. Extensionality, \eta-equivalence, and \eta-reduction
***** Extensionality principle
The *principle of extensionality* is defined as the following rule

\[\begin{prooftree}
\LeftLabel{($ext_{\forall}$)}
\AxiomC{$\forall A. M A = M' A$}
\UnaryInfC{$M = M'$}
\end{prooftree}\]

***** Single step \eta-reduction
***** Single step \beta-reduction

**** 4.2. Statement of the Church-Rosser Theorem
Let $\twoheadrightarrow$ be $\twoheadrightarrow_{\beta}$ or $\twoheadrightarrow_{\beta\eta}$; and lambda terms such that $M\twoheadrightarrow N$ and $M \twoheadrightarrow P$; then
there exists a term $Z$ such that $N \twoheadrightarrow Z$ and $P \twoheadrightarrow Z$.

\[\begin{tikzcd}[column sep=small]
& M \drar[two heads] \dlar[two heads] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

**** 4.3. Preliminary remarks on the proof of the Church-Rosser theorem
***** Church-Rosser property

\[\begin{tikzcd}[column sep=small]
& M \drar[two heads] \dlar[two heads] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

***** Semidiamond property

\[\begin{tikzcd}[column sep=small]
& M \drar[] \dlar[] & \\
N \drar[two heads,dashed] & & P \dlar[two heads,dashed] \\
& Z & \\
\end{tikzcd}\]

***** Diamond property

\[\begin{tikzcd}[column sep=small]
& M \drar[] \dlar[] & \\
N \drar[dashed] & & P \dlar[dashed] \\
& Z & \\
\end{tikzcd}\]

***** Relationship between properties
**** 4.4. Proof of the Church-Rosser Theorem (Tait & Martin-Lf)
***** Parallel one-step reduction
We define the *parallel one-step reduction* as the smallest relation
satisfying

\[\begin{prooftree}
\LeftLabel{(1)}
\AxiomC{$a$}
\UnaryInfC{$x \rhd x$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(2)}
\AxiomC{$P \rhd P'$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$PN \rhd P'N'$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(3)}
\AxiomC{$N \rhd N'$}
\UnaryInfC{$\lambda x. N \rhd \lambda x.N'$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(4)}
\AxiomC{$Q \rhd Q'$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$(\lambda x. Q) N \rhd Q'[N' / x]$}
\end{prooftree}\]

\[\begin{prooftree}
\LeftLabel{(5)}
\AxiomC{$P \rhd P'$, where $x \notin \mathrm{FV}(P)$}
\AxiomC{$N \rhd N'$}
\BinaryInfC{$(\lambda x. Q) N \rhd Q'[N' / x]$}
\end{prooftree}\]

***** TODO Lemmas on the parallel one-step reduction

***** Proof of the Church-Rosser Theorem
We know that $\rhd$ satisfies the diamond property, so its reflexive transitive
closure $\rhd^{\ast}$ also satisfies it. We use now that $\rhd^{\ast}$ is the same as $\twoheadrightarrow_{\beta\eta}$ and
that the diamond property for $\twoheadrightarrow_{\beta\eta}$ is the Church-Rosser property for $\twoheadrightarrow$.

*** 5. Combinatory algebras
**** 5.1. Applicative structures
***** Applicative structure
An *applicative structure* $(\mathbf{A},\cdot)$ is a set with a binary operation, that
can be non-associative.

***** Polynomials of applicative structures
A *polynomial* on an applicative structure $(\mathbf{A},\cdot)$ is a formal expression built
with the binary operation on variables and coefficients. It is the set of
expressions built from the grammar

\[
t,s ::= x \mid a \mid ts,
\]

where $x$ is a variable and $a \in A$.

**** 5.2. Combinatory completness
***** Combinatory completness
***** SK characterization of combinatory completness
**** 5.5. Lambda algebras

*** 6. Simply-typed lambda calculus, propositional logic, and the Curry-Howard isomorphism
**** 6.1. Simple types and simply-typed terms
***** Basic types
We assume a set of *basic types* to exist.

***** Simple types
The set of *simple types* is given by the BNF

\[
A,B ::= \iota\mid A \to B \mid A \times B \mid 1
\]

where $\iota$ is a [[*Basic types][basic type]] and $1$ is a one-element type.

***** Raw types lambda terms
The set of *typed lambda terms* is given by the BNF

\[ \mathtt{Term} ::=
\ast \mid
x \mid
\mathtt{Term}\mathtt{Term} \mid
\lambda x^{\mathtt{Type}}. \mathtt{Term} \mid
\left\langle \mathtt{Term},\mathtt{Term} \right\rangle \mid
\pi_1 \mathtt{Term} \mid
\pi_2\mathtt{Term}
\]

where $\ast$ will be the unique element of type $1$. Besides the
previously considered term application, we now introduce a typed
lambda abstraction and an explicit construction of the pair element with
its projections.

***** Typing rules for the simply-typed lambda calculus
**** 6.2. Connections to propositional logic
*** 7. Weak and strong normalization
**** 7.1. Definitions
**** 7.2. Weak and strong normalization in typed lambda calculus
*** 8. Polymorphism
System F is obtained extending the typed lambda calculus with the quantifier $\forall$.

**** 8.4. Church-Rosser property
*** 9. Type inference
A /type inference algorithm/ decides, given a term, whether it is typable or
not, and outputs a type if it is.

*** 10. Denotational semantics
Denotational semantics give an interpretation of the lambda calculus using
mathematical objects.

*** 11. The language PCF
*** 12. Complete partial orders
*** 13. Denotational semantics of PCF
** Higher order categorical logic - Lambek, Scott
*** 0. Introduction to category theory
**** 0.1. Categories and functors
**** 0.2. Natural transformations
**** 0.6. Triples
**** 0.7. Examples of cartesian closed categories
*** I. Cartesian closed categories and \lambda-calculus
*** II. Type theory and toposes
*** III. Representing numerical functions in various categories
** An introduction to homological algebra - Rotman
*** 1. Introduction
**** 1.1. Simplicial Homology
***** Motivation: Green's Theorem
****** Original statement
Let $C$ be a positively oriented, smooth and simple closed curve in
a plane; being $D$ the region bounded by $C$. If $L,M$ have continuous
partial derivatives in $D$, then:

\[ \oint_C (L dx + M dy) = 
\iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

****** A rewrite
If we have some "bad points" that we want to delete from $C$.
We can define multiple $\gamma_i$ around them and have our integral to be:

\[ \oint_C (L dx + M dy) +
\sum^n_{i=1} \left( \int_{\gamma_i} L dx + Q dy \right) 
= \iint_D \left(
  \frac{\partial M}{\partial x} - \frac{\partial L}{\partial y}
\right) dx dy\]

As the diagram is:

[[./images/greentheorem.png]]

In this setting, the notion of $\mathbb{Z}$ linear combinations of paths
makes sense. We can take the free abelian group $G[Y]$ with $Y$ being
the set of paths $\gamma : [0,1] \longrightarrow X$.

****** An equivalence relation
For functions satisfying $\frac{\partial Q}{\partial x} = \frac{\partial P}{\partial y}$, the double integral dissapears,
and we have:

\[ \int_{m\gamma + \sum_i m_i\gamma_i} P dx + Q dy = 0\]

Here we can define an equivalence relation between pairs of paths,
where $\beta \sim \beta'$ if:

\[ \int_\beta P dx + Q dy = \int_{\beta'} P dx + Q dy \]

The equivalence class of $\beta$ is called its *homology class*.

***** Boundaries
If we take the simplices to form abelian groups, the boundaries
are homomorphisms.

[[./images/rectangle.png]]

For instance, if we can take this rectangle and compute its boundary.
We use free abelian groups of $n\text{-simplexes}$, called $C_n(X)$.

****** Boundary of a triangle
We use the minus sign to denote the inverse path, and we have:

\[ \delta([a,b,c]) = [a,b] + [b,c] - [a,c]\]

****** Boundary of the boundary of a triangle
As the double boundary is the boundary of a sphere, it is 
automatically null:

\[
\delta(\delta([a,b,c])) = (a - b) + (b - c) - (a - c) = 0
\]

****** Boundary of the rectangle
Now, we can compute the boundary of the rectangle; assuming that
the boundary function is a homomorphism preserving the union:

\[\begin{aligned}
\delta(\square) &=  \delta[a,b,c] + \delta[a,c,d] \\ 
&= [a,b]+[b,c]-[a,c]+[a,c]+[c,d]-[a,d] \\
&= [a,b]+[b,c]+[c,d]-[a,d]
\end{aligned}\]

***** Simplicial boundary maps
Let $X$ be a finite simplicial complex. We define:

\[ \delta_n [v_0,\dots,v_n] 
= \sum^n_{i=0} (-1)^i [v_0,\dots,\hat{v_i},\dots,v_n]\]

being a map from $C_n(X)$ to $C_{n-1}(X)$. We define $\delta_0 = 0$ as a convention.

***** Boundary maps are exact
For all $n > 0$, 

\[\delta_{n-1}\delta_n = 0\]

****** Proof
We can see that, for every pair of indexes, we have the same term 
twice, depending on whether we take the two indexes ordered or using
an inverse order:

\[ 
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{i+(j-1)} +
[x_0,\dots,\hat{x_i},\dots,\hat{x_j},\dots,x_n](-1)^{j+i} = 0
\]

***** Simplicial cycles and boundaries
The elements in $Z_n(X) = \ker \delta_n \subset C_n(X)$ are called *simplicial cycles*.
The elements in $B_n(X) = \im \delta_{n+1} \subset C_n(X)$ are called *simplicial 
boundaries*.

***** Exactness for cycles and boundaries
For all $n$,

\[ B_n(X) \subseteq Z_n(X)\]

****** Proof
It is trivial knowing that boundary maps are [[*Boundary maps are exact][exact]].

***** Simplicial homology group
The nth simplicial homology group of a finite simplicial complex is:

\[ H_n(X) = Z_n(X) / B_n(X) \]

What survives in this group are the cycles that are not boundaries;
that is, the boundaries of punctured sections.

***** Two modifications
We can consider *homology* with coefficients in $G$ by tensoring the
sequence of chain groups by $G$ and taking homology groups. We can
consider the *cohomology* with coefficients in $G$ applying $Hom(-,G)$
to the chain of groups and then taking homology groups.

**** 1.2. Categories and Functors
***** 1.2.1. Russell's paradox
The Russell paradox is solved in with the Zermelo-Fraenkel axioms,
specifically, the *axiom of comprehension*. It says that any definable
subclass of a set is a set; restricting the comprehension to only
already defined sets.

***** 1.2.2. Classes and sets
A class in ZFC is called *small* if it has a cardinal number. A *set*
is only a small class. In this book, we only worry about classes and
sets that are not a member of themselves.

# A cardinal number?
# More details in Mac Lane, Categories for the working mathematician.

***** 1.2.3. Categories
A category ${\cal C}$ consists of:

 - $obj({\cal C})$, a class of objects.
 - $Hom(A,B)$, a set of morphisms for every ordered pair $(A,B)$.
 - $\circ : Hom(A,B) \times Hom(B,C) \longrightarrow Hom(A,C)$, composition of functions.

***** 1.2.4. Axioms of categories
A category has disjoint $Hom$ sets, and there must be an identity element
$1_A \in Hom(A,A)$ for every morphism, following these rules:

 - The identity is a neutral element: $f \circ 1_A = f$ and $1_B \circ f = f$.
 - Composition is associative: $f \circ (g \circ h) = (f \circ g) \circ h$

***** 1.2.5. Examples of categories
****** Sets
****** Groups
****** Partially ordered sets
****** Inclusion of open sets
****** Topological spaces
****** Abstract simplicial complexes
******* Abstract simplicial complexes
We denote =Abs= the category of abstract simplicial complexes.
An abstract simplicial complex $K$ is a set of *vertices* $Vert(K)$ and
a family of nonempty finite subsets called *simplexes* 
$\sigma \subseteq Vert(K)$ such that:

 1. $\{v\}$ is a simplex for every $v \in Vert(K)$.
 2. Every subset of a simplex is a simplex.

******* Simplicial maps
A *simplicial map* is a function $\phi : Vert(K) \longrightarrow Vert(L)$ 
such that, if $\sigma$ is a simplex in $K$, then $\phi(\sigma)$ is a simplex
in $L$.

******* Dimension
A simplex with $|\sigma| = n+1$ is called a *n-simplex*. Simplicial
maps don't have to preserve dimension.

****** Nerves
If ${\cal U} = \{U\}_{i\in I}$ is the cover of a topological space, we define an 
abstract simplicial complex ${\cal N}({\cal U})$ having vertices $Vert({\cal N}({\cal U})) = {\cal U}$
and simplexes $\{U_0,\dots,U_n\} \subseteq {\cal U}$ such that:

\[ \bigcap_{k=0}^n U_k = \varnothing\]

****** Monoids
****** Homotopy category
***** 1.2.6. Algebraic examples of categories
****** Abelian groups
****** Rings (unital)
****** Commutative rings
***** 1.2.7. Modules
A left R-module, where $R$ is a ring, is an additive abelian group $M$
with a scalar multiplication $R \times M \longrightarrow M$, such that:

 1. $r(m+m') = rm+rm'$
 2. $(r+r')m = rm + r'm$
 3. $(rr')m = r(r'm)$
 4. $1m = m$

A right module is defined anagously.

***** 1.2.8. Examples of modules
****** Vector spaces over a field
****** Abelian groups over Z
****** Every ring over itself
****** Every ring over its center

***** 1.2.9. Homomorphisms of R-modules
A function $f : M \longrightarrow N$ such that:

 1. $f(m+m') = f(m)+f(m')$
 2. $f(rm) = rf(m)$

In the case of right modules, we can define them anagously.

****** The composite and inverse of homomorphisms is an homomorphism
Trivial.

***** 1.2.10. Examples of homomorphisms
****** Linear transformations in vector spaces
****** Homomorphisms of abelian groups for Z-modules
****** Homothety
Let $M$ be an R-module, and $r \in Z(R)$; multiplication by $r$, $\mu_r$, is
an homomorphism because:

\[ \mu_r(am) = r(am) = a(rm) = a\mu_r(m)\]

***** 1.2.11. Opposite rings
If $R$ is a ring, its opposite ring $R^{op}$ is the same ring with the
opposite multiplication, defined by:

\[ \mu^o(r,t) = \mu(t,r)\]

***** 1.2.12. Categories of modules
We call $_RMod$ the category of *left* R-modules, and $Mod_R$ to the 
category of *right* R-modules.

***** 1.2.13. Subcategories
A category ${\cal S}$ is a subcategory of ${\cal C}$ when:

 1. $obj({\cal S}) \subseteq obj({\cal C})$.
 2. $Hom_S(A,B) \subseteq Hom_C(A,B)$.
 3. Identities and compositions are the same.

***** 1.2.14. Full subcategories
A full subcategory has $Hom_S(A,B) = Hom_C(A,B)$ for every $A,B \in obj({\cal S})$.

***** 1.2.15. Functors
A functor $T : {\cal C} \longrightarrow {\cal D}$ is a function such that:

 1. $T : obj({\cal C}) \longrightarrow obj({\cal D})$.
 2. $T : Hom(A,B) \longrightarrow Hom(TA,TB)$.
 3. Preserves composition: $T(f \circ g) = Tf \circ Tg$.
 4. Preserves identities: $T(1_A) = 1_{T(A)}$.

***** 1.2.16. Examples of functors
****** Subcategories as inclusion functors
****** Identity functor
****** Hom(A,-) functor
****** Chains as functors from the partially ordered integers
****** Forgetful functors

***** 1.2.27. Diagrams
A diagram is a functor whose domain is a *small category*; that
is $T : {\cal D} \longrightarrow {\cal C}$, where $obj({\cal D})$ is a set.

***** 1.2.28. Paths
A path is a functor $P : n+1 \longrightarrow {\cal C}$, where the domain is the partial 
ordering of integers $0,\dots,n+1$. A path is *simple* if the functor is
injective.

***** 1.2.29. Commutativity of diagrams
A diagram commutes if the composites of the labels on any two simple path
are equal.

***** TODO 1.2.30. Contravariant functors
***** TODO 1.2.31. Examples of contravariant functors
****** Hom(-,B) functor
****** The dual space functor
\[( )^\ast = Hom_k(-,k) : \sideset{_k}{}{Mod} \longrightarrow \sideset{_k}{}{Mod}\]
****** Order-reversing functions on partially ordered sets

****** Presheaves
If ${\cal U}$ is a topology with the inclusion, a contravariant functor 
${\cal P} : {\cal U} \longrightarrow {\cal C}$ is a presheaf.

***** 1.2.32. Faithful functors
A functor is faithful if all the functions 
$Hom(A,B) \longrightarrow Hom(TA,TB)$ are injective.
***** 1.2.33. Concrete categories
A category is concrete if there is a faithful functor ${\cal C} \longrightarrow \mathtt{Set}$.

***** 1.2.33. Opposite category
We define ${\cal C}^{op}$ to be the category with:

 - $obj({\cal C}^{op}) = obj({\cal C})$
 - $Hom_{{\cal C}^{op}}(A,B) = Hom_{\cal C}(B,A)$
 - $g \circ_{op} f = f \circ g$

***** 1.2.34. Isomorphisms
A morphism $f : A \longrightarrow B$ such that exists $g : B \longrightarrow A$ with
$f \circ g = 1$ and $g \circ f = 1$.

***** 1.2.35. Functors preserve isomorphisms
Let $T$ be a functor, if $f$ is an isomorphism, then $T(f)$ is an isomorphism.

****** Proof
If $g$ is its inverse, then:

\[ T(f)T(g) = T(fg) = 1\]
\[ T(g)T(f) = T(gf) = 1\]

If $T$ is a contravariant functor, the proof remains the same.

***** 1.2.36. Natural transformations
Let $F,G : {\cal A} \longrightarrow {\cal B}$ be covariant functors. A natural transformation
$\tau : F \Longrightarrow G$ is a family of morphisms $\tau_A : S A \longrightarrow T A$, making the following
diagram commute for every $f \in Hom(A,B)$:

\[ \begin{tikzcd}
FA \rar{\tau_A} \dar{Ff} & GA \dar{Gf} \\
FB \rar{\tau_B} & GB
\end{tikzcd} \]

We write the natural transformations as $Nat(F,G)$.

***** 1.2.37. Natural isomorphisms
A natural transformation $\tau$ for which each $\tau_A$ is an isomorphism.

***** 1.2.38. Composition of natural transformations
If $\tau : F \Longrightarrow G$ and $\sigma : G \Longrightarrow H$ are natural transformations, then the
composition is a natural transformation.

****** Proof
Composing the two commutative diagrams gives us the proof.

***** 1.2.39. Identity natural transformation
For any functor $F : {\cal A} \longrightarrow {\cal B}$, we can describe an identity natural 
transformation using the identity morphisms.

***** TODO 1.2.40. Examples of natural transformations
***** TODO 1.2.41. Natural transformations are proper classes
***** 1.2.42. Yoneda Lemma
Let $A \in obj({\cal C})$ and $G : {\cal C} \longrightarrow \mathtt{Set}$ be a covariant functor. 
There is a bijection:

\[ y : Nat(Hom_C(A,-), G) \longrightarrow G(A)\]

given by $y : \tau \longrightarrow \tau_A(1_A)$.

****** Proof
******* Every choice of p determines a natural transformation
Given $p \in GA$, we can create an unique natural transformation having
$\eta_A(1_A) = p$. A natural transformation has to obey the following 
commutative diagram:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,B)\dar{\eta} \\
GA \rar{Gf}& GB
\end{tikzcd}\]

Then, the image of $\eta_B(f)$ is determined.

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
p \rar{Gf}& (Gf)(p)
\end{tikzcd}\]

******* Every choice gives us a natural transformation
This gives us, in fact, a natural transformation which makes every
natural square to commute:

\[\begin{tikzcd}
Hom(A,B) \rar{g \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
GB \rar{Gg}& GC
\end{tikzcd}\]

Given any element $f \in Hom(A,B)$, we can check the commutativity:

\[\begin{tikzcd}
f \rar{g \circ \_}\dar{\eta}& g \circ f\dar{\eta} \\
(Gf)(p) \rar{Gg}&  G(g \circ f)(p)
\end{tikzcd}\]

Knowing that $G(g \circ f)(p) = (Gg \circ Gf) (p)$.

***** 1.2.43. Representable functors
A covariant functor $F: {\cal C} \longrightarrow \mathtt{Set}$ is representable if $F \cong Hom(A,-)$
for some $A$.

***** 1.2.44. Yoneda Corollary
For $A,B \in obj({\cal C})$:

  1. If $\eta \in Nat(Hom(A,-),Hom(B,-))$, then $\eta = (\_ \circ \psi)$ for some unique $\psi$.
  2. If $\eta = (\_ \circ \psi)$ and $\tau = (\_\circ\phi)$, then $\tau\circ\eta = (\_ \circ \psi\circ\phi)$.
  3. $\eta = (\_\circ\psi)$ is a natural isomorphism iff $\psi$ is an isomorphism.

****** Proof
******* Corollary 1
If we apply Yoneda Lemma, every transformation is defined by
$\eta(id_A) = \psi$. The transformation has to be $(\_ \circ\psi)$ because of commutativity:

\[\begin{tikzcd}
Hom(A,A) \rar{f \circ \_}\dar{\eta}& Hom(A,C)\dar{\eta} \\
Hom(B,A) \rar{f \circ\_}& Hom(B,C)
\end{tikzcd}\]

So, given any element $f \in Hom(A,C)$, we have $\eta(f) = f \circ \psi$:

\[\begin{tikzcd}
id \rar{f \circ \_}\dar{\eta}& f\dar{\eta} \\
\psi \rar{f \circ\_}& f \circ \psi
\end{tikzcd}\]

******* Corollary 2
Trivial consequence of the first corollary.

******* Corollary 3
It is trivial given the previous corollaries and:

\[(\_\circ\psi^{-1})\circ \psi = (\_\circ id)\]

***** TODO Examples
***** TODO Yoneda Imbedding
**** 1.3. Singular Homology
***** 1.3.1. Hilbert spaces and euclidean spaces
A *Hilbert space* is the set ${\cal H}$ of all sequences $(x_i) \in \mathbb{R}$ such that
$\sum x_i^2 < \infty$. A *Euclidean space*, $\mathbb{R}^n$ is a subset of ${\cal H}$ consisting of
all sequences of the form $(x_0,x_1,\dots,x_{n-1},0,\dots)$.

***** 1.3.2. Standard n-simplex
The standard n-simplex is the set of all convex combinations:

\[\Delta^n = [e_0,e_1,\dots,e_n]\]

Where $e_i$ form an orthogonal basis.

***** 1.3.3. Singular n-simplex
Given a topological space $X$, a singular n-simplex is a continuous map
$\sigma : \Delta^n \longrightarrow X$.

***** 1.3.4. Singular n-chains
We define $S_n(X)$ as the free group with singular n-simplexes as basis.
By convention, $S_{-1}(X) = \{0\}$. The elements on this group are called
singular n-chains.

***** TODO 1.3.5. Face maps
The ith face map $\epsilon^n_i : \Delta^{n-1} \longrightarrow \Delta^n$ is defined by:

**** Exercises
***** Exercise 1.1
#+begin_statement
1. Prove, in every category ${\cal C}$, that each object $A \in {\cal C}$ has a unique identity
   morphism.
2. If $f$ is an isomorphism in a category, prove that its inverse is unique.
#+end_statement

We have $id = id \circ id' = id'$ and $\varphi^{-1} = \varphi' \circ \varphi \circ \varphi^{-1} = \varphi'$.

*** 2. Hom and Tensor
**** 2.1. Modules
***** Representation of a ring
A *representation* of $R$ is an homomorphism $\varphi : R \longrightarrow End_\mathbb{Z}(M)$.

****** Equivalence of representations and modules
The product of a R-module is a representation, and every
representation gives an R-module.

******* Equivalence of types
Type of a representation:

\[R \longrightarrow End(M)\]

Type of an R-module product:

\[R \times M \longrightarrow M\]

Both types are equivalent.

***** Example: Group ring
Given $G$, a group, and $R$, a ring; we define the group ring, $RG$ to be
the set of functions $G \longrightarrow R$ of finite support, with the operations:

  - Sum of functions: $(f+g)(a) = f(a)+g(a)$
  - Convolution (product): $(f\cdot g)(a) = \sum_{uv = a} f(u)g(v)$
  - Product by a scalar on $R$: $(kf)(a) = kf(a)$

It defines a ring and an R-module.

****** Inclusion of the group
The group can be included on $RG$ with the indicator function $y \mapsto 1_{(=y)}$,
defined as:

\[
y(a) = 1_{(=y)}(a) =
\left\{\begin{array}{ll} 
1 & \mbox{if } a = y  \\
0 & \mbox{if } a \neq y
\end{array} 
\right.
\]

A function that only outputs $1$ when its input is $y$.

******* Preservation of the product

\[
1_{(=y)}\cdot 1_{(=z)} (a)
=
\sum_{u\cdot v = a} 1_{u=y}1_{v=z}
=
1_{a=yz}
\]

***** Additive functors
A functor $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ is called *additive* if, for every pair of R-maps,
$f,g$, we have:

\[
T(f+g) = Tf + Tg
\]

****** Properties of additive functors
Let $T : \mathtt{RMod} \longrightarrow \mathtt{Ab}$ be an additive functor:

  1. $T(0) = 0$, the zero map.
  2. $T(\{0\}) = \{0\}$, the zero group.

******* Proof
******** First property
$T0 = T(0+0) = T0+T0$, and then $T0 = 0$.

******** Second property
$Hom(A,\{0\})$ only has one element.

***** Homomorphisms of r-modules are abelian groups
Given $A,B$ R-modules, $Hom_{R-mod}(A,B)$ is an abelian group with the
componentwise sum.

***** Hom as an additive functor
$Hom_{R-mod}(A,-)$ is an additive functor.

****** TODO Central case

***** TODO Hom as a contravariant functor
***** Submodules
Given $M$, an R-module, a *submodule* $N \subseteq M$ is an additive subgroup
closed under scalar multiplication.

****** Examples of submodules
******* Subgroups
A submodule of a Z-module (abelian group) is a subgroup.

***** Quotient of modules
***** Kernels, images and cokernels
***** First Isomorphism Theorem
***** Second Isomorphism Theorem
***** Third Isomorphism Theorem
***** Correspondence Theorem
***** Simple module
A proper R-module $M$ is simple if it has no proper submodules.

****** Characterization
$M$ is simple iff $M \cong R/I$, where $I$ is a maximal left ideal.

******* TODO Proof

***** Exact sequences
***** Zero-ended exact sequences
***** Short exact sequences
***** External direct sum
****** Properties of the external direct sum
***** Internal direct sum
***** Direct summands and complements
****** Retractions
***** Direct product
****** Direct sum
****** Projections
****** Injections
***** Free modules
****** Basis
****** Free abelian groups
***** Basis
****** Invariant basis number
****** Rank
***** Left exactness
**** 2.2. Tensor products
***** Bilinearity
****** Biadditivity
***** Tensor product
****** Uniqueness
****** Existence
***** Tensor functors
***** Universal property of the tensor product
***** Commutativity
***** Enveloping algebra
***** Right exactness
***** Tensor and direct sum
***** Four Lemma I
***** Four Lemma II
***** Five Lemma
***** Divisible abelian group
**** 2.2.1. Adjoint isomorphisms
***** Adjoint isomorphisms
***** Right exactness
*** 3. Special Modules
**** 3.1. Projective modules
***** Exact functor
***** Lifting on free modules
***** Lifting
***** Projective modules
***** Characterization of projective modules
***** Projective modules and direct summands
***** Kaplansky theorem
***** Projective basis
***** Schnauel's Lemma
***** Ascending chaing condition
***** Noetherian rings
***** Characterization of noetherian rings
***** Hilbert basis theorem
**** 3.2. Injective modules
***** Injective module
***** Characterization of injective modules
***** Product of injective modules
***** Baer criterion
***** Divisible modules
***** Bass-Papp theorem
***** Characterization by short exact sequences
***** Essential extension
***** Characterizacion by essential extensions
***** Injective envelope
***** Eckmann-Schpf
**** 3.3. Flat modules
***** Flat module
***** Direct sum of flat modules
***** Finitely generated submodules and flat modules
***** Torsion module
***** Torsion-free module
****** PID module
****** Flat modules
***** Character module
***** Lambek theorem
***** Villamayor theorem
***** Left coherent ring
***** Chase theorem
**** 3.3.1. Purity
***** Pure exact sequence
****** Pure submodule
***** Characterization of flatness
***** Cohn theorem
*** 4. Specific Rings
**** 4.2. Von Neumann Regular Rings
***** Von Neumann Regular ring
A ring $R$ is *Von Neumann regular* if:

\[
\forall r \in R: \exists r' \in R: rr'r = r
\]

****** Boolean rings
A ring is boolean if every element is idempotent. Every boolean ring
is a commutative Von Neumann regular ring.

*** 5. Setting the stage
**** 5.4. Sheaves
***** Protosheaves
 #+begin_definition
 *Local homeomorphism*. Continuous map $p : E \longrightarrow X$ such that for each $e \in E$ there is
 an open neighboorhood $S$ of $e$ such that $p|_S$ is an isomorphism.
 #+end_definition
 #+begin_definition
 *Protosheaf*. Surjective local homeomorphism.
 #+end_definition

***** Etale-sheaves
 #+begin_definition
 *Etale-sheaf of abelian groups*. A *protosheaf* such that:

 - The stalk $E_x$ is an abelian group.
 - Inversion and adition are continuous.
 #+end_definition

 #+begin_definition
 *Etale-map*. Given two etale-sheaves $E$ and $E'$, a map $\phi : E \longrightarrow E'$ such
 that $p'\phi = p$, and each $\phi|_{E_x}$ is a homomorphism.
 #+end_definition

 Here, etale-sheaves of abelian groups over a topological space X form an
 abelian category $\mathtt{Sh}_{et}(X,\mathtt{Ab})$.

**** 5.5. Abelian categories
***** Additive category
 #+begin_definition
 *Additive category*. ${\cal C}$ is additive if:

 - $Hom(A,B)$ is an *abelian group*.
 - *Distributivity* holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a *zero object*.
 - Has finite *products* and *coproducts*.

 A functor $T$ between two additive categories is additive if $T(f+g) = Tf+Tg$.
 #+end_definition

 #+begin_theorem
 *Sums and products are the same*. Products and coproducts are isomorphic:

 \[A \mathbin{\Pi} B \cong A \amalg B\]

 So we call them *direct sums*, $A \oplus B$. And there are canonical morphisms:

 \[ \begin{tikzcd}
 & A \oplus B \dlar[bend right,swap]{\pi_A} \drar[bend left]{\pi_B} $ \\
 A \urar[bend right,swap]{i_A} & & B \ular[bend left]{i_B}
 \end{tikzcd} \]

 Such that: \(i_A \circ \pi_A + i_b \circ \pi_B = id\) and \(\pi_B \circ i_A = \pi_A \circ i_B = 0\).
 #+end_theorem

***** Monomorphisms and epimorphisms

#+begin_definition
*Monomorphism*. A morphism $u$ such that:
\[u \circ f = u \circ g \quad \Rightarrow \quad f = g\]
#+end_definition

#+begin_definition
*Epimorphism*. A morphism $u$ such that:
\[f \circ u = g \circ u \quad \Rightarrow \quad f = g\]
#+end_definition

We have that $u : B \longrightarrow C$ is *monomorphism* iff the induced 
$u^\ast : Hom(A,B) \longrightarrow Hom(A,C)$ is injective. And $v : B \longrightarrow C$ is *epimorphism* 
iff the induced $v^* : Hom(B,D) \longrightarrow Hom(C,D)$ is surjective.

***** Kernels and cokernels
 #+begin_definition
 *Kernel*. The kernel of $u$ is the equalizer of $u$ and $0$. In a diagram:

 \[ \begin{tikzcd}
 & C \dar[dashed] \arrow[ddr, bend left] \arrow[ddl,bend right] &\\
 & \ker(u) \dlar[swap]{i} \drar{0} & \\
 A \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & B
 \end{tikzcd} \]
 #+end_definition
 #+begin_definition
 *Cokernel*. The cokernel of $u$ is the coequalizer of $u$ ans $0$. In a diagram

 \[ \begin{tikzcd}
 & C &\\
 & \ker(u) \uar[dashed]   & \\
 A \urar{0} \arrow[uur, bend left]
 \arrow[shift left]{rr}{u} \arrow[shift right]{rr}[swap]{0} & & 
 B \ular[swap]{\pi} \arrow[uul,bend right]
 \end{tikzcd} \]
 #+end_definition

 #+begin_theorem
 *Monomorphisms and kernels*.
 - If $\ker(u)$ exists, $u$ is monomorphism iff $ker(u) = 0$.
 - If $coker(v)$ exists, $v$ is epimorphism iff $coker(v) = 0$.
 #+end_theorem
***** Abelian category
 #+begin_definition
 *Abelian category*. ${\cal C}$ is abelian if

 - Every morphism has *kernel* and *cokernel*.
 - Every monomorphism is a *kernel*.
 - Every epimorphism is a *cokernel*.
 #+end_definition

 Abelian categories are /self-dual/, if ${\cal A}$ is an abelian category, then
 ${\cal A}^{op}$ is an abelian category.

 #+begin_definition
 *Image*. Given $f : A \longrightarrow B$ in an abelian category, its image is:

 \[img(f) = ker(coker(f))\]
 #+end_definition
** Intermediate logic - Open Logic, Zach
*** II. First-order logic
**** 5. Syntax and Semantics
***** 5.1. Introduction
 - Syntax :: how well-formed terms and formulas can be defined.
 - Semantics :: how meaning can be given to expressions.

***** 5.2. First-order languages
Any first-order language ${\cal L}$ is determined by logical, non-logical
symbols and some punctuation marks.

****** Logical symbols
 1. Logical connectives: $\neg,\land,\lor,\forall,\exists$,
 2. Propositional constant for falsity: $\bot$,
 3. Binary identity predicate: $=$,
 4. Numerable set of variables: e$v_0,v_1,\dots$

We assume $\top$ and $\leftrightarrow$ as defined as abbreviatures. We could use 
"truth functionally complete" subsets of boolean operators such
as $\{\neg,\lor\}$.

****** Non-logical symbols
 1. A numerable set of n-ary predicates for each $n>0$, as $\{A_0^n,A_1^n,\dots\}$,
 2. A numerable set of constants $c_0,\dots$,
 3. A numerable set of n-ary functions, as $\{f_0^n,f_1^n,\dots\}$.

****** Examples
 - Arithmetic with $S,O,<,+,\times$.
 - Set theory with $\in$.
 - Orders with $\leq$.

***** 5.3. Terms and formulas
****** Terms
The set of *terms* of a language ${\cal L}$ is defined inductively

 1. variables are terms,
 2. constants are terms,
 3. given an n-ary function and $n$ terms, $f(t_1,\dots,t_n)$
    is a term.

Constants are regarded as 0-ary functions.

****** Formulas
The set of *formulas* of a language ${\cal L}$ is defined inductively

 1. $\bot$ is a formula;
 2. given any n-ary predicate and $n$ terms, $R(t_1,\dots,t_n)$ is
    a formula;
 3. given any two terms, $t_1 = t_{2}$ is a formula;
 4. $\neg \varphi$;
 5. $\varphi \lor \psi$;
 6. $\varphi \land \psi$;
 7. $\varphi \to \psi$;
 8. $\forall x. \varphi$;
 9. $\exists x.\varphi$.

****** Syntatic identity
Two strings of symbols are syntatically identical, $\varphi \equiv \psi$, if
they contain the same symbols in the same place.

***** 5.4. Unique readability
Every formula has a unique reading. The correct definitions, using
parentheses constraint the set of possible formulas.  The number of
left and right parentheses in a formula are equal, by induction.

****** Proper prefixes
A string $\varphi$ is a *proper prefix* of $\psi$ if it can be obtained by 
appending symbols to $\varphi$.

#+ATTR_LATEX: :options []
#+BEGIN_lemma
Every proper prefix of a formula is not a formula.
#+END_lemma
#+BEGIN_proof
Using the fact that there is an equal number of left and right
parentheses in every formula.
#+END_proof

****** Unique readability
Every atomic formula satisfies one and only one of the following
conditions

 1. $\varphi \equiv \bot$
 2. $\varphi \equiv R(t_1,\dots,t_n)$
 3. $\varphi \equiv t_1 = t_2$

And every formula is of the form

 1. atomic
 2. $\neg \psi$
 3. $\varphi \lor \psi$
 4. $\varphi \land \psi$
 5. $\psi \to \varphi$
 6. $\forall x.\psi$
 7. $\exists x.\psi$

The proof crucially uses the fact that no formula is a proper prefix
of any other formula.

***** 5.5. Main operator of a formula
The outermost operator of a formula exists if the formula is not
atomic. It is always unique, as we have proved earlier.

***** 5.6. Subformulas
****** Immediate subformulas
*Immediate subformulas* are defined inductively as

 1. no subformulas for atomic formulas;
 2. $\varphi$ and $\psi$ are immediate subformulas of $\varphi \ast \psi$;
 3. $\psi$ is an immediate subformula of $\forall x.\psi$;
 4. $\psi$ is an immediate subformula of $\exists x.\psi$.

****** Proper subformulas
The *proper subformulas* of a formula are its immediate subformulas and
their proper subformulas.

We also consider the formula to be a non-proper subformula of itself.

***** 5.7. Free variables and sentences
A variable appears *free* when it is not bounded by a quantifier. The
precise definition can be trivially written by induction. Every
bounded variable has a *scope*, a subformula over which the quantifier
acts.

****** Sentences
A formula is a *sentence* if it contains no free ocurrences of variables.

***** 5.8. Substitution
*Substitution* of a variable by a term, $s[t/x]$, can be recursively
defined as

 * $c[t/x]$ is $c$, provided $c$ is a constant;
 * $y[t/x]$ is $y$, provided $y$ is a variable;
 * $x[t/x]$ is $t$;
 * $f(t_1,\dots,t_n)[t/x]$ is $f(t_1[t/x],\dots,t_n[t/x])$.

Substitution can be extended trivially to formulas; but we have to
check that every term appears free for the variable in order to avoid
undesired bounds for a variable.

***** 5.9. Structures for first-order languages
*Structures* are the basis for /semantic notions/. A structure $\model$ for
a language ${\cal L}$ consists of

 1. a *domain*, a non empty set $|\model|$;
 2. an interpretation for each *constant*, $c^{\model} \in |\model|$;
 3. an interpretation for each *predicate*, $R^{\model} \subseteq |\model|^n$;
 4. an interpretation for each *function*, $f^{\model} \colon |\model|^n\to |\model|$.

Non emptiness ensures that the existential generalization is sound.

****** Examples
 - Standard model of arithmetic.
 - Structure of hereditarily finite sets.

***** 5.10. Covered structures for first-order languages
****** Values
The value of a term is defined recursively as

 * $\mathrm{Val}^{\model}(c) = c^{\model}$;
 * $\mathrm{Val}^{\model}(f(t_1,\dots,t_n)) = f^{\model}(\mathrm{Val}^{\model}(t_1),\dots \mathrm{Val}^{\model}(t_n))$.

****** Covered structures
A structure is covered if every element is the value of some
closed term.

***** 5.11. Satisfaction of a formula in a structure
****** Satisfaction
A formula is *satisfied* in a structure if the interpretation makes
the formula true.

****** Variable assignment
A problem with quantifiers arise when we try to interpret free variables.
We need to define *variable assignments*, functions $s : \mathrm{Var} \to |\model|$.

The value of a variable $x$ under an assignment $s$ is given by $s(x)$.

****** x-Variant
Any variable assignment $s'$ which differs from $s$ at most in one variable $x$ is
called an *x-variant*, and written as $s \sim_x s'$.

****** Satisfaction
*Satisfaction* of a formula $\varphi$ in a structure $\model$ relative to a variable
assignment $s$; written as $\model,s \models \varphi$ is defined recursively as

 1. $\model,s \not\models \bot$;
 2. $\model, s \models R(t_1,\dots,t_n)$ iff $\langle \mathrm{Val}^{\model}_s(t_1),\dots,\mathrm{Val}^{\model}_s(t_n) \rangle \in R^{\model}$;
 3. $\model,s \models t_1 = t_2$ iff $\mathrm{Val}^{\model}_s(t_1) = \mathrm{Val}^{\model}_s(t_2)$;
 4. $\model,s \models \neg\varphi$ iff $\model,s \not\models \varphi$;
 5. $\model,s \models \varphi \land \psi$ iff $\model,s \models \varphi$ and $\model,s \models \psi$;
 6. $\model,s \models \varphi \lor \psi$ iff $\model,s \models \varphi$ or $\model,s \models \psi$;
 7. $\model,s \models \varphi \to \psi$ iff  $\model,s \not\models \varphi$ or $\model,s \models \psi$;
 8. $\model,s \models \forall x. \varphi$ iff $\model,s' \models \varphi$ for every x-variant $s'$;
 9. $\model,s \models \exists x. \varphi$ iff $\model,s' \models \varphi$ for some x-variant $s'$;

Variable assignments are crucial here because we have to define a
formula for every $a \in |\model|$, but $a$ is not a formula.

***** 5.12. Variable assignments
Two assignments assigning the same value to the same free variables
produce the same values and entail the same formulas. In particular,
in the case of *sentences* without free variables, the truth value
is independent of the variable assignment.

****** Independence of variables in values
#+BEGIN_proposition
If $t$ has variables among $x_1,\dots,x_n$ and $s_1(x_i) = s_2(x_i)$; then
$\mathrm{Val}^{\model}_{s_1}(t) = \mathrm{Val}^{\model}_{s_2}(t)$.
#+END_proposition

Trivially by induction.

****** Independence of variables in formulas
#+BEGIN_proposition
If $\varphi$ has variables among $x_1,\dots,x_n$ and $s_1(x_i) = s_2(x_i)$; then
$\model,s_1 \models \varphi$ iff $\model,s_2 \models \varphi$.
#+END_proposition

Again by induction.

****** Satisfaction in a structure
A structure $\model$ *satisfies* $\varphi$, and it is written as $\model \models \varphi$, if
$\model, s \models \varphi$ for all variable assignments $s$.

***** 5.13. Extensionality
Where two structures agree on all elements, they entail the same truth
values. If $\model_1$ and $\model_2$ agree on constants, relations and functions;
$\model_1,s \models \varphi$ iff $\model_2,s \models \varphi$.

In particular, this happens for any sentence.

****** Dependence on subterms for values
Given a structure $\model$ and $s$ with $s \sim_x s'$ given by $s'(x) = \mathrm{Val}^{\model}_s(t')$.
Then $\mathrm{Val}^{\model}_s(t[t'/x]) = \mathrm{Val}^{\model}_{s'}(t)$.

******* Proof by induction
****** Dependence on subterms for formulas
Given a structure $\model$ and $s$ with $s \sim_x s'$ given by $s'(x) = \mathrm{Val}^{\model}_s(t)$.
Then $\model,s \models \varphi[t/x]$ iff $\model,s' \models \varphi$.

***** 5.14. Semantics notions
Semantic properties.

****** Validity
$\varphi$ is *valid*, written $\models \varphi$ iff $\model \models \varphi$ for every structure $\model$.

****** Entailment
A set of sentences $\Gamma$ *entails* $\varphi$, written $\Gamma \models \varphi$ iff $\model \models \varphi$ for
every structure such that $\model \models \Gamma$.

****** Satisfiability
A set of sentences $\Gamma$ is *satisfiable* if $\model \models \Gamma$ for some structure
$\model$.

****** Validity and entailment
A sentence $\varphi$ is valid iff $\Gamma \models \varphi$ for any set of sentences $\Gamma$.

****** Satisfiability and entailment
$\Gamma \models \varphi$ iff $\Gamma \cup \{\neg \varphi\}$ is unsatisfiable.

****** Strengthening
If $\Gamma \subseteq \Gamma'$ and $\Gamma \models \varphi$, then $\Gamma' \models \varphi$.

****** Semantic deduction theorem
$\Gamma \cup \{\varphi\} \models \psi$ iff $\Gamma \models \varphi \to \psi$.

****** Quantifiers and entailment
 1. $\varphi(t) \entail\exists x.\varphi(x)$,
 2. $\forall x. \varphi(x) \entail \varphi(t)$.
**** 6. Theories and their models
***** 6.1. Introduction
****** Closure
A set of sentences $\Gamma$ is *closed* if it is equal to its closure,
$\{ \varphi : \Gamma \models \varphi\}$. $\Gamma$ is *axiomatized* by $\Delta$ if it is its closure.

***** 6.2. Expressing properties of structures
****** Model
The structure $\model$ is a *model* of $\Gamma$ if $\model \models \varphi$ for all $\varphi \in \Gamma$.

***** 6.3. Examples of first-order theories
****** Strict linear orders
****** Theory of groups
****** Peano arithmetic with induction schemas
****** Pure sets with naive comprehension schemes
***** 6.4. Expressing relations in a structure
A formula $\varphi(v_1,\dots,v_n)$ expresses the relation $R \subseteq |\model|^n$ if
\[
Ra_1\dots a_n
\quad\mbox{ iff }\quad
\model,s \models \varphi(v_1,\dots,v_n)
\]
for any variable assignment such that $s(v_i) = a_i$.

***** 6.5. The theory of sets
ZFC is the most widely studied axiomatic system for set theory.
Inclusion can be defined by defining membership, and sets have
to be implicitely defined.

For example, the empty set $\varnothing$ is defined with
\[
\exists x. (\neg \exists y. y \in x) \land (\forall z. x \subseteq z)
\]
and operations on set could be defined in the same way.

The comprehension principle is inconsistent (Russell's paradox),
therefore, ZFC only allows the separation principle,
\[
\forall z. \exists y. \forall x. (x \in y \leftrightarrow (x \in z \land \varphi(x))).
\]

***** 6.6. Expressing the size of structures
There are sentences which are true in a structure iff the domain
has a specific size. The property of being non-enumerable or being
finite cannot be expressed even with an infinite set of sentences
(Lwenheim-Skolem theorems).

*** III. Proofs and completeness
**** 7. The Sequent Calculus
***** 7.1. Rules and derivations
****** 7.1. Sequent
A *sequent* is an expression $\Gamma \seq \Delta$ between sequences of
sentences. Semantically, it means that, if $\Gamma = \left\langle \varphi_1,\dots,\varphi_n \right\rangle$
and $\Delta = \left\langle \psi_1,\dots,\psi_m \right\rangle$,

\[
(\varphi_1 \land \dots \land \varphi_n) \to
(\psi_1 \lor \dots \lor \psi_m).
\]

****** 7.2. Initial sequent
An *initial sequent* is of the form

 1. $\varphi \seq \varphi$
 2. $\bot \seq$

where $\varphi$ is a sentence.

***** 7.2. Propositional rules
****** Rules for negation
Formation (L)

\[\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta,\varphi$
\UI$\neg \varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}\]

Formation (R)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta$
\UI$\Gamma \fCenter\seq \Delta,\neg \varphi$
\end{prooftree}

****** Rules for conjunction
Formation (L)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta$
\UI$\varphi \land \psi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R)

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\Gamma \seq \Delta,\psi$}
\BIC{$\Gamma \seq \Delta,\varphi \land \psi$}
\end{prooftree}

****** Rules for disjunction
Formation (L)

\begin{prooftree}
\AXC{$\varphi, \Gamma \seq \Delta$}
\AXC{$\psi, \Gamma \seq \Delta$}
\BIC{$\varphi \lor \psi, \Gamma \seq \Delta$}
\end{prooftree}

Formation (R)

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta,\varphi$
\UI$\Gamma \fCenter\seq \Delta,\varphi \lor \psi$
\end{prooftree}

****** Rules for implication
Formation (L)

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\psi, \Pi \seq \Lambda$}
\BIC{$\varphi \to \psi, \Gamma, \Pi \seq \Delta,\Lambda$}
\end{prooftree}

Formation (R)

\begin{prooftree}
\AX$\varphi, \Gamma \fCenter\seq \Delta, \psi$
\UI$\Gamma \fCenter\seq \Delta, \varphi \to \psi$
\end{prooftree}

***** 7.3. Quantifier rules
****** Rules for universal quantifiers
Formation (L), where $t$ is a closed term

\begin{prooftree}
\AX$\varphi(t), \Gamma \fCenter\seq \Delta$
\UI$\forall x.\varphi(x), \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R), where $a$ is an *eigenvalue*; a constant which must not
occur anywhere in the lower sequent

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi(a)$
\UI$\Gamma \fCenter\seq \Delta, \forall x.\varphi(x)$
\end{prooftree}

****** Rules for existential quantifiers
Formation (L), where $a$ is an *eigenvalue*

\begin{prooftree}
\AX$\varphi(a), \Gamma \fCenter\seq \Delta$
\UI$\exists x.\varphi(x), \Gamma \fCenter\seq \Delta$
\end{prooftree}

Formation (R), where $t$ is a closed term

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi(t)$
\UI$\Gamma \fCenter\seq \Delta, \exists x.\varphi(x)$
\end{prooftree}

***** 7.4. Structural rules
****** Weakening
Left weakening

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta$
\UI$\varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Right weakening

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta$
\UI$\Gamma \fCenter\seq \Delta, \varphi$
\end{prooftree}

****** Contraction
Left contraction

\begin{prooftree}
\AX$\varphi, \varphi, \Gamma \fCenter\seq \Delta$
\UI$\varphi, \Gamma \fCenter\seq \Delta$
\end{prooftree}

Right contraction

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi, \varphi$
\UI$\Gamma \fCenter\seq \Delta, \varphi$
\end{prooftree}

****** Exchange
Left exchange

\begin{prooftree}
\AX$\Gamma, \varphi, \psi, \Pi \fCenter\seq \Delta$
\UI$\Gamma, \psi, \varphi, \Pi \fCenter\seq \Delta$
\end{prooftree}

Right exchange

\begin{prooftree}
\AX$\Gamma \fCenter\seq \Delta, \varphi, \psi, \Lambda$
\UI$\Gamma \fCenter\seq \Delta, \psi, \varphi, \Lambda$
\end{prooftree}

****** Cut
Cut is not necessary, but makes it easier to reuse derivations

\begin{prooftree}
\AXC{$\Gamma \seq \Delta,\varphi$}
\AXC{$\varphi, \Pi \seq \Lambda$}
\BIC{$\Gamma,\Pi \seq \Delta, \Lambda$}
\end{prooftree}

It follows from the implication rule.

***** 7.5. Derivations
****** LK-derivation
An *LK-derivation* of a sequent is a tree of sequents starting from
initial sequents and applying inference rules.

***** 7.6. Examples of derivations
***** 7.7. Derivations with quantifiers
***** 7.8. Proof-theoretic notions
****** Theorems
A *theorem* is a sentence $\varphi$ such that there is a derivation of $\seq \varphi$.
We write $\vdash \varphi$ if it is a theorem and $\not\vdash \varphi$ if it is not.

****** Derivability
A sentence $\varphi$ is *derivable* from $\Gamma$ if there is a finite subset $\Gamma' \subseteq \Gamma$
such that the system derives $\Gamma \seq \varphi$. We write $\Gamma \vdash \varphi$ if $\varphi$ is derivable,
we write $\Gamma \not\vdash \varphi$ if it is not.

****** Consistency
A set of sentences $\Gamma$ is *inconsistent* if a finite subset $\Gamma' \subseteq \Gamma$ derives
$\Gamma' \seq$ . If a system is not inconsistent, it is *consistent*.

****** Reflexivity
If $\varphi \in \Gamma$, then $\Gamma \vdash \varphi$.

******* Proof
$\varphi \seq \varphi$ is an initial sequent.

****** Monotony
If $\Gamma \subseteq \Delta$ and $\Gamma \vdash \varphi$, then $\Delta \vdash \varphi$.

******* Proof
Given $\Gamma' \subseteq \Gamma \subseteq \Delta$, we know that $\Gamma' \subseteq \Delta$.

****** Transitivity
If $\Gamma \vdash \varphi$ for every $\varphi \in \Delta$ and $\Delta \vdash \psi$, then $\Gamma \vdash \varphi$.

******* Proof
If $\Delta \vdash \psi$, then there exists a finite $\Delta_0 \seq \psi$. We proceed by
induction on the size of $\Delta_0$,

 * if $\Delta_0$ is empty, $\seq \psi$ and, in particular $\Gamma \vdash \psi$;
 * if $\varphi \in \Delta_0$, we define $\Delta_1 = \Delta_0 \setminus \{\varphi\}$; and we know that $\varphi, \Delta_1 \seq \psi$,
   so $\Delta_1 \seq \varphi \to \psi$. By induction hypothesis, there exist $\Gamma_0 \seq \varphi \to \psi$
   and $\Gamma_1 \seq \varphi$; thus $\varphi \to \psi, \Gamma_1 \seq \psi$ and, by cut elimination rule,
   $\Gamma_0, \Gamma_1 \seq \psi$.

****** Principle of explosion
$\Gamma$ is inconsistent iff $\Gamma \vdash \varphi$ for every $\varphi$.

******* Proof
If $\Gamma \seq \bot$, by cut elimination, $\Gamma \seq$ . If $\Gamma \seq$ , then by
weakening, $\Gamma \seq \varphi$.

****** Compactness
 1. If $\Gamma \vdash \varphi$, there exists a subset $\Gamma_0 \subseteq \Gamma$ such that $\Gamma_0 \vdash \varphi$.
 2. If every subset of $\Gamma$ is consistent, $\Gamma$ is consistent.

******* Proof
By definition of derivability.

***** 7.9. Derivability and consistency
****** Transitivity of inconsistency
If $\Gamma \vdash \varphi$ and $\Gamma \cup \{\varphi\}$ is inconsistent, $\Gamma$ is inconsistent.

******* Proof
We have $\Gamma_0,\Gamma_1 \subseteq \Gamma$ such that $\Gamma_0 \seq \varphi$ and $\varphi, \Gamma_1 \seq$ ; thus,
by cut elimination, $\Gamma_0, \Gamma_1 \seq$.

***** 7.10. Derivability and the propositional connectives
****** Conjunction
We know that

 * $\varphi \land \psi \vdash \varphi$
 * 4$\varphi \land \psi \vdash \psi$
 * $\varphi, \psi \vdash \varphi \land \psi$

******* Proof
Applying the propositional rules for conjunction, we know that
$\varphi \land \psi \seq \varphi$ and $\varphi \land \psi \seq \psi$; while applying the right hand
side rule, $\varphi, \psi \seq \varphi \land \psi$.

****** TODO Disjunction

***** 7.11. Derivability and the quantifiers
****** Derivability of the universal quantifier
If $\Gamma \vdash \varphi(c)$ and $c$ does not appear in $\Gamma$; $\Gamma \vdash \forall x.\varphi(x)$.

******* Proof
Trivial by definition of derivability.

****** Initial derivations for quantifiers
 1. $\varphi(t) \vdash \exists x.\varphi(x)$
 2. $\forall x.\varphi(x) \vdash \varphi(t)$

******* Proof
Both are derivable from the quantifier rules.

***** 7.12. Soundness
****** Satisfaction of a sequent
A structure $\model$ *satisfies* a sequent $\Gamma \seq \Delta$ if and only if $\model \not\models \varphi$ for
some $\varphi \in \Gamma$ or $\model \models \varphi$ for some $\varphi \in \Delta$.

****** Valid sequents
A sequent is *valid* if every structure $\model$ satisfies it.

****** Soundness
If LK derives $\Theta \seq \Xi$, then it is a valid sequent.

******* Proof
By structural induction on the derivation. If it has no inferences,
it has to be an initial sequent, and $\varphi \seq \varphi$ and $\bot \seq$  are valid
sequents. In other case, we apply structural induction to get

 1. left and right weakening, trivially;
 2. left and right negation, trivially;
 3. left conjunction, trivially;
 4. right disjunction, trivially;
 5. right implication, trivially;
 6. universal quantifiers, trivially using previous lemmas;

with one premise, and

 1. cut elimination,
 2. right conjunction,
 3. left disjunction,

with two premises. All are valid by the definition of [[*Satisfaction of a sequent][satisfaction]] and
the notion of [[*Satisfaction][satisfaction]] of a formula in a structure.

**** 8. The Completeness Theorem
***** 8.3. Complete consistent sets of sequences
****** Complete set
A set $\Gamma$ is *complete* iff for any sentence either $\varphi \in \Gamma$
or $\neg \varphi \in \Gamma$.

******* Membership
In particular, $\varphi \not\in \Gamma$ implies $\neg\varphi\in\Gamma$.

****** Complete consistent sets
If $\Gamma$ is complete and consistent,

 1. if $\Gamma \vdash \varphi$, then $\varphi \in \Gamma$;
 2. $\varphi \land \psi \in \Gamma$ iff $\varphi \in \Gamma$ and $\psi \in \Gamma$;
 3. $\varphi \lor \psi \in \Gamma$ iff $\varphi \in \Gamma$ or $\psi \in \Gamma$;
 4. $\varphi \to \psi \in \Gamma$ iff $\varphi \not\in \Gamma$ or $\psi \in \Gamma$.

***** 8.4. Henkin expansion
Henkin expansion adds infinitely many constant symbols to allow
existential quantifiers to be satisfied by one of these symbols.

****** Extension of consistency
If $\Gamma$ is consistent in ${\cal L}$ and we obtain a new language by adding
a numerable set of constants, ${\cal L}'$, then $\Gamma$ is consistent in ${\cal L}'$.

******* Proof
Trivial by definition of [[*Consistency][consistency]].

****** Saturated set
A set $\Gamma$ is *saturated* iff for each formula $\varphi(x) \in \mathrm{Frm}({\cal L})$ where
$x$ is a free variable, there is a constant symbol $c \in {\cal L}$ such that
$\exists x.\varphi(x) \to \varphi(c) \in \Gamma$.

****** Theta sentences
Given a language ${\cal L}'$ and an enumeration $\varphi_i(x_i)$ of formulas of ${\cal L}'$ in
which a variable $x_i$ occurs free.

Let $c_0$ be the first fresh constant symbol not in $\varphi_0(x_0)$, and $c_n$
the first fresh constant symbol not in $\theta_0,\dots,\theta_{n-1}, \varphi_n(x_n)$.

We define $\theta_n$ as $\exists x_n. \varphi_n(x_n) \to \varphi(c_n)$.

****** Extension of saturation
If $\Gamma$ is consistent, it can be extended to a saturated consistent set
$\Gamma'$.

******* Proof
Given ${\cal L}$, we get ${\cal L}'$, and then let using [[*Theta sentences][theta sentences]],

 * $\Gamma_0 = \Gamma$,
 * $\Gamma_{n+1} = \Gamma_n \cup \{\theta_n\}$,

then $\Gamma' = \bigcup \Gamma_n$ is saturated. If it were [[*Consistency][inconsistent]], empty could be
derived from a finite set of sentences, so some $\Gamma_n$ would be inconsistent.
We will show that each $\Gamma_n$ is consistent. If we had

 * $\Gamma_n \vdash \neg\{\theta_n\}$,

where $\theta_n$ is $\exists x_n.\varphi_n(x_n)$ then we would have

 * $\Gamma_n \vdash \exists x_n. \varphi_n(x_n)$,
 * $\Gamma_n \vdash \neg \varphi_n(c_n)$;

but as $c_n$ does not appear in $\Gamma_n$, $\Gamma_n \vdash \forall x.\neg \varphi_n(x)$ and then

\[
\forall x.\neg \varphi_n(x) \vdash \neg \exists x_{n}.\varphi_n(x)
\]

thus making $\Gamma_{n}$ inconsistent.

****** Complete, consistent and saturated sets
If $\Gamma$ is complete, consistent and saturated

 1. $\exists x.\varphi(x) \in \Gamma$ iff there exists $\varphi(t) \in \Gamma$, for some $t$;
 2. $\forall x.\varphi(x) \in \Gamma$ iff $\varphi(t) \in \Gamma$ for all closed $t$.

******* Proof
 1. By saturation we have $\exists x.\varphi(x) \to \varphi(c)$ for
    some $c$; then by completion, $\varphi(c) \in \Gamma$ or $\neg\varphi(c) \in \Gamma$;
    but only the first case allows consistency to be true.

    In the other direction, if $\varphi(t) \in \Gamma$, then by completion
    and consistency, $\exists x.\varphi(x) \in \Gamma$.

 2. If $\forall x.\varphi(x) \in \Gamma$, then for every $t$, by completion, we have $\varphi(t) \in \Gamma$
    or $\neg \varphi(t) \in \Gamma$; if we had $\neg\varphi(t)$, it would be inconsistent.

    In the other direction, by completion, if we had $\neg\forall x.\varphi(x) \in \Gamma$
    then we deduce $\exists x. \neg \varphi(x) \in \Gamma$, and by saturation and completion,
    again, $\neg \varphi(c) \in \Gamma$.

***** 8.5. Lindenbaum's lemma
****** Lindenbaum's lemma
Every consistent set $\Gamma'$ in a language ${\cal L}'$ can be extended to a complete
and consistent set $\Gamma^{\ast}$.

******* Proof
We take $\Gamma_0 = \Gamma'$ and we enumerate all formulas $\{\varphi_i\}$. At each step we
add $\Gamma_{n+1} = \Gamma_n \cup \{\varphi_{n}\}$ if it is consistent or $\Gamma_{n+1} = \Gamma_n \cup \{\neg\varphi_{n}\}$ 
otherwise. Let $\Gamma^{\ast} = \bigcup \Gamma_n$.

If both $\Gamma_n\cup \{\varphi_n\}$ and $\Gamma_n\cup \{\neg\varphi_n\}$ were inconsistent, $\Gamma_n$ would be
inconsistent. Thus, every subset of $\Gamma^{\ast}$ is consistent and it has to be
consistent.

***** 8.6. Construction of a model
****** Term model
Given $\Gamma^{\ast}$ complete, consistent and saturate; the *term model* $\model(\Gamma^{\ast})$ is
defined with

 1. domain $|\model(\Gamma^{\ast})|$ given by the set of closed terms;
 2. the interpretation of every constant as itself, $c^{\model(\Gamma^{\ast})} = c$;
 3. the function symbol is assigned to a function which returns the
    closed term of that function, $f^{\model(\Gamma^{\ast})}(t_1,\dots,t_n) = f(t_1,\dots,t_n)$;
 4. and if $R$ is an n-place symbol,
    \[
    \left\langle t_1,\dots,t_n \right\rangle \in R^{\model(\Gamma^{\ast})}
    \text{ iff }
    R(t_1,\dots,t_n) \in \Gamma^{\ast}.
    \]

****** TODO Term model and quantifiers
# Our model is covered

****** Truth lemma
If $\varphi$ does not contain $=$, then $\model(\Gamma^{\ast})\models \varphi$ iff $\varphi \in \Gamma^{\ast}$.

First-order logic for sets $\Gamma$ that do not contain $=$ is complete.

******* TODO Proof

***** 8.7. Identity
****** Factoring identity
Given $\Gamma^{\ast}$ a consistent and complete set in ${\cal L}$, the *relation* $\approx$ is
defined as $t \approx t'$ iff $t=t' \in \Gamma^{\ast}$.

****** TODO Properties of the new identity relation

****** Equivalence classes
Given $\Gamma^{\ast}$ a consistent and complete set in ${\cal L}$, then $t$ is a term and
$\approx$ as in the previous definition,

\[
[t]_{\approx} = \left\{ t' : t' \in \mathrm{Trm}({\cal L}), t \approx t' \right\};
\]

and $\mathrm{Trm}({\cal L})/_{\approx} = \left\{ [t]_{\approx} : t \in \mathrm{Trm}({\cal L}) \right\}$.

****** Representative term structure
***** 8.8. Completeness theorem
****** Gdel's Completeness theorem
Let $\Gamma$ be a set of sentences; if it is consistent, it is satisfiable.

******* Proof
There is a saturated $\Gamma' \supseteq \Gamma$, and there is a $\Gamma^{\ast} \supseteq \Gamma'$ consistent and
complete; while it is also saturated. If $\Gamma$ contains $=$, then we compute
the quotient to have $\model/_{\approx}\models \varphi$ iff $\varphi \in \Gamma^{\ast}$.

****** Completeness theorem, second version
For all $\Gamma$ and $\varphi$, if $\Gamma\models\varphi$, then $\Gamma \vdash \varphi$.

******* Proof
If $\Gamma \models \varphi$, then $\Gamma \cup \{\neg\varphi\}$ is unsatisfiable; by completeness theorem,
it has to be inconsistent, so $\Gamma \vdash \varphi$.

***** TODO 8.9. Compactness theorem
***** TODO 8.10. A direct proof of the compactness theorem
***** TODO 8.11. The Lwenheim-Skolem theorem
***** TODO 8.12. Overspill
** Introduction to categorical logic (2017) - Bauer, Awodey
*** II. Type theories
**** II.1. Algebraic theories
****** Signatures
A *signature* $\left\{ \Sigma_k \right\}$ is a family of sets of k-ary operations. Its *terms*
are constructed inductively knowing that

 * variables are terms.
 * given $\left( x_1,\dots,x_{k} \right)$ a k-uple of terms and $f \in \Sigma_k$, $f(x_1,\dots,x_{k})$ is a term.

****** Algebraic theories
An *algebraic theory* $\mathbb{A} = (\Sigma,A)$ is a signature and a set of equation
between its terms.

They are also called /equational theories/ and /Lawvere theories/.

******* Examples
******** Theory of groups
******** Theory of unital commutative rings
******** Theory of sets
******** Theory of pointed sets
******** Theory of R-modules
******** Counterexample: theory of fields
******** Theory of inductive datatypes

***** II.1.1. Many-sorted algebraic theories
****** Examples
******* Theory of left modules
******* Theory of graphs
******* Theory of symmetric graphs
******* Theory of a RAM
***** II.1.2. Models of algebraic theories
The motivation is to generalize the classical notions of algebraic
structures to morphisms and commutative diagrams.

****** Interpretation
An *interpretation* of a theory $\mathbb{A}$ on a category ${\cal C}$ with finite products
is given by an object $I\mathbb{A} \in \mathrm{obj}({\cal C})$ and a morphism for each operation of 
arity $k$,

\[
\forall f \in \Sigma_k,\qquad If : (I\mathbb{A})^k \to I\mathbb{A}.
\]

The interpretation of a term with a *context* of variables, $x_1,\dots,x_n \mid t$,
is given inductively by

 1. the interpretation of $x_i$ is the projection $\pi_i$.
 2. a term $f(t_1,\dots,t_k)$ is interpreted as the composition of the 
    interpretation of every subterm with the interpretation of $f$ as

    \[\begin{tikzcd}[column sep=huge]
    (I\mathbb{A})^n  \rar{(It_1,\dots,It_k)}  &
    (I\mathbb{A})^k  \rar{If}  &
    \mathbb{A}.
    \end{tikzcd}\]
    
Note that the interpretation of a term depends on the context.

****** Satisfacibility of equations
An equation $u=v$ of two terms in the same context is *satisfied*
by the interpretation $I$ if $Iu = Iv$ as morphisms.

****** Models of algebraic theories
A *model* is an interpretation that satisfies all the axioms of the
theory.

***** II.1.3. Algebraic theories as categories
The motivation is to have a general theory of what is a group,
independent from the choice of basic constants, operations and axioms.

****** Category of an algebraic theory
Given $\mathbb{A}$, we take as objects all the possible contexts $\left[ x_1,\dots,x_n \right]$ and
tuples $\langle t_1,\dots,t_n \rangle : [x_1,\dots,x_m] \to [x_1,\dots,x_n]$ of terms with context the
domain as morphisms.

Two morphisms are equal iff the axioms imply $t_k = t_{k}'$ on every $k$; and
the composition of morphisms $v = u \circ t$ is done by substitution

\[
v_i = u_i \left[ t_1,\dots,t_m / x_1,\dots,x_m \right].
\]

******* Closed to products
The product of $\left[ x_1,\dots,x_n \right]$ and $\left[x_1,\dots,x_m \right]$ exists as $\left[ x_1,\dots,x_{n+m} \right]$
in this category. Every object is a product of finitely many instances
of $[x_1]$.

****** Algebraic theory (alternative definition)
An *algebraic theory* is a small category with finite products whose
objects are $A^0,A^1,A^2,\dots$ such that $A^m\times A^n = A^{m+n}$.

******* Algebraic theory in the former sense
The basic operations of $\Sigma_k$ are the morphisms $A^k \to A$. An equation
$u = v$ is an axiom if the canonical interpretations of each morphism
being interpreted by itself coincide.

****** Examples
******* Algebraic theory of smooth maps
******* Algebraic theory of total recursive functions
******* Algebraic theory of an object
***** II.1.4. Models of algebraic theories as functors
****** Interpretations as functors
Given a model $M$ of $\mathbb{A}$ in ${\cal C}$, the interpretation is a functor $M : \mathbb{A} \to {\cal C}$
defined by

\[
M[x_1,\dots,x_k] = (M\mathbb{A})^k
\]

on objects and by the following rules on morphisms

 1) the morphism $\left\langle x_i \right\rangle : \left[ x_1,\dots,x_k \right] \to [x_1]$ is mapped to $\pi_i : (M\mathbb{A})^k \to M\mathbb{A}$.
 2) the morphism $\left\langle f(t_1,\dots,t_m) \right\rangle : [x_1,\dots,x_k] \to [x_{1}]$ is mapped into the
    composition

    \[\begin{tikzcd}[column sep=huge]
    (M\mathbb{A})^m \rar{(Mt_1,\dots,Mt_m)} &
    (M\mathbb{A})^k \rar{Mf} &
    \mathbb{A}
    \end{tikzcd}\]

 3) the morphism $\left\langle t_1,\dots,t_m \right\rangle : [x_1,\dots,x_k] \to [x_1,\dots,x_{m}]$ is mapped to the
    morphism $\left\langle Mt_1,\dots,Mt_m \right\rangle$, where $Mt_i$ is the value of $M\left\langle t_i \right\rangle$.

This interpretation is a in fact a functor.

******* The interpretation is a functor 
As $M$ is a model, all the equations of the theory are satisfied by
it. This preserves the identities given by composition of morphisms.

****** Model (alternative definition)
A *model* of $\mathbb{A}$ in ${\cal C}$ is a functor preserving finite products.

****** Category of models
The category $\mathtt{Mod}_{{\cal C}}(\mathbb{A})$ of models of the theory $\mathbb{A}$ in ${\cal C}$ has models
$M : \mathbb{A} \to {\cal C}$ as objects and natural transformations as morphisms.

****** Algebraic categories
An algebraic category is a category that is equivalent to a
category of models of an algebraic theory.

******* Examples
******** Category of groups
******** Category of C-rings
***** II.1.5. Completeness and universal models
****** Categorical logic
Categorical logic has two sides, the logical and the categorical.
The logic consists of

  1) A *type theory*, a calculus of types and terms. In the case
     of algebraic theories, there is only one type.
  2) A *logic*. In the case of algebraic theories, the logic only
     involves equations.
  3) A *theory* given by basic types, terms and axioms.
  4) *Interpretations and models*. The type theory and logic are
     interpreted denotationally in a category with enough structure.
     In the case of algebraic theories, those are categories with
     finite products.

There are special cases of simple logics

  * a /single-sorted logic/ if there is only one type.
  * a /type theory/ if there is only a very simple type system.
  * in /ML-type systems/, logic and types are identified.

And complementary to a logical system, we have its categorical
semantics

  1) Theories are categories. The structure of a category hides
     sintactic details and reflects types and logic.
  2) Models are functors. They go from theories to categories with
     richer structure, preserving the structure of the theory.
  3) Homomorphisms are natural transformations.
  4) Completeness and universal models. It is desirable for a
     categorical semantics to be complete or to have universal
     models.

****** Semantic completeness
The property that gives that if every model of $\mathbb{A}$ satisfies
an equation, the equation can be proved on the algebraic theory is
called *semantic completeness*.

****** Completeness for algebraic theories
Given $\mathbb{A}$ algebraic theory, exists a model $U \in \mathtt{Mod}_{{\cal A}}(\mathbb{A})$ called the
*universal model* for $\mathbb{A}$, such that,

\[
U \text{ satisfies } u = v
\iff
\mathbb{A} \text{ proves } u = v.
\]

As a corollary, categorical semantics of algebraic theories is
complete.

******* Proof
We can simply take $U = 1_{\mathbb{A}} : \mathbb{A} \to \mathbb{A}$ as a model, which clearly
identifies $1(f)=1(g)$ if and only if $f = g$.

****** Universal model on generalized sets
The Yoneda embedding $y : \mathbb{A} \to \widehat{\mathbb{A}}$ is a universal model for $\mathbb{A}$.

******* Proof
The embedding $y$ preserves limits and therefore, finite products.
It is a functor and a faithful one, which makes $\widehat{\mathbb{A}}$ an universal
model.

**** II.2. Cartesian closed categories
***** II.2.1. Exponentials
****** Exponentials
In a category with binary products ${\cal C}$, an *exponential* is an object $B^A$
with an evaluation morphism $e : B^A \times A \to B$ such that for every $f : C \times A \to B$
exists a unique $\widetilde f : C \to B^A$ for which this diagram commutes

\[\begin{tikzcd}
B^A &
B^A \times A \drar{e} &
\\
C \uar[dashed]{\widetilde f} &
C \times A \uar{{\widetilde f} \times 1_A} \rar[swap]{f} &
B
\end{tikzcd}\]

This is the universal property of exponentials.

****** Exponentiable object
An object $A \in \mathrm{obj}({\cal C})$ is exponentiable if $B^A$ exists for every $B$.

****** Characterization of exponentiable objects
An object $A$ is exponentiable iff the functor $- \times A$ has a right
adjoint $-^{A}$.

******* TODO Proofs

****** Examples
******* Propositional calculus
***** II.2.2. Cartesian closed categories
****** Cartesian category
A *cartesian category* is a category that has finite products.

****** Cartesian closed category
A *cartesian closed category* is a cartesian category with
exponentials.

****** Characterization of cartesian closed categories by adjoints
The category ${\cal C}$ is cartesian closed if the following functors
have adjoints

 * the functor $! : {\cal C} \to 1$ to the terminal category.
 * the diagonal functor $\Delta : {\cal C} \to {\cal C} \times {\cal C}$.
 * the product by every object $-\times A : {\cal C} \to {\cal C}$.

******* TODO Proof

****** Characterization of cartesian closed categories by equations
A category ${\cal C}$ is cartesian closed if and only if

  1) $1 \in {\cal C}$ and exists a morphism $! : A \to 1$ for every $A \in {\cal C}$.
  2) a product $A \times B$ with projections and the universal property
     of the product.
  3) an exponential $B^A$ with an evaluation map and the universal
     property of the exponential.

We write the projections as $\pi_0,\pi_1$; the unique function from the product
as $\left\langle f,g \right\rangle$ and $f \times g = \left\langle f \circ \pi_0, g \circ \pi_1 \right\rangle$. The types satisfy

  1) for every $f : A \to 1$, $f = !$.
  2) for all functions $\pi_0 \circ \left\langle f,g \right\rangle = f$, $\pi_1 \circ \left\langle f,g \right\rangle = g$ and $\left\langle \pi_0\circ h, \pi_1\circ h \right\rangle = h$.
  3) for all functions $e \circ (\widetilde{f} \times 1) = f$ and $(e \circ (g \times 1))^{\sim} = g$.

****** Examples of cartesian closed categories
******* Sets with hom-objects
******* Categories with functor categories
******* Presheaf category of a small category
***** II.2.3. Frames
****** Complete poset is cocomplete poset
A poset is complete iff it is cocomplete.

******* TODO Proof
****** TODO Infinite distributive law
****** Frames
A *frame* is a complete and cartesian closed poset. That is, it
is a complete poset with the distributive law

\[ x \wedge \bigvee_{i\in I} y_i = \bigvee_{i\in I} x \wedge y_i.
\]

****** Frame morphisms
A *frame morphism* is a $f : L \to M$ between frames preserving finite
infima and arbitrary suprema.

***** II.2.4. Heyting algebras
****** Lattices
A *lattice* is a poset with finite limits and colimits.

****** Lattice homomorphisms

** Types and programming languages - Pierce
*** Preface
**** 1. Introduction
**** 2. Mathematical preliminaries
*** I. Untyped Systems
**** 3. Untyped arithmetic expressions
**** 4. An ML implementation of arithmetic expressions
**** 5. The untyped lambda calculus
**** 6. Nameless representation of terms
**** 7. An ML implementation of the lambda-calculus
*** II. Simple typesa

* Papers
** TODO Dependent types at work - Ana Bove, Peter Dybjer
*** 1. What are dependent types?
*** 2. Simply Typed Functional Programming in Agda
**** 2.1. Truth Values
**** 2.2. Natural numbers
***** Notion of Inductive type
      /Recursive types/ in Haskell are *inductive types* in constructive type
      theory.
***** Notion of Canonical form
      Elements on canonical form are built up by constructors only. They do not
      contain defined functions. Martin-Lf considers /lazy canonical forms/, where
      it suffices to begin with a constructor:

      #+BEGIN_SRC haskell
      Zero * Zero        -- Not a canonical form
      Succ (Zero + Zero) -- Lazy canonical form
      Succ (Succ Zero)   -- Canonical form
      #+END_SRC
      
**** 2.3. Lambda Notation and Polymorphism
     In Agda we have no type variables, we have families of functions:

     #+BEGIN_SRC 
     id : (A : Set) -> A -> A
     id = \(A : Set) -> \(x : A) -> x
     #+END_SRC

**** 2.4. Implicit Arguments
     Implicit arguments are declared by enclosing their typings within curly 
     braces.

**** 2.5. Gdel System T
     Gdel System T is a system of primitive recursive functionals. All typable
     programs in Gdel System T terminate. We can only use -reduction and the
     definitions of:

     #+BEGIN_SRC 
     true
     false
     zero
     succ
     if_then_else
     natrec
     #+END_SRC

     We can define all primitive recursive functions, but also others such as the
     Ackermann fuction.

**** 2.6. Parametrised Types
**** 2.7. Termination-checking
     In M-L Type Theory, all recursion is *primitive recursion*; a structural
     recursion on the well-founded data types.

     As the Agda's termination-checker has not yet been documented, if Agda will
     be used as a system for formalising mathematics rigorously, it is advisable to
     stay within a well-specified subset such as Martin-Lf type theory.

     In fact, the termination checker will not recognize calls to non-constructors
     as smaller arguments. =(m-n)= will not be recognized as smaller than =m=,
     for example.

*** 3. Dependent Types
**** 3.1. Vectors of a given length
     We have to alternatives to define vectors of a given length:
     
     - *As a Recursive Family*:
       
       #+BEGIN_SRC 
       Vec : Set -> Nat -> Set
       Vec A zero = Unit
       Vec A (succ n) = A X Vec A n
       #+END_SRC

       Functions must be written by induction on the length of the vector.

     - *As an Inductive Family*:

       #+BEGIN_SRC 
       data Vec (A : Set) : Nat -> Set where
         [] : Vec A zero
	 _::_ : {n : Nat} -> A -> Vec A n -> Vec A (succ n)
       #+END_SRC
       
     We can use type-checking to define functions that work only over non-empty
     vectors, such as =tail= or =head=.

**** 3.2. Finite Sets
     This data type is useful when we want to access the element at a certain
     position in a vector.

**** 3.3. More Inductive Families
*** TODO 4. Propositions as Types
** TODO Monads for functional programming - Philip Wadler
*** 1. Introduction
*** 2. Evaluating monads
**** 2.1. Variation zero: The basic evaluator
**** 2.2. Variation one: Exceptions
**** 2.3. Variation two: State
**** 2.4. Variation three: Output
**** 2.5. A monadic evaluator
**** 2.6. Variation zero, revisited: The basic evaluator
**** 2.7. Variation one, revisited: Exceptions
**** 2.8. Variation two, revisited: State
**** 2.9. Variation three, revisited: Output
*** 3. Monad Laws
    Son equivalentes =return,join= y =return,bind=. Y adems, desde cualesquiera
    de ellos, se define =map=.
*** 4. State
**** 4.1. Arrays
**** 4.2. Array transformers
**** 4.3. Array readers
     Conmutative monads.
**** 4.4. Conclusion
*** TODO 5. Parsers
** TODO P?=NP - Scott Aaronson
** TODO Semantics for type theory
# Notes on paper.

*** Formal languages and semantics
Traditional definition of formal languages. An alphabet and rules to
inductively construct words. We call $L$ the set of valid strings.

**** Example: boolean algebra
 * symbols $\Sigma = \left\{ p_1,\dots,p_n, \wedge,\neg,\implies,(,),\top,\bot,\dots \right\}$ 
   atomic propositions and logical symbols.
 * valid strings are defined inductively as
   * singletons $p_i$, $\top$ or $\bot$
   * connectors: if $a, b$ are valid, so are $a \wedge b, a \vee b, \neg a, \dots$

**** Semantics
The semantics assigns to each string a number $0$ or $1$,

\[
s \colon L \to \left\{ 0,1 \right\}
\]

and this evaluation will depend on the evaluation of atomic propositions.
If we call $\Omega = \left\{ p_1,\dots,p_n \right\}$, it depends on a valuation $v \colon \Omega \to \left\{ 0,1 \right\}$.
Connectives are interpreted naturally.

**** Observation
Sometimes $s_v(a) = s_v(b)$ regardless of $v$; in particular, $s_v(a) = 1$ regardless
of $v$ for some formulae (tautologies and absurds).

\[
s_v(A \wedge B) = s_v(B \wedge A)
\]

*** Simply typed lambda calculus
**** Definition
Taking a inductively defined set of types

 * given type $I$
 * function types $\alpha \to \beta$

The set $\Sigma$ of symbols has countably many variables of each type and the symbols of
lambda calculus $(,),\lambda, O,+,r$. We call a pair $<s,\alpha>$ a typed string; the set of
valid strings is our set of valid strings; we write $s : \alpha$ instead of $<s,\alpha> \in L$.

We have

 * $0 : I$
 * $^+ \colon I \to I$
 * $r \colon I \to (I \to I) \to I \to I$

and the usual typing rules for application and abstraction

 * if $s : \alpha, l : \alpha \to \beta$ then $sl : \beta$,
 * if $s : \beta$ and $x$ var of type $\beta$, $\lambda x.s \colon \alpha \to \beta$.

**** Semantics
We associate a set to each type, with $M(I) := \mathbb{N}$ and $M(\alpha \to \beta) := M(\beta)^{M(\alpha)}$;
and to each constant a correspondant element on the set, for example,
$M(r)$ is the unique function defined by induction.

Based on this, we construct an interpretation for each lambda term with
$M(s) \in M(\alpha)$. We give first an interpretation of variables $v = (v_{\alpha})_{\alpha \in Tp}$.
Application is interpreted as application of functions and abstraction
is interpreted as the interpretation of the body of the lambda under
a valuation that takes the bounded variable to the argument.

We can define a set of free variables of a string. Note that an
interpretation $M_{v}(x)$ with a valuation $v$ only depends on the
values of $v$ for the elements of $FV(x)$.

**** Observations
We have alpha-equivalence, beta-reduction and eta-reduction
inside the interpretation.

*** Semantics of MLTT
**** Set-theoretical semantics
It is more difficult to write a complete formalization of mltt.

We want to interpret $x_1:A_1,\dots,x_n:A_n \vdash A\ \mathrm{type}$ after interpreting

$A_1,\dots,A_n$ as sets. The interpretation will be a tuple
\[
a = \left\langle a_1,\dots,a_n \right\rangle
\]
where $a_i \in M(A_i)$, this is called the *realization of the context*.

To create an element $x_1:A_1,\dots,x_n:A_n \vdash t : A$ we should get
$M_v(t) \in M_v(A)$. We want an interpretation such that for every
definitional equality $A \equiv B$, we have the same sets $M_v(A) = M_v(B)$.

\[
M(s = t) = \left\{ \ast \right\} \mbox{ if } M(s)=M(t) \mbox{, and } \varnothing \mbox{ otherwise}
\]

But these semantics satisfy UIP.
**** Topological semantics
We interpret each type as a topological space; and each function type
as the set of continuous functions. We use simplicial sets in MLTT.

UIP does not hold under this interpretation.
** Classification of Surfaces - Chen Hui George Tao
*** 1. Introduccin
Vamos a demostrar que todas las superficies compactas son homeomorfas
a la esfera, la suma conexa de toros o la suma conexa de planos proyectivos.

*** 2. Superficies
**** Superficies
Una *superficie* es una 2-variedad. Un espacio Hausdorff contable
localmente homeomorfo a $\mathbb{R}^2$.

**** Idea del artculo
Dado un polgono, si identificamos las aristas en pares, tendremos una
superficie. Veremos que toda superficie se construye a partir de un
polgono con las aristas identificadas.

*** 3.1. Triangulaciones. Complejos simpliciales
**** Simplex
Dados $v_0,\dots,v_k$ en posicin general, el *simplex* que generan es el
conjunto de combinaciones convexas bajo la topologa inducida.

**** Complejo simplicial eucldeo
Un *complejo simplicial* es una coleccin $K$ de smplices cumpliendo:

  1. Si $\sigma \in K$, cada cara suya est en $K$.
  2. Si $\sigma,\tau \in K$, $\sigma \cap \tau$ es vaca o una cara de ambas.
  3. Cada punto tiene un entorno que interseca a slo finitos smplices.

**** Poliedro
La unin de todos los smplices de $K$ es un espacio simplicial llamado
su *poliedro*, $|K|$.

**** Homomorfismo simplicial
Funcin continua entre dos poliedros cuya restriccin a cada simplex
es afn. Es *isomorfismo simplicial* cuando es homeomorfismo.

*** 3.2. Triangulaciones
**** Triangulacin
Una triangulacin es un homeomorfismo entre un espacio topolgico
y un espacio simplicial eucldeo.

**** Teorema de Rad
Toda superficie es un poliedro de un complejo simplicial 2-dimensional.
Donde adems, cada 1-smplex es cara de dos 2-smplex.

***** Demostracin
La demostracin es larga. La idea es recubrir toda la superficie con
discos regulares y usar el Teorema de Schonflies.

*** 4.1. Presentacin poligonal. Polgonos
**** Regin poligonal
Compacto $P$ del plano cuya frontera es un 1-smplex cumpliendo:

  1. Cada $q$ que no es vrtice tiene un entorno $U$ tal que $P \cap U$ es
     interseccin de $U$ con un plano.
  2. Cada $q$ que es vrtice tiene un entorno $U$ tal que $P \cap U$ es
     interseccin de $U$ con dos planos con fronteras intersecando en $q$.

**** Una regin poligonal relacionada a pares es una superficie compacta
Sea $P$ regin poligonal. Dada una relacin que identifique cada 
arista con exactamente otra por isomorfismo simplicial, el
espacio cociente resultante es una superficie compacta.

***** Demostracin
Sea $M = P/\sim$, con proyeccin $\pi:P \longrightarrow M$. Por compacidad, $\pi(P) = M$
es compacto. Podemos dividir los puntos de $M$ en:

****** Puntos en una cara
Como la proyeccin es homeomorfismo local en el interior del polgono,
tenemos que son localmente eucldeos.

****** Puntos en una arista
Claramente, existe un entorno sin vrtices. Por definicin de la
relacin, el punto est identificado con exactamente otro y podemos
usar los entornos $V_1,V_2$ que son discos de intersecciones con planos.

Ahora creamos aplicaciones afines $\alpha_1,\alpha_2$ que peguen las dos partes del 
disco en $\mathbb{R}^2$ y las usamos para construir una proyeccin de $V_1\cup V_2$ a
$\mathbb{R}^2$. Por tener la misma relacin de equivalencia que $\pi$, los espacios
cocientes son homeomorfos, y podemos ver que el punto tiene un
entorno eucldeo en este espacio.

****** Vrtices
Repetimos exactamente lo mismo que hemos hecho con la arista pero
sabiendo que cada identificacin del vrtice nos da un ngulo que
debemos pegar despus en $\mathbb{R}^2$.

*** 4.2. Presentacin poligonal. Suma conexa de superficies
**** Suma conexa
Dadas superficies $M_1,M_2$, bolas regulares $B_1,B_2$, y un homeomorfismo
$f : dM_2' \longrightarrow dM_1'$. El espacio que identifica cada punto con su imagen
es la *suma conexa*.

**** Suma conexa de superficies conexas
La suma conexa de superficies conexas es una superficie conexa.

***** Demostracin
Debemos ver que es localmente eucldea y Hausdorff. Tomamos como
proyeccin:

\[
\pi : M_1' \sqcup M_2' \longrightarrow M_1\# M_2
\]

Y tenemos dos tipos de puntos.

****** Puntos en el interior
Los puntos que no tocan al disco de unin tienen a la proyeccin
localmente homeomorfa en ellos y por eso son localmente eucldeos.

****** Puntos en el borde
Tomamos un entorno de ambos puntos tal que contengan los mismos
puntos identificados del borde. Los proyectamos a $\mathbb{R}^2$ pegando
ambos bordes y nos damos cuenta de que es la misma relacin de
equivalencia que dara $\pi$, luego son espacios homeomorfos y el
punto en ellos, llevado al $0$, es localmente eucldeo.

*** 4.3. Presentacin poligonal
**** Presentacin poligonal
Una *presentacin poligonal* es un conjunto finito con finitas palabras
$W_1,\dots,W_k$, cada una de longitud 3 o mayor.

**** Realizacin geomtrica de una presentacin poligonal
La *realizacin geomtrica* de una presentacin poligonal se construye:

  1. Cada palabra $W_i$ da $P_i$, regin poligonal de $k$ lados construda del
     polgono regular modelo.
  2. Damos una biyeccin de cada smbolo con los lados de $P_i$ en orden.
  3. Unimos disjuntamente los $P_i$ e identificamos aristas con el mismo
     nombre y homeomorfismos afines.

**** Presentacin de superficie
Presentacin poligonal donde cada smbolo ocurre exactamente dos veces.

***** La realizacin de una presentacin de superficie es superficie compacta
Hemos probado antes que en este caso, obtenamos una [[*Una regin poligonal relacionada a pares es una superficie compacta][superficie compacta]]
en la realizacin.

**** Presentaciones topolgicamente equivalentes
Dos presentaciones son equivalentes si tienen la misma realizacin 
geomtrica.

**** Toda superficie compacta tiene una presentacin de superficie
Toda superficie compacta tiene una presentacin de superficie.

***** Demostracin
Dada una superficie $M$, por triangulacin es homeomorfa a un complejo
simplicial donde cada arista es cara de dos smplices. Dado un complejo
simplicial podemos construir una presentacin donde:

  - Cada 2-smplex es una palabra de longitud 3.
  - Dos aristas se llaman igual si vienen del mismo smplex.

La presentacin entonces nos da dos proyecciones desde los polgonos
hasta la realizacin de la presentacin y al smplex.

  - $\pi_K : P_1\sqcup\dots\sqcup P_n \longrightarrow |K|$
  - $\pi_{\cal P} : P_1\sqcup\dots\sqcup P_n \longrightarrow |{\cal P}|$

****** Ambas proyecciones identifican los mismos puntos
Es claro que identifican las mismas aristas por construccin.
Debemos comprobar que identifican los mismos vrtices. Sea $v$
un vrtice, que debe estar en una arista que debe estar en dos 
2-smplex $\sigma,\sigma'$. Definimos una relacin entre 2-smplices si
comparten una arista. Para comprobar que los vrtices se mantienen
por una proyeccin entre aristas, comprobaremos que hay una sola
clase de equivalencia.

Si hubiera dos clases de equivalencia $\{\sigma_i\},\{\tau_i\}$, podemos tomar una
bola suficientemente pequea (por la condicin de finitud de los
complejos simpliciales) para que interseque slo a smplices 
conteniendo a $v$. Esto nos da una bola homeomorfa a $\mathbb{R}^2$, luego
$U \setminus \{v\}$ es conexo. Podramos quitar el $v$ en los complejos simpliciales
de ambas clases de equivalencia y seran disconexas.

**** Extensin de isomorfismo de bordes
Sean $P_1,P_2$ polgonos convexos con $f : bP_1 \longrightarrow bP_2$ isomorfismo simplicial,
entonces se extiende a un homeomorfismo $F : P_1 \longrightarrow P_2$.

***** Demostracin
Cualquier punto en el interior forma unindose con los vrtices un
complejo simplicial. Los poliedros de ambos son homeomorfos porque
los complejos simpliciales lo son.

**** Las transformaciones elementales dan realizaciones equivalentes
Las transformaciones elementales de las presentaciones dan lugar a
superficies topolgicamente equivalentes

***** Reflexin
Claramente una aplicacin afn de reflexin nos da lo buscado.

***** Rotacin
La rotacin es una aplicacin afn que nos da lo buscado.

***** Cortar
Tomamos las dos proyecciones de presentacin antes y despus de
cortar y comprobamos que identifican los mismos puntos.

***** Doblar
Tomamos las dos proyecciones y aadimos las aristas que faltan para
comprobar que identifican los mismos puntos.

**** Presentacin de la suma conexa
La presentacin de la suma conexa es la unin de las palabras.

***** Demostracin
Dadas $W_1,W_2$, cortamos un disco como $W_1c^{-1}b^{-1}a^{-1}$ y $abcW_2$ e 
identificamos las aristas dadas.

*** 5. Teorema de clasificacin
**** Lema: Botella de Klein
**** Lema: Suma de toro y plano proyectivo
**** Teorema de clasificacin
Toda superficie compacta conexa es homeomorfa a una de las siguientes:

  - $\mathbb{S}^2$
  - $\mathbb{T}^{\#n}$
  - $\mathbb{RP}^{2\#n}$

***** Demostracin
Tomamos transformacin desde la presentacin hasta llegar a la
presentacin de un modelo.

****** Paso 1: Una sola cara
****** Paso 2: Sin pares complementarios adyacentes
****** Paso 3: Todos los pares retorcidos adyacentes
****** Paso 4: Identificamos todos los vrtices en un punto
****** Paso 5: Comprobamos que los complementarios estn entrelazados
****** Paso 6: Llevamos los complementarios juntos
****** Paso 7: Comprobamos que es una presentacin modelo
** Koszul Pairs and applications - Pascual Jara, Drago tefan
*** Introduction
**** Koszul ring
*Koszul ring*. A graded ring $A$ is *Koszul* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.

**** Graded ring
*Graded ring*. A ring that is a direct sum of abelian groups:

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.

***** Homogeneous Elements
A *homogeneous element* is an element of any factor $A_i$ of the 
decomposition.

*Example:* A polynomial ring $A = \mathbb{K}[x_1,x_2, \dots]$ is graded with $A_i$ 
being the abelian group of polynomials with only monomials of 
degree $i$.
# QUESTION: Do they admit a different gradation?
# We can take $A_i$ to be the group of polynomials of degree 
# *equal or less* than i!

**** Semisimple group
*Semisimple group*. A group is semisimple if it has no non-trivial 
normal abelian subgroups.

Different uses of this term can be found [[http://planetmath.org/semisimplegroup][here]].
# QUESTION: Which are we interested in?

**** Semisimple module
*Semisimple module*. It is a direct sum of simple modules, that is, 
they have no non-zero proper submodules.

**** Semisimple algebra
An associative finite dimensional algebra $A$ is *semisimple* if
$A$ is a direct product of simple algebras or equivalently, if $A$ has
trivial Jacobson radical.

*** 1. Almost-koszul pairs
**** 1.1. R-rings
***** R-Ring
*R-ring*. Associative and unital algebra. It is an associative and 
unital ring $A$ together with a morphism $u : R \longrightarrow A$.

***** Graded and connected R-rings
*Graded and connected R-rings*. A R-ring is graded if it is equipped 
with a decomposition:

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

**** 1.2. R-corings
***** Definition of coalgebra
A [[https://en.wikipedia.org/wiki/Coalgebra#Formal_definition][coalgebra]] over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$

Sometimes, the coalgebras use [[https://en.wikipedia.org/wiki/Coalgebra#Sweedler_notation][Sweedler notation]].

***** Examples of coalgebras
****** The divided power coalgebra
Consider $K[X]$, the polynomial ring, where we define by linearity:

\[\Delta(X^n) = \sum^n_{k=0} {n \choose k} X^k \otimes X^{n-k}\]

\[\epsilon(X^n) = \twopartdef{1}{n=0}{0}{n>0}\]

When the structures of algebra and coalgebra are compatible, they
are called [[https://en.wikipedia.org/wiki/Bialgebra][bialgebras]].

***** R-coring
*R-coring*. Coassociative and counital coalgebra. It is an R-bimodule 
with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and 
a /counit/ $\epsilon : C \longrightarrow R$.

***** Graded corings
*Graded corings*. Decomposition $C = \bigoplus_{n \in \mathbb{N}} C_n$, 
such that:

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}\]

**** 1.3. Almost-Koszul pair
*Almost-Koszul pair*. Connected R-ring and R-coring $(A,C)$ with an 
isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$, that satisfies the relation:

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0\]

Or, using Sweedler notation, for any $c \in C_2$:

\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0\]

**** 1.4. Opposite Koszul pair
If $(A,C)$ is a Koszul pair, then $(A^{op},C^{op})$ are Koszul pairs with
respect to:

\[\theta_{C^{op},A^{op}} = \theta_{C,A}\]

**** 1.5. The normalized bar resolution of R
For every strongly graded R-ring A, there is a graded coring C such that
$(A,C)$ is an almost-Koszul pair.

***** The normalized right bar resolution
The exact sequence $\beta_\ast^r(A)$:

\[ 0 \longleftarrow 
R \overset{\delta_0}\longleftarrow 
A \overset{\delta_1}\longleftarrow
\overline{A} \otimes A \overset{\delta_2}\longleftarrow
\overline{A} \otimes \overline{A} \otimes A \overset{\delta_3}\longleftarrow
\overline{A} \otimes \overline{A} \otimes \overline{A} \otimes A \longleftarrow
\dots
\]

is called the *normalized right bar resolution*. Where
the $\delta$ are defined as:

 - $\delta_0 = \pi^0_A$
 - \[ \delta_n(a_1 \otimes \dots \otimes a_n \otimes a_{n+1}) 
      = \sum_{i=1}^n (-1)^i  a_1 \otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_{n+1}\]

***** TODO Normalized bar complex

*** 2. Koszul Pairs

*** 3. Hochschild (co)homology of Koszul rings
**** 3.1. The cyclic tensor product
***** Enveloping algebra of R
The tensor product algebra $R^e = R \otimes_\mathbb{K} R^{op}$ is called the 
*enveloping algebra* of $R$.

*** 4. Almost-Koszul pairs associated to twisted tensor products

*** 5. The Hochschlid cohomology of a twisted tensor product

** The derivative of a regular type is its type of one-hole contexts - Connor McBride
Presented by [[https://www.youtube.com/watch?v=K7tQsKxC2I8][Erik Hinton]].

*** Types and fixed points
Empty type, unit type, product and other basic types.
We use parametric types with type variables.

# We need inductive types and the W from ML-theory?
Fixed points are used to define types. Naturals are
the fixed point of $Z + S x$. We write the fixed point
of a formula $F$ over a variable $x$ as $\mu x.F$.

\[
\mathtt{Nat} = \mu x. 1 + x
\]

*** Zippers and holes
One-hole contexts with respect to some interior type. A zipper is a
one-hole context of a type and the value that was removed.

*** Derivatives
To find the type of a context of type $T$ with a hole in place of some
$x$, take the partial derivative of $T$ with respect to $x$.

Partial derivatives with respect of a type variable work directly.

Product and sum rules can be proved. Chain rule can be proved.

*** Recursive derivatives

*** Questions
Negative and fractional types. Algebraic types and the field of rationals.
Computing on the field of rationals.
** From sets to types to categories to sets - Steve Awodey
*** 1. Sets to Types
*** 2. Types to Categories
**** Syntactic topos
*** 3. Categories to Sets
**** How to extract an elementary set theory from a topos
**** At least BIST
*** TODO 4. Composites

* Notes
** lgebra conmutativa y computacional
# Exportaba con config.setup

*** 1. Anillos e ideales
**** La categora CRing
***** Categora
Consideramos la categora de los *anillos conmutativos*, que consta de
los anillos conmutativos como objetos y de los homomorfismos de
anillos; respetando suma, producto y unidad; como morfismos.

***** Z es objeto inicial
El anillo $\mathbb{Z}$ es inicial en =CRing=. El homomorfismo nico
queda unvocamente definido con $f(1) = 1$ y $f(n) = nf(1)$.

***** Subanillos
*Subanillo*. Subconjunto cerrado para la suma y el producto
conteniendo a 1.

***** Monomorfismos y epimorfismos
En =CRing= coinciden la inyectividad con ser monomorfismo y la
sobreyectividad con ser epimorfismo.

**** Ideales
***** Definicin
Un *ideal* es un subconjunto cerrado para la suma y el producto de cualquier 
elemento desde $R$.

***** Retculo de ideales
Los ideales forman un retculo con la suma y la interseccin.
Dos ideales son *primos relativos* cuando suman el anillo.

***** Generacin de ideales
Llamamos $(X)$ al *ideal generado* por $X$; el menor ideal que 
contiene a $X$:

\[ (X) = \bigcap_{X \subset \alpha \text{, ideal}} \alpha\]

Lo llamamos *ideal finitamente generado* cuando $X$ es finito,
cumplindose:

\[ (X) = \left\{ \sum^{finita} r_ix_i \mid r_i \in R, x_i \in X\right\}\]

E *ideal principal* cuando $X$ tiene un slo elemento.

***** Producto de ideales
Se define para $\alpha, \beta$ ideales como:

\[ \alpha\beta = \left\{ xy \mid x\in\alpha, y\in\beta \right\}\]

***** Ideales primos relativos
Dos ideales son *primos relativos* cuando $\alpha+\beta = R$. Cuando son 
primos relativos se cumple que $\alpha\beta = \alpha \cap \beta$.

**** Anillo cociente
***** Definicin
Sea $R$ anillo y $\alpha \subset R$ ideal, tomamos la relacin de equivalencia
$x \sim y \Leftrightarrow x-y \in \alpha$, para obtener:

\[ R/\alpha = \{x+\alpha \mid x\in R\}\]

***** Ideales del anillo cociente
Los ideales del anillo cociente sobre $\alpha$ estn en correspondencia biyectiva
con los ideales que lo contienen, $\beta \supset \alpha$. Son siempre de la forma $\beta/\alpha$.

***** Primer Teorema de Isomorfa
Para cualquier homomorfismo de anillos $f$:

\[ R/\ker(f) \cong \mathrm{img}(f)\]

Y adems, los ideales estn en correspondencia biyectiva por $f_\ast$ y $f^{-1}$:

\[ \{ \alpha \mid \ker(f)\subset\alpha \} 
\longleftrightarrow 
\{ \beta \mid \beta \subset \mathrm{img}(f)\}\]

****** Demostracin
Trivial desde la descomposicin de morfismos en una categora arbitraria.
Adems, se comprueba que $f^{-1}$ preserva ideales y que $f_\ast$ preserva ideales en su 
imagen.

**** Ideales primos y maximales
***** Definicin
$P$ es ideal *primo* si no es el total y $xy\in P \Rightarrow x \in P \vee y \in P$.
$P$ es ideal *maximal* si $M \neq R$ y es maximal en el retculo de ideales 
sin $R$.

***** Caracterizacin de ideales primos y maximales
En relacin a su cociente en el anillo:

 - $P$ es primo ssi $R/P$ es un dominio de integridad no trivial.
 - $M$ es maximal ssi $M/P$ es un cuerpo no trivial.

****** Demostracin trivial
***** Preservacin de ideales primos y maximales
Dado un homomorfismo $f$,

 1. Si $\Pi$ es ideal primo, entonces $f^{-1}(\Pi)$ es ideal primo.
 2. La imagen y preimagen de ideales preserva primos y maximales 
    entre el ncleo y sobre la imagen del anillo.

Como consecuencia los ideales primos (resp. maximales) de un
anillo $R/\alpha$, son los ideales de la forma $\Pi/\alpha$ con $\alpha\subset\Pi$ primo (resp.
maximal).

****** Demostracin
*1* es trivial. *2* tenemos que demostrarlo en cuatro pasos:

 - Si $M$ es maximal en $\mathrm{img} f$, entonces $f^{-1}(M)$ es maximal entre los 
   ideales que contienen a $\ker f$.
 - Si $M$ es maximal, entonces $f(M)$ es maximal en $\mathrm{img} f$.
 - Si $\Pi$ es primo en $\mathrm{img} f$, entonces $f^{-1}(\Pi)$ es primo, ya demostrado.
 - Si $\ker f \subset \Pi$ es primo, entonces $f(\Pi)$ es primo en $\mathrm{img} f$.

***** Teorema de Krull
Dados $\alpha \subseteq R$ ideal y $S$ multiplicativamente cerrado con $\alpha\cap S = \varnothing$, 
existe un ideal $M$ tal que:

  - $\alpha \subset M$ 
  - $M \cap S = \varnothing$
  - $M$ es maximal respecto a estas condiciones.

Adems, $M$ es un ideal primo.

****** Subconjunto multiplicativamente cerrado
Es un subconjunto $S$ con:

 - $1 \in S$
 - $x,y\in S \implies xy \in S$

****** Demostracin
Dada una cadena de ideales cumpliendo la condicin su unin tambin 
la cumple y es cota de la cadena. Aplicando lema de Zorn obtenemos 
un maximal.

Supongamos $xy \in M$, pero $x,y \notin M$. Entonces $M+(x) \cap S \neq \varnothing$ y
$M + (y) \cap S \neq \varnothing$ por maximalidad, y deben existir $xz,yt \in S$; luego
se tendra $xzyt \in M \cap S$, contradiccin.

***** Corolario al teorema de Krull
Tomando $S=\{1\}$ tenemos que; dado un ideal, existe un ideal maximal que 
lo contiene. En particular, todo elemento no unidad est contenido en un 
ideal maximal, tomando $S = (x)$.

**** Anillos locales
***** Inclusin en ideales primos
Sean ideales $\alpha_1,\dots,\alpha_n$ y $\pi$ un ideal primo. Si $\bigcap \alpha_i \subset \pi$, entonces,

$\exists i: \alpha_i \subset \pi$.

****** Demostracin
Supongamos que $\forall i: \alpha_i \nsubseteq \Pi$; entonces tenemos $x_i \in \alpha_i - \Pi$ tales que ninguno
est en $\Pi$, pero su producto debe estar, contraviniendo que sea primo.

***** Inclusin de ideales primos
Sean ideales primos $\pi_1,\dots,\pi_n$, (salvo quiz 2) y $\alpha$ un ideal. Si $\alpha \subset \bigcup \pi_i$, 
entonces,

$\exists i: \alpha \subset \pi_i$.

****** Demostracin
En el caso $n=2$, supongamos $\alpha \subset \pi_1 \cup \pi_2$; y tomemos $x \in \alpha, x\in\pi_1$, $y\in\alpha, y\in\pi_2$.
Entonces tendra $x+y \in \alpha$, pero no estara en $\pi_1 \cup \pi_2$. Ntese que no usamos
todava que sean primos.

En el caso inductivo, aplico la hiptesis de induccin para obtener, para cada $k$:

\[\exists x_k \in \alpha : x_k \notin \bigcup_{i\neq k} \pi_i\]

Luego debe tenerse $x_k \in \alpha_k$; sea ahora $x = x_1x_2\dots x_{n-1}+x_n \in \alpha$; 
luego $\exists r: x\in\alpha_r$. Si $r=n$, tendramos $x_1x_2\dots x_{n-1} \in \alpha_r$, y por primalidad debera
estar alguno; si no, tendramos $x_n \in \alpha_r$.

***** Definicin de anillo local
Un *anillo local* es aquel con un nico ideal maximal. A $R/M$ se le llama 
*cuerpo residual*.

***** Caracterizacin de anillos locales
Un anillo $R$ es local ssi $\{x\in R \mid x \text{ no unidad}\}$ es un ideal.

Sea $M$ ideal propio:

 - $R$ es local con maximal $M$ ssi $R-M \subset {\cal U}(R)$.
 - Si $M$ es maximal y $\{1+x \mid x\in M\}\subset {\cal U}(R)$ entonces es $R$ local y $M$ su maximal.

****** Demostracin
1. Una no unidad debe estar contenida en el nico maximal que hay, que no contiene
   a las unidades y adems es ideal.
   Por otro lado, por Krull, el ideal de las no unidades debera estar contenido
   en un ideal maximal que tampoco tuviera unidades, luego debe ser l mismo.
2. Por la caracterizacin anterior tenemos una implicacin. Sea $R-M \subset {\cal U}(R)$,
   si tenemos $M \not\subset \beta$, entonces tendramos un $x \in \beta,x \notin M$, luego $x \in {\cal U}(R)$
   y entonces $\beta = R$. Si tenemos otro $M'$ maximal, entonces $\exists x\in M': x \notin M$,
   pero eso me vuelve a dar $M' = R$. Luego $M$ es el nico ideal y maximal.
3. Por la caracterizacin anterior tenemos una implicacin. Sea $x \notin R-M$,
   tenemos por maximalidad: $rx+m = 1$, luego $rx = 1-m \in {\cal U}(R)$.
   En conclusin, $R-M \subset {\cal U}(R)$ y es local.

**** Radicales
***** Nilradical
Sus elementos se llaman *nilpotentes*:

\[\operatorname{Nil}(R) = \{x \in R \mid \exists n: x^n = 0\}\]

El nilradical es un ideal.

***** Anillo reducido
Un anillo es *reducido* si $\operatorname{Nil}(R) = 0$. Los dominios de integridad son 
reducidos. Adems, podemos reducir un anillo dividiendo por su 
nilradical $R/\operatorname{Nil}(R)$.

***** Espectro
El *espectro* de un anillo R es el conjunto de sus ideales primos:

\[\spec(R) = \{\pi\subset R \mid \pi \text{ es un ideal primo}\}\]

***** Caracterizacin del nilradical
El nilradical de $R$ es la interseccin de los ideales del espectro:

\[ \operatorname{Nil}(R) = \bigcap_{\pi \in \operatorname{Spec}(R)} \pi\]

****** Demostracin
Sea $x^n = 0$, entonces $x^n \in \pi, \forall \pi \in \operatorname{Spec}(R)$; y, por primalidad, $x \in \pi$.
Sea $x \notin \operatorname{Nil}(R)$, entonces $S = \{1,x,x^2,\dots\}$ es multiplicativamente cerrado 
con $S \cap \operatorname{Nil}(R) = \varnothing$. Por Krull, tenemos un $\pi$ tal que $\pi \cap S = \varnothing$.

***** Radical de un ideal
Se define como:

\[\sqrt{\alpha} = \{x \in R \mid \exists n \geq 1 : x^n \in \alpha\}\]

Tenemos que $\operatorname{Nil}(R/\alpha) = \sqrt{\alpha}/\alpha$. Cuando $\alpha = \sqrt{\alpha}$ decimos que es *ideal radical*.
Se caracteriza como:

\[\sqrt{\alpha} = \bigcap_{\alpha \subset \pi \in Spec(R)} \pi\]

****** Demostracin
Tenemos claramente $\pi^{-1}(\operatorname{Nil}(R/\alpha)) = \sqrt{\alpha}$, pero entonces:

\[\sqrt{\alpha} = 
\pi^{-1}(\operatorname{Nil}(R/\alpha))=
\pi^{-1} \left( 
\bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R/\alpha)} \pi/\alpha 
\right) = \bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R)} \pi\]

***** Radical de Jacobson
Se define el *radical de Jacobson* como:

\[{\cal J}(R) = \bigcap_{{\cal M} \text{ maximal}} {\cal M}\]

****** Caracterizacin del radical de Jacobson
Tenemos que $x \in {\cal J}(R)$ ssi $1-xy \in U(R)$ para cualquier $y$.

******* Demostracin
Un elemento $1-xy$ para $x \in {\cal J}(R)$ no puede estar en ningn ideal maximal, 
porque estara entonces el $1$. Por corolario de Krull, debe ser unidad.

Supongamos $x \notin M$, entonces $(x) + M = R$, y por tanto $1-xy \in M$. Pero 
un maximal no puede contener una unidad.

**** Ideales residuales y anulador
***** Ideales residuales
Definimos el *ideal residual* (a veces llamado *cociente*) de dos 
ideales como:

\[ (\alpha : \beta) = \{x\in R\mid x\beta \subset\alpha\}\]

***** Anulador
\[\operatorname{Ann}(\beta) = \{x \in R \mid x\beta = 0\} = (0 : \beta)\]

**** Ideales contrados y extendidos
***** Ideal extendido
Dado un homomorfismo $f : R \longrightarrow S$ llamamos *ideal extendido* de $\alpha$ al ideal:

\[ \alpha^e = (f(\alpha)) = \left\{ \sum s_i f(x_i) \mid s_i \in S, x_i \in \alpha\right\}\]

***** Ideal contrado
Dado un homomorfismo $f$ llamamos *ideal contrado* de $\beta$ al ideal:

\[ \beta^c = f(\beta) \]

***** Biyeccin entre ideales
Para $f : S \longrightarrow R$ homomorfismo y $\alpha,\beta$ ideales:

  1. $\alpha \subset \alpha^e^c$, y $\beta \supset \beta^c^e$.
  2. $\alpha^e = \alpha^e^c^e$, y $\beta^c = \beta^c^e^c$.
  3. Hay una biyeccin con $(-)^e,(-)^c$ entre ideales contrados y extendidos, 
     que adems pueden escribirse como $\{\alpha \subset R \mid \alpha = \alpha^e^c\}$ y $\{\beta \subset S \mid \beta = \beta^c^e\}$.

****** Demostracin
Pueden escribirse as porque si tengo $\beta = \alpha^e$, entonces $\beta^c^e = \alpha^e^c^e = \alpha^e = \beta$. 
La biyeccin es trivial desde la definicin y las proposiciones anteriores.

**** Producto directo de anillos
***** Producto directo
Para $R_1,R_2,\dots,R_n$ tomamos como su producto directo a:

\[R_1\times \dots \times R_n = \prod_{i=1}^n R_i\]

con las operaciones definidas componente a componente.

***** Proyecciones e inclusiones
Las *proyecciones*, $p_k$, a cualquier factor son homomorfismos.
Las *inclusiones*, $u_k$, *no* son homomorfismos, ya que no respetan
el uno del anillo, que en este caso es $(1,\dots,1)$. Cumplen adems:

 - $p_k \circ u_k = \delta_{kj}id$
 - $\sum u_i \circ p_i = id$
 - $\ker(p_j) = \sum \mathrm{img}(u_j)$

***** Propiedad universal
El producto con las proyecciones es el *producto categrico* de la
categora de los anillos:

\[ \begin{tikzcd}
& & S \dar[dashed]{\exists!} \arrow[bend right]{ddll} \arrow[bend right]{ddl} \arrow[bend left]{ddr} \arrow[bend left]{ddrr} & &\\
& & \prod R \arrow{dll}[swap]{\pi_1} \arrow{dl}{\pi_2} \arrow{dr}[swap]{\pi_3} \arrow{drr} & & \\
R_1 & R_2 &  & R_3 & \dots
\end{tikzcd} \]

***** Teorema Chino del Resto
En la situacin de la propiedad universal sobre el cociente por unos
ideales $\alpha_1,\dots,\alpha_n$:

\[ \begin{tikzcd}
\prod_{i=1}^n R/\alpha_i \rar{\pi_i} &  R/\alpha_i \\
R \uar{\exists! f} \urar{p_i}
\end{tikzcd} \]

Tenemos que:

  1. Si los $\alpha_i$ son primos entre s, $\prod \alpha_i = \bigcap \alpha_i$.
  2. La $f$ es sobreyectiva ssi los $\alpha_i$ son primos entre s.
  3. La $f$ es inyectiva ssi $\bigcap \alpha_i = 0$. De hecho, $\ker(f) = \bigcap \alpha_i$.

****** Demostracin
1. El caso $n=2$ es conocido. En el caso $n>2$, aplicamos la hiptesis
   de induccin a $\alpha_1\alpha_2\dots\alpha_{n-1}$ y a $\alpha_n$, que se demuestran primos relativos.
2. Doble implicacin:
   - Si $f$ es sobreyectiva, existe $f(x) = (1,0,0,\dots)$, que me da $x \in \alpha_i$
     para cualquier $i$, y adems, $x-1 \in \alpha_1$; luego $1 \in \alpha_i+\alpha_1$.
   - Si son primos relativos, existen $x_i + y_i = 1$ con $x_i \in \alpha_1$, $y_i \in \alpha_i$.
     $y = y_2y_3\dots y_n = 1 + x$, con $x \in \alpha_1$; luego $y \equiv_{\alpha_1} 1$ pero $y \equiv_{\alpha_i} 0$; luego
     puedo crear una base del anillo.
3. Trivial.

*** 2. Bases de Grbner
**** R-lgebras
***** R-mdulo
Dado $R$ anillo. Un *R-mdulo* (izquierdo) es un grupo abeliano $M$ junto
a una operacin $\cdot : (R,M) \longrightarrow M$ verificando:

  - $r(x+y) = rx+ry$
  - $(r+s)x = rx+sx$
  - $r(sx) = (rs)x$
  - $1x = x$

***** R-lgebras
Una *R-lgebra* $S$ es un anillo con estructura de R-mdulo, tal que:

\[\forall r\in R, x,y\in S:\; (rx)y = r(xy) = x(ry)\]

***** Homomorfismo de estructura
Equivalentemente, una R-lgebra es un anillo $S$ junto a un 
*homomorfismo de estructura* $\lambda : R \longrightarrow S$.

****** Equivalencia
Ntese que puedo pasar de una a otra definicin tomando $\lambda(r) = r1$.

***** Homomorfismos de R-lgebras
Un homormorfismo de R-lgebras $f : S_1 \longrightarrow S_2$ es un homomorfismo de 
anillos que sea tambin homomorfismo de R-mdulos.

\[ f(rs) = rf(s) \]

***** Anillo de polinomios
Definimos el anillo de polinomios en varias variables recursivamente:

\[ R[X_1,X_2,\dots,X_n] = R[X_1,X_2,\dots,X_{n-1}][X_n] \]

Y forma una R-lgebra con la inclusin desde $R$.

***** Propiedad universal del anillo de polinomios
Sea $S$ anillo y $f : R \longrightarrow S$ homomorfismo de anillos. Sean $s_1,\dots,s_n \in S$
elementos arbitrarios; entonces existe un nico homomorfismo de 
R-lgebras $f_{s_1,\dots,s_n} : R[X_1,\dots,X_n] \longrightarrow S$ tal que:

\[ \begin{tikzcd}
R \rar[hook]{i} \drar[swap]{f} & R[X_1,X_2,\dots,X_n] \dar[dashed]{f_{s_1,\dots,s_n}} \\
  & S
\end{tikzcd} \]

Llevando $f(X_i) = s_i$.

****** TODO Demostracin

***** R-lgebras finitamente generadas
Una R-lgebra $S$ es finitamente generada si existe un epimorfismo de
R-lgebras $f : R[X_1,\dots,X_n] \longrightarrow S$.

**** rdenes monomiales
***** Representacin recursiva de un polinomio
Llamamos representacin recursiva a la siguiente:

\[
F = \sum_{j=0}^t F_j X^j_n
\]

donde $F_j \in K[X_1,\dots,X_{n-1}]$. Ntese que es la representacin natural una
vez asumimos la definicin recursiva del anillo de polinomios.

***** Representacin distributiva de un polinomio
Llamamos representacin distributiva a la siguiente:

\[ p = \sum a_{(\alpha_1,\dots,\alpha_n)} 
X_1^{\alpha_1} X_2^{\alpha_2} \dots X_n^{\alpha_n} \]

Si escribimos los monomios como $X^{\alpha}$ para cada $\alpha \in \mathbb{N}^n$, nos
queda:

\[p = \sum_{\alpha \in \mathbb{N}^n} a_\alpha X^\alpha\]

***** Base de los polinomios
Los monomios forman una K-base vectorial del espacio de polinomios:

\[\{ X^\alpha \mid \alpha \in \mathbb{N}^n \}\]

****** Demostracin
Son claramente sistema de generadores y, por definicin, un polinomio
con algn coeficiente no nulo no puede ser nunca nulo. Ntese que puede
haber cuerpos donde los polinomios evalen a cero en cualquier punto
del cuerpo, como $X(X-1)$ en $\mathbb{F}_2$, pero ese polinomio no se considera 
nulo.

***** Grado de un monomio
El grado de un monomio $X^\alpha$ con $\alpha \in \mathbb{N}^n$ es la suma:

\[gr(X^\alpha) = \sum^n_{i=1} \alpha_i\]

***** rdenes compatibles
Un orden $\leq$ en $\mathbb{N}^n$ es compatible si:

\[\alpha \leq \beta \Longrightarrow \alpha + \gamma \geq \beta + \gamma\]

***** rdenes montonos
Un orden $\leq$ es montono si:

\[ 0 \leq \alpha \]

***** rdenes monomiales
Un orden monomial es compatible, montono y total.

***** Orden lexicogrfico
Definimos $\alpha \geq_{lex} \beta$ cuando para el primer $\alpha_i \neq \beta_i$, se tiene $\alpha_i \geq \beta_i$.

***** Orden lexicogrfico graduado
Definimos $\alpha \geq_{grlex} \beta$ cuando $\sum \alpha > \sum \beta$  se da la igualdad
y se tiene $\alpha \geq_{lex} \beta$.

***** Orden lexicogrfico graduado inverso
Definimos $\alpha \geq_{invgrlex} \beta$ cuando $\sum \alpha > \sum \beta$  se da la igualdad
y para el primer $\alpha_i \neq \beta_i$ a la derecha, se tiene $\alpha_i < \beta_i$.

***** Prerdenes
Un preorden es una relacin binaria transitiva y reflexiva.
Equivalentemente, es un orden sin la antisimetra.

***** Relacin de equivalencia en predenes
Dado un preorden $\sqsubseteq$, se define la relacin de equivalencia $x \equiv y$,
que se tiene cuando $x \sqsubseteq y \wedge y \sqsubseteq x$.

***** Producto lexicogrfico de prerdenes
Definimos el producto lexicogrfico de dos prerdenes $\sqsubseteq_1,\sqsubseteq_2$
como:

\[x \sqsubseteq_{12} y = \left\{
\begin{array}{l} 
x \sqsubseteq_1 y \wedge y \not\sqsubseteq_1 x \\ 
\text{  } \\
x \equiv_1 y \wedge x \sqsubseteq_2 y
\end{array}\right.\]

***** Propiedades del producto
El producto de prerdenes cumple:

  1. $\sqsubseteq_{12}$ es un preorden.
  2. $\sqsubseteq_2$ orden $\Rightarrow$ $\sqsubseteq_{12}$ orden
  3. $\sqsubseteq_1,\sqsubseteq_2$ totales $\Rightarrow$ $\sqsubseteq_{12}$ total
  4. $\sqsubseteq_1,\sqsubseteq_2$ compatible $\Rightarrow$ $\sqsubseteq_{12}$ compatible
  5. $\sqsubseteq_1,\sqsubseteq_2$ montono $\Rightarrow$ $\sqsubseteq_{12}$ montono

****** Demostracin
******* Punto 1
Es reflexivo trivialmente. La transitividad se obtiene analizando 
por casos.

******* Punto 2
Cuando $x \equiv_{12} y$, se tiene $x \equiv_1 y$ y por tanto $x \equiv_2 y$; lo que llevara
a $x = y$.

******* Punto 3
Si ambos son totales, suponemos s.p.g. que $x \sqsubseteq_1 y$. Si no tuviramos
que $y \sqsubseteq_1 x$, entonces $x \equiv_1 y$ y como son totales, podemos suponer s.p.g
que $x \sqsubseteq_2 y$, llgando a $x \sqsubseteq_{12} y$.

******* Punto 4
# No parece obvio si no son rdenes. Adems, tenemos definido lo que
# es ser compatible o montono slo para rdenes.

******* Punto 5
Tenemos $0 \sqsubseteq_1 x$; si tuviramos $x \sqsubseteq_1 0$, entonces $x \equiv_1 0$; pero como
sabemos que $0 \sqsubseteq_2 x$, tenemos finalmente $0 \sqsubseteq_{12} x$.

***** Los rdenes son monomiales
Los rdenes $\leq_{lex},\leq_{grlex},\leq_{invgrlex}$ son monomiales.

****** Demostracin
******* El orden lexicogrfico es monomial
Una forma de definir el orden lexicogrfico es con el signo del primer
elemento de la resta. Sabemos que es total. La monotona y la 
compatibilidad se tienen por:

\[(\alpha+\gamma)-(\beta+\gamma) = (\alpha-\beta)\]

Tenemos que $\alpha - 0 = \alpha$, positivo.

******* El resto de rdenes son monomiales
Simplemente notando que el grado es un preorden y que son [[*Propiedades del producto][producto]]
de preorden con el lexicogrfico o con un lexicogrfico inverso.

**** Lema de Dickson
***** Lema de Dickson
Para $S \subseteq \mathbb{N}^n$ no vaco, existe $G \subseteq S$ finito tal que $S \subseteq G + \mathbb{N}^n$.

****** Demostracin
******* Caso base
Cuando $n=1$, como los naturales estn bien ordenados, podemos tomar
el mnimo

******* Caso inductivo
Tomamos un $y \in S$, y tenemos dos casos, o bien $x \in \{y\} + \mathbb{N}^n$, o bien
se tiene $x \in S_{i|j}$ para $j < y_i$. Donde definimos:

\[
S_{i|j} 
= 
\{ x \in S \mid x_i = j\}
\]

Y una familia de conjuntos:

\[
S_{i|j}'
=
\{ 
x \in \mathbb{N}^n
\mid
x_i=0, (x_1,\dots,j,\dots,x_n) \in S
\}
\]

Que por hiptesis de induccin dejando nula a cada paso una de las
coordenadas, dan lugar a $G_{i|j}' \subseteq S_{i|j}'$ finito con $S'_{i|j} = G_{i|j}'+\mathbb{N}^{n-1}$.

\[
G_{i|j} = 
\{x \in S_{i|j} \mid (x_1,\dots,0,\dots,x_n) \in G'_{ij} \}
\]

Sea ahora $x \in S_{i|j}$. Si hacemos un cero en $i$, se tiene 
$(x_1,\dots,0,\dots,x_n) \in S'_{i|j} \subseteq G_{i|j}'+ \mathbb{N}^{n-1}$. Luego

\[\begin{aligned}
(x_1,\dots,0,\dots,x_n) &= z + \alpha \\
(x_1,\dots,j,\dots,x_n) &= (z_1,\dots,j,\dots,z_n) + (\alpha_1,\dots,0,\dots,\alpha_n)
\end{aligned}\]

Por lo tanto, $S_{i|j} \subseteq G_{i|j} + \mathbb{N}^{n}$; y tenemos finalmente $S \subseteq G + \mathbb{N}^n$ si
definimos:

\[G = \{y\} \cup \bigcup_{i,j<y_i} G_{i|j}\]

Tenemos que cada uno de ellos es finito.

***** Orden monomial es buen orden
Todo orden monomial en $\mathbb{N}^n$ es buen orden.

****** Demostracin
Por Dickson, cualquier subconjunto tiene un $G$ finito con $S \subseteq G + \mathbb{N}^n$.
El mnimo de $G$ existe por finitud y ser orden total. Es el mnimo de
$S$ porque cualquier otro $s \in S$ cumple $s = g + \gamma$ para $g \in G$, lo que lleva
por monotona y compatibilidad, a $s \geq g$.

***** Monoideales
Un subconjunto $E \subseteq \mathbb{N}^n$ es monoideal cuando $E = E + \mathbb{N}^n$.

***** Sistemas de generadores
Si $E$ es monoideal, existe $G \subset E$ finito con $E = G + \mathbb{N}^n$.
Llamamos a $G$ sistema de generadores de $E$.

****** Demostracin
Por Dickson tenemos $E \subset G + \mathbb{N}^n$, luego $E = E + \mathbb{N}^n = G + \mathbb{N}^n$. 

***** Sistema de generadores minimal
Un sistema de generadores es minimal si ningn subconjunto
suyo es sistema de generadores.

***** Unicidad del sistema de generadores minimal
El sistema de generadores minimal de un monoideal es nico.

****** Demostracin
Supongamos que hubiera dos $G,G'$, con $\beta \in G' \setminus G$. Entonces tendra una
representacin con $g \in G, g' \in G', \gamma \neq 0$ como:

\[
\beta = g + \gamma = g' + \delta + \gamma
\]

Con lo cual, $\beta \in G'\setminus \{\beta\} + \mathbb{N}^n$, contraviniendo minimalidad.

**** Divisin de polinomios
***** Diagrama de Newton
El conjunto de exponentes para un polinomio $p = \sum a_\alpha x^\alpha$:

\[N(p) = \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\}\]

***** Exponente
El exponente de un polinomio, fijado un orden monomial, es el mximo
exponente de su diagrama:

\[exp(p) = \max \{\alpha\in\mathbb{N}^n \mid a_\alpha \neq 0\} \]

***** Grado total
Definimos el grado total, fijado un orden monomial, como el mximo
grado de los exponentes:

\[Grtot(p) = \max \{gr(\alpha) \mid a_\alpha \neq 0\} \]

***** Trmino lder
Llamamos trmino lder al que aporta el exponente, $a_{Exp(p)}X^{Exp(p)}$.
Su coeficiente lder es $a_{Exp(p)}$ y su monomio lder, $X^{Exp(p)}$.

***** Propiedades del exponente
Dados $F,G \in K[X_1,\dots,X_n]$ no nulos: 

  1. $exp(FG) = exp(F) + exp(G)$.
  2. $exp(F+G) \leq \max\{exp(F),exp(G)\}$.
  3. Si $exp(F) < exp(G)$; entonces $exp(F+G) = exp(G)$.

****** Demostracin
En el fondo, parte slo de la observacin de que son K-espacios 
vectoriales y tienen de base a los distintos monomios.

******* Punto 1
Primero notamos que si estamos en un cuerpo, el producto de dos
polinomios tendr en su diagrama de Newton a la suma de cualesquiera
exponentes de ambos polinomios. Supongamos la suma mxima $\gamma + \delta$, y
la suma de los mximos $\alpha+\beta$. Usamos que son mximos y orden monomial
para tener:

\[\alpha + \beta \geq \gamma + \delta\]

******* Punto 2
Si un exponente no aparece en $F$ ni en $G$, tendr coeficiente nulo
tambin en $F+G$.

******* Punto 3
La suma tendr como mucho los exponentes de $F$ y de $G$. Pero adems,
conserva los exponentes que slo estuvieran en uno de los dos con los
coeficientes intactos.

***** Particin de generadores
Dada una lista de elementos $a_1,\dots,a_k$, tenemos una particin que
definimos inductivamente como:

  1. Los elementos que genera el primer generador: 

     \[\Delta^1 = a_1 + \mathbb{N}^n\]

  2. Los elementos nuevos que aporta cada nuevo generador:

     \[\Delta^i = (a_i + \mathbb{N}^n) \setminus \bigcup_{j < i} \Delta^j \]

  3. Todos los dems elementos:

     \[ \overline{\Delta} = \mathbb{N}^n \setminus \bigcup_{j \leq k} \Delta^j\]

***** Teorema de la divisin
Dado un orden monomial y una lista de polinomios $G_i$; consideramos la
particin $\Delta_1,\dots,\overline{\Delta}$ dada por los exponentes $exp(G_i)$. Tenemos que para
cada $F \in K[X_1,\dots,X_n]$, existen $Q_1,\dots,Q_t,R$ nicos tales:

  1. $F = Q_1G_1 + \dots + Q_tG_t + R$.
  2. $R = 0$  $N(R) \subseteq \overline\Delta$.
  3. $exp(G_i) + N(Q_i) \subseteq \Delta^i$.

****** Demostracin
******* Caso base
Aplicamos induccin a $exp(F)$ aprovechando el [[*Orden monomial es buen orden][buen orden]]. Sea 
$exp(F) = (0,\dots,0)$.

******** Aparece en algn elemento de la particin
Si $exp(F) \in \Delta^i$, entonces forzosamente $exp(G_i)=0$. Entonces tomamos
$Q_i = {F}/{G_i}$, y $Q_j=0$ para $j \neq i$.

******** Slo aparece en el resto de la particin
Simplemente tomamos $R = F$.

******* Caso inductivo
Sabiendo que se tiene el resultado para todo $G$ con $exp(G) < exp(F)$,
tenemos de nuevo dos casos.

******** Aparece en algn elemento de la particin
Si $exp(F) \in \Delta^i$, entonces $exp(F) = exp(G) + \gamma$. Tomando $H=X^\gamma G$,
aplicamos induccin sobre:

\[F - \frac{cl(F)}{cl(H)} H 
=
F'
= 
\sum Q'_iG_i + R'
\]

Pero si tomamos $Q_i = Q_i' + \frac{cl(F)}{cl(H)} X^\gamma$ y $Q_j = Q_j'$ para todos los dems:

\[F = \sum Q_i G_i + R\]

******** Slo aparece en el resto de la particin
Aplicamos hiptesis de induccin sobre:

\[F-tl(F) = F' = \sum Q_i'G_i + R'\]

Entonces tomamos $R = R' + tl(F)$ y se tiene:

\[F = \sum Q_i'G_i + R\]

***** Ejemplo de divisin
Dividimos $F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4$ entre los polinomios:

  - $G_1 = X^3Y-2X^2Z^2$
  - $G_2 = X^2Y^3+XZ^3$
  - $G_3 = XY^2Z - X^2YZ - 3XYZ^2$

Usando el orden lexicogrfico.

****** Exponentes
Con el orden dado, tenemos exponentes:

  - $exp(G_1) = (3,1,0)$
  - $exp(G_2) = (2,3,0)$
  - $exp(G_3) = (2,1,1)$

Con ellos creamos las particiones $\Delta_i$.

****** Desarrollo
A cada paso tomamos el exponente mayor, lo encuadramos en un subconjunto
de la particin y dividimos para el siguiente elemento.

\[F = X^4Y^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(4,2,0) \in \Delta_1$, as que restamos $XYG_1$:

\[F = 2X^3YZ^2+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(3,1,2) \in \Delta_1$, as que restamos $2Z^2G_1$:

\[F = 4X^2Z^4+X^2Y^3Z-2XY^2Z^3-3X^2YZ^4\]

Tenemos $(2,3,1) \in \Delta_2$, as que restamos $ZG_2$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - 3X^2YZ^4 - XZ^4\]

Tenemos $(2,1,4) \in \Delta_3$, as que restamos $3Z^3G_3$:

\[F = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Tenemos $(2,0,4) \in \overline\Delta$, as que tomamos lo dems como resto. Nos acabar
quedando que:

\[R = 4X^2Z^4 - 2XY^2Z^3 - XZ^4 - 3XY^2Z^4 + 9XYZ^5\]

Por lo tanto:

\[F = (XY+2Z^2)G_1 + ZG_2 + 3Z^3G_3 + R\]

****** Clculo en Sage
Calculamos el resto de la divisin en sage. Ntese cmo se ve afectado
por el orden de los polinomios que escojamos para la divisin.

#+BEGIN_SRC sage
  R.<x,y,z> = PolynomialRing(QQ, 3, 'xyz', order='lex')
  f = x^4*y^2 + x^2*y^3*z - 2*x*y^2*z^3 - 3*x^2*y*z^4
  g1 = x^3*y - 2*x^2*z^2
  g2 = x^2*y^3 + x*z^3
  g3 = x*y^2*z - x^2*y*z - 3*x*y*z^2
  f.reduce(Ideal([g1])).reduce(Ideal([g2])).reduce(Ideal([g3]))
  f.reduce(Ideal([g3])).reduce(Ideal([g2])).reduce(Ideal([g1]))
#+END_SRC

#+RESULTS:
: 4*x^2*z^4 - 3*x*y^2*z^4 - 2*x*y^2*z^3 + 9*x*y*z^5 - x*z^4
: x^2*y^3*z - 3*x^2*y*z^4 + 4*x^2*z^4 - 2*x*y^2*z^3

**** Ideales monomiales
***** Ideales monomiales
Un ideal es monomial si est generado por monomios. Es decir, si es de la 
forma:

\[ I = (X^\alpha \mid \alpha\in A)\]

Para algn $A \subset \mathbb{N}^n$.

***** Pertenencia a ideal monomial
Si $X^\beta \in (X^\alpha \mid \alpha\in A)$ es de la forma: $X^\beta = FX^\alpha$.

****** Demostracin
Los monomios forman una K-base del espacio. Como:

\[X^\beta = \sum F_iX^\alpha\]

Todo monomio de la expresin de la derecha es divisible por algn $X^\alpha$,
y en particular, $X^\beta$ debe serlo.

***** Monomios en ideal monomial
Sea $I = (X^\alpha \mid \alpha\in A)$ monomial, equivalen:

  1. $F \in I$.
  2. Todo monomio de $F$ est en $I$.
  3. $F$ es combinacin lineal de monomios de $I$.

Y adems, si para cualquier polinomio todos sus monomios estn en
el ideal, es monomial.

****** Demostracin
Los monomios forman una K-base del espacio. Como:

\[F = \sum F_iX^\alpha\]

Todo monomio de $F$ debe ser mltiplo de algn $X^\alpha$.

El resto de implicaciones son triviales. Ntese que podemos escribir
el ideal como $(X^\alpha \mid \alpha \in Exp(I))$.

***** Exponente de un ideal
Dado un ideal $I$ no nulo, definimos su exponente como el subconjunto:

\[Exp(I) = \{Exp(F) \mid 0\neq F \in I\} \subseteq \mathbb{N}^n\]

***** El exponente es monoideal
$Exp(I)$ es un monoideal de $\mathbb{N}^n$.

****** Demostracin
Sea $F \in I$, tenemos $X^\alpha F \in I$ para cualquier $\alpha$ y:

\[exp(X^\alpha F) = \alpha + exp(F)\]

Gracias a que los rdenes son compatibles.

***** Lema de Dickson para ideales monomiales
Todo ideal monomial tiene un sistema de generadores finito y formado
por monomios.

****** Demostracin
Como $Exp(I)$ es [[*Monoideales][monoideal]], tiene [[*Sistemas de generadores][sistema de generadores]] $Exp(I) = G + \mathbb{N}^n$.
Dado un exponente $\alpha \in Exp(I)$, [[*Monomios en ideal monomial][tenemos]] $X^\alpha \in I$, luego tomamos como sistema
de generadores:

\[ (X^\alpha \mid \alpha \in G) \]

Dado cualquier $F \in I$, sus monomios estarn en $I$ y sern mltiplo
de ellos.

***** Corolario de generacin de ideales
Sean $I,J \subseteq K[X_1,\dots,X_n]$ ideales monomiales:

\[I=J \iff Exp(I)=Exp(J)\]

****** Demostracin
Si tienen el mismo exponente, tienen el mismo generador.

***** Unicidad del sistema de generadores minimal
Sea $I$ monomial no nulo. Existe un nico sistema de generadores minimal
formado por monomios, es decir, ningn subconjunto suyo es generador.

****** Demostracin
Dado $G$ el [[*Unicidad del sistema de generadores minimal][nico]] sistema generador minimal de $Exp(I)$. Entonces, sus
monomios generan al ideal y si:

\[H \subseteq (X^\alpha\mid \alpha \in G)\]

genera al ideal, en particular se tendra $Exp(I) = H + \mathbb{N}^n$, contraviniendo
minimalidad.

***** Otros sistemas de generadores
Sea $G = \{\alpha_1,\dots,\alpha_n\}$ sistema de generadores de $Exp(I)$. Si $exp(F_i)=\alpha_i$,
entonces $\{F_1,\dots,F_n\}$ es sistema de generadores de $I$.

****** Demostracin
Para $F\in I$, por [[*Teorema de la divisin][divisin]] tenemos:

\[F = \sum Q_iF_i + R\]

Como $R\in I$, $exp(R) \in Exp(I)$ y debe tenerse $R = 0$.

**** Bases de Grbner
***** Bases de Grbner
Sea $I \subseteq K[X_1,\dots,X_n]$ un ideal no nulo. Una base de Grbner es un conjunto
$\mathbb{G} = \{G_1,\dots,G_n\} \subseteq I$ cumpliendo $Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n$.

***** Propiedades de bases de Grbner
Las bases de Grbner en $K[X_1,\dots,X_n]$ cumplen:

  1. Todo ideal no nulo tiene una base de Grbner.
  2. Toda base de Grbner de un ideal es base de generadores del ideal.
  3. *Teorema de la base de Hilbert*: todo ideal es finitamente generado.

****** Demostracin 
******* Punto 1
Sabemos que $Exp(I)$ es [[*El exponente es monoideal][monoideal]] y por tanto tiene un sistema de
[[*Sistemas de generadores][generadores]]. Existen entonces polinomios cumpliendo:

\[Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n\]

Que forman una base de Grbner

******* Punto 2
Por el algoritmo de la [[*Teorema de la divisin][divisin]], tenemos que todo polinomio del ideal
se divide entre ellos dando un resto tal que $exp(R) \in \overline{\Delta} \cap Exp(I) = \varnothing$.
Por tanto, $R=0$.

******* Punto 3
Todo ideal est generado por su base de Grbner, que es finita.

***** Resto en bases de Grbner
Sea $I$ ideal con bases de Grbner $\mathbb{G},\mathbb{G}'$. Para $F \in K[X_1,\dots,X_n]$:

\[R(F;\mathbb{G}) = R(F;\mathbb{G}')\]

****** Demostracin
Tenemos que, al coincidir los exponentes:

\[Exp(I) = \bigcup_{i=1}^t \Delta^i\]

Por lo tanto, $\overline{\Delta} = \overline{\Delta}'$, y tenemos ${\cal N}(R-R') \subseteq {\cal N}(R) \cup {\cal N}(R') \subseteq \overline{\Delta}$.
Pero como $R-R' \in I$, y tenemos $exp(R-R') \in Exp(I)$, debe ser nulo.

***** Caracterizacin de bases de Grbner
Sea $I$ ideal no nulo, equivalen:

  1. $\mathbb{G}$ es base de Grbner de $I$.
  2. $R(F,\mathbb{G}) = 0$, para todo $F \in I$.

****** Demostracin
******* Primer punto al segundo
Tenemos $exp(R) \in Exp(I) \cap \overline{\Delta}$, luego debe ser $exp(R) = 0$.

******* Segundo punto al primero
Por la divisin, cualquier $F \in I$ es de la forma:

\[ F = \sum_{i=0}^n Q_iG_i\]

Donde $exp(Q_iG_i) \in \Delta^i$, y como forman una particin disjunta, se tiene 
que el $exp(F) = max\{exp(Q_iG_i)\} \notin \overline{\Delta}$. Por tanto $Exp(I) \cap \overline{\Delta} = \varnothing$.

***** Semizigia
Sean $F,G \in K[X_1,\dots,X_n]$ no nulos. Definimos el S-polinomial o *semizigia*
como el siguiente polinomio:

\[{\cal S}(F,G) 
= \frac{1}{cl(F)}X^{\gamma-\alpha}F - \frac{1}{cl(G)}X^{\gamma-\beta}G\]

donde $\alpha = exp(F)$, $\beta = exp(G)$, y $\gamma_i = \max\{\alpha_i,\beta_i\}$, para $\gamma = (\gamma_1,\dots,\gamma_n)$.

***** Teorema de Buchberger
Sea $I$ ideal no nulo de $K[X_1,\dots,X_n]$ y $\mathbb{G} = \{G_1,\dots,G_n\}$ un sistema de
generadores. Equivalen:

  1. $\mathbb{G}$ es base de Grbner.
  2. Para cualquier ordenacin de $\mathbb{G}$, se tiene $R({\cal S}(G_i,G_j); \mathbb{G}) = 0$
     para cualesquiera $i \neq j$.
  3. Para alguna ordenacin de $\mathbb{G}$, se tiene $R(S(G_i,G_j); \mathbb{G}) = 0$.

****** Demostracin
******* Primera implicacin
Trivialmente por la [[*Caracterizacin de bases de Grbner][caracterizacin]] una vez que vemos que las 
semizigias son combinaciones lineales.

******* Tercera implicacin
No es trivial. Puede consultarse [[http://people.math.aau.dk/~diego/Libro.pdf][aqu]].

***** Algoritmo de Buchberger
Sea $I$ ideal no nulo y $\mathbb{G} = (G_1,\dots,G_n)$ sistema de generadores. Es posible 
construir una base de Grbner con los siguientes pasos:

  1. $\mathbb{G}_0 = \{G_1,\dots,G_n\}$
  2. $\mathbb{G}_{n+1} = \mathbb{G}_n \cup \{R(S(F,G);\mathbb{G}_n) \neq 0 \mid F,G \in \mathbb{G}_n, F \neq G\}$

Entonces cuando $\mathbb{G}_i = \mathbb{G}_{i+1}$, podemos asegurar que $\mathbb{G}_i$ es base de Grbner del
ideal $I$.

****** Demostracin
Cuando el algoritmo termina, la base que tenemos es claramente de 
Grbner debido a la caracterizacin que nos da [[*Teorema de Buchberger][Buchberger]].

Hay que demostrar que el algoritmo termina en algn punto. Esto se
deduce de el hecho de que, dado un monoideal, el conjunto de monoideales
que lo contienen es finito. Pero si un elemento es resto de una divisin
por $\mathbb{G}$ no nulo, no puede estar en el monoideal generado por los exponentes.
As, al aadirlo tendremos un monoideal generado mayor, y esto slo puede
hacerse un nmero finito de pasos.

***** Retirando un polinomio de una base de Grbner
Sea $\mathbb{G}$ una base de Grbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ y sea
$F \in \mathbb{G}$ tal que $exp(F) \in \{exp(G) \mid G \in \mathbb{G}, F \neq G \}+\mathbb{N}^n$. Entonces, $\mathbb{G}\setminus\{F\}$
es tambin una base de Grbner de $I$.

****** Demostracin
# Esto no parece necesario. Es trivial desde la definicin.
Si $R(F;\mathbb{G}\setminus \{F\})$ est en $\overline\Delta$, que es el mismo que generaran
con $F$. Pero como est en el ideal, debera ser $0$.

Por lo tanto $F$ est generado por $\mathbb{G}$, que es generadora y por tanto,
base de Grbner.

***** Base de Grbner minimal
Una base de Grbner de un ideal no nulo $I \subseteq K[X_1,\dots,X_n]$ se dice minimal
si:

  1. $cl(F) = 1,\quad\forall F\in\mathbb{G}$.
  2. $exp(F) \notin \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n$.

Es claro que todo ideal tiene una base de Grbner minimal, simplemente
[[*Retirando un polinomio de una base de Grbner][retirando]] polinomios.

***** Caracterizacin de bases minimales
Sea $\mathbb{G}$ un sistema de generadores de $I$. Equivalen:

  1. $\mathbb{G}$ es una base de Grbner minimal de $I$.
  2. $\{exp(G_1),\dots,exp(G_t)\}$ es sistema minimal de generadores de $Exp(I)$
     y se tiene $cl(G_i) = 1$.

Los trminos lderes de los polinomios de una base de
Grbner minimal estn determinados de forma nica y, adems, dos bases
de Grbner minimales tienen el mismo nmero de elementos.

****** Demostracin
******* Primera implicacin
Si no fuera sistema minimal, un subconjunto suyo lo sera y generara
tambin $Exp(I)$. Pero entonces, podemos quitar elementos de la base
de Grbner y seguiran generando lo mismo; contraviniendo minimalidad.

******* Segunda implicacin
Si no fuera minimal, algn $exp(F)$ sera generado por los dems,
y por tanto los exponentes no formaran un sistema mnimal.

Ntese que hay que considerar los coeficientes lderes para que sean
$1$.

******* Unicidad
Como el sistema minimal de generadores de $Exp(I)$ es nico, los
trminos lderes de los polinomios de una base de Grbner minimal
deben ser nicos.

******* Cardinalidad invariante
Dos bases minimales daran lugar a dos sistemas minimales de 
generadores, que deben ser iguales y tener la misma cardinalidad.

***** Base de Grbner reducida
Una base de Grbner $\mathbb{G}$ de $I$ es reducida si para cualquier $\forall F \in \mathbb{G}$:

  1. $cl(F) = 1$.
  2. ${\cal N}(F) \cap \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n = \varnothing$.

***** Una base de Grbner reducida es minimal
Toda base de Grbner reducida es minimal.

****** Demostracin
Trivialmente, si todo el diagrama de Newton est fuera de lo que
generan los dems; el exponente est fuera de lo que generan los dems.

***** Existencia y unicidad de la base reducida
Todo ideal no nulo $I$ tiene una nica base de Grbner reducida.

****** Demostracin
******* Existencia
Dada una base de Grbner minimal, $F \in \mathbb{G}$, veremos que podemos tomar
otra base minimal en la que ${\cal N}(F)$ no est en los exponentes que 
generan los dems. Si dividimos $F$ entre los dems polinomios
de la base de Grbner:

\[
F = \sum Q_iG_i + F'
\]

Como $exp(F) = \max(\max\{Q_iG_i\},exp(F'))$ y sabemos que por ser minimal
tiene que ser distinto del exponente de los $Q_iG_i$; luego
$exp(F) = exp(F')$.

Entonces sustituyendo $F$ por $F'$ tenemos otra base de Grbner minimal
en la que $F$ est reducido. Podemos repetir esto para todos los 
elementos obteniendo una base reducida.

******* Unicidad
Sean bases de Grbner reducidas $\mathbb{G}$ y $\mathbb{G}'$. Sea $F \in \mathbb{G}$ y sea $F' \in \mathbb{G}'$ el
que tiene el mismo exponente. Tenemos que si intentamos dividir
por $\mathbb{G}$, por ser ambas reducidas:

\[{\cal N}(F-F') \subseteq \overline{\Delta}\]

Entonces $R(F-F';\mathbb{G}) = F-F'$, pero como $F - F' \in I$, debe 
ser $F - F' = 0$.

**** Teora de eliminacin
***** Ideal de eliminacin
Sea $I$ ideal no nulo. Definimos el j-simo ideal de eliminacin como:

\[ I_j = I \cap K[X_{j+1},\dots,X_n]\]

***** Base del ideal de eliminacin
Sea $I$ ideal no nulo y $\mathbb{G}$ base de Grbner del orden lexicogrfico
dado por $X_1 > X_2 > \dots > X_n$. Entonces:

\[\mathbb{G}_j = \mathbb{G} \cap I_j\]

es base de Grbner de $I_j$.

****** Demostracin
Sea $F \in I_j$, veremos que $exp(F) = exp(G) + \gamma$ para algn $G \in \mathbb{G}_j$.
Tenemos ya $exp(F) = exp(G) + \gamma$ para $G \in \mathbb{G}$. Como el exponente de $F$ es
nulo en las $j$ primeras variables, entonces $exp(G)$ tambin lo hace.
Como estamos usando orden lexicogrfico ${\cal N}(G)$ entero se anula en las
$j$ primeras variables. Luego $G \in \mathbb{G}$.

***** Extensin de un ideal
Sea $I$ ideal de $K[X_1,\dots,X_n]$. Un sistema de generadores suyo es
tambin sistema de generadores de:

\[
I^e = \left\{
\sum_{i=1}^k Q_iF_i \;\middle|\; Q_i \in K[T,X_1,\dots,X_n], F_i \in I
\right\}
\]

en el espacio $K[T,X_1,\dots,X_n]$.

****** Demostracin
Trivialmente por ser generador de $I$.

***** Clculo de la interseccin
Sean $I,J$ dos ideales no nulos de $K[X_1,\dots,X_n]$. Sea:

\[ H = TI^e + (1-T)J^e \subseteq K[T,X_1,\dots,X_n]\]

Entonces $I\cap J = H \cap K[X_1,\dots,X_n]$, primer ideal de eliminacin de $H$.
Esto nos permite calcular la interseccin usando bases de Grbner.

****** TODO Demostracin
Si est en $I\cap J$ tenemos $TF + (1-T)F = F \in H$. Si est en 
$H \cap K[X_1,\dots,X_n]$, entonces es de la forma:

\[TF+(1-T)G = G + (F-G)T\]

Y por tanto debe tenerse $F = G \in I \cap J$.

***** Cociente de ideales
Dados $I,J$ ideales no nulos, definimos el ideal cociente como:

\[(I : J) 
= 
\{F \in K[X_1,\dots,X_n] \mid FJ \subset I\}
=
\bigcap_{i=1}^n (I : G_i)\]

Siendo $J = (G_1,\dots,G_n)$.

****** Demostracin
Trivialmente, si incluye al ideal $J$ incluye a todos sus generadores.
Si est en la interseccin incluye a todos los generadores por tanto
a todo el ideal.

***** Caracterizacin del cociente
Para $G \in K[X_1,\dots,X_n]$ se verifica que $G(I:G) = I \cap (G)$. Luego:

\[(I:G) = \frac{1}{G}(I \cap (G))\]

***** Mximo comn divisor y mnimo comn mltiplo
Sean $F,G \in K[X_1,\dots,X_n]$ con $D = \operatorname{mcd}(F,G)$ y $M = \text{mcm}(F,G)$. Entonces:

  1. $(F) \cap (G) = (M)$
  2. $D = \frac{FG}{M}$

Ntese que la interseccin puede calcularse como el primer ideal de
eliminacin de:

\[
H = T(F)^e + (1-T)(G)^e = (TF,(1-T)G)
\]

*** 3. Variedades afines
**** Funciones polinmicas
***** Espacio afn de un lgebra
Llamamos $\mathbb{A}^n(K)$ al espacio afn sobre $K^n$ con la funcin afn
$\varphi : K^n \times K^n \longrightarrow K^n$ dada por $\varphi(u,v) = v-u$.

***** Funciones polinmicas
A partir de cada polinomio $F \in K[X_1,\dots,X_n]$, tenemos definida una funcin
polinmica $F^\ast : \mathbb{A}^n(K) \longrightarrow K$.

****** lgebra de funciones polinmicas
Al conjunto de funciones polinmicas lo denotamos por $P(\mathbb{A}^n(K))$.
Forma una K-lgebra con las operaciones usuales:

\[\begin{aligned}
(F^\ast+G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)+G^\ast(a_1,\dots,a_n)
\\
(F^\ast G^\ast)(a_1,\dots,a_n) 
&= 
F^\ast(a_1,\dots,a_n)G^\ast(a_1,\dots,a_n)
\\
(\alpha F^\ast)(a_1,\dots,a_n) 
&= 
\alpha F^\ast(a_1,\dots,a_n)
\end{aligned}\]

***** Epimorfismo de los polinomios a las funciones polinmicas
Por definicin se tiene un epimorfismo $\Delta : K[X_1,\dots,X_n] \longrightarrow P(\mathbb{A}^n(K))$ 
dado por:

\[\Delta(F) = F^\ast\]

****** No es inyectivo en general
La funcin dada por un polinomio no nulo puede ser nula. Por ejemplo:

\[F = X(X+1)\]
\[G = 0\]

Dan lugar a la misma funcin en $\mathbb{F}_2$, pero son polinomios distintos.

***** Isomorfismo de los polinomios en cuerpos infinitos
Sea $K$ cuerpo infinito. Sus polinomios verifican:

  1. $F^\ast = 0 \iff F = 0$.
  2. $F^\ast=G^\ast \iff F = G$.

****** Demostracin
Un polinomio que de la funcin constante $0$ en un cuerpo infinito 
debera tener infinitas races. Eso slo puede darlo el polinomio
constantemente $0$.

**** Variedades afines
***** Variedad de un polinomio
Dado $F \in K[X_1,\dots,X_n]$, denotamos por $\mathbb{V}(F)$ al conjunto de sus ceros:

\[\mathbb{V}(F) = \Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0 \Big\}\]

Dado un ideal ${\cal F}$, denotamos por $\mathbb{V}({\cal F})$ al conjunto de sus ceros:

\[\mathbb{V}({\cal F})
=
\Big\{(a_1,\dots,a_n) \in \mathbb{A}^n(K) \;\Big|\; F(a)=0\; \forall F \in {\cal F} \Big\}\]

***** Variedad algebraica afn
Un conjunto es una *variedad algebraica afn* cuando existe
${\cal F} \subseteq K[X_1,\dots,X_n]$ tal que es de la forma $\mathbb{V}({\cal F})$.

***** Variedad de un ideal
Sea ${\cal F} \subseteq K[X_1,\dots,X_n]$ y sea ${\cal I} = ({\cal F})$ el ideal generado. Se tiene:

  1. $\mathbb{V}({\cal F}) = \mathbb{V}({\cal I})$
  2. $\exists F_1,\dots,F_t : \mathbb{V}({\cal F}) = \mathbb{V}(F_1,\dots,F_t)$

****** Demostracin
******* Punto 1
Si los generadores se anulan en un punto, sus combinaciones lineales
tambin.

******* Punto 2
Todo ideal en el anillo de polinomios es finitamente [[*Propiedades de bases de Grbner][generado]]
gracias a las bases de Grbner.

***** Propiedades de las variedades
Las variedades dadas por ideales cumplen:

  1. \[\bigcap_{\lambda \in \Lambda} \mathbb{V}(J_\lambda)
     = \mathbb{V}\left(
     \sum_{\lambda \in \Lambda} J_\lambda
     \right)\]

  2. $\mathbb{V}(J_1) \cup \mathbb{V}(J_2) = \mathbb{V}(J_1J_2) = \mathbb{V}(J_1 \cap J_2)$

  3. $\mathbb{V}(0) = \mathbb{A}^n(K)$

  4. $\mathbb{V}(K[X_1,\dots,X_n]) = \varnothing$

****** Demostracin
******* Punto 1
Si un punto se anula para todos los polinomios de cada $J_\lambda$, en
particular est en cada $\mathbb{V}(J_\lambda)$. Si est en cada $\mathbb{V}(J_\lambda)$, se anula
para todos sus polinomios y por tanto para sus combinaciones
lineales.

******* Punto 2
Si $x \notin \mathbb{V}(J_1) \cup \mathbb{V}(J_2)$, entonces existiran polinomios en cada ideal
para los que no sera cero, y no sera cero de su producto, luego
$x \notin \mathbb{V}(J_1J_2)$.

El resto de los contenidos son triviales, viendo:

\[\mathbb{V}(J_1) \cup \mathbb{V}(J_2) \subseteq
\mathbb{V}(J_1\cap J_2) \subseteq
\mathbb{V}(J_1J_2)\]

******* Punto 3
Todos los puntos son races del constante $0$.

******* Punto 4
Ningn punto es raz de todos los polinomios, porque existen los
polinomios constantes no nulos en cualquier cuerpo.

***** Topologa de Zariski
Las variedades son los cerrados de una topologa sobre $\mathbb{A}^n(K)$.

\[\{
V \subseteq \mathbb{A}^n(K) 
\mid
V \text{ es variedad algebraica afn}
\}\]

****** Demostracin
Desde las propiedades de una [[*Variedad de un ideal][variedad]] tenemos que la 
interseccin arbitraria y la unin finita de variedades son variedad.
Adems, lo son el vaco y el total.

***** Ejemplos
****** Puntos discretos
Dado un conjunto discreto de puntos:

\[\{(a_1,\dots,a_n)\} = \mathbb{V}(X_1-a_1,\dots,X_n-a_n)\]

****** Hipersuperficies
Toda variedad generada por un polinomio no constante:

\[
\mathbb{V}(F) = \Big\{ 
\alpha \in \mathbb{A}^n(K) \mid F(\alpha) = 0
\Big\}
\]

Toda variedad afn es una interseccin finita de hipersuperficies.

****** Hiperplano
La variedad de un polinomio de grado total 1 es un hiperplano.
Para $F = a_0 + a_1X_1 +a_2X_2 + \dots + a_nX_n$, tenemos:

\[
\mathbb{V}(F) = \Big\{
\alpha \in \mathbb{A}^n(K) 
\mid 
a_0 + a_1\alpha_1 + a_2\alpha_2 + \dots + a_n\alpha_n = 0
\Big\}
\]

La interseccin finita de hiperplanos es una variedad afn lineal.

**** Teorema de los ceros de Hilbert
***** Representaciones paramtricas
Una *representacin paramtrica racional* de $\mathbb{V}(F_1,\dots,F_t)$ es un conjunto
de funciones $G_i,H_i \in K[X_1,\dots,X_n]$ cumpliendo:

\[\left\{ 
\frac{G_1}{H_1}(t_1,\dots,t_n),
\frac{G_2}{H_2}(t_1,\dots,t_n),
\dots,
\frac{G_n}{H_n}(t_1,\dots,t_n)
\;\middle|\;
t_1,\dots,t_n \in \mathbb{K}
\right\}
\subseteq
V\]

Cuando $H_i = 1$, la llamamos *representacin polinomial*.

****** Ejemplos
******* Representacin no racional del crculo
El crculo es una variedad de la que puede darse una representacin
no paramtrica.

\[V = \{(sen(t), cos(t)) \midt \in \mathbb{R}\}\]

Sabemos que es variedad porque puede expresarse como:

\[ V = \mathbb{V}(X^2+Y^2-1) \]

Y podemos darle adems una representacin paramtrica racional
no trivial:

***** Ideal de un conjunto
Sea $S \subseteq \mathbb{A}^n(K)$. Definimos el ideal asociado a $S$ como:

\[
\mathbb{I}(S)
=
\Big\{F \in K[X_1,\dots,X_n] \mid \forall a \in S: F(a) = 0\Big\}
\]

****** Es ideal
Trivialmente sabiendo que se conservan los ceros por suma y producto
externo.

***** Propiedades de variedades e ideales
Los ideales y sus variedades cumplen:

  1. $S_1 \subseteq S_2 \implies \mathbb{I}(S_1) \supseteq \mathbb{I}(S_2)$.
  2. $\mathbb{I}(\varnothing) = K[X_1,\dots,X_n]$.
  3. $S \subseteq \mathbb{V}\mathbb{I}(S)$ y $J \subseteq \mathbb{I}\mathbb{V}(J)$.
  4. $\mathbb{I}(S) = \mathbb{I}\mathbb{V}\mathbb{I}(S)$ y $\mathbb{V}(J) = \mathbb{V}\mathbb{I}\mathbb{V}(J)$.
  5. $\mathbb{I}(S)$ es ideal radical.
  6. Cuando $V \subseteq \mathbb{A}^n(K)$ es variedad afn, $V = \mathbb{V}\mathbb{I}(V)$.
  7. $V_1 \subseteq V_2 \iff \mathbb{I}(V_1) \supseteq \mathbb{I}(V_2)$.
  8. $\mathbb{I}(S_1 \cup S_2) = \mathbb{I}(S_1) \cap \mathbb{I}(S_2)$.
  9. $V_1 \cup V_2 = \mathbb{V}(\mathbb{I}(V_1)\mathbb{I}(V_2)) = \mathbb{V}(\mathbb{I}(V_1) \cap \mathbb{I}(V_2))$.
  10. \[\bigcap_{\lambda \in \Lambda} V_\lambda = \mathbb{V}\left(\sum_{\lambda\in\Lambda} \mathbb{I}(V_\lambda)\right)\].

****** Demostracin
******* Punto 1, 2 y 3
Triviales desde la definicin. Ntese que las inclusiones vienen
dadas directamente.

******* Punto 4
Uniendo las dos inclusiones anteriores.

******* Punto 5
Si $f^n \in \mathbb{I}(S)$ entonces para cualquier punto en $S$ se cumple $f^n(s) = 0$, 
lo que lleva a $f(s) = 0$.

******* Punto 6
Al igual que el punto 4 uniendo las dos inclusiones anteriores.

******* Punto 7
Usando la igualdad y por definicin se tiene.

******* Punto 8
Trivial por definicin.

******* Punto 9
La unin de variedades es variedad y se tiene por la igualdad y por 
el punto anterior.

******* Punto 10
Por propiedades de las variedades y la igualdad.

***** No todo ideal radical es de esa forma
La funcin $\mathbb{{I}}$ considerada como:

\[ \mathbb{I} : \left\{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\right\}
\longrightarrow
\left\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\right\}\]

Es inyectiva, se tiene $\mathbb{V}\mathbb{I} = 1$ y en general no se tiene $\mathbb{I}\mathbb{V} = 1$.

***** Teorema de los ceros de Hilbert
Cuando $K$ es algebraicamente cerrado, para cualquier ideal
$J \subseteq K[X_1,\dots,X_n]$, se verifica que:

\[\mathbb{I}\mathbb{V}(J) = \sqrt{J}\]

Y por tanto hay una biyeccin entre ideales radicales y variedades.

\[ \{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\}
\cong
\{ J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}\}\]

****** TODO Demostracin                                         :extra:
**** Anillos de coordenadas
***** Aplicaciones polinmicas
Un *morfismo entre variedades* de $\mathbb{A}^n$ y $\mathbb{A}^m$ es una aplicacin $f : V \longrightarrow W$
tal que existen polinomios $F_1,\dots,F_n$ tales que:

\[f(a) = (F_1(a),F_2(a),\dots,F_n(a)) \quad \forall a \in V\]

Los llamamos tambin *aplicaciones polinmicas*.

****** Isomorfismos de variedades afines
Un isomorfismo entre variedades afines es un morfismo entre variedades
cuya inversa es un morfismo entre variedades.

***** Anillo de coordenadas
Sea $V \subset \mathbb{A}^n(K)$ una variedad algebraica afn. Definimos el anillo de 
coordenadas de $V$ como:

\[
K[V] = \frac{K[X_1,\dots,X_n]}{\mathbb{I}(V)}
\]

Estos anillos son K-lgebras.

****** Ejemplos de anillo de coordenadas
Sea $V = \mathbb{V}(X^3-Y^2) \subseteq \mathbb{A}^2(K)$. 

******* En caracterstica 0
Si $car(K)=0$, entonces $\mathbb{I}(V) = (X^3-Y^2)$. Entonces:

\[K[V] = \frac{K[X_1,\dots,X_n]}{(X^3-Y^2)\]

******* En caracterstica 2
En caracterstica 2 tenemos $V = \{(0,0),(1,1)\}$, luego
$\mathbb{I}(V) = \mathbb{I}(\{(0,0\} \cup \{(1,1)\}) = (X,Y) \cap (X-1,Y-1)$, y en este caso:

\[\mathbb{F}_2[V]
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y) \cap (X-1,Y-1)}
= 
\frac{\mathbb{F}_2[X,Y]}{(X,Y)} +
\frac{\mathbb{F}_2[X,Y]}{(X-1,Y-1)}
=
\mathbb{F}_2 \times \mathbb{F}_2
\]

***** Funtor entre anillos de coordenadas y aplicaciones polinmicas
Sea $V \subseteq \mathbb{A}^n(K)$ y $W \subseteq \mathbb{A}^m(K)$ variedades algebraicas afines.

  1. Toda aplicacin polinmica $f : V \longrightarrow W$ define un homomorfismo de
     K-lgebras $\tilde{f} : K[W] \longrightarrow K[V]$.
  2. Para cada homomorfismo de K-lgebras $h : K[W] \longrightarrow K[V]$ existe una
     nica aplicacin polinmica $f : V \longrightarrow W$ nica tal que $\tilde{f} = h$.
  3. Si $V_1 \overset{f}\longrightarrow V_2 \overset{g}\longrightarrow V_3$ son aplicaciones polinmicas, $\widetilde{f} \circ \widetilde{g} = \widetilde{g \circ f}$.
  4. $f$ es isomorfismo ssi $\widetilde{f}$ es isomorfismo.

Es decir, hay un funtor contravariante entre ambas categoras.

****** Demostracin
******* Punto 1
Sea $f(a) = (F_1(a),\dots,F_m(a))$. Por propiedad universal del anillo de
polinomios tenemos un $f'$ cumpliendo $f'(Y_j) = F_j$:

\[\begin{tikzcd}
K \rar[hook]\drar[hook]& K[Y_1,\dots,Y_n] \dar{\exists! f'} \\
& K[X_1,\dots,X_n]
\end{tikzcd}\]

Comprobamos que baja al cociente. Para $G \in \mathbb{I}(W)$, veamos que $f'(G) \in \mathbb{I}(V)$.
Sea $a \in V$, entonces $f(a) \in W$ y por tanto:

\[ f'(G)(a) = G(F_1(a),\dots,F_n(a)) = G(f(a)) = 0\]

Acabamos de ver que est bien definida una funcin:

\[\widetilde{f}(G + \mathbb{I}(W)) = G(F_1,\dots,F_n)+\mathbb{I}(V)\]

******* Punto 2
******** Existencia
Dada $h$, calculamos:

\[h(Y_i + \mathbb{I}(W)) = F_i + \mathbb{I}(V)\]

Y definimos $f : V \longrightarrow \mathbb{A}^m(K)$ como:

\[f(a) = (F_1(a),\dots,F_m(a))\]

********* Bien definida
Si $a \in V$, veremos que $f(a) \in W = \mathbb{VI}(W)$. Para $G \in \mathbb{I}(W)$:

\[h(0) = h(G+\mathbb{I}(W)) = G(F_1,\dots,F_n) + \mathbb{I}(V)\]

Luego $G(f(a)) = G(F_1,\dots,F_n)(a) + 0 = 0$, tenemos una funcin
polinmica $f : V \longrightarrow W$.

********* Cumple el requisito
Si $h(Y_j + \mathbb{I}(W) = F_j'+\mathbb{I}(V)$, entonces $F_j + \mathbb{I}(V) = F_j' + \mathbb{I}(V)$.
Y $F_j(a) = F_j'(a)$ para cualquier $a$. Es claro por tanto que $\widetilde{f} = h$.

******** Unicidad
Supongamos una $g : V \longrightarrow W$ tal que $\widetilde{g} = h$ con $g(a) = (G_1(a),\dots,G_m(a))$.
Entonces $\widetilde{g} : K[W] \longrightarrow K[V]$:

\[\tilde{g}(Y_j + \mathbb{I}(W)) = G_j + \mathbb{I}(V)\]
\[h(Y_j + \mathbb{I}(W)) = F_j + \mathbb{I}(V)\]

Por lo tanto $G_j - F_j \in \mathbb{I}(V)$ para cualquier $j$.

******* Punto 3
Por construccin.

******* Punto 4
Por el punto anterior, comprobando que el funtor respeta la identidad.

****** Ejemplo de polinmica biyectiva no isomorfismo
Sea $V = \mathbb{A}^1(\mathbb{R})$ y $W = \mathbb{V}(X^3-Y^2) \subseteq \mathbb{A}^2(\mathbb{R})$. Tenemos una aplicacin
del tipo $f : \mathbb{A}^1(\mathbb{R}) \longrightarrow W$:

\[ f(a) = (a^2,a^3)
\]

Que es claro que es polinmica. Tenemos $f$ biyectiva. Pero vemos que no
es isomorfismo de variedades con $\widetilde f(X) = T^2$, $\widetilde f(X) = T^3$:

\[\widetilde{f} : \frac{K[X,Y]}{(X^3-Y^2)} \longrightarrow K[T]\]

Ya que $\tilde{f}$ no es sobreyectiva porque $T \notin \mathrm{img}(\tilde{f})$.

***** Ncleos e imgenes de morfismos de anillos de coordenadas
Sea $h : K[W] \longrightarrow K[V]$ un morfismo de K-lgebras dado por
$h(Y_j + \mathbb{I}(W)) = F_j+\mathbb{I}(V)$.

  1. Sea el ideal de $K[X_1,\dots,X_n,Y_1,\dots,Y_n]$ dado por
     $C = (Y_1-F_1,\dots,Y_m-F_m) + \mathbb{I}(V)$, entonces:

     \[\ker(h) = 
     ((C \cap K[Y_1,\dots,Y_m]) + \mathbb{I}(W)) / \mathbb{I}(W)\]

  2. Sea $\mathbb{G}$ una base de Grbner reducida de $C$ con orden lexicogrfico:

     \[F + \mathbb{I}(V) \in \mathrm{img}(h) 
   \iff
   R(F;\mathbb{G}) \in K[Y_1,\dots,Y_n]
   \]

     Adems, en tal caso, $F+\mathbb{I}(V) = h(R(F;G) + \mathbb{I}(W))$.

***** Corolario: caracterizacin de inyectividad y sobreyectividad
Se cumple:

  1. $h$ inyectiva $\iff$ $C \cap K[Y_1,\dots,Y_m] \subseteq \mathbb{I}(W)$.
  2. $h$ sobreyectiva $\iff$ existen $M_i \in K[Y_1,\dots,Y_m]$ tal que $X_i-M_i \in \mathbb{G}$.

****** TODO Demostracin
***** Clausura de Zariski
Dada una variedad $V$ y una representacin paramtrica polinomial suya:

\[
U = \left\{
(F_1(t_1,\dots,t_k),F_2(t_1,\dots,t_k), \dots, F_n(t_1,\dots,t_k))
\mid
t_1,t_2,\dots,t_k \in K
\right\}
\subseteq V
\]

su clausura en la topologa de Zariski es:

\[
\overline{U} =
\mathbb{V}(J \cap K[X_1,\dots,X_n])
\]

donde $J = (X_1-F_1,\dots,X_m-F_m) \subseteq K[X_1,\dots,X_n,T_1,\dots,T_n]$.

*** Temas de teora
**** 1. Ideales maximales y primos. Teorema de Krull.
***** Ideales                                                     :extra:
Un ideal de $R$ es un subconjunto cerrado para la suma y
el producto por elementos $R$.

****** Anillo cociente
Para un $R$ anillo con $\alpha$ ideal, se define el *anillo cociente*:

\[
R/\alpha = \{x+\alpha\mid x \in R\}
\]

Obtenido por la relacin $x \sim y \iff x-y\in\alpha$, con la suma y el
producto proyectados.
***** Retculo de ideales                                         :extra:
Los ideales forman un retculo con la suma y la interseccin.
Se tiene:

  - $I,J \subseteq I + J$
  - $I \cap J \subseteq I,J$

****** Son ideales
Claramente son cerrados para la suma y el producto externo por serlo
ambos.

***** Anillo cociente                                             :extra:
Dado $R$ anillo con $\alpha$ ideal, tomamos la relacin de equivalencia 
$x \sim y \iff x-y\in\alpha$, para obtener el ideal:

\[
R/\alpha = \{x+\alpha \mid x \in R\}
\]

***** Ideales primos y maximales
Un ideal propio $P$ es:

  - Primo, si $xy \in P \implies x \in P \vee y \in P$.
  - Maximal, si es maximal en el retculo de ideales.
 
****** Caracterizacin de ideales primos y maximales
Un ideal $P$ propio es:

  - Primo ssi $R/P$ es dominio de integridad.
  - Maximal ssi $R/P$ es un cuerpo.
 
As, tenemos que primo implica maximal.

******* Demostracin: primos
Vase que es equivalente a pedir que a $(x+P)(y+P) \neq 0$ equivalga
$x+P = 0$  $y+P = 0$.

******* Demostracin: maximales
Ser maximal equivale a que no podamos aadir ningn elemento sin
llegar al ideal total. Esto es, si intentamos aadir $y$, tendremos
algn $z$ tal que $(y+P)(z+P) = 1+P$, que es equivalente a la
condicin de cuerpo.

***** Teorema de Krull
Dados $\alpha \subset R$ ideal y $S$ multiplicativamente cerrado con $\alpha\cap S=\varnothing$,
existe un ideal $M$ tal que:

  - $\alpha \subset M$
  - $M \cap S = \varnothing$
  - $M$ es maximal respecto a esta condicin.

Adems, $M$ es un ideal primo.

****** Multiplicativamente cerrado
Un subconjunto $S$ es multiplicativamente cerrado si:

  - $1 \in S$
  - $a,b \in S \implies ab \in S$

****** Demostracin
Dada una cadena de ideales que cumple $\alpha \subset I$ y $I \cap S = \varnothing$, su unin
tambin lo cumple y es cota de la cadena. Aplicando lema de Zorn,
sabemos que debe haber un ideal maximal $M$ respecto a las condiciones.

Supongamos $xy \in M$ pero $x,y \notin M$. Por maximalidad, $(M+(x)) \cap S$ y
$(M+(y)) \cap S$ son no vacos y existen $xz,yt \in S$. Entonces tenemos 
que $xzyt \in M \cap S$, contradiccin.

****** Corolario al teorema de Krull
Todo ideal tiene un ideal maximal que lo contiene. Adems, todo elemento
no unidad tiene un ideal maximal que lo contiene.

******* Demostracin
Tomando $S = \{1\}$.

***** Inclusin en ideales primos                                 :extra:
Sean ideales $\alpha_1,\dots,\alpha_n$ y $\pi$ un ideal primo. Si $\bigcap \alpha_i \subseteq \pi$, entonces,

\[
\exists \alpha_i \subseteq \pi
\]

**** 2. Nilradical y radical de Jacobson.
***** Nilradical
El *nilradical* es el ideal dado por los elementos nilpotentes:

\[
\operatorname{Nil}(R) = \{x \in R \mid \exists n : x^n = 0\}
\]

****** Es un ideal
Trivial usando el binomio de Newton.

****** Anillo reducido
Un anillo se dice reducido si $\operatorname{Nil}(R) = 0$. Los dominios de integridad son
trivialmente reducidos. Adems, podemos reducir un anillo dividindolo
por su nilradical, $R/\operatorname{Nil}(R)$.

***** Caracterizacin del Nilradical
El nilradical es la interseccin de ideales del espectro, los ideales
primos del anillo.

\[
\operatorname{Nil}(R) = \bigcap_{{\cal \pi}\text{ primo}} \pi
\]

****** Demostracin
******* Nilpotente en la interseccin
Si $x^n = 0 \in \pi$, por primalidad, $x \in \pi$ para cualquier ideal primo.

******* En la interseccin es nilpotente
Si $x \notin \operatorname{Nil}(R)$, $S=\{1,x,x^2,\dots\}$ es multiplicativamente cerrado con
$S \cap \operatorname{Nil}(R) = \varnothing$, y por Krull, existe un primo con $\pi \cap S = \varnothing$.

***** Radical de un ideal                                         :extra:
El *radical de un ideal* se define como:

\[
\sqrt{\alpha} = \{x \in R \mid x^n \in \alpha\}
\]

Cuando $\alpha = \sqrt{\alpha}$, lo llamamos *ideal radical*.

****** Caracterizacin
Tenemos que $\operatorname{Nil}(R/\alpha) = \sqrt{\alpha}/\alpha$ por construccin. De esa forma adems 
llegamos a caracterizar al radical como:

\[
\sqrt{\alpha} = \bigcap_{\alpha \subset \pi \in \operatorname{Spec}(R)} \pi
\]

***** Radical de Jacobson
El *radical de Jacobson* es el dado por:

\[
{\cal J}(R) = \bigcap_{{\cal M} \text{ maximal}} {\cal M}
\]

***** Caracterizacin del radical de Jacobson
Tenemos que $x \in {\cal J}(R)$ ssi $1-xy \in U(R)$ para cualquier $y$.

****** Demostracin
******* Primera implicacin
Si $x \in {\cal J}(R)$, entonces $1-xy$ no puede estar en ningn ideal maximal,
porque estara tambin el $1$. Pero todo elemento no unidad est en un
ideal maximal por teorema de Krull.

******* Segunda implicacin
Si $x\notin M$ maximal, $(x)+M = R$. Luego $1-xy \in M$, y un maximal
no puede contener una unidad.

**** 3. Algoritmo de la divisin en K[X1,,Xn].
***** rdenes monomiales                                          :extra:
Un orden monomial $\leq$ en $\mathbb{N}^n$ es un orden compatible, montono y total.

  1. *Compatible:* si $x\leq y$, entonces $\gamma+x \leq \gamma+y$.
  2. *Montono:* $0 \leq x$.
  3. *Total:* o bien $x \leq y$, o bien $y \leq x$.

El orden lexicogrfico, el orden lexicogrfico graduado y el orden 
lexicogrfico graduado inverso son rdenes monomiales.

***** Componentes de la divisin                                  :extra:
Definimos los siguientes componentes para un polinomio
expresado como $p = \sum a_\alpha X^\alpha$:

  - ${\cal N}(p) = \{\alpha \in \mathbb{N}^n \mid a_\alpha \neq 0\}$, diagrama de Newton.
  - $exp(p) = \max\{\alpha \in \mathbb{N}^n \mid a_\alpha \neq 0\}$, exponente.
  - $tl(p) = a_{exp(p)}X^{exp(p)}$, trmino lder.

****** Propiedades del exponente
Dados $F,G \in K[X_1,\dots,X_n]$ no nulos, se cumple:

  1. $exp(FG) = exp(F)+exp(G)$
  2. $exp(F+G) \leq \max\{exp(F),exp(G)\}$
  3. Si $exp(F) < exp(G)$, entonces $exp(F+G) = exp(G)$.

******* Demostracin
Se demuestran usando que los polinomios forman un K-espacio vectorial
teniendo de base a los monomios.

***** Particin de generadores
Dada una lista de elementos $a_1,\dots,a_k$, tenemos una particin que
definimos inductivamente como:

  1. Los elementos que genera el primer generador:

     \[\Delta^1 = a_1 + \mathbb{N}^n\]

  2. Los elementos que aporta cada nuevo generador:

     \[
     \Delta^i = (a_i+\mathbb{N}^n) \setminus \bigcup_{j<i} \Delta^j
     \]

  3. Todos los dems elementos:

     \[
     \overline{\Delta} = \mathbb{N}^n \setminus \bigcup_{j \leq k} \Delta^j
     \]

***** Teorema de la divisin
Dado un orden monomial y una lista de polinomios $\{G_1,\dots,G_t\}$; consideramos
la particin $\Delta_1,\dots,\Delta_t,\overline{\Delta}$ dada por los generadores $exp(G_i)$. Tenemos que,
para cada $F \in K[X_1,\dots,X_n]$, existen $Q_1,\dots,Q_t,R$ nicos tales que:

  1. $F = Q_1G_1+\dots+Q_tG_t+R$.
  2. $R=0$  $N(R) \subset \overline{\Delta}$.
  3. $exp(G_i)+N(Q_i) \subseteq \Delta^i$.

****** Demostracin
Procedemos por induccin sobre $exp(F)$ con el orden monomial que
tenemos. Distinguimos siempre segn si aparece en $\Delta_i$ o en $\overline{\Delta}$.
Ntese que en cada caso debemos comprobar que se cumplen trivialmente
las condiciones del teorema.

******* Caso base
******** Aparece en algn elemento de la particin
Si $exp(F) \in \Delta^i$, entonces forzosamente $exp(G_i)=0$. Entonces
tomamos $Q_i = F/G_i$ y $Q_j=0$ para $j \neq i$.

******** Aparece en el resto de la particin
Simplemente tomamos $R=F$.

******* Caso inductivo
Sabiendo ahora que podemos dividir todo $G$ con $exp(G) < exp(F)$.

******** Aparece en algn elemento de la particin
Si $exp(F) \in \Delta^i$ entonces $exp(F) = exp(G_i) + \gamma$. Tomando $H=X^\gamma G$,
aplicamos induccin sobre:

\[
F -\frac{cl(F)}{cl(H)}H = F' = \sum Q_i'G_i+R'
\]

Ahora tomamos $Q_i = Q_i'+\frac{cl(F)}{cl(H)}X^\gamma$ y $Q_j = Q_j'$, para llegar a:

\[
F = \sum Q_iG_i+R'
\]

******** Aparece en el resto de la particin
Aplicamos induccin sobre:

\[
F - tl(F) = \sum Q_i'G_i + R'
\]

Y tomamos entonces $R=R'+tl(F)$, que sigue cumpliendo las 
condiciones.

**** 4. Ideales monomiales.
***** Exponente de un ideal                                       :extra:
El exponente de un ideal es el conjunto de exponentes de sus polinomios:

\[
Exp(I) = \{
exp(F) \mid 0\neq F \in I
\} \subseteq \mathbb{N}^n
\]

El exponente es un monoideal, es decir, $Exp(I) + \mathbb{N}^n = Exp(I)$.

****** Demostracin
Ntese que tenemos $exp(X^\gamma F) = \gamma + exp(F)$.

***** Lema de Dickson y sistemas generadores                      :extra:
Para $S \subseteq \mathbb{N}^n$ no vaco, existe $G \subseteq S$ finito tal que $S \subseteq G + \mathbb{N}^n$.

****** Monoideal
Un subconjunto $E \subseteq \mathbb{N}^n$ es monoideal cuando $E = E+\mathbb{N}^n$.

****** Sistemas de generadores
Si $E$ es monoideal, existe un $G \subset E$ finito con $E = G + \mathbb{N}^n$. Llamamos
a $G$ sistema de generadores de $E$.

Esto es debido al lema de Dickson.

***** Ideales monomiales
Un *ideal monomial* est generado por monomios, es de la forma:

\[
I = (X^{\alpha}\mid \alpha \in A)
\]

para algn $A \subseteq \mathbb{N}$.

***** Monomios en un ideal monomial
Sea $I = (X^\alpha \mid \alpha \in A)$ monomial, equivalen:

  1. $F\in I$.
  2. Todo monomio de $F$ est en $I$.
  3. $F$ es combinacin lineal de monomios de $I$.

Y adems, si para cualquier polinomio de un ideal todos sus monomios 
estn en el ideal, es monomial.

****** Demostracin
******* Primera implicacin
Si $F \in I$, ser de la forma:

\[
F = \sum F_iX^\alpha
\]

Como los monomios son una K-base del espacio, todo monomio de la
suma ser mltiplo de algn $X^\alpha$.

******* Segunda y tercera implicaciones
Triviales desde lo anterior.

******* Caracterizacin de ideales monomiales
Ntese que podemos tomar todos los polinomios del ideal y generarlo
como: $(X^\alpha \mid \alpha \in Exp(I))$.
***** Lema de Dickson para ideales monomiales
Todo ideal monomial tiene un sistema de generadores finito y 
formado por monomios.

****** Demostracin
Como el exponente de un ideal es siempre monoideal, podemos aplicar
el lema de Dickson para darle un sistema de generadores $Exp(I)=G+\mathbb{N}^n$.
Dado un exponente $\alpha \in Exp(I)$, tenemos $X^\alpha\in I$, luego tomamos como
sistema de generadores:

\[
(X^\alpha \mid \alpha \in G)
\]

Dado cualquier $F\in I$, cada monomio suyo estar en $I$, luego ser 
generado por este sistema.
**** 5. Bases de Grbner. Aplicaciones.
***** Base de Grbner
Una *base de Grbner* de un ideal $I$ es un conjunto $\mathbb{G} = \{G_1,\dots,G_n\} \subseteq I$
cumpliendo $Exp(I) = \{exp(G_1),\dots,exp(G_n)\} + \mathbb{N}^n$.

***** Propiedades de bases de Grbner
Las bases de Grbner en $K[X_1,\dots,X_n]$ cumplen:

  1. Todo ideal no nulo tiene base de Grbner.
  2. Toda base de Grbner de un ideal genera al ideal.
  3. *Teorema de la base de Hilbert*: todo ideal es finitamente generado.

****** Demostracin
******* Primer punto
Todo ideal tiene $Exp(I)$ monoideal, y por tanto tiene un sistema de
generadores. Tomamos polinomios que tengan como exponente estos
generadores y tenemos una base de Grbner.

******* Segundo punto
Por algoritmo de la divisin, todo polinomio del ideal se divide
entre ellos dando un resto tal que $exp(R) \in \overline{\Delta} \cap Exp(I) = \varnothing$. Por
tanto, $R=0$.

******* Tercer punto
Todo ideal est generado por su base de Grbner, que es finita.

***** Caracterizacin de las bases de Grbner
Sea $I$ ideal no nulo, equivalen:

  1. $\mathbb{G}$ es base de Grbner de $I$.
  2. $R(F,\mathbb{G}) = 0$, para todo $F\in I$.

****** Demostracin
******* Primera implicacin
Como $exp(R) \in Exp(I)\cap\overline{\Delta}$, tenemos $exp(R) = 0$.

******* Segunda implicacin
Por teorema de la divisin, todo $F \in I$ es de la forma:

\[
F = \sum_{i=0}^n Q_iG_i
\]

Donde $exp(Q_iG_i) \in \Delta^i$, y como forman una particin disjunta, se
tiene que el $exp(F) = \max\{exp(Q_iG_i)\} \notin \overline{\Delta}$. Por tanto $Exp(I)\cap\overline{\Delta} = \varnothing$.

***** Clculo de bases de Grbner                                 :extra:
Las bases de Grbner de un ideal pueden calcularse a partir de sus
generadores utilizando el Algoritmo de Buchberger, que aade a cada
paso los restos de las semizigias de los generadores a la base.

****** Teorema de Buchberger
Dado un sistema de generadores $\mathbb{G} = \{G_1,\dots,G_n\}$ de una base de Grbner,
equivalen:

  1. $\mathbb{G}$ es base de Grbner.
  2. Para alguna ordenacin de $\mathbb{G}$, se tiene $R(S(G_i,G_j);\mathbb{G}) = 0$ para $i\neq j$.

****** Semizigia
Definimos la semizigia de dos polinomios como:

\[{\cal S}(F,G) 
= \frac{1}{cl(F)}X^{\gamma-\alpha}F - \frac{1}{cl(G)}X^{\gamma-\beta}G\]

***** Base de Grbner minimal                                     :extra:
Una base de Grbner de $I$ se dice minimal si, para cualquier $F \in \mathbb{G}$:

  1. $cl(F) = 1$
  2. $exp(F) \notin \{exp(G) \mid G\in\mathbb{G}, G\neq F\} + \mathbb{N}^n$

****** Retirar polinomios
Sea $\mathbb{G}$ base de Grbner con un ideal no nulo y sea un $F \in \mathbb{G}$ que no
cumple la segunda condicin de minimalidad. Tenemos que $\mathbb{G}\setminus\{F\}$ es
tambin base de Grbner, ya sus exponentes siguen generando $Exp(I)$.
***** Base de Grbner reducida                                    :extra:
Una base de Grbner $\mathbb{G}$ de $I$ es reducida cuando para cualquier $\forall F\in\mathbb{G}$:

  1. $cl(F) = 1$
  2. ${\cal N}(F) \cap \{exp(G) \mid G \in \mathbb{G}, G \neq F\} + \mathbb{N}^n = \varnothing$

Toda base de Grbner reducida es minimal y todo ideal no nulo $I$ tiene una
nica base de Grbner reducida.

****** Demostracin: existencia
Dada una base de Grbner, podemos llegar a una base de Grbner minimal
retirando polinomios. Y dada una base minimal, podemos llegar a una base
reducida dividiendo cada polinomio por todos los dems y sustituyndolo
por su resto, que tiene el mismo exponente por ser la anterior una base
minimal.

****** Demostracin: unicidad
Si hubiera dos bases reducidas, tomaramos los dos elementos con el mismo
exponente en cada una de ellas, y dividiramos su resto $F-F' \in I$, que
debe dar resto $0$:

\[R(F-F';\mathbb{G}) = F-F'
\]

Ya que por ser una base reducida, ${\cal N}(F-F') \subseteq \overline{\Delta}$.

***** Aplicaciones: Problema de pertenencia
Sea $I$ ideal con un sistema de generadores. Podemos calcular si $F \in I$
calculando una base de Grbner del ideal y usando:

\[F \in I \iff R(F,\mathbb{G}) = 0\]

***** Aplicaciones: Igualdad de ideales
Dados dos ideales $I,J$ con sus sistemas de generadores. Podemos comprobar
que sern iguales calculando sus bases de Grbner reducidas, que por
unicidad, deben ser iguales.

***** Aplicaciones: Ideal de eliminacin
Dado $I$ ideal no nulo. Definimos el j-simo ideal de eliminacin como:

\[
I_j = I \cap K[X_{j+1},\dots,X_n]
\]

Si $\mathbb{G}$ era base de Grbner con el orden lexicogrfico de $I$, entonces:

\[
\mathbb{G}_j = \mathbb{G} \cap I_j
\]

es base de Grbner de $I_j$.

****** Clculo de la interseccin
Sean $I,J$ ideales no nulos de $K[X_1,\dots,X_n]$ y sea:

\[
H = TI + (1-T)J \subseteq K[T,X_1,\dots,X_n]
\]

considerando los ideales extendidos. Entonces su interseccin es el
primer ideal de eliminacin de $H$:

\[
I \cap J = H \cap K[X_1,\dots,X_n]
\]

**** 6. Variedades algebraicas afines. Correspondencia ideal-variedad.
***** R-lgebras                                                  :extra:
Dado un anillo $R$, un R-mdulo es un grupo abeliano $M$ junto a una
operacin $\cdot : (R,M) \longrightarrow M$ verificando:

  - $r(x+y) = rx+ry$
  - $(r+s)x = rx + sx$
  - $r(sx) = (rs)x$
  - $1x = x$

Una *R-lgebra* $S$ es un anillo con estructura compatible de R-mdulo,
tal que:

\[
\forall r \in R; x,y \in S: (rx)y = r(xy) = x(ry)
\]

***** Variedades algebraicas afines
Dado un ideal ${\cal F} \subseteq K[X_1,\dots,X_n]$, denotamos:

\[
\mathbb{V}({\cal F}) = \left\{ (a_1,\dots,a_n) \mid 
\forall F \in {\cal F}: F(a) = 0 \right\}
\]

Y llamamos *variedad algebraica afn* a los conjuntos de esta forma.

***** Topologa de Zariski
Las variedades son los cerrados de una topologa sobre $\mathbb{A}^n(K)$, ya
que cumplen:

  1. \[\bigcap_{\lambda\in\Lambda} \mathbb{V}(J_\lambda) =
     \mathbb{V}\left(\sum_{\lambda\in\Lambda} J_\lambda\right)}\]

  2. $\mathbb{V}(J_1) \cup \mathbb{V}(J_2) = \mathbb{V}(J_1J_2) = \mathbb{V}(J_1\cap J_2)$

  3. $\mathbb{V}(0) = \mathbb{A}^n(K)$

  4. $\mathbb{V}(K[X_1,\dots,X_n]) = \varnothing$

****** Demostracin
******* Punto 1
Ntese que un punto se anula para un conjunto de ideales ssi
se anula para todas sus combinaciones lineales.

******* Punto 2
Si $x \notin \mathbb{V}(J_1) \cup \mathbb{V}(J_2)$, entonces existen polinomios en cada ideal
que no lo anulan, y su producto da $x \notin \mathbb{V}(J_1J_2)$ y $x \notin \mathbb{V}(J_1\cap J_2)$.

El resto de inclusiones son triviales.

******* Punto 3
El polinomio $0$ anula todos los puntos.

******* Punto 4
Ningn punto es raz de todos los polinomios. Existen los 
polinomios constantes no nulos en particular.

***** Correspondencia ideal-variedad
Se define el *ideal de un conjunto* como:

\[
\mathbb{I}(S) = 
\left\{
F \in K[X_1,\dots,X_n]
\mid
\forall a \in S: F(a) = 0
\right\}
\]

Los ideales y variedades cumplen:

  1. $\mathbb{I}(\varnothing) = K[X_1,\dots,X_n]$.

  2. $\mathbb{I}(S_1\cup S_2) = \mathbb{I}(S_1) \cap \mathbb{I}(S_2)$.

  3. $S_1 \subseteq S_2 \implies \mathbb{I}(S_1) \supseteq \mathbb{I}(S_2)$.

  4. $\mathbb{I}(S)$ es ideal radical.

  5. $S \subseteq \mathbb{VI}(S)$ y $J \subseteq \mathbb{IV}(J)$.

  6. $\mathbb{I}(S) = \mathbb{IVI}(S)$ y $\mathbb{V}(J) = \mathbb{VIV}(J)$.

  7. Cuando $V \subseteq \mathbb{A}^n(K)$ es variedad afn, $V = \mathbb{VI}(V)$.

  8. $V_1 \subseteq V_2 \iff \mathbb{I}(V_1) \supseteq \mathbb{I}(V_2)$.

  9. $V_1\cup V_2 = \mathbb{V}(\mathbb{I}(V_1)\mathbb{I}(V_2)) = \mathbb{V}(\mathbb{I}(V_1) \cap \mathbb{I}(V_2))$.

  10. \[\bigcap_{\lambda\in\Lambda} V_\lambda = \mathbb{V}\left(\sum_{\lambda\in\Lambda} \mathbb{I}(V_\lambda)\right)\]

****** Demostracin
******* Puntos 1, 2 y 3
Triviales por definicin.

******* Punto 4
Notamos que $f^n(s)=0 \implies f(s) = 0$.

******* Puntos 5, 6 y 7
Desde la definicin se tienen las desigualdades. Uniendo ambas nos
da la igualdad. El siguiente es un caso particular.

******* Punto 8
Trivial por definicin y por la igualdad anterior.

******* Punto 9
La unin de variedades es variedad, aplicamos $\mathbb{VI}$ y las propiedades
anteriores.

******* Punto 10
La interseccin es variedad y volvermos a aplicar $\mathbb{VI}$.

***** Teorema de los ceros de Hilbert
En general las funciones $\mathbb{I}, \mathbb{V}$ dan una correspondencia no biyectiva
entre ideales radicales y variedades, con $\mathbb{VI} = id$. Cuando $K$ es adems
*algebraicamente cerrado*, se tiene $\mathbb{IV}(J) = \sqrt{J}$, y hay biyeccin:

\[
\left\{ V \in \mathbb{A}^n(K) \mid V \text{ es v.a.}\right\}
\cong
\left\{
J \subseteq K[X_1,\dots,X_n] \mid J = \sqrt{J}
\right\}
\]

**** 7. Anillo de coordenadas de una variedad. Aplicaciones polinmicas.
***** Espacio afn de un cuerpo                                   :extra:
Llamamos $\mathbb{A}^n(K)$ al espacio afn sobre $K^n$ con la funcin afn
$\varphi : K^n \times K^n \longrightarrow K^n$ dada por $\varphi(u,v) = v-u$.

***** Aplicaciones polinmicas
Una aplicacin polinomial o morfismo entre variedades es una aplicacin
$f : V \longrightarrow W$, variedades de $\mathbb{A}^n$ y $\mathbb{A}^m$, de la forma:

\[
f(a) = (F_1(a),F_2(a),\dots,F_m(a))
\]

donde los $F_1,\dots,F_m \subseteq K[X_1,\dots,X_n]$ son polinomios.

***** Anillo de coordenadas
El anillo de coordenadas de una variedad $V \subseteq \mathbb{A}^n(K)$ es la K-lgebra:

\[
K[V] = \frac{K[X_1,\dots,X_n]}{\mathbb{I}(V)}
\]

***** Relacin entre aplicaciones polinmicas y anillos de coordenadas
Para $V \subseteq \mathbb{A}^n(K), W \subseteq \mathbb{A}^m(K)$ variedades,

  1. Toda aplicacin polinmica $f : V \longrightarrow W$ induce un homomorfismo de
     K-lgebras $\widetilde f : K[W] \longrightarrow K[V]$ cumpliendo $\widetilde f(G+\mathbb{I}(W)) = G(f) + \mathbb{I}(V)$.

  2. Cada homomorfismo $h : K[W] \longrightarrow K[V]$ induce una nica aplicacin
     polinmica $h' : V \longrightarrow W$ tal que $\tilde{h}' = h$.

  3. Dadas aplicaciones polinmicas $V_1 \overset{f}\longrightarrow V_2 \overset{g}\longrightarrow V_3$, $\widetilde{f} \circ \widetilde{g} = \widetilde{g \circ f}$.

  4. $f$ es isomorfismo ssi $\widetilde f$ es isomorfismo.

Es decir, hay un funtor contravariante entre ambas categoras.

****** Demostracin
******* Punto 1
Dado $f(a) = (F_1(a),\dots,F_m(a))$, por propiedad universal del anillo de
polinomios definimos $f'(Y_j) = F_j$. Para $G \in \mathbb{I}(W)$, si tomamos $a \in V$,
se tiene $f(a) \in W$, y por tanto:

\[
f'(G)(a) = G(F_1(a),\dots,F_n(a)) = G(f(a)) = 0
\]

As, est bien definida la funcin:

\[
\widetilde f (G + \mathbb{I}(W)) = G(F_1,\dots,F_m) + \mathbb{I}(V)
\]

******* Punto 2
******** Existencia
Dada $h$, llamamos $h(Y_i+\mathbb{I}(W)) = F_i$, y definimos $f(a) = (F_1(a),\dots,F_m(a))$.
Est bien definida porque para $G \in \mathbb{I}(W)$,

\[
h(0) = h(G) = G(F_1,\dots,F_m) + \mathbb{I}(V)
\]

Luego $G(f(a)) = G(F_1,\dots,F_m)(a) + 0 = 0$, y $f(a) \in \mathbb{VI}(W) = W$. Es claro
adems que $\widetilde f = h$, por estar definida como ella en una base de los
polinomios.

******** Unicidad
Supongamos $\widetilde g = h$ con $g(a) = (G_1(a),\dots,G_m(a))$, entonces:

\[\widetilde g(Y_j+\mathbb{I}(W)) = G_j + \mathbb{I}(V)\]
\[h(Y_j+\mathbb{I}(W)) = F_j + \mathbb{I}(V)\]

Por lo tanto, $G_j-F_j \in \mathbb{I}(V)$, para cualquier $j$.

******* Punto 3
Por construccin. Sean:

  - $f(a) = (F_1(a),\dots,F_m(a))$
  - $g(a) = (G_1(a),\dots,G_m(a))$
  - $g \circ f (a) = (G_1(F_1(a),\dots), \dots, G_m(F_1,\dots))$

Entonces comprobamos que: $\widetilde{g \circ f}(H) = \widetilde f  \circ \widetilde{g} (H)$.

******* Punto 4
Por el punto anterior y viendo simplemente que $\widetilde{id} = id$.

***** Caracterizacin de ncleos e imgenes                       :extra:
Sea $h : K[W] \longrightarrow K[V]$ un morfismo de K-lgebras dado por $h(Y_j) = F_j$.

  1. Sea $C = (Y_1-F_1,\dots,Y_m-C_m) + \mathbb{I}(V)$ ideal de $K[X_1,\dots,X_n,Y_1,\dots,Y_m]$
     se tiene:

     \[
     \ker(h) = ((C\cap K[Y_1,\dots,Y_m]) + \mathbb{I}(W))/\mathbb{I}(W)
     \]
     
  2. Sea $\mathbb{G}$ Grbner reducida de $C$ con orden lexicogrfico:

     \[F + \mathbb{I}(V) \in \mathrm{img}(h) \iff
     R(F;\mathbb{G}) \in K[Y_1,\dots,Y_m]\]
     
     Adems, en tal caso, $F + \mathbb{I}(V) = h(R(F;G)+\mathbb{I}(W))$.

****** Demostracin
******* Primer punto
******** Primera implicacin
Sea $G \in \ker(h)$, entonces $G(F_1,\dots,F_m) = h(G) = 0+\mathbb{I}(V) \in C$.
Dividimos ahora $H = G - G(F_1,\dots,F_m)$ entre $Y_1-Y_1,\dots,Y_m-C_m$
pero con orden lexicogrfico $Y_1>\dots >Y_m>X_1> \dots>X_n$:

\[
H = \sum_{i=1}^m (Y_i-F_i) Q_i + R
\]

Como ${\cal N}(R) \subseteq \overline\Delta$, $R \in K[X_1,\dots,X_m]$, pero:

\[
H(F_1,\dots,F_m) = G(F_1,\dots,F_m) - G(F_1,\dots,F_m) = 0 = R
\]

Luego $H \in C$, y $G \in C \cap K[Y_1,\dots,Y_m]$.

******** Segunda implicacin
Si escribimos $\mathbb{I}(V) = (H_1,\dots,H_s)$, tenemos entonces:

\[
G = \sum (Y_i-F_i)T_i + \sum H_jR_j
\]

luego:

\[
G(F_1,\dots,F_m) = \sum_{j=1}^s H_jR_j(X_1,\dots,X_n,F_1,\dots,F_m) 
\in \mathbb{I}(V)
\]

Y por tanto tenemos $G \in \ker(H)$:

\[
h(G) = G(F_1,\dots,F_m) + \mathbb{I}(V) = 0
\]

******* TODO Segundo punto
****** Inyectividad y sobreyectividad
Se tiene desde lo anterior que:

  1. $h$ inyectiva ssi $C \cap K[Y_1,\dots,Y_m] \subseteq \mathbb{I}(W)$.
  2. $h$ sobreyectiva ssi $\exists M_i \in K[Y_1,\dots,Y_m]$ tal que $X_i-M_i \in \mathbb{G}$.

*** Ejercicios
**** Relacin 1
***** Ejercicio 1
#+begin_statement
Sea $R$ un anillo conmutativo. Demostrar:

 1. Los elementos $0$ y $1$ estn determinados de forma nica.
 2. Para cada elemento $x\in R$, el opuesto $-x$ y el inverso si existe $x^{-1}$, estn
    determinados de forma nica.
 3. El conjunto ${\cal U}(R)$ de las unidades de $R$ es un grupo abeliano.

$\quad$
#+end_statement
****** Punto 1
Supongamos que hubiera dos elementos neutros de cualquier tipo:

\[e = e \otimes e' = e'\]

****** Punto 2
Supongamos que hubiera dos inversos $x,y$ de cualquier tipo:

\[x = x \otimes (a \otimes y) = (x \otimes a) \otimes y = y\]

****** Punto 3
El anillo es conmutativo. As que el grupo de las unidades con el producto ser
abeliano.

***** TODO Ejercicio 2
#+begin_statement
Sea $R$ anillo conmutativo. Demostrar:

  1. $x0=0$ para todo $x\in R$.
  2. $R$ tiene ms de un elemento ssi $0\neq 1$.
  3. $(-x)y = -(xy) = x(-y)$ para cualesquiera $x,y \in R$.
  4. $(nx)y = n(xy) = x(ny)$ para cualesquiera $x,y \in R$ y todo $n \in \mathbb{Z}$.
  5. $(nx)(my) = (nm)(xy)$ para cualesquiera $x,y \in R$ y $n,m \in \mathbb{Z}$.
  6. $\left(\sum_{i=1}^n x_i\right) \left(\sum^m_{j=1} y_j\right) = \left(\sum^{n,m}_{i=1,j=1} x_iy_j\right)$, para $x_i,y_j \in R$ y $n,m > 0$.
  7. $(x+y)^n = \sum_{i=0}^n {n \choose i} x y^{n-i}$, para cualesquiera $x,y \in R$ y $n,m \geq 0$.
  8. $(xy)^n = x^ny^n$ y $(x^n)^m = x^{nm}$, para cualesquiera $x,y\in R$ y $n,m \geq 0$.
$\quad$
#+end_statement
***** Ejercicio 3
#+begin_statement
Sea $X$ un conjunto, en ${\cal P}(X)$ se consideran las opearciones

\[A+B := (A\cup B) \setminus (A\cap B)\]
\[AB := A \cap B\]

para cualesquiera $A,B \in {\cal P}(X)$.

Prueba que ${\cal P}(X)$, con las operaciones anteriores y elemento uno igual a $X$, es un
anillo conmutativo. Cul es el elemento cero?. Observa que este anillo es un 
*anillo de Boole*, es decir $A^2=A$ para $A\in{\cal P}(X)$ y que por tanto $2A = 0$.
#+end_statement

Demostramos que ${\cal P}(X)$ con la suma forma un grupo abeliano. Cada conjunto es su
inverso, es conmutativo y tiene al conjunto vaco como neutro. La asociatividad
se comprueba viendo que pertenecer a $A+B+C$ es pertenecer a uno o a los tres.

Que es conmutativo se tiene por:

\[0 = (A+B)^2 - (A+B) = AB + BA\]
\[0 = A+A\]

***** Ejercicio 4
#+begin_statement
Dado un anillo $R = (R,+,\times,1)$, definir sobre $R$ dos operaciones $\oplus,\otimes$ de forma
que $(R,\oplus,\otimes,0)$ sea un anillo con elemento $1$ como cero.
#+end_statement
Nos sirve tomar:

\[a \oplus b = a+b-1\]
\[a \otimes b = a + b - ab\]

Debemos comprobar las propiedades.

***** TODO Ejercicio 7
***** Ejercicio 8
#+begin_statement
Se deduce la condicin $f(1) = 1$ en la definicin de homomorfismo de anillos de 
las dos condiciones $f(x+y) = f(x)+f(y)$ y $f(xy) = f(x)f(y)$?
#+end_statement
Una inclusin en la suma directa de dos anillos cumple lo pedido pero no cumple
que $i(1) = 1$.

\[i : R \longrightarrow R \oplus S,\quad i(r) = (r,0)\]

***** Ejercicio 9
#+begin_statement
Prueba que los elementos nilpotentes de un anillo forman un ideal.
#+end_statement
Sean $n^p = 0$ y $m^q = 0$, dos nilpotentes. Tenemos que $(n+m)^{p+q} = 0$, por binomio de 
Newton, y que $(rn)^p = 0$ por conmutatividad.
***** Ejercicio 10
#+begin_statement
Demuestra que todo dominio de integridad finito es un cuerpo.
#+end_statement
Dado $x \in R$, considero el endomorfismo $(\lambda a. xa)$. Por ser dominio de integridad, es
inyectivo, y siendo inyectivo y finito, es sobreyectivo. Luego $\exists a : xa = 1$.
***** Ejercicio 11
#+begin_statement
Demuestra que todo dominio de integridad con un nmero finito de ideales es un
cuerpo.
#+end_statement
Dado $x\in R$, considero una aplicacin que lleva un ideal $I$ en $(x)I$. Tenemos que es
inyectiva por ser dominio de integridad. De hecho, sean $i \in I$ con $(x)I = (x)J$:

\[xi = rxj = xrj \Rightarrow i = rj\]

Luego $I\subset J$, simtricamente $I =J$. Por ser inyectiva y ser de nmero finito, es
biyectiva, luego $\exists I: (x)I = (1)$.
***** Ejercicio 12
Sea una cadena de ideales $\Pi \subset \beta\subset R$, con $x \in \beta$, $x \notin \Pi$.
Entonces $x(x^{n-1}-1) = 0 \in \Pi$, y debe tenerse $x^{n-1}-1 \in \Pi \subset \beta$.
Con eso, debe ser $\beta = R$.

***** Ejercicio 13
 Por definicin de *radical*, tenemos que cuando es radical es interseccin de 
 anillos primos.

 Sea $\alpha$ interseccin de ideales primos, ser en particular interseccin de ideales
 primos ms algunos que lo contienen.

***** Ejercicio 14
 Sea $x$ idempotente y sea $M$ el maximal de $R$. 

 - Sea $x \notin M$, entonces debe ser $x$ una
   unidad; por ser $R$ local. Siendo unidad $x^2 = x$ nos da $x=1$.

 - Sea $x \in M$. Sabemos ${\cal J}(R) = M$, luego $x$ est en el radical de Jacobson.
   Esto quiere decir que $1-xy \in U(R)$ para cualquier $y \in R$. En particular $1-x$
   est en las unidades del anillo. Como $x(1-x) = 0$, se tiene $x = 0$.

***** Ejercicio 15
 Aplicaremos Zorn, viendo que todo conjunto totalmente ordenado tiene cota inferior.

 Sea una cadena de ideales primos $\Pi_i$, entonces sea $ab \in \bigcap \Pi_i$, entonces, supongamos que
 $a$ no perteneciera a la interseccin, entonces, por primalidad, si $b \notin \Pi_j$, tampoco
 pertenecera a ninguno por debajo de l; y $a$ debera pertenecer a todos ellos y
 por tanto a la interseccin.

***** Ejercicio 16
****** Punto 1
 Tenemos que $0 = (2x)^2 - 2x = 4x - 2x= 2x$.

****** Punto 2
 Si $\pi$ es primo, entonces $R/\pi$ es dominio de integridad. Sea $m \in R/\pi$, tenemos que
 $m(m-1) = 0$, luego $m=0$  $m=1$. As, slo puede ser isomorfo a $\mathbb{Z}_2$
 y cuerpo. $\pi$ es maximal.

 Adems, la primera parte se obtiene tambin por caso particular del ejercicio 12.

****** Punto 3
 Definimos la operacin $a \oplus b = a+b+ab$ y comprobamos que $(a,b) = (a \oplus b)$, ya que
 $a (a\oplus b) =a$ y $b(a\oplus b) = b$. Por induccin, cada ideal generado por varios lo podemos
 generar por un elemento.

***** Ejercicio 17
Tenemos que los divisores de cero ya forman un ideal primo.
***** TODO Ejercicio 18
 Esto es equivalente a decir, ya que estamos en un anillo de ideales principales,
 que $X^3-Y^2$ es irreducible.

***** Ejercicio 19
 Vemos que $\alpha$ es ideal. Supongamos que fuera principal, debera estar generado
 por uno de mnimo grado. Si est generado por una constante, como contiene a $(2)$,
 debe estar generado por $(2)$, pero no es el caso porque no contendra a $x+2$.

***** TODO Ejercicio 21
***** Ejercicio 24
1. => 2. Sea $R$ con un ideal primo, y sea $a \in R$ no unidad. Tengo $a \in M$ para algn 
   maximal, que debe ser el nico ideal primo que hay. Aplicando Krull a  
   $S = \{1,a,a^2\dots\}$ contra el ideal $(0)$ tendra un ideal no conteniendo 
   a $S$ pero primo, lo que es imposible, as que $S$ tiene interseccin no vaca 
   con $(0)$.
2. => 3. Trivial.
3. => 1. Si $R/{\cal N}$ es un cuerpo, ${\cal N}$ es maximal. Si hubiera otro ideal primo, 
   lo meteramosen su maximal ${\cal M}$ y; si hubiera $m \in {\cal M}-{\cal N}$, se 
   tendra $(m) \cup {\cal M} = R$. Entonces $km+n = 1$, luego $km$ es unidad y ${\cal M} = R$.

***** TODO Ejercicio 25
***** Ejercicio 26
 Ntese que si $x$ es nilpotente, tambin lo es $ux$ para $u$ unidad.
 Sea $x^n = 0$. Tenemos que:

 \[(1+x)(1-x+x^2-\dots+x^{n-1}) = 1 + (-x)^n = 1\]

 Luego es unidad. Dada suma de unidad y nilpotente, podemos escribirla como:

 \[(u+x) = u(1+u^{-1}x)\]

 Producto de unidades.

***** Ejercicio 27
****** Punto 1
 Por un lado, si todos los $a_i$ fueran nilpotentes se tendran $a_iX^i$ nilpotentes.
 Y como la suma de unidad por nilpotente es unidad, la suma total es unidad.

 Sea $\sum b_iX^i$ el inverso de un polinomio $f(x) = \sum a_iX^i$. Es obvio que $a_0$ es unidad
 porque $a_0b_0 = 1$. Veamos por induccin que  $a^{r+1}_nb_{m-r} = 0$.

  - *Caso base:* $a_nb_m = 0$ por ser coeficiente del grado mximo.
  - *Caso de induccin*: El coeficiente de grado $n+m-1$ sera:
    $a_nb_{m-1} + a_{n-1}b_n = 0$, luego $a_n(a_nb_{m-1} + a_{n-1}b_m) = a_n^2b_{m-1} = 0$; y aplicaramos
    induccin en los siguientes casos de forma similar.

 En particular, para $r=n$ tenemos que $a_n^{n+1}b_0 = 0$, luego $a_n$ es nilpotente.
 Ahora hacemos induccin sobre el grado. Tambin es nilpotente $a_nX^n$, y 
 entonces tenemos que el polinomio siguiente tambin es unidad, pero de menor grado 
 que el original:

 \[f - a_nX^n = \sum^{n-1} a_iX^i \in {\cal U}(R[X])\]

****** Punto 2
 Tenemos que las $a_iX^i$ son nilpotentes; y la suma de nilpotentes es trivialmente
 nilpotente. 

 Hacia el otro lado, hacemos induccin sobre $grd(f)$:

  - Si $grd(f) = 0$, entonces $f = a_0$.
  - Sea $f = a_0 + \dots + a_nX^n$, tenemos que que si $f$ es nilpotente a la potencia $m$:
    \[ 0 = f^m = \sum_{j=0}^m {m \choose j}(a_0+\dots+a_n-1X^{n-1})^j(a_nX^n)^{m-j} = a_n^mX^{nm} + \dots\]
    Luego $a^m_n = 0$. El polinomio total es suma de esto y un polinomio de grado menor,
    que por induccin es nilpotente.

****** Punto 3. Teorema de MaCoy.
 Una implicacin es trivial por definicin.

 Sea $f$ divisor de cero. Tomamos un polinomio $g = \sum b_iX^i$ de grado mnimo con

 $fg = 0$. Entonces $a_nb_m = 0$, y por tanto $a_ng$ anulara tambin a $f$ pero tendra grado
 menor que $m$, luego debera ser $a_ng = 0$. Ahora procedemos por induccin, y se 
 volvera a tener $a_{n-r}g = 0$.

 Si $a_{n-r}g = 0$ para cualquier $r$, entonces:

 \[ 0 = \sum a_{n-r}b_i X^i\]

 As que $a_{n-r}b_0 = 0$ y se concluye $fb_0 = 0$.

***** Ejercicio 30
#+begin_statement
Calcular el radical de cualquier ideal de $\mathbb{Z}$.
#+end_statement
Dado $(n\mathbb{Z})$ y escribiendo $n = p_1^{e_1}\dots p_n^{e_n}$, podemos ver que un nmero que perteneciera
a su radical debera ser tal que:

\[ p_1^{e_1}\dots p_n^{e_n} | (q_1^{f_1}\dots q_n^{f_n})^k\]

Para algn $k$, lo que equivale a que $e_i \leq kf_i$. Es decir, necesitamos slo $f_i \neq 0$.
En conclusin, $\sqrt{n\mathbb{Z}} = (p_1p_2\dots p_n)\mathbb{Z}$, ideal del producto de sus factores primos.

***** Ejercicio 31
#+begin_statement
Demostrar los siguientes resultados para radicales de ideales de un anillo $R$:

  1. $\sqrt{\sqrt{\alpha}} = \sqrt{\alpha}$.
  2. $\sqrt{\alpha\beta} = \sqrt{\alpha \cap \beta} = \sqrt{\alpha} \cap \sqrt{\beta}$.
  3. $\sqrt{\alpha} = R \Leftrightarrow \alpha = R$.
  4. $\sqrt{\alpha+\beta} = \sqrt{\sqrt{\alpha}+\sqrt{\beta}}$.
  5. Si $\pi$ es un ideal primo, entonces $\sqrt{\pi} = \pi$.
  6. Si $\sqrt{\alpha} + \sqrt{\beta} = R$, entonces $\alpha+\beta = R$.

$\quad$
#+end_statement
****** Punto 1
Sea $y \in \sqrt{\sqrt{\alpha}}$, entonces $y^n \in \sqrt\alpha$, y entonces $(y^n)^m \in \alpha$, luego $y \in \sqrt{\alpha}$.
****** Punto 2
Sea $y \in \sqrt{\alpha \cap \beta}$, entonces $y^n \in \alpha \cap \beta$, y entonces $y^ny^n \in \alpha\beta$, luego 
$y \in \sqrt{\alpha\beta}$.
****** Punto 3
Sea $\sqrt{\alpha} = R$, entonces $1 = 1^n \in\alpha$.
****** Punto 4
Sea $x \in \sqrt{\sqrt\alpha+\sqrt\beta}$, entonces $x^n = u+v$, donde $u^p \in \alpha$, $v^q \in \beta$. Tengo entonces que
$(x^n)^{p+q} = (u+v)^{p+q} \in \alpha+\beta$, donde aplicamos Binomio de Newton.
****** Punto 5
Si fuera $x^n \in \pi$ para $n>1$, por primalidad, debera tenerse $x^{n-1} \in \pi$. As que $x\in\pi$.
****** Punto 6
Si $1 = a+b$ con $a^n\in \alpha$, $b^m\in\beta$, entonces, por Binomio de Newton tenemos que 
$1^{n+m} = (a+b)^{n+m} \in \alpha+\beta$.

***** Ejercicio 32
#+begin_statement
Sean $\alpha,\beta$ ideales de un anillo $R$ tales que $\sqrt{\alpha},\sqrt{\beta}$ son primos entre s. Demostrar que
entonces $\alpha,\beta$ tambin son primos entre s.
#+end_statement
Trivial por el punto 6 del ejercicio 31.

***** Ejercicio 33
#+begin_statement
Sea $R$ un anillo y $\alpha,\beta$ ideales. Demostrar que si $(\alpha)^n\subseteq\beta$ para algn $n\geq 0$, entonces
$\sqrt\alpha \subseteq \sqrt\beta$.
#+end_statement
Tengo trivialmente que $\alpha \subseteq \sqrt\beta$, puedo tomar 
races para tener $\sqrt{\alpha} \subseteq \sqrt{\sqrt{\beta}}$.

***** Ejercicio 34
#+begin_statement
Sea $\alpha\subseteq R$ un ideal tal que $\sqrt\alpha$ es finitamente generado. Demostrar que existe
$n \in \mathbb{N}$ tal que $(\sqrt{\alpha})^n\subseteq\alpha$.
#+end_statement

Sea $(\sqrt{\alpha}) = (x_1,\dots,x_m)$ tales que $x_i^{e_i} \in \alpha$. Entonces se tiene por binomio de Newton:

\[(\sqrt\alpha)^{e_1+\dots+e_m} \subset \alpha\]

Ya que cada sumando tiene algn $x_i$ elevado a ms que $e_i$.

***** Ejercicio 35
#+begin_statement
En el anillo de polinomios $\mathbb{F}_2[X,Y]$, con $\mathbb{F}_2$ cuerpo finito de dos elementos, sean
$\alpha_1 = (X,Y)$ y $\alpha_2 = (X-1,Y-1)$. Haciendo uso del ejercicio anterior, demuestra que el
ideal producto $\alpha = \alpha_1\alpha_2$ es un ideal radical.
#+end_statement
Primero vemos que $\alpha_1$ y $\alpha_2$ son radicales. $\alpha_1$ lo forman todos los polinomios con
trmino independiente $0$, y ningn polinomio con trmino independiente $1$ puede
elevarse hasta tener trmino $0$. $\alpha_2$ es la imagen de $\alpha_1$ por el homomorfismo de 
anillos que lleva la indeterminada $X$ en $X+1$, as que tambin lo es.

Sabemos que $\alpha_1$,$\alpha_2$ son primos entre s. Luego $\alpha_1\alpha_2 = \alpha_1 \cap \alpha_2$. Ahora tenemos
que:

\[\sqrt{\alpha_1\alpha_2} = \sqrt\alpha_1 \cap \sqrt\alpha_2 = 
\alpha_1\cap\alpha_2 = \alpha_1\alpha_2\]

***** Ejercicio 36
Sea $x \in \sqrt{\alpha}$, entonces $x^n \in \alpha \subset \bigcap \pi_i$, pero $x^n \in \pi_i$ me da $x \in \pi_i$, luego $x \in \bigcap \pi_i$.

***** Ejercicio 37
***** Ejercicio 38
***** Ejercicio 39
***** Ejercicio 40
***** Ejercicio 41
****** Punto 1
 Veamos que la aplicacin que va del producto de ideales a $R$ es un homomorfismo
 de grupos abelianos multiplicativo biyectivo.

 \[ f((x_1,\dots,x_n)) = x_1+\dots+x_n\]

 Por la definicin de *conjunto independiente*, sabemos que dado $x\in R$ existen nicos
 $x_1 \in \alpha_1, x_2 \in \alpha_2,\dots, x_t \in \alpha_t$ tales que $x = x_1 + \dots + x_t$. Esto en el caso $2$ es trivial, y
 se puede ampliar por induccin.

****** Punto 2
 Por el apartado primero, sabemos que existen $e_1+e_2+\dots+e_t = 1$. Puedo tomar
 $\alpha_i$ como anillo sobre la suma y el producto, pero tomando $e_i$ como unidad.

 Sea $x_i \in \alpha_i$, tenemos que $x_i = x_i(e_1+e_2+\dots+e_t)$, as que por unicidad de la 
 descomposicin, debe ser $x_i = e_ix_i$.

****** Punto 3
 Tenemos un conjunto de elementos que suman $1$, son idempotentes y ortogonales.

***** Ejercicio 43
****** Punto 1
 Tenemos $X \times \mathbb{Z}$ grupo abeliano con la suma por serlo $X$ y $\mathbb{Z}$. La asociatividad se 
 tiene por:

 \[(x_1,n_1)(x_2,n_2)(x_3,n_3) 
 = (x_1x_2x_3 + n_1x_2x_3+x_1n_2x_3+x_1x_2n_3+x_1n_2n_3+n_1x_2n_3+n_1n_2x_3, 
 n_1n_2n_3)\]

 Y la distributividad:

 \[\begin{aligned}
 (x,y)((a,b)+(c,d)) &= (x,y)(a+c,b+d) = (x(a+c)+y(a+c)+x(b+d)), y(b+d)) \\
 &= (xa+ya+xb,yb) + (xc+yc+xd,yd)
 \end{aligned}\]

****** Punto 2
 Vemos que es trivialmente cerrado para la suma y el producto. Cualquier
 elemento de $X\times \mathbb{Z}$ puede expresarse como $(x,0)+(0,n)$ as que tomamos el isomorfismo
 entre $X\times \mathbb{Z}/ X$ y $\mathbb{Z}$ siguiente:

 \[\phi(x,n) = n\]

 Bien definido porque tiene a $X$ como ncleo.

****** Punto 3
 El valor de $f'(x,0) = f(x)$ est fijado por la condicin, y por ser homomorfismo
 de anillos debe tener $f'(0,1) = 1$; por tanto, para preservar suma, $f'(x,n) = f(x)+n$.

 Ahora, para comprobar que es homomorfismo vemos que respeta las sumas, la unidad
 y los productos:

 \[\begin{align*}
 f'((a,b)(c,d)) &= f(ac+bc+da) + bd = f(a)f(c)+bf(c)+df(a)+bd \\
		&= (f(a)+b)(f(c)+d) = f'(a,b)f'(c,d)
 \end{align*}\]

***** Ejercicio 44
 $S,T$ son R-Mdulos, as que entendemos por $S\times T$ la suma directa como mdulos.
 Tomamos como definicin de $R \cong S \times T$ el que:

 \[\forall r \in R: \exists! s\in S, t\in T:\quad s + t = r\]

****** Descompone con un idempotente
 Primero vemos que $\forall r \in R: re + r(1-e) = r$, y es forma nica, porque si existieran
 dos formas de expresar $r$:

 \[\begin{align*}
 r &= s + t \\
 r &= s' + t'
 \end{align*}\]

 Entonces $(s-s') + (t-t') = 0$, y no es posible salvo que
 sean iguales, porque $s + t = 0$, con $ea + (1-e)b = 0$ conduce a:

 \[\begin{align*}
 0 &= eea + e(1-e)b &=& ea \\
 0 &= (1-e)ea + (1-e)(1-e)b &=& (1-e)b
 \end{align*}\]


****** Toda descomposicin es por idempotente
 Supongamos $R \cong S \times T$. Tenemos la nica descomposicin de $1$ como $u+v = 1$.
 Hacemos otra descomposicin de $1$ como:

 \[1 = (u+v)(u+v) = u^2+v^2+2uv\]

 Aqu tenemos que $uv \in S$ y $uv \in T$, as que $uv = 0$ (si no, tendra dos 
 descomposiciones); por tanto $1 = u^2 + v^2$, y por unicidad $u=u^2$ y $v=v^2$.

 Ahora veamos $S = (u)$, si tengo $s \in S$, entonces $su+sv = s$, y como $sv \in S$ y
 adems $sv \in T$, debe ser nulo y tenerse $s = su$.
***** Ejercicio 45
****** Punto 1
 El producto directo de ideales es trivialmente ideal.

 Sea $\alpha$ un ideal del producto directo, tomamos los siguientes ideales
 \[\beta_i = \{ e_ix \med| x \in \alpha\}\]. Siendo $\pi_i$ la proyeccin cannica, tomamos:

 \[ \alpha_i = \pi_i(\beta_i) \]

 Por ser sobreyectivo $\pi$, se tiene que es ideal. Queda probar:

 \[\alpha = \prod \alpha_i\]

****** Punto 2
 Vemos que los ideales primos son de la forma $R_1 \times \dots \times P_i \times \dots R_n$, para algn
 $P_i$ primo en $R_i$.

 Sea un ideal primo del producto, ser producto de ideales 
 \[P = \alpha_1\times\alpha_2\dots\times\alpha_n\]. Veremos que son todos el total salvo uno. Supongamos que 
 tuviramos dos ideales propios $\alpha_i,\alpha_j$, con $x_i \in \alpha_i$ y $x_j \in \alpha_j$. Tengo:

 \[x = (0,\dots,x_i,0,\dots,1,0,\dots,0) \notin \Pi\]
 \[y = (0,\dots,1,0,\dots,x_j,0,\dots,0) \notin \Pi\]

 Y sin embargo, $xy \in \pi$.

 Para maximales, la demostracin es anloga.

****** Punto 3
 Por el apartado primero, tiene $2^n$ ideales.

***** Ejercicio propuesto
 Veamos que si $x \in J(R)$, entonces $1-xy$ es unidad. Tenemos que $yx \in J(R)$. Si 
 $1-xy$ no fuera unidad, habra un maximal contenindolo, luego ese maximal contendra
 a la vez a $1-xy$ y a $xy$.

 Ahora, sea $1-xy$ unidad para cualquier $y$. Si un maximal no contuviera a $x$, entonces
 contendra a $1-xy$. Tendra que necesariamente al aadir $x$ a ese maximal obtendra
 todo el anillo. Luego $m + xy = 1$ y entonces $m = 1-xy$ sera unidad y pertenecera
 al ideal maximal, lo que es imposible.

**** Relacin 2
***** DONE Ejercicio 8
***** Ejercicio 16
#+begin_statement
Sea $\leq$  un orden en $\mathbb{N}^n$ que es total y compatible. Haciendo uso de la teora
de ideales monomiales, probad que $\leq$ es un buen orden si, y slo si, es
montono.
#+end_statement

Si es montono, entonces es monomial, y los monomiales son buenos [[*Sistemas de generadores][rdenes]].

Si es buen orden, todo $\mathbb{N}^n$ tiene un mnimo. Si fuera $a$, se tendra
que $a \leq 0$ y por tanto $2a \leq a$, llegando a $a = 2a$, lo que da $a = 0$.

***** Ejercicio 17
#+begin_statement
Sean $I,J \subset K[X_1,\dots,X_n]$ ideales monomiales generados por $\{A_1,\dots,A_s\}$ y
$\{B_1,\dots,B_n\}$, respectivamente:

  1. Demuestra que $I \cap J$ es un ideal monomial.
  2. Demuestra que $\{M_{i,j} \mid i=1,\dots,s;\;j=1,\dots,t\}$, $M_{i,j}$ es un m.c.m. de
     $A_i$ y $B_j$, es un sistema de generadores de $I \cap J$.
  3. Calcula la interseccin de los ideales $I = (X,Y^2Z,YZ^2)$ y
     $J = (X^3YZ, X^2Y, Y^2Z^3)$ en el anillo $K[X,Y,Z]$.
#+end_statement

****** Punto 1 y punto 2
Un monomio $X^\mu \in I \cap J$ debe cumplir $A_i \mid X^\mu$, $B_j\mid X^\mu$ y por tanto
$M_{ij}\mid X^\mu$ para algunos $i,j$. Todo monomio del ideal es generado por 
los $M_{ij}$.

Pero dado un $F \in I \cap J$, sus monomios deben estar en $I \cap J$ tambin,
as que todo polinomio del ideal es generado por los $M_{i,j}$, y es monomial.

****** TODO Punto 3
Como ambos son ideales monomiales, tenemos que calcular slo sus
$M_{ij}$.
 
***** Ejercicio 19
#+begin_statement
Demuestra que si $\{J_i \mid i \in I\}$ es una cadena de ideales monomiales, entonces
la unin $\bigcup_{i} J_i$ es un ideal monomial.
#+end_statement

Sea un polinomio que est en la unin. Sus monomios estn en algn $J_i$,
as que el ideal es monomial.

***** Ejercicio 20
#+begin_statement
Demostrad que la interseccin de ideales monomiales es un ideal monomial.
#+end_statement

Si un polinomio pertenece a la interseccin, todos sus monomios pertenecen
a cada ideal y a la interseccin. Por lo tanto, la interseccin es monomial.

***** Ejercicio 22
#+begin_statement
Demuestra que:

  1. Un ideal monomial es primo ssi est generado por un subconjunto 
     de $\{X_1,\dots,X_n\}$.
  2. El nmero de ideales monomiales primos es finito, y cada uno de ellos
     es finitamente generado.
  3. $(X_1,\dots,X_n)$ es el nico ideal maximal que es monomial.
#+end_statement

****** Punto 1
Si est generado de esa forma, debe ser primo, ya que es imposible que
el producto de dos polinomios que no contienen a una incgnita contenga
a la incgnita o sea nulo.

Si tengo un ideal monomial primo:

\[ I = (X^\alpha \mid \alpha \in A \subseteq \mathbb{N}^n)\]

Tengo que si $gr(\alpha) > 1$, entonces podra escribirse como $\alpha = \beta + \gamma$
y debera tenerse a $X^\beta$ o $X^\gamma$ en el ideal, generando a $X^\alpha$. Por
descenso infinito tengo todos los generadores de grado $1$.

****** Punto 2
Como son de la forma dada, debe tenerse.

****** Punto 3
Tenemos que es un cuerpo su cociente, luego debe ser un ideal
maximal:

\[ \frac{K[X_1,\dots,X_n]}{(X_1,\dots,X_n)} \cong K\]

Ahora bien, todo ideal maximal es primo, y por tanto de la forma
anterior, y por tanto est contenido en este, que debe ser el nico
maximal.

***** Ejercicio 26
#+begin_statement
Da un ejemplo de dos polinomios $F,G \in K[X_1,\dots,X_n]$ tales que
$Exp((F,G)) \not\subseteq \{exp(F), exp(G)\} + \mathbb{N}^n$. Observar que la inclusin contraria
es siempre cierta.
#+end_statement

Incluso en una variable podemos tener $F = X^2+X$ y $G = X^2-X$, que
cumplen:

\[Exp((F,G)) = \{1\}+\mathbb{N}^n\]
$\{exp(F),exp(G)\} + \mathbb{N}^n = \{2\} + \mathbb{N}^n$

La inclusin contraria es cierta porque podemos multiplicar por monomios
como $X^\gamma$ para cualquier $\gamma$.

***** Ejercicio 32
Vemos que en el primer caso queda invariante en el algoritmo de Buchberger
y en el segundo no. Es decir, las semizigias dan un resto distinto de cero
slo en el segundo caso.

*** Prcticas
**** Prctica 1: Anillos e ideales
***** Anillos bsicos
#+BEGIN_SRC sage
  ZZ in Fields
  ZZ in EuclideanDomains
#+END_SRC

#+RESULTS:
: False
: True

****** Extensiones algebraicas
 #+BEGIN_SRC sage
 K = NumberField(x^2+1, 's')
 OK = K.ring_of_integers()
 OK
 SS = NumberField(x^2-5,'s').ring_of_integers()
 SS.0
 SS
 #+END_SRC

 #+RESULTS:
 : Gaussian Integers in Number Field in s with defining polynomial x^2 + 1
 : 1/2*s + 1/2
 : Maximal Order in Number Field in s with defining polynomial x^2 - 5

****** Anillos de enteros mdulo n
 #+BEGIN_SRC sage
 Z7 = Integers(7)
 Z7.is_field()
 Z8 = Integers(8)
 Z8.cardinality()
 #+END_SRC

 #+RESULTS:
 : True
 : 8

****** Anillos de polinomios
 #+BEGIN_SRC sage
 P = QQ['x']
 P
 P2 = QQ['x','y','z']
 P2
 #+END_SRC

 #+RESULTS:
 : Univariate Polynomial Ring in x over Rational Field
 : Multivariate Polynomial Ring in x, y, z over Rational Field

***** Cuerpos finitos
#+BEGIN_SRC sage
K = GF(5)
a = K.0
a+a+a+a
K.characteristic()
#+END_SRC

#+RESULTS:
: 4
: 5

****** Cuerpos de fracciones
 #+BEGIN_SRC sage
 P.<x> = QQ[]
 K = P.fraction_field()
 1/x in K
 #+END_SRC

 #+RESULTS:
 : True

***** Producto de anillos
#+BEGIN_SRC sage
CZQ = ZZ.cartesian_product(QQ)
CZQ
CZQ.one()
#+END_SRC

#+RESULTS:
: The Cartesian product of (Integer Ring, Rational Field)
: (1, 1)

***** Ideales
#+BEGIN_SRC sage
P.<x,y> = QQ[]
I = Ideal(P,[x+y,x^2+1])
I
ZZ8 = ZZ.quotient(ZZ.ideal(8))
ZZ8 == Integers(8)
#+END_SRC

#+RESULTS:
: Ideal (x + y, x^2 + 1) of Multivariate Polynomial Ring in x, y over Rational Field
: True

****** Inclusin de ideales
 Definimos la inclusin de ideales y sobrecargamos el mtodo de 
 orden para expresarla.
 #+BEGIN_SRC sage
   I = 2*ZZ
   J = 4*ZZ
   def contenido(I,J):
       return I+J == J

   contenido(I,J)
   contenido(J,I)
   sage.rings.ideal.Ideal_pid.__lt__=contenido
   I < J
   J > I
 #+END_SRC

 #+RESULTS:
 : False
 : True
 : False
 : True

****** Operaciones con ideales
 #+BEGIN_SRC sage
   # Suma de ideales
   4*ZZ + 6*ZZ

   # Producto de ideales
   (4*ZZ)*(6*ZZ)

   # Interseccin de ideales
   def intersection(I,J):
       a = I.gen()
       b = J.gen()
       q = (a*b).quo_rem(gcd(a,b))
       return Ideal(q[0])
   sage.rings.ideal.Ideal_pid.__and__=intersection

   (4*ZZ)&(6*ZZ)

   # Cociente de ideales
   def cocienteideales(I,J):
       if not (J<I):
           raise "El cociente necesita de inclusin"
       return I.gens()*I.ring().quo(J)
   sage.rings.ideal.Ideal_pid.__div__=cocienteideales

   (2*ZZ)/(4*ZZ)

   # Operaciones con ideales
   6*ZZ/((6*ZZ)&(4*ZZ))
 #+END_SRC

 #+RESULTS:
 : Principal ideal (2) of Integer Ring
 : Principal ideal (24) of Integer Ring
 : Principal ideal (12) of Integer Ring
 : Principal ideal (2) of Ring of integers modulo 4
 : Principal ideal (6) of Ring of integers modulo 12

****** Ideales primos y maximales
 #+BEGIN_SRC sage :file images/idealpoly.png :output both
 P.<x,y> = QQ[]
 I = (x^3-y^2)*P
 I.is_prime()
 implicit_plot(x^3-y^2, (x,-1,2), (y,-1,1))
 #+END_SRC

 #+RESULTS:
 [[file:images/idealpoly.png]]

****** Ideales radicales
 #+BEGIN_SRC sage
 R.<x,y> = GF(2)[]
 I = (x,y)*R
 J = (x-1,y-1)*R
 K = I*J
 K.radical() == K
 #+END_SRC

 #+RESULTS:
 : True

***** Homomorfismos de anillos
#+BEGIN_SRC sage
# Inclusin 
H = Hom(ZZ,QQ)
inc = H([1])
inc(1)

# Homomorfismo al cociente
f = ZZ.hom([1],ZZ.quo(4*ZZ))
f(1) == f(5)
f(6)

# Composicin de homomorfismos
R.<x,y,z> = QQ[]
S.<t> = QQ[]
f = R.hom([t^3,t^5,t^7],S)
g = S.hom([t^2],S)
g*f
#+END_SRC

#+RESULTS:
#+begin_example
1
True
2

Ring morphism:
  From: Multivariate Polynomial Ring in x, y, z over Rational Field
  To:   Univariate Polynomial Ring in t over Rational Field
  Defn: x |--> t^6
        y |--> t^10
        z |--> t^14
#+end_example

**** Prctica 2: Anillos de polinomios
***** Anillos de polinomios
    Para poder usar las variables del anillo de polinomios en 
    sage debemos insertarlas

#+BEGIN_SRC sage
P = PolynomialRing(QQ,['x','y','z','t'])
P.inject_variables()
x in P
#+END_SRC
#+RESULTS:
: Defining x, y, z, t
: True

***** Factorizacin
#+BEGIN_SRC sage
P.<x,y> = QQ[]
c = x^3-y^2
c.factor()

f = x*y-1
g = x^2+y^2-4
#+END_SRC
#+RESULTS:
: (-1) * (-x^3 + y^2)

***** Polinomios en una variable
#+BEGIN_SRC sage
R = Zmod(2)['x']
R.inject_variables()
filter(is_prime,list(R.monics(of_degree=5)))
#+END_SRC
#+RESULTS:
: Defining x
: 
: [x^5 + x^2 + 1,
:  x^5 + x^3 + 1,
:  x^5 + x^3 + x^2 + x + 1,
:  x^5 + x^4 + x^2 + x + 1,
:  x^5 + x^4 + x^3 + x + 1,
:  x^5 + x^4 + x^3 + x^2 + 1]

***** Ejemplo: Cuerpo de 256 elementos
Vamos a tomar un cuerpo de 256 elementos y vamos a multiplicar en l usando 
logaritmos. Es decir, vamos a representar cada polinomio como un nmero binario
y vamos a sumarlos para multiplicar.

#+BEGIN_SRC sage
p = R.irreducible_element(8)
Q = R.quo(p*R,'a')
Q.is_field()
a = Q.0

# Potencias de a, son todo elementos de Q
l = [a^i for i in range(2**8-1)]
l.index(a^2+1)
#+END_SRC
#+RESULTS:
: True
: 50

***** TODO Ejercicio 1
    #+begin_statement
    Demuestra que la clase de $x+1$ genera $\mathbb{Z}_2[x]/(x^8+x^4+x^3+x+1)$.
    #+end_statement

***** rdenes monomiales
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,x,3,order='lex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)

      P=PolynomialRing(QQ,x,3,order='degrevlex')
      P.inject_variables()

      ds = list(WeightedIntegerVectors(2,[1,1,1]))+list(WeightedIntegerVectors(1,[1,1,1]))
      ms=[P({tuple(l):1}) for l in ds]
      sorted(ms)
    #+END_SRC

    #+RESULTS:
    : Defining x0, x1, x2
    : [x2, x2^2, x1, x1*x2, x1^2, x0, x0*x2, x0*x1, x0^2]
    : Defining x0, x1, x2
    : [x2, x1, x0, x2^2, x1*x2, x0*x2, x1^2, x0*x1, x0^2]

****** Ejercicio
     Ordena mediante el orden lexicogrfico y lexicogrfico graduado todos los 
     monomios en tres variables de grado 3.

     #+BEGIN_SRC sage
       P=PolynomialRing(QQ,x,3)
       P.inject_variables()

       ds = list(WeightedIntegerVectors(3,[1,1,1]))
       ms=[P({tuple(l):1}) for l in ds]
       sorted(ms)
     #+END_SRC

     #+RESULTS:
     #+begin_example
     Defining x0, x1, x2

     [x2^3,
      x1*x2^2,
      x0*x2^2,
      x1^2*x2,
      x0*x1*x2,
      x0^2*x2,
      x1^3,
      x0*x1^2,
      x0^2*x1,
      x0^3]
     #+end_example

***** Algoritmo de la divisin
**** Prctica 3: Bases de Grbner
***** Bases de Grbner
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ, ['x','y','z'], order='lex')
      I = (x^4-y^4+z^3-1, x^3+y^2+z^2-1)*P
      len(I.groebner_basis())
    #+END_SRC

    #+RESULTS:
    : 5

***** Pertenencia de polinomios
    #+BEGIN_SRC sage
      P.<x,y>=QQ[]
      I = (x^2-y^3,x)*P
      I.groebner_basis()
      y**3 in I
    #+END_SRC

    #+RESULTS:
    : [y^3, x]
    : True

****** Ejercicio
     #+BEGIN_SRC sage
       P.<x,y,z>=QQ[]
       g1=x^2*y*z+y^2*z+1
       g2=x*y^2*z+y*z^2-2
       g3=x*y*z^2+z+3
       I = (g1,g2,g3)*P
       len(I.groebner_basis())
       P.quo(I).()
     #+END_SRC

     #+RESULTS:
     : 8
     : Rational Field

***** Cpside
    #+BEGIN_SRC sage
      P = PolynomialRing(QQ,["t","x","y"],order="lex")
      P.inject_variables()
      I = (x-t^2,y-t^3)*P
      I.groebner_basis()
      I.elimination_ideal([t])
    #+END_SRC

    #+RESULTS:
    : Defining t, x, y
    : [t^2 - x, t*x - y, t*y - x^2, x^3 - y^2]
    : Ideal (x^3 - y^2) of Multivariate Polynomial Ring in t, x, y over Rational Field

    
****** Ejercicio
     #+BEGIN_SRC sage
       P = PolynomialRing(QQ,["t","x","y","z","u"],order="lex")
       P.inject_variables()
       I = (x-t-u, y-t^2-2*t*u, z-t^3-3*t^2*u)*P
       I.elimination_ideal([t,]u)
     #+END_SRC

     #+RESULTS:
     : Defining t, x, y, z, u
     : Ideal (4*x^3*z - 3*x^2*y^2 - 6*x*y*z + 4*y^3 + z^2) of Multivariate Polynomial Ring in t, x, y, z, u over Rational Field
     
** lgebra III
# Exportaba con config.setup

*** 1. Polinomios simtricos
**** Motivacin: La cbica
***** Polinomios cbicos
Toda ecuacin cbica polinmica puede escribirse en la forma
\(Y^3 + pY + q\), tomando un cambio de variable desde la original
\(X \mapsto - \frac{1}{3} b\). Esto se llama una cbica deprimida.

****** Mtodo de Vieta
El mtodo de Vieta toma \(t = w - \frac{p}{3w}\), y llega a la ecuacin:

\[w^3 + q - \frac{p^3}{27w^3} = 0\]

Ahora podemos resolver esa cuadrtica y resolver luego la ecuacin
en $w^3$.

**** 1.1. Polinmios simtricos
***** Polinomios simtricos
Un *polinomio simtrico* es aquel invariante por $f_\sigma$ para cualquier $\sigma \in S_r$, 
donde $f_\sigma (X_i) = X_{\sigma i}$. Llamamos $Sim(A[X_1\dots X_n])$ al subanillo de polinomios 
simtricos.

***** Componentes homogneas
Llamamos *componente homognea* a cada sumando homogneo maximal de un
polinomio. Un polinomio es simtrico si y slo si cada una de sus
componentes lo es.

***** Polinomios simtricos elementales
Los polinomios simtricos elementales son aquellos de la forma:

\[e_i = \sum_{i_1 < \dots < i_i} X_{i1} X_{i2} \dots X_{ii}\]

***** Teorema fundamental de los polinomios simtricos
Los polinomios elementales generan cada polinomio $Sim(A[X_1\dots X_n])$ 
de forma nica. En particular,

\[\omega : A[X_1,\dots,X_r] \longrightarrow Sim(A[X_1,\dots,X_r])\]

con $\omega(a) = a$ y $\omega(X_i) = e_i$ es un isomorfismo.

****** Demostracin
Damos una relacin de orden lexicogrfica entre los monomios de un
polinomio simtrico homogneo. Al mayor de ellos, llamado 
$X_1^{k_1} \dots X_r^{k_r}$ le restamos $e^{b1}_1 e^{b2}_2 \dots e^{br}_r$, donde
$b_i = k_i - k_{i+1}$. Nos quedar $0$ u otro polinomio simtrico de
igual grado pero menor en el orden lexicogrfico. Este proceso debe
ser finito.

La unicidad se obtiene con $0 = h(e_1\dots e_r) - k(e_1\dots e_r) =
l(e_1 \dots e_r)$.

**** 1.2. Polinomios alternados
***** 1.2.1. Polinomio alternado
Un polinomio $f$ es alternado cuando para toda permutacin se tiene
$\sigma(f) = sign(\sigma) f$.

**** 1.3. La resultante
***** 1.3.2. Resultante
Dados dos polinomios $f,g$ en un cuerpo $K$ en el que descomponen 
podemos escribirlos como:

\[ f = a_n(X-\alpha_1)\dots(X-\alpha_n) = a_n \prod^n_{i=1}(X-\alpha_i)\]
\[ g = b_n(X-\beta_1)\dots(X-\beta_n) = a_n \prod^n_{i=1}(X-\beta_i)\]

La *resultante* busca ser una expresin que se anula cuando tienen
raz comn, y se define como:

\[ R(f,g) = a_n^m b_m^n \prod^n_{i=1} \prod^m_{j=1} (\alpha_i - \beta_j)\]

***** TODO 1.3.3. Propiedades de la resultante
La resultante de dos polinomios $f,g$ cumple:

 1. $R(f,g) = 0$ ssi tienen una raz comn.
 2. $R(g,f) = (-1)^{nm}R(f,g)$, siendo $nm$ el producto del nmero de races.
 3. $R(f,g) = a^m_n \prod^n_{i=1} g(\alpha_i)$
 4. $R(fg,h) = R(f,h)R(g,h)$, $R(f,gh) = R(f,g)R(f,h)$
 5. Si $m=0$, entonces $R(f,k) = k^n$
 6. $R(X^k,f) = a_0^k$; con $R(f,X^k) = (-1)^{nk}a_0^k$

**** 1.4. Discriminante
***** 1.4.1. Races mltiples
Podemos usar la resultante para caracterizar los polinomios
con races mltiples, que son aquellos que comparten raz con
su derivada.

\[ R(f,f') = a_n^{n-1} \prod f'(\alpha_j)\]

***** 1.4.1. El discriminante
El *discriminante* de un polinomio con races $\alpha_1, \dots, \alpha_n$ en una 
clausura algebraica es:

\[\text{Discr}(p) = a^{2n-2}_n \prod_{i<j}(\alpha_i-\alpha_j)^2\]

***** 1.4.1. Relacin con la resultante
\[R(p,p') = (-1)^{\frac{n(n-1)}{2}}a_n \text{Discr}(p)\]

***** 1.4.2. Propiedades del discriminante
El determinante cumple:

  1. $f_1,f_2 \in F[X] \implies D(f_1f_2) = D(f_1)D(f_2)R(f_1,f_2)^2$.
  2. $f_1,\dots,f_r \in F[X] \implies D(f_1\dots f_r) = D(f_1)\dots D(f_r)R^2$ con $R \in F$.

**** 1.5. Mtodos de clculo
***** TODO 1.5.2. Mtodo modular
***** TODO 1.5.3. Por el algoritmo de Euclides
***** 1.5.4. Resultante de Euler-Sylvester-Cayley
Definimos la resultante de Euler-Sylvester-Cayley:

\[
R(f,g) = \left| \begin{matrix}
a_n & a_{n-1} & \dots & a_0 & 0 & \dots &\\
0   & a_n & \dots & a_{1} & a_0 & 0 & \dots \\
0   &   0 & a_n & \dots & a_1 & a_0 & \dots \\
&      &     &\vdots & & & \\
b_m & b_{m-1} & \dots & b_0 & 0 & \dots &\\
0   & b_m & \dots & b_1 & b_0 & 0 & \dots \\
0   &   0 & b_m & \dots & b_1 & b_0 & \dots \\
\end{matrix} \right|
\]

****** Origen
La resultante se obtiene como la determinante de la
matriz del sistema de ecuaciones que dan:

\[ \begin{aligned}
X^{m-1} f &= 0 \\
X^{m-2} f &= 0 \\
& \vdots \\
1f &= 0 \\
X^{n-1}g &= 0 \\
X^{n-2}g &= 0 \\
& \vdots \\
1g &= 0 \\
\end{aligned}\]

Por Teorema de Rouch, este sistema tiene solucin ssi 
el determinante de los coeficientes es cero.

***** 1.5.5. Resultante como determinante
La *resultante* de dos polinomios $p,q$ es el determinante solucin de 
$pq' - qp' = 0$ dados $p$ y $q$.

\[R(p,q) = \left| \begin{matrix}
a_0 & a_1 & \dots & a_n & 0 & \dots &\\
0   & a_0 & \dots & a_{n-1} & a_n & 0 & \dots \\
0   &   0 & a_0 & \dots & a_{n-1} & a_n & \dots \\
&     &     &\dots & & & \\
b_0 & b_1 & \dots & b_m & 0 & \dots &\\
0   & b_0 & \dots & b_{m-1} & b_m & 0 & \dots \\
0   &   0 & b_0 & \dots & b_{m-1} & b_m & \dots \\
\end{matrix} \right|
\]

Y llamamos *matriz resultante* a la matriz de la que es determinante.

*** 2. Series de grupos y grupos solubles
**** 2.1. Series de composicin
***** 2.1.1. Factor
Sea $G$ grupo, llamamos factor a cualquier $H/H'$ donde $G > H \trianglerighteq H'$.

***** 2.1.2. Proyeccin
Llamamos proyeccin de $H/H'$ sobre $K/K'$, ambos factores, a:

\[\frac
{K'(H\cap K)}
{K'(H'\cap K)}\]

***** 2.1.3. Serie
Llamamos serie a toda cadena finita:

\[ G > G_1 > G_2 > \dots > G_r = 1\]

Donde llamamos a $r$ la longitud del grupo.

***** 2.1.4. Refinamiento de una serie
Dadas dos series,

\[ G > G_1 > G_2 > \dots > G_r = 1\]
\[ G > G'_1 > G'_2 > \dots > G'_r = 1\]

llamamos a la segunda refinamiento si todo grupo suyo aparece en
la primera. Es refinamiento propio si adems son distintas.

***** 2.1.5. Serie normal
Una serie es *normal* cuando se verfica $G_i \trianglerighteq G_{i+1}$. Llamamos a $G_{i-1}/G_i$
los *factores* de la serie.

***** 2.1.5. Serie propia
Una serie propia tiene slo inclusiones propias $G_i \gneq G_{i+1}$.

***** 2.1.5. Isomorfismo de series
Dos series son isomorfas cuando existe una permutacin que hace 
isomorfos sus factores:

\[\exists \sigma \in S_r : \quad 
G_{i-1}/G_i \cong H_{\sigma(i)-1}/H_{\sigma(i)}\]

***** 2.1.5. Serie de composicin
Una *serie de composicin* es una serie normal propia sin 
refinamientos normales. Llamamos *factores de composicin* a sus
factores.

***** 2.1.6. Grupo simple
Un grupo simple es aquel que no admite subgrupos normales propios.

***** 2.1.7. Grupos abelianos finitos simples
Un grupo abeliano, finito y simple es isomorfo a $\mathbb{Z}_p$ para algn $p$ primo.

****** TODO Demostracin

***** 2.1.8. Los factores de composicin son simples
Los factores de cualquier serie de composicin son simples.

****** TODO Demostracin

***** 2.1.9. Existencia de la serie de composicin
Todo grupo finito posee una serie de composicin.

***** 2.1.10. Teorema de refinamiento de Schreier
Dos series normales de un grupo tienen refinamientos isomorfos.

***** 2.1.11. Teorema de Jordan-Holder
Si un grupo admite serie de composicin, toda serie normal propia puede
refinarse a una serie de composicin. Las series de composicin son 
isomorfas.

**** 2.2. El programa de Holder
***** TODO 2.2.1. Teorema de clasificacin de grupos simples finitos
***** 2.2.2. Teorema de Abel
El grupo $A_n$ es simple para $n \geq 5$.

****** TODO Demostracin

***** 2.2.3. Teorema de Feit-Thompson
Si $G$ es simple de orden impar, entonces $G \cong \mathbb{Z}_p$ con $p$ primo.

****** TODO Demostracin

**** 2.3. Grupos solubles
***** 2.3.1. Serie derivada
Dado $G$, definimos la serie derivada de $G$ como:

\[G = G^0 > G' > G'' > \dots \]

donde $G^{(i+1} = [G^{(i}, G^{(i}]$ es el grupo derivado. Ntese que no tiene por
qu ser finita.

***** 2.3.2. Caracterizacin de grupos solubles
Para $G$ grupo finito, equivalen:

 1. Los factores de composicin son cclicos de orden primo.
 2. $G$ tiene serie normal con factores cclicos.
 3. $G$ tiene serie normal con factores abelianos.
 4. Se tiene $G^{(i} = 1$.

****** TODO Demostracin

***** 2.3.3. Grupo soluble
Un grupo es soluble si tiene una serie normal con factores cclicos.

***** 2.3.4. Subgrupos de solubles
Son solubles:

 1. Los subgrupos de un grupo soluble.
 2. Los cocientes de un grupo soluble.
 3. Si $N$ y $G/N$ son solubles, $G$ es soluble.

****** TODO Demostracin

***** 2.3.5. Producto de solubles
Todo producto finito de grupos solubles es soluble.

****** TODO Demostracin

***** 2.3.6. Teorema de Hall
Sea $G$ soluble de orden $mk$ cumpliendo $mcd(m,k) = 1$. Entonces:

 1. $G$ posee un grupo de orden $m$.
 2. Dos subgrupos cualesquiera de orden $m$ son conjugados.
 3. Todo subgrupo de orden $m' \mid m$ est contenido en uno de orden $m$.
 4. El nmero de subgrupos de orden $m$, $r_m$ es producto de factores
    congruentes a $1$ mdulo algn factor primo de $m$. Es adems potencia
    de primo y divide a alguno de los factores de $G$.

****** TODO Demostracin

***** 2.3.7. Caracterizacin de grupo soluble
Dado $G$ grupo finito, es soluble ssi para cualquier descomposicin $|G|=mk$
con $mcd(m,k) = 1$, existe un subgrupo de orden $m$.

*** 3. Extensiones de cuerpos
**** 3.1. Generalidades
***** 3.1.1. Extensiones de cuerpos
Una *extensin de cuerpos* es un subcuerpo $K$ de $F$, se nota por $F/K$. 

***** 3.1.2. Grado de la extensin
Llamamos *grado* a la dimensin de $F$ como espacio vectorial.
Notamos por $[F : K]$.

***** 3.1.3. Cuerpo intermedio
Un cuerpo intermedio entre $F$ y $K$ es cualquier subcuerpo de $F$ 
conteniendo a $K$.

***** 3.1.4. Torre de cuerpos
Una torre es una sucesin de subcuerpos:

\[F_0 \subset F_1 \subset \dots \subset F_n\]

***** 3.1.5. Extensiones finitas
Una extensin es finita ssi $[F:K]$ es finito.

***** 3.1.6. Base de una torre de inclusiones
Sea $K \supset F \supset E$ una torre de inclusiones. Sean $\{u_i\}_{i\in I}$ una base de $E$
sobre $F$ y $\{v_j\}_{j\in J}$ una base de $F$ sobre $K$. Entonces $\{u_iv_j\}$ es una base
de $E$ sobre $K$.

****** Demostracin
******* Es sistema de generadores
Si tenemos ambos sistemas de generadores, podemos escribir cada
elemento de $E$ como:

\[ e 
= \sum u_i f_i 
= \sum u_i \left(\sum v_j k_{ij}\right) 
= \sum u_iv_ik_{ij}\]

******* Son linealmente independientes
Aplicando la independencia lineal de cada una de las bases:

\[ \sum u_iv_jk_{ij} 
= \sum u_i \left( \sum v_jk_{ij}\right) = 0\]

Tenemos que $\sum v_jk_{ij} = 0$, luego $k_{ij} = 0$.

***** 3.1.7. Teorema del grado
Sean $K \subset F \subset E$, extensiones de cuerpos, se tiene que:

\[ [E:K] = [E:F][F:K] \]

****** Demostracin
Teniendo una base de cada uno de ellos, calculamos la base
de la [[*3.1.6. Base de una torre de inclusiones][torre de inclusiones]], que nos da la dimensin.

***** 3.1.8. Corolario al Teorema del grado: finitud
Sean $K \subset F \subset E$, la extensin $E/K$ es finita ssi las extensiones
$E/F$ y $F/K$ lo son.

****** Demostracin
Si ambas son finitas, podemos aplicar el [[*3.1.7. Teorema del grado][teorema del grado]]. Cuando
$E/K$ es finita, tenemos que $E/F$ tiene como sistema generador a la
base y $F/K$ es un subespacio de $E/K$.

***** 3.1.9. Corolario al Teorema del grado: torres de cuerpos
Sea $F_0 \subset F_1 \subset \dots \subset F_n$ torre de longitud $n$, entonces:

\[ [F_n : F_0] =
[F_n:F_{n-1}] \dots [F_2:F_1][F_1 : F_0]
\]

****** Demostracin
Por induccin sobre la longitud de la torre y aplicando el teorema
del grado a cada paso.

***** 3.1.10. Corolario al Teorema del grado: extensiones primas
Sea $F/K$ una extensin tal que $[F:K] = p$ es primo. Entonces no
existe ningn cuerpo intermedio propio.

****** Demostracin
Usando el teorema del grado, tenemos que debera tener grado $p$, en
cuyo caso sera un subespacio de la misma dimensin que $F$, y por
tanto $F$. O debera tener grado $1$, en cuyo caso sera $K$.

**** 3.2. Elementos algebraicos y extensiones algebraicas
***** 3.2.1. Homomorfismo unital
Para todo anillo $A$ existe un nico homomorfismo de anillos
$1_\mathbb{Z} : \mathbb{Z} \longrightarrow A$, llamado *homorfismo unital*.

***** 3.2.2. Caracterstica del anillo
La caracterstica de $A$ es el entero no negativo que genera
al ideal $ker(1_\mathbb{Z})$.

***** 3.2.3. Caracterstica en dominios de integridad
Si $A$ es dominio de integridad, $car(A)$ es primo o $0$.

****** Demostracin
Trivialmente desde el homomorfismo unital. Si no fuera as,
tendramos $ab = 0$ enteros.

***** 3.2.4. Caracterizacin de la caracterstica
$car(A)=n$ ssi $n$ es el menor entero positivo tal que $na = 0$ para
todo $a \in A$.

****** Demostracin
Si hubiera otro menor, debera pertenecer al ncleo del homomorfismo
unital, y no podra ser generado por $n$. Si cumple la condicin
y es el menor, todo el resto de elementos del ncleo deben ser 
mltiplos, porque si no lo fueran, podramos crear un menor con 
Bezout.

***** 3.2.5. Interseccin de anillos
Sea $A$ un anillo y sea $\{B_i\}_{i\in I}$ una familia de subanillos. Entonces
$\bigcap B_i$ es subanillo. Anlogo para cuerpos y subcuerpos.

****** Demostracin
Si dos elementos pertenecen a todos los $B_i$, tenemos que su suma
y su producto pertenece a cada uno de ellos.

***** 3.2.6. Anillo primo
Llamamos subanillo primo de $A$ a la interseccin de todos los 
subanillos de $A$.

***** 3.2.7. Clasificacin de anillos primos
El subanillo primo de un $A$ es isomorfo a $\mathbb{Z}$ si $car(A) = 0$ y
a $\mathbb{Z}/n\mathbb{Z}$ si $car(A) = n \neq 0$.

****** Demostracin
En ambos casos, ellos son subanillos por ser imgenes del 
homomorfismo unital, como se comprueba por primer teorema de
isomorfa.

***** 3.2.8. Subcuerpo primo
Llamamos subcuerpo primo de $K$ a la interseccin de todos los
subcuerpos de $K$.

***** 3.2.9. Clasificacin de subcuerpos primos
El subcuerpo primo de un cuerpo $K$ es isomorfo a $\mathbb{Q}$ cuando
$car(K)=0$ y a $\mathbb{Z}/p\mathbb{Z}$ cuando $car(K) = p \neq 0$.

****** Demostracin
De nuevo, vuelve a tenerse una inyeccin de ambos por el 
homomorfismo unital. Cualquier subanillo contendr a $1$ y por
tanto a este subcuerpo.

***** 3.2.10. Subanillo generado
Sea $F/K$ extensin con $S\subseteq F$; llamamos *subanillo generado*
$K[S]$ a la interseccin de todos los subanillos de $F$ conteniendo
a $K$ y a $S$.

***** 3.2.10. Subcuerpo generado
Sea $F/K$ extensin con $S \subseteq F$; llamamos *subcuerpo generado*
$K(S)$ a la interseccin de todos los subcuerpos de $F$ conteniendo
a $K$ y a $S$.

***** 3.2.11. Propiedades de subanillos y subcuerpos generados
Para $S,T \subseteq F$ extensin de $K$, tenemos:

 - $K[S \cup T] = K[S][T] = K[T][S]$
 - $K(S \cup T) = K(S)(T) = K(T)(S)$

****** Demostracin
En cualquiera de los dos casos la definicin es la interseccin
de todos los que contienen a $K$, $T$ y $S$.

***** 3.2.12. Subcuerpo compuesto
Dados $K \subset E,F \subset L$, definimos el subcuerpo compuesto
$EF = E(F) = F(E)$.

****** Demostracin
Son iguales trivialmente desde la definicin.

***** 3.2.13. Conjunto de generadores
Sea $F/K$ con $S \subseteq F$, es un subconjunto de generadores si
$F = K(S)$.

***** 3.2.14. Extensin finitamente generada
Una extensin $F/K$ es finitamente generada cuando tiene un
conjunto finito de generadores, $F = K(u_1,u_2,\dots,u_n)$.

***** 3.2.15. Extensiones simples y elementos primitivos
Una extensin $F/K$ se llama simple cuando $F = K(u)$. Al $u$
se le llama *elemento primitivo* para la extensin.

***** 3.2.16. Elementos algebraicos
$\alpha \in F$ es *algebraico* sobre $K$ si existe polinomio $f \in K[x]$ tal 
que $f(\alpha) = 0$. 

Un no algebraico es *trascendente* y una extensin es *algebraica* 
si lo son todos sus elementos.

***** 3.2.16. Polinomios irreducibles
Dado $F/K$ con $\alpha \in F$ algebraico. Existe un nico polinomio 
irreducible del que $\alpha$ es raz salvo asociados, llamado $Irr(\alpha)$.
   
****** Existencia y unicidad del polinomio irreducible
Tomo el ncleo del homomorfismo que evala un polinomio en $\alpha$. 
Por ser un ideal en PID, estar generado por algn polinomio $f$ 
no nulo y no constante.

Este ser irreducible, porque si no lo fuera, con $f = g_1g_2$ se 
tendra:

\[0 = f(\alpha) = g_1(\alpha)g_2(\alpha)\]

Un polinomio de grado mnimo debera estar dentro del ideal, 
y por tanto ser asociado de $f$, que lo genera.

***** 3.2.16. Propiedades de los polinomios irreducibles
Sea $F/K$ extensin con $u \in F$ algebraico. Se cumple:

  1. $K(u) = K[u]$
  2. $K[u] \cong K[X]/(Irr(u,K))$
  3. $[K(u):K]$ es igual al grado de $Irr(u,K)$.
  4. $\{1,u,u^2,\dots,u^{n-1}\}$ es una base de $K[u]$ sobre $K$.
  5. $f(u)=0$ ssi $Irr(u,K) \mid f$.

Llamamos *grado* del elemento $u$ al grado de $Irr(u,K)$.

****** Demostracin
******* Punto 1
Sabemos que el anillo generado est dentro del cuerpo generado,
y adems, $u^{-1}$ est en el anillo generado porque, si su polinomio
irreducible nos da $\sum a_iu^i = 0$, tenemos:

\[ u \left(a_nu^{n-1} + a_{n-1}u^{n-2} + \dots a_1 \right)\frac{1}{a_0} = 1\]

******* Punto 2
Aplicando el primer teorema de isomorfa al morfismo evaluacin,
tenemos el resultado.

******* Punto 3
Tenemos que $1,u,u^2,\dots,u^{n-1}$ son linealmente independientes porque
una relacin lineal entre ellos dara un polinomio menor que el
mnimo. Adems son base trivialmente porque $u^{-1}$ puede expresarse
linealmente como polinomio suyo como mostramos [[*Punto 1][antes]] y porque
cuaquier expresin polinmica de grado mayor a $n$ puede dividirse 
por el polinomio irreducible para obtener otra de grado menor.

******* Punto 4
La misma demostracin [[*Punto 3][anterior]].

******* Punto 5
Un polinomio verificando $f(u)=0$ est dentro del ncleo del
homomorfismo evaluacin.

***** 3.2.17. Algebraicos en una torre de cuerpos
Sea $K \subset F \subset E$ con $u \in E$ algebraico sobre $K$, entonces $u$ es
algebraico sobre $F$ y $Irr(u,F)$ divide a $Irr(u,K)$.

****** Demostracin
Notamos que $Irr(u,K)$ es tambin un polinomio sobre $F$ que anula
a $u$, as que, por las propiedades de los polinomios irreducibles,
se debe tener $Irr(u,F) \mid Irr(u,K)$.

***** 3.2.18. Extensiones algebraicas
Una extensin se llama *algebraica* si todos sus elementos lo son.
Es *trascendente* en otro caso.

***** 3.2.19. Elementos algebraicamente independientes
Los elementos $\{u_i \mid i\in I\}$ son algebraicamente independientes si el
homomorfismo de evaluacin sobre el cuerpo de polinomios en varias
variables $K[X_i \mid i\in I]$ es inyectivo.

***** 3.2.20. Extensiones puramente trascendentes
Una extensin $F/K$ se llama puramente trascendente si $F = K(S)$
donde $S$ un conjunto de algebraicamente independientes.

***** 3.2.21. Generacin finita de elementos
Para $F/K$ extensin cualquiera $S \subseteq F$, se tiene:

 1. Para $u \in K[S]$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K[u_1,\dots,u_n]$.
 2. Para $u \in K(S)$ existe un subconjunto $\{u_1,\dots,u_n\} \subset S$ tal que
    $u \in K(u_1,\dots,u_n)$.

****** Demostracin
Tener $u \in K[S]$ nos da una expresin polinmica finita como elementos
de $S$. Los elementos involucrados en esa expresin crean una extensin
finita en la que est $u$. Anlogo en el caso de cuerpos.

***** 3.2.22. Generacin del compuesto
Sean $K \subset E,K(S) \subset L$, entonces $EK(S) = E(S)$.

****** Demostracin
Por definicin del cuerpo compuesto, ser $EK(S) = K(E)(S) = E(S)$.

***** 3.2.23. Grado de una extensin compuesta
Sean $K \subset E,F \subset L$. Entonces:

\[ [EF:K] \leq [E:K][F:K]\]

****** Demostracin
En el caso finito, el cuerpo generado por las bases de $E$ y
de $F$ multiplicadas contiene a todo elemento de $E$ y de $F$, por 
lo que es sistema de generadores de $EF$.

***** 3.2.24. Extensiones primas relativas
Sean $K \subset E,F \subset L$ con $n = [E:K]$ y $m = [F:K]$ primos relativos.
Entonces $[EF:K] = [E:K][F:K]$.

****** Demostracin
Sea $\{f_i\}$ base de $F$ sobre $K$. Tenemos que es sistema de generadores
de $F$ sobre $E$, y por tanto, de $EF$ sobre $E$. As $[EF:E] \leq [F:K]$
y anlogamente $[EF:F] \leq [E:K]$.

Por otro lado, por teorema del grado tenemos:

\[[EF:K] = [EF:F][F:K] = [EF:F]m\]
\[[EF:K] = [EF:E][E:K] = [EF:E]n\] 

As, por ser primos relativos, tenemos $n \mid [EF:E]$ y $m \mid [EF:F]$; 
tenindose finalmente:

\[ [EF:F] = [E:K] \]
\[ [EF:E] = [F:K] \]

***** 3.2.25. Extensin finitamente generada por algebraicos es finita
Una extensin $F = K(u_1,\dots,u_n)$ finitamente generada por $u_i$ algebraicos
es finita.

****** Demostracin
Todo elemento algebraico cumple una relacin polinmica. As,
todo elemento de grado igual o mayor a esta relacin, puede
expresarse como elementos de grado menor.

Si tenemos $e_i$ como el exponente mayor al que puedo elevar $u_i$ sin
que pueda ser reescrito, tenemos un sistema de generadores de $F$ 
finito como:

\[\{ 1, u_1^1, u_1^2, \dots u_1^{e_i}, u_2^1, \dots, u_2^{e_j}, u_3^1,\dots\}\]

***** 3.2.26. Extensin generada por algebraicos es algebraica
Una extensin $K(S)/K$ es algebraica sobre $K$ ssi todo $u \in S$ es 
algebraico sobre $K$.

****** Demostracin
Si es algebraica, en particular lo es cada elemento de $S$.
Si lo son los elementos de $S$, podemos ver que cualquier 

***** 3.2.27. Finita es algebraica y finitamente generada
Una extensin es finita ssi es algebraica y finitamente generada

****** Demostracin
Tenemos que extensin finitamente generada por algebraicos es
[[*3.2.25. Extensin finitamente generada por algebraicos es finita][finita]]. Por otro lado, si es finita, tendr una base finita que
la genera; y para cada elemento de la base, $\{1,u,\dots,u^n\}$ no
ser linealmente independiente. Luego ser finita.

***** 3.2.28. Caracterizacin de elementos algebraicos
Un elemento $u \in F$ es algebraico sobre $K$ ssi existe una extensin
finita intermedia $E/K$ donde $u \in E$.

****** Demostracin
Si es algebraico de grado $n$, tenemos $K(u)$ algebraica y finitamente
generada, [[*3.2.27. Finita es algebraica y finitamente generada][luego finita]]. Si existe una extensin finita intermedia, 
ser algebraica.

***** 3.2.29. Torre algebraica
Sean $K \subset F \subset E$, $E/K$ es algebraica ssi $E/F$ y $F/K$ son ambas 
algebraicas.

****** Demostracin
******* Si es algebraica, lo son sus partes
Un elemento algebraico sobre $K$ lo ser sobre $F$. Y todo elemento
de $F$ est en $E$, luego ser algebraico sobre $K$.

******* Si las partes son algebraicas, es algebraica
Todo elemento $e \in E$ es algebraico sobre $F$, luego cumple algn
polinomio con elementos en $F$. Los elementos que generan el polinomio
en $F$ son todos algebraicos sobre $K$, luego $K$ extendido con esos
elementos es finito. Si lo extiendo con $e$, que es algebraico sobre
ellos, llego a otra extensin finita. Toda finita es [[*3.2.27. Finita es algebraica y finitamente generada][algebraica]].

***** 3.2.30. Clausura algebraica relativa
Dada $F/K$ extensin, el conjunto de elementos algebraicos forman un
subcuerpo de $F$. Llamado *clausura algebraica relativa* de $K$ en $F$.

****** Demostracin
Sean $a,b \in F$ algebraicos; entonces $K(a,b)$ es finito, luego $a+b$ y
$ab$ son tambin algebraicos.

****** Demostracin constructiva para la suma
Se puede [[http://mathoverflow.net/a/81640/45365][encontrar constructivamente]] un polinomio que tenga como
raz a la suma de dos algebraicos.

***** DONE Existencia de clausura
*Teorema de Steinitz*. Todo cuerpo tiene una extensin algebraicamente 
cerrada.

***** DONE Homomorfismos sobre un cuerpo
     Un *homomorfismo sobre cuerpos* $K,K'$ es un homomorfismo $\phi$ sobre extensiones
     $F,F'$ con un isomorfismo $\omega : K \longrightarrow K'$ debe cumplir: $\phi|_K = \omega$. 
     Cuando no se especifica, se asume la identidad.

     \[ \phi : F/K \longrightarrow F'/K' \]

***** DONE Automorfismos entre extensiones
     Un automofismo de extensiones es un homomorfismo sobre el cuerpo $K$, 
     $\phi : F/K \longrightarrow F/K$ que es isomorfismo.

*** 4. Cuerpos de descomposicin
**** 4.1. Cuerpo de descomposicin
***** 4.1.1. Teorema de Kronecker
Sea $f$ de grado no nulo sobre $K$, entonces existe una extensin $F/K$ 
tal que existe $u \in F$ con $f(u) = 0$.

****** Demostracin
Puedo descomponer en irreducibles $f = f_1f_2\dots f_m$; y tener una 
extensin cumpliendo lo pedido:

\[ F = \frac{K[X]}{(f_1)}\]

Para el elemento $u = x + (f_1)$.

***** 4.1.2. Extensin de un homomorfismo
Dadas extensiones $F_1/K_1, F_2/K_2$, decimos que $\tau : F_1 \longrightarrow F_2$ es una extensin
de $\sigma : K_1 \longrightarrow K_2$, ambos homomorfismos de cuerpos, cuando $\tau|_{K_1} = \sigma$.

***** 4.1.3. Isomorfismo extendido a polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Existe una nica extensin a
un isomorfismo $\sigma : K_1[X] \longrightarrow K_2[X]$ cumpliendo que $\sigma(X) = X$.

****** Demostracin
Por la propiedad universal por el anillo de polinomios. Las imgenes
de todos los elementos estn fijas excepto la de $X$ y sus mltiplos.

***** 4.1.4. Isomorfismos respetan irreducibilidad
Sea $f_1 \in K_1[X]$ irreducible sobre $K_1$, entonces $\sigma(f)$ es irreducible 
sobre $K_2$; donde $\sigma$ es la [[*4.1.3. Isomorfismo extendido a polinomios][extensin]] a polinomios de un isomorfismo.

****** Demostracin
Si tuviramos $f_1 = gh$ dos polinomios no triviales, su grado se 
conservara al aplicar el isomorfismo y tendramos
$\sigma(f)=\sigma(g)\sigma(h)$.

***** 4.1.5. Isomorfismo de races de polinomios
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos y sean $F_1/K_1, F_2/K_2$ 
extensiones algebraicas. Dado un homomorfismo $\tau : F_1 \longrightarrow F_2$ sobre $\sigma$;
si $u$ es raz de $p$ entonces $\tau(u)$ es raz de $\sigma(p)$.

****** Demostracin
Por simple clculo tomando $p(x) = a_nx^n + \dots + a_1x + a_0$:

\[ \begin{aligned}
\sigma(p)(\tau(u)) &= \sigma(a_n)\tau(u)^n + \dots + \sigma(a_1)\tau(u) + \sigma(a_0) \\ 
                   &= \tau(a_n)\tau(u)^n + \dots + \tau(a_1)\tau(u) + \tau(a_0) \\
                   &= \tau(a_nu^n + \dots + a_1u + a_0) \\
                   &= \tau(0) = 0
\end{aligned} \]

***** 4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos
Sea $F/K$ una extensin algebraica y $\tau : F/K \longrightarrow F/K$ un endomorfismo
sobre $K$. Entonces $\tau$ es un automorfismo.

****** Demostracin
Tenemos que es una extensin de la identidad y que preserva [[*4.1.5. Isomorfismo de races de polinomios][races]].
Por eso, dado un elemento $u \in F$, tomamos su $f = Irr(u,K)$. Y tenemos
que $\{\tau^n(u)\}_{n\in \mathbb{N}}$ es una sucesin de races del polinomio que, por 
inyectividad, deber repetir los elementos en algn momento.

Tendremos $\tau^m(u)=u$ y ser sobreyectiva. Ntese que estamos usando
la inyectividad de todo homomorfismo de cuerpos.

***** 4.1.7. Isomorfismo intercambiando conjugadas
Sea $\sigma : K_1 \longrightarrow K_2$ isomorfismo de cuerpos. Sea $p$ irreducible
y $u_1,u_2$ races de $p$ y $\sigma(p)$ en extensiones $F_1,F_2$. Entonces existe un 
nico isomorfismo $\tau : K_1(u_1) \longrightarrow K_2(u_2)$ sobre $\sigma$ tal que $\tau(u_1) = u_2$.

****** Demostracin
El isomorfismo buscado sale como composicin:

\[K_1(u_1) \cong 
  \frac{K_1[X]}{(f_1)} \cong 
  \frac{K_2[X]}{(f_2)} \cong
  K_2(u_2)\]

***** 4.1.8. Nmero de extensiones
El nmero de extensiones $\tau : K_1[u_1] \longrightarrow F_2$ sobre $\sigma$ es el nmero de
races distintas de $\sigma(p)$ en $F_2$.

****** Demostracin
Por la [[*4.1.7. Isomorfismo intercambiando conjugadas][proposicin anterior]], una para cada raz de $\sigma(p)$. Ntese
que no puede haber ms porque la imagen de $u_1$ determina completamente
el morfismo y porque la imagen de raz [[*4.1.5. Isomorfismo de races de polinomios][debe ser]] una raz.

***** 4.1.9. Cuerpo de descomposicin
Un $E/K$ es un cuerpo de descomposicin de $f$ ssi existen $u_1,\dots,u_n \in E$ 
tales que $f = (X-u_1)\dots(X-u_n)$ y $E = K(u_1,\dots,u_n)$.

****** Caracterizacin
Ntese que es el mnimo en el que factoriza linealmente. Cualquier
otro en el que factorice linealmente necesita contar con sus races.

***** 4.1.10. Cuerpo de descomposicin en una torre
Sean $K \subset F \subset E$. Si $E$ es cuerpo de descomposicin de $f$ sobre $K$, 
tambin lo es de $f$ sobre $F$.

****** Demostracin
Se cumple trivialmente:

\[ E = K(u_1,\dots,u_n) \subset F(u_1,\dots,u_n) \subset E\]

***** 4.1.11. Existencia del cuerpo de descomposicin
Cualquier $f \in K[X]$ de grado $n$ tiene un cuerpo de descomposicin, 
que adems verifica $[F:K] \leq n!$

****** Demostracin
******* Induccin: caso base
Cuando $n=1$, tenemos una raz en el cuerpo.

******* Induccin: caso inductivo
En otro caso, por [[*4.1.1. Teorema de Kronecker][Kronecker]], tenemos que existe una extensin
en la que hay una raz del polinomio. Tomamos esa raz para crear
$K(u)$. Por hiptesis de induccin, hay un cuerpo de descomposicin
de $f/(X-u)$ sobre $K(u)$, llamado $F$. Por ltimo, podemos construir 
un cuerpo de descomposicin con sus races.

Tenemos adems que la raz tiene menos grado que el polinomio:

\[ [F:K] = [F:K(u)][K(u):K] \leq (n-1)!n = n! \]

***** 4.1.12. Isomorfismo entre cuerpos de descomposicin
Sean $F_1/K_1, F_2/K_2$ cuerpos de descomposicin de $f \in K_1[X]$ y 
$\sigma(f) \in K_2[X]$; para $\sigma : K_1 \longrightarrow K_2$ isomorfismo. Entonces son
isomorfos.

****** Demostracin
******* Caso base
Si ambos son de grado $1$ tenemos extensiones triviales y 
hemos terminado.

******* Caso inductivo
Sea $u \in F_1$ raz de $f$. Como $Irr(u,K) \mid f$, tenemos que 
$\sigma(Irr(u,K)) \mid \sigma(f)$. Si tomamos una raz $v$ de $\sigma(Irr(u,K))$ y 
aplicamos el [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo intercambiando conjugadas]] anterior,
tenemos una extensin $\tau : K_1(u) \longrightarrow K_2(v)$ que lleva una en 
otra. Ahora tomamos $f=g(X-u)$ y por induccin tenemos
un isomorfismo extendiendo hasta el cuerpo de descomposicin.

***** 4.1.13. Unicidad del cuerpo de descomposicin
Dos cuerpos de descomposicin de $f \in K[X]$ sobre $K$ son isomorfos.

****** Demostracin
Trivial aplicando lo [[*4.1.12. Isomorfismo entre cuerpos de descomposicin][anterior]] al isomorfismo igualdad.

***** 4.1.23. Cuerpo de descomposicin de una familia
Sea ${\cal P} \subseteq K[X]$ una familia de polinomios no constantes. Una
extensin $E/K$ es cuerpo de descomposicin suyo si todo polinomio
factoriza linealmente y es adems se tiene $E = K(S)$ con:

\[ S = \{ u \in E \mid \exists f \in {\cal P}: f(u)=0\} \]

***** 4.1.24. Existencia del cuerpo de descomposicin de una familia
Para toda familia de polinomios existe un cuerpo de descomposicin.

****** Demostracin
******* Caso finito
En el caso finito, multiplicamos toda la familia para aplicar
la [[*4.1.11. Existencia del cuerpo de descomposicin][existencia del cuerpo de descomposicin]] al producto.

******* Caso infinito
Cuando tenemos una familia $\{ f_\lambda \mid \lambda \in \Lambda\}$. Si tomamos $I \subset \Lambda$ finito, 
podemos asignarle un cuerpo de descomposicin $F_I$ tal que $I\subset J$ 
implique $F_I \subset F_J$.

Tomamos:

\[F = \bigcup_{J\text{ finito}} F_J \]

Las operaciones entre dos elementos de $F$ se definen en el menor
cuerpo que contenga a los dos.

Esto es un cuerpo de descomposicin porque todo polinomio ya
descompone linealmente en cualquier $F_J$ que lo contenga; y cada
$F_J$ era ya cuerpo de descomposicin de los polinomios que contena,
as que el cuerpo de descomposicin debe al menos contener a todos
los $F_J$.

***** 4.1.25. Unicidad (esencial) del cuerpo de descomposicin de una familia
El cuerpo de descomposicin de una familia de polinomios es nico
salvo isomorfismos.

****** Demostracin
******* Caso finito
Aplicamos que los cuerpos de descomposicin de un polinomio
[[*4.1.13. Unicidad del cuerpo de descomposicin][son isomorfos]] al polinomio producto.

******* Caso infinito
Sean $F_1,F_2$ dos cuerpos de descomposicin sobre $K$ de una familia
de polinomios.

Ordenamos el siguiente conjunto por inclusin y por extensin del
isomorfismo. 

\[ (E,\tau) \leq (F,\psi) \Leftrightarrow 
(E \subset F) \wedge (\psi|_E = \tau)\]

Es una ordenacin inductiva porque la unin arbitraria da una 
cota maximal de cualquier cadena:

\[ {\cal E} = 
\left\{ (E,\tau) 
\mid F_1 \supset E \supset K;\;
\tau : E/K \longrightarrow F_2/K
\right\}\]

Que sabemos no vaco por el caso finito. Sea $(F,\sigma)$ maximal. Y 
supongamos que $F \subsetneq F_1$, entonces existe alguna raz de alguno
de los polinomios que no est en $F$. Creando un [[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]]
sobre $F$ que la llevara a su conjugada, contravendramos maximalidad.

Ahora, todo $f$ de la familia descompondra en $F$ y por $\sigma$, se las
llevaran a $F_2$.

**** 4.2. Clausura algebraica
***** 4.2.1. Algebraicamente cerrado
Un cuerpo tal que toda extensin algebraica suya sea trivial es un
cuerpo algebraicamente cerrado.

***** 4.2.2. Caracterizacin de los algebraicamente cerrados
Equivalen las siguientes propiedades:

 1. Todo polinomio no constante tiene raz en $K$.
 2. Todo polinomio descompone linealmente en $K$.
 3. Un polinomio es irreducible en $K$ ssi es de grado $1$.
 4. Toda extensin algebraica de $K$ es trivial.

****** Demostracin
******* Implicacin 1 a 2
Como $f$ tiene raz en $K$, podemos dividirlo por $(x-u)$, para
obtener un nuevo polinomio de grado menor.

******* Implicacin 2 a 3
Trivialmente.

******* Implicacin 3 a 4
Sea un elemento en la extensin algebraica, su irreducible
debe ser de grado $1$, luego debe estar en el cuerpo base.

******* Implicacin 4 a 1
Si algn polinomio no constante no tuviera raz, aplicamos
[[*4.1.1. Teorema de Kronecker][Teorema de Kronecker]] para crear una extensin algebraica
no trivial.

***** 4.2.3. Infinitud de algebraicamente cerrados
Todo cuerpo algebraicamente cerrado es infinito.

****** Demostracin
Si tengo un cuerpo finito $K$ formo el polinomio irreducible
siguiente, que no tiene races en $K$:

\[ 
f(x) = \prod_{k \in K} (x-k) + 1
\]

***** 4.2.4. Cuerpo algebraicamente cerrado de elementos algebraicos
Sea $E/K$ con $E$ algebraicamente cerrado. Los elementos algebraicos
de $E$ forman un cuerpo algebraicamente cerrado.

****** Demostracin
Sabemos que [[*3.2.30. Clausura algebraica relativa][forman un cuerpo]]. Para ver que es algebraicamente cerrado
vemos que todo polinomio sobre ellos tiene una raz en $E$, por ser
este algebraicamente cerrado. Como una raz es algebraica, tiene
una raz en el subcuerpo de los algebraicos.

***** 4.2.5. Clausura algebraica absoluta
Una extensin algebraica $E/K$ es la clausura algebraica (absoluta) 
si es una extensin algebraica y $E$ es algebraicamente cerrado.

***** 4.2.6. Caracterizacin de la clausura algebraica
Equivalen:

 1. $E/K$ clausura algebraica.
 2. $E/K$ algebraica y todo polinomio no constante $f \in K[X]$ descompone
    en factores lineales en $E[X]$.
 3. $E$ es cuerpo de descomposicin de todos los polinomios no 
    constantes de $K$.
 4. $E/K$ algebraica y todo no constante tiene una raz en $E$.

****** Demostracin
******* Implicacin 1 a 2
Como $E$ es algebraicamente cerrado, [[*4.2.2. Caracterizacin de los algebraicamente cerrados][sabemos que]] todos sus polinomios
descomponen en factores lineales en $E[X]$.

******* Implicacin 2 a 3
Todo polinomio descompone. Adems, todo elemento de $E$ es algebraico;
as que $K(S) = E$.

******* Implicacin 3 a 1
$E$ est generado por elementos algebraicos, luego es algebraico.
Adems, todo polinomio no constante descompone en l, luego
es algebraicamente cerrado por la [[*4.2.2. Caracterizacin de los algebraicamente cerrados][caracterizacin]].

******* TODO Equivalencia con 4
***** 4.2.7. Transitividad de la clausura algebraica
Sean $K \subset F \subset E$ torre de cuerpos, con $F/K$ algebraica. 
Entonces $E$ es clausura algebraica de $F$ ssi lo es de $K$.

****** Demostracin
Ser algebraicamente cerrado es independiente del cuerpo base de
la extensin. Ser algebraico [[*3.2.29. Torre algebraica][equivale]] a que lo sean las dos partes.

***** 4.2.8. Teorema de Steinitz
Para todo cuerpo existe una clausura algebraica.

****** Demostracin
Sabemos que [[*4.1.24. Existencia del cuerpo de descomposicin de una familia][existe]] el cuerpo de descomposicin de todos los polinomios
no constantes. Por la caracterizacin de [[*4.2.6. Caracterizacin de la clausura algebraica][clausura algebraica]] sabemos
que lo es.

***** 4.2.9. Unicidad esencial de la clausura algebraica
Dos clausuras algebraicas $E_1,E_2$ del mismo cuerpo $K$ son isomorfas 
sobre $K$.

****** Demostracin
Tenemos unicidad de esencial de los cuerpos de descomposicin,
y estos son cuerpos de descomposicin de todos los polinomios
no constantes.

***** 4.2.10. Extensin de homomorfismos a algebraicas
Sea $K \subset F \subset E$ con $E/K$ algebraica. Entonces todo $\sigma : F \longrightarrow \overline{K}$ tiene
una extensin $\tau : E \longrightarrow \overline{K}$.

****** Demostracin
Aplicamos Zorn sobre el siguiente conjunto ordenado para la inclusin,
sabiendo que toda cadena de cuerpos est acotada por su unin y que cada
$\sigma_i$ es extensin del anterior:

\[{\cal S} = \{(E_i,\sigma_i) \mid 
F \subset E_i \subset E;\; \sigma_i : E_i \longrightarrow \overline{K};\;
\sigma_i|_F = \sigma\}\]

Esto nos da el maximal $E_1$. Si $E_1 \subsetneq E$, tomo $u \in E - E_1$; y busco un
[[*4.1.7. Isomorfismo intercambiando conjugadas][isomorfismo]] intercambiando $u$ por una conjugada tambin raz de $Irr(u,K)$.
Esto me da $(E_1,\sigma_1) \leq (E_1(u),\tau)$.

***** 4.2.11. Cardinalidad de la clausura algebraica
Sea $K$ cuerpo y $\overline{K}$ su clausura.

 1. Si $K$ es finito, $\overline{K}$ es infinito numerable
 2. Si $K$ es infinito, $\#K = \#\overline{K}$.

****** Demostracin
******* Caso finito
Cuando $K$ es finito, el nmero de polinomios irreducibles
sobre l es infinito numerable.
******* Caso infinito
En el caso infinito, como mximo se tendr la acotacin que
da el nmero de polinomios, que es una unin numerable:

\[ \#\overline{K} \leq \#\left(\bigcup K^n\right) = \#K \]

*** 5. Extensiones normales y separables
**** 5.1. Elementos conjugados y extensiones conjugadas
***** 5.1.1. Elementos conjugados
Sean $u,v \in \overline{K}$, clausura algebraica. Equivalen:

  1. $Irr(u,K) = Irr(v,K)$
  2. $\exists \tau : K(u) \longrightarrow K(v)$ *isomorfismo* con $\tau(u) = v$.
  3. $\exists\sigma : K(u) \longrightarrow \overline{K}$ *homomorfismo* con $\sigma(u) = v$.
  4. $\exists \sigma : \overline{K} \longrightarrow \overline{K}$ *automorfismo* con $\sigma(u) = v$.

Morfismos manteniendo $K$. Estos elementos se llaman 
*elementos conjugados*.

****** Demostracin
******* Implicacin 1 a 2
Supongamos que tienen el mismo polinomio irreducible $f(X)$, 
entonces podemos construir un isomorfismo que lleve $u,v$ a 
$X + (f(X))$ para tener:

\[K(u) \cong \frac{K[X]}{(f(X))}\cong K(v)\]

******* Implicacin 2 a 3 y 4
Dado el isomorfismo, lo podemos prolongar a un homomorfismo.
Y dado un homomorfismo, lo podemos [[*4.2.10. Extensin de homomorfismos a algebraicas][prolongar]] a un automorfismo 
por ser una extensin algebraica.

******* Implicacin 4 a 1
Supongamos que existe el automorfismo de $\overline{K}$. Sea $f(X) = Irr(u,K)$,
y tenemos $0 = \phi(f(u)) = f(\phi(u)) = f(v)$; luego $Irr(u,K) = Irr(v,K)$.

***** 5.1.3. Extensiones conjugadas
Sean $F_1/K$, $F_2/K$ extensiones algebraicas, equivalen:

 1. $\exists \sigma: F_1 \longrightarrow F_2$ *isomorfismo* sobre $K$.
 2. $\exists \sigma : F_1 \longrightarrow \overline{K}$, *homomorfismo* sobre $K$ con $\sigma(F_1) = F_2$.
 3. $\sigma : \overline{K} \longrightarrow \overline{K}$, *isomorfismo* tal que $\sigma(F_1) = F_2$.

Estas extensiones se llaman *extensiones conjugadas*.

****** Demostracin
******* Implicacin 1 a 2
Extendiendo el isomorfismo se pasa de 1 a 2.

******* Implicacin 2 a 3
Dado el homomorfismo, lo podemos [[*4.2.10. Extensin de homomorfismos a algebraicas][prolongar]] a un homomorfismo
por ser $\overline{K}$ algebraica. Tenemos entonces un endomorfismo de un
cuerpo algebraico, que [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][debe ser]] un automorfismo.

******* Implicacin 3 a 1
La restriccin a $F_1$ es isomorfismo.

**** 5.2. Extensiones normales
***** 5.2.1. Extensiones normales
Sea $F/K$ extensin algebraica, subcuerpo de $\overline{K}$, equivalen:

  - $\sigma : F \longrightarrow \overline{K}$ sobre $K$, me da $\sigma(F) = F$.
  - Todo irreducible de $K[X]$ con una raz en $F$ descompone en 
    lineales en $F[X]$.
  - $F$ es cuerpo de descomposicin de una familia de polinomios
    sobre $K[X]$.

 A una extensin de este tipo se le llama *extensin normal*.

****** Demostracin
******* Implicacin 1 a 2
Dos races del mismo irreducible son conjugadas, luego existe
un [[*5.1.1. Elementos conjugados][homomorfismo]] que lleva una en otra, como debe llevar $F$ en $F$,
la otra debe estar en $F$.

******* Implicacin 2 a 3
Para cada elemento de $F$ puedo tomar su irreducible, como tiene
una raz en $F$ tiene todas. $F$ es el cuerpo de descomposicin de la
familia de todos los irreducibles de sus elementos.

******* Implicacin 3 a 1
Tenemos que $F = K(\alpha_1,\alpha_2,\dots)$, races de los polinomios. La imagen
de la raz de un polinomio sobre $K$ debe ser raz de ese mismo 
polinomio porque este debe quedar invariante sobre $\sigma$. As tenemos
que $\sigma(F) \subset F$, y por ser algebraico, todo [[*4.1.6. Los endomorfismos de extensiones algebraicas son automorfismos][endomorfismo es automorfismo]].

***** 5.2.3. Propiedades de las extensiones normales
Sea $E$ extensin normal. Cumple:

 1. Si $A/K$ es algebraica, $EA/A$ es normal.
 2. Si $K \subset F \subset E$, entonces $E/F$ es normal.
 3. Si $E_1/K, E_2/K$ son normales, $E_1E_2/K$ es normal.
 4. Sea $E_\lambda$, familia de extensiones normales; $F = \bigcap E_\lambda$ es normal.

****** Demostracin de 1
Dado $\sigma : EA/A \longrightarrow \overline{K}/A$, tengo que $\sigma(EA) = \sigma(E)\sigma(A) = EA$.

****** Demostracin de 2
Sea $\sigma : E/F \longrightarrow \overline{K}/F$, como deja fijo $K$, debe tenerse $\sigma(E)=E$.

****** Demostracin de 3
Sea $\sigma: E_1E_2/K \longrightarrow \overline{K}/K$, las restricciones dejan fijos ambos cuerpos
y $\sigma(E_1E_2) = \sigma(E_1)\sigma(E_2) = E_1E_2$.

****** Demostracin de 4
Si un homomorfismo de la interseccin lo extiendo y lo restrinjo a
cada uno, debe dejar todos los cuerpos fijos. Por tanto, un elemento
en la interseccin debe quedarse en la interseccin.

****** Contraejemplo: subcuerpo de normal no es normal
El ltimo es cuerpo de descomposicin de $x^3-2$,
pero el primero no es normal, porque no estn todas las
races del polinomio irreducible de $\sqrt[3]{2}$.

$\mathbb{Q} 
\subset \mathbb{Q}(\sqrt[3]{2}) 
\subset \mathbb{Q}(\sqrt[3]{2}, i)$

***** 5.2.4. Clausura normal
Llamamos clausura normal de $F/K$ a:

\[ E = \bigcap \{ H \mid H \supset F;\; H/K\text{ normal}\}\]

***** 5.2.5. Existencia de la clausura normal
Para toda extensin algebraica existe una clausura normal. 

****** Demostracin
Trivial porque la clausura algebraica es normal.

***** 5.2.6. Unicidad de la clausura normal
La clausura normal es nica salvo isomorfismos.

****** Demostracin
Sean las dos clausuras sobre la clausura algebraica absoluta.
Como son interseccin de normales y ambas lo son, deben ser
la misma.

***** 5.2.7. Extensin de homomorfismos a extensin normal
Sea $K \subset F \subset E$ con $E/K$ normal. Todo $\tau : F \longrightarrow E$ extiende a
un $\tau : E \longrightarrow E$. 

****** Demostracin
Tenemos que extiende a $\tau : F \longrightarrow \overline{K}$ y de ah, por ser $E$ algebraica,
se [[*4.2.10. Extensin de homomorfismos a algebraicas][prolonga]] a $\tau : E \longrightarrow \overline{K}$. Por ser normal, $\tau(E) = E$.

***** 5.2.8. Clausura de una extensin finita
Sea $F = K(u_1,u_2,\dots,u_n)$ y $f_i = Irr(u_i,K)$; entonces la clausura normal
es el cuerpo de descomposicin de $f = f_1f_2\dots f_n$.

****** Demostracin
Es normal por ser cuerpo de descomposicin de un polinomio, es
la mnima porque debe contener las races de $f_i = Irr(u_i,K)$
para ser normal, y si las contiene, debe contener al cuerpo de
descomposicin de $f$.

***** 5.2.9. La clausura normal de extensin finita es finita
Sea $F/K$ finita, su clausura normal es finita.

****** Demostracin
El cuerpo de descomposicin anterior es finito porque puedo
crearlo insertando las races de cada polinomio.

***** 5.2.10. Polinomio normal
Un polinomio irreducible es normal si en toda extensin
algebraica $F/K$ con una raz de $f$, descompone en factores 
lineales.

***** 5.2.11. Caracterizacin de polinomios normales
Sea $f$ un polinomio en $K[X]$, equivalen:

 1. $f$ es normal sobre $K$.
 2. El cuerpo de descomposicin de $f$ es $K(u)$, una raz de $f$.
 3. Todas las races de $f$ es expresan como polinomios de una de ellas.

****** Demostracin
******* Implicacin 1 a 2
Tenemos que en $K(u)$, $f$ descompone en factores lineales,
luego es cuerpo de descomposicin.

******* Implicacin 2 a 3
Trivial.

******* Implicacin 3 a 1
Una extensin con una raz $u$ contendra a $K(u)$, y como todas
las races se expresan como polinomios de $u$, contendra a todas
las races y $f$ descompondra en polinomios lineales.

**** 5.3. Extensiones separables
***** 5.3.1. Elemento separable
Un elemento algebraico $u$ es separable en $K$ si $Irr(u,K)$ no tiene 
races mltiples.

***** 5.3.2. Extensiones separables
Una extensin algebraica $F/K$ es *separable* si todos sus elementos 
lo son.

****** Ejemplo de extensin normal no separable
Existen [[http://math.stackexchange.com/questions/982702/example-of-a-non-separable-normal-extension][ejemplos]] de extensiones normales no separables.

***** 5.3.3. Torres separables
Si $E \supset F \supset K$ es extensin separable, lo son $E/F$ y $F/K$.

****** Demostracin
Que $F/K$ es separable es trivial. Y $E/F$ es separable porque
$Irr(u,F) \mid Irr(u,K)$, y si el segundo no tiene races mltiples,
no puede tenerlas el primero.

***** 5.3.4. Grado separable
El *grado separable* es cardinal del conjunto de homomorfismos
de $F/K \longrightarrow \overline{K}/K$.

\[ [F : K]_s = \#\{F/K \longrightarrow \overline{K}/K\}\]

***** 5.3.5. Grado separable en torres
Sea $K \subset F \subset E \subset \overline{K}$ entonces $[E:K]_s = [E:F]_s[F:K]_s$.

****** Demostracin
******* Con dos homomorfismos construyo el mayor
Dados $\sigma : F/K \longrightarrow \overline{K}/K$ y $\psi : E/F \longrightarrow \overline{K}/F$, puedo extender $\sigma$ al
algebraico $E$ para tener $\sigma^\ast : \overline{K}/K \longrightarrow \overline{K}/K$. Ahora, la composicin
$\sigma^\ast \circ \psi$, me da el homomorfismo buscado.

******* Y es nico
Supongamos que $\sigma^\ast \circ \psi = \sigma'^\ast \circ \psi'$; como deben ser iguales para 
cualquier $f \in F$, se tiene $\sigma = \sigma'$. Ahora, si tomamos la misma extensin
para cada elemento, $\sigma^\ast = \sigma'^\ast$ y entoces por inyectividad $\psi = \psi'$.

As tenemos ya:

\[ [E:K]_S \geq [E:F]_S[F:K]_S \]

******* Con el mayor construyo los dos menores
Dado un $\sigma : E/K \longrightarrow \overline{K}/K$, para cada $\sigma|_F$ construyo una extensin
a la clausura, $\tau : \overline{K}/K \longrightarrow \overline{K}/K$, que es isomorfismo. Como 
es isomorfismo podemos construirle inversa para tener 
$\tau^{-1} : \overline{K}/K \longrightarrow \overline{K}/K$. A la vez, podemos extender todos los $\sigma$ a
la clausura algebraica como $\sigma^\ast$.

Ahora bien, como $\tau|_F = \sigma|_F$, tenemos que $\sigma^\ast \circ \tau^{-1}$ deja fijo a $F$. 
As, hemos partido $\sigma$ en $\sigma^\ast \circ \tau^{-1}|_E$ y $\sigma|_F$.

******* Y son nicas
Supongamos que tenemos $\sigma|_F = \sigma'|_F$, entonces las dos extensiones $\tau$
las hemos tomado iguales. Si tenemos $\sigma \circ \tau^{-1}|_E = \sigma' \circ \tau^{-1}|_E$, como $\tau^{-1}$
es sobreyectiva, tenemos $\sigma^\ast|_E = \sigma'^\ast|_E$, y por tanto $\sigma = \sigma'$.

As tenemos que:

\[ [E:K]_S \leq [E:F]_S[F:K]_S \]

***** 5.3.6. Relacin de grado y grado separable
Sea $F/K$ extensin finita, entonces $[F:K]_s \mid [F:K]$.

****** Demostracin
******* Caso simple
Sea $K(u)$ la extensin, con polinomio $Irr(u,K)$ de grado $n$. 
Si la raz $u$ tiene multiplicidad $m$ en el polinomio, todas las
races del polinomio tienen la misma multiplicidad y hay
$n/m$ races distintas.

Cada homormofismo quedar determinado por la imagen de $u$, y
tenemos $n/m$ imgenes distintas para $u$.

******* Caso compuesto
Ahora procedemos por induccin sobre el grado de la extensin. 
Tomamos un elemento de la base y hacemos:

\[ [F:K(u)]_S[K(u):K]_S  \mid  [F:K(u)][K(u):K] \]

Lo primero es divisible por el caso simple y lo segundo por
hiptesis de induccin.

***** 5.3.7. Igualdad de grados en torres
Sea $K \subset F \subset E$, con $E/K$. Entonces $[E:K]_s = [E:K]$ ssi 
$[E:F]_s = [E:F]$ y $[F:K]_s = [F:K]$.

****** Demostracin
Tenemos que deben tenerse ambos casos de igualdad en:

\[
[E:K]_S = [E:F]_S[F:K]_S \leq [E:F][F:K] = [E:K]
\]

***** 5.3.8. Caracterizacin de extensin separable
La extensin finita $E/K$ es separable ssi $[E:K]_s = [E:K]$.

****** Demostracin
Usamos la idea de la demostracin de la relacin con el grado.
En el caso simple tenemos $[K(u):K]_S = [K(u):K]$ solo cuando la
multiplicidad de cada raz es uno. En el caso compuesto exigimos
eso a cada paso.

***** 5.3.9. Extensin por un conjunto separable
Para $K(S)/K$ algebraica es separable ssi todo elemento de $S$ es
separable sobre $K$.

****** Demostracin
La suma o producto de elementos separables [[http://math.stackexchange.com/a/82837/85067][es separable]].

***** 5.3.10. Propiedades de extensiones separables
Las extensiones separables cumplen:

 1. Para $K \subset F \subset E$, se tiene $E/K$ separable ssi $E/F$ y $F/K$ 
    separables.
 2. Sea $E/K$ algebraica separable y $H/K$ extensin, entonces $EH/H$ 
    es separable.
 3. Sean $E/K$ y $F/K$ separables, entonces $EF/K$ es separable.

****** Demostracin
******* Punto 1
Simplemente usar que la igualdad de grados de separabilidad
se da en [[*5.3.7. Igualdad de grados en torres][torres]] y que equivale a la [[*5.3.8. Caracterizacin de extensin separable][separabilidad]].

******* Punto 2
Tenemos $EH/H = H(E)/H$. Que sea separable [[*5.3.9. Extensin por un conjunto separable][equivale]] a que
cada elemento de $E$ lo sea. Pero $Irr(e,H) \mid Irr(e,K)$, y si uno
tiene slo races simples, el otro las tendr tambin.

******* Punto 3
Tenemos $K(E,F)/K$ separable por serlo todos los elementos en 
$E,F$.

***** 5.3.11. La clausura normal de una separable es separable
Sea $F/K$ separable y $E/K$ su clausura normal. Entonces $E/K$ es
separable.

****** Demostracin
Si extiendo $F$ con todas las races de los irreducibles de sus
elementos, tengo la clausura normal; porque debe contenerlas
y es normal, as que es la mnima. Como cada una de ellas es
separable porque tiene como irreducible el mismo irreducible
de un elemento de $F$, la [[*5.3.9. Extensin por un conjunto separable][extensin entera]] es separable.

***** 5.3.12. Clausura separable
El conjunto de todos los elementos de $\overline{K}$ separables sobre $K$ forman
un subcuerpo $K^{sep}$ que se llama *clausura separable*.

****** Demostracin
La suma o producto de elementos separables es separable, como
demostramos [[*5.3.9. Extensin por un conjunto separable][anteriormente]].

***** 5.3.13. Teorema del elemento primitivo
Sea $E/K$ una extensin finita. Es simple ssi el conjunto de
cuerpos intermedios $\{ F \mid K \subset F \subset E\}$ es finito.

****** Demostracin
******* Primera implicacin
Sea $K(\alpha)$ simple, como es finita es algebraica, y $Irr(a,K)$ tiene 
finitos divisores en la clausura. 

Para cada divisor del polinomio irreducible creo $K[|p|]$, el subcuerpo
generado por los coeficientes del polinomio. Todo cuerpo intermedio $E$,
en el que el irreducible de $\alpha$ sea $p$ contendr a $K[|p|]$, pero como:

\[ [K(\alpha): E] = [K(\alpha) : K[|p|]] \]

Se tendr forzosamente $E = K[|p|]$.

******* Segunda implicacin
******** Cuerpo base finito
Como la extensin es finita, tenemos que hay finitos elementos.
El grupo multiplicativo de un cuerpo finito es [[http://mathoverflow.net/a/54741/45365][cclico]], luego es 
simple.

******** Cuerpo base infinito
Siendo $E = K(a_1,a_2,\dots,a_n)$, nos limitamos a probar $K(a,b)$ simple.
Consideramos las $K(a+xb)$ para $x \in F$. Como los elementos de $F$ son 
infinitos y las extensiones intermedias finitas, se tienen $x \neq y$
tales que $K(a+xb) = K(a+yb)$, y por tanto:

\[
b = \frac{ a +bx - (a + by)}{x-y} \in K(a+bx)
\]

****** Contraejemplo:
Hay extensiones finitas de cuerpos que no son simples

***** 5.3.13. Finita y separable es simple
Una extensin finita y separable es simple.

****** Demostracin
Si es finita y separable, podemos tomar su clausura normal.
La clausura normal de una extensin finita es [[*5.2.8. Clausura de una extensin finita][finita]], as que
tengo una extensin de Galois finita. Habr finitas subextensiones
porque habr finitos subgrupos de Galois.

****** Contraejemplo: cuerpo finito no simple
Tenemos [[https://en.wikipedia.org/wiki/Primitive_element_theorem#Counterexamples][contraejemplos]] en caracterstica $p$ con cuerpos de
dimensin $p^2$.

***** 5.3.14. Endomorfismo de Frobenius
Sea $K$ de caracterstica de $p$. Llamamos *endomorfismo de Frobenius* 
a $\phi(u) = u^p$.

***** 5.3.15. Cuerpos perfectos
Para $K$ cuerpo equivalen:

  1. Todo $f \in K[X]$ irreducible tiene races simples.
  2. Toda $E/K$ algebraica es separable.
  3. Toda $E/K$ finita es separable.
  4. $car(K)=0$  $car(K)=p$, y el endomorfismo de Frobenius es 
     sobreyectivo.

Y en ese caso, llamamos a $K$ *cuerpo perfecto*.

****** Demostracin
******* Implicacin 1 a 2
Todo elemento de la extensin cumple algn polinomio,
y son todos separables, luego es separable.

******* Implicacin 2 a 3
Trivial

******* Implicacin 3 a 4
Supongamos que no fuera sobreyectivo, existe $y \neq x^p$.
Si tomamos $(x^p-y)$, tenemos que es irreducible. Y si creamos
entonces $z^p = y$ tendramos una extensin no finita no
separable.

# TODO: Por qu es irreducible? Por Eisenstein en algn cuerpo 
# raro podra tenerse.

******* Implicacin 4 a 1 en caracterstica 0
En caracterstica $0$, un polinomio no puede dividir a su derivada,
que ser de grado menor, as que un irreducible no puede tener races
dobles.

******* Implicacin 4 a 1 en caracterstica p
Para que un irreducible divida a la derivada, que debe ser de grado
menor, se debe tener que sea $0$. El polinomio original debe ser
de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left(\sum \sqrt[p]{a_i} x^i\right)^p\]

contraviniendo irreducibilidad. Todos los polinomios deben tener
races simples.

***** 5.3.17. Ejemplos de cuerpos perfectos
Son perfectos:

  1. Todo cuerpo de caracterstica cero.
  2. Todo cuerpo finito.
  3. Todo cuerpo algebraicamente cerrado.
    
****** Demostracin
******* Punto 1
Trivial desde la [[*5.3.15. Cuerpos perfectos][caracterizacin]].
******* Punto 2
En todo cuerpo finito, un endomorfismo es sobreyectivo.
******* Punto 3
En un algebraicamente cerrado, todo irreducible es lineal y
tiene races simples.

**** 5.4. Derivada y races mltiples
***** 5.4.1. Races
Sea $f\in F[X]$ y $u \in F$. Es raz de multiplicidad $k$ cuando $f = (X-u)^kf_0$,
con $f_0(u) \neq 0$.

***** 5.4.2. Derivada
Se define la derivada de $f$ como:

\[ f' = \sum_{i=1}^n ia_iX^{i-1} = na_nX^{n-1} + \dots + a_1\]

***** 5.4.3. Propiedades de la derivada
La derivada verifica:

 1. $(f+g)' = f'+g'$
 2. $(f \cdot g)' = f' \cdot g'$
 3. $(f^m)' = mf^{m-1}\cdot f'$

***** 5.4.4. Condicin de races simples
Las races de $f$ son simples ssi $mcd(f,f') = 1$.

***** 5.4.5. Condicin de races simples en irreducibles
Sea $f$ irreducible con $f' \neq 0$, las races de $f$ son simples.

***** 5.4.6. Propiedades de las races simples
Se cumple:

 1. En caracterstica $0$, todo irreducible tiene races simples.
 2. En caracterstica $p$ prima, un irreducible tiene races mltiples
    ssi $f(x) = g(x^p)$.

****** TODO Demostracin
***** 5.4.7. Polinomio separable
Un polinomio $f \in K[X]$ se llama separable $K$ si sus factores 
irreducibles tienen slo races simples.

*** 6. Teora de Galois Finita
**** 6.1. Grupos de automorfismos
***** 6.1.1. Espacio vectorial de las aplicaciones de un conjunto
Sea $S$ un conjunto. Las aplicaciones $Fun(S,F)$ con la suma y producto
de escalares elevados desde $F$ forman un espacio vectorial de dimensin
$|S|$.

****** Demostracin
Simplemente comprobar que cumplen las propiedades de espacio 
vectorial.

***** 6.1.2. Proposicin al lema de Dedekind
Sean $\sigma_1,\dots, \sigma_m : G \longrightarrow F^\times$ homomorfismos desde un grupo $G$. 
Son distintos ssi son linealmente independientes sobre $F$.

****** Demostracin
******* Caso base
Procedemos por induccin. Cuando $n=1$, es trivial.

******* Caso inductivo
Tomemos un subconjunto mnimo de linealmente dependientes, 
$\sigma_1,\dots,\sigma_s$. Tendramos $b_i \in F^\times$:

\[\sigma_s = b_1\sigma_1 + \dots + b_{s-1}\sigma_{s-1}\]

Si tomamos ahora $y$ tal que $\sigma_1(y) \neq \sigma_s(y)$, evaluamos en $xy$ y 
multiplicamos por $\sigma_s(y)$ obtenemos dos ecuaciones que restadas
dan:

\[0 = b_1(\sigma_1(y)-\sigma_s(y))\sigma_1 + \dots + b_{s-1}(\sigma_{s-1}(y) - \sigma_s(y)) \sigma_{s-1}\]

Relacin de dependencia no nula menor que la anterior.

***** 6.1.3. Lema de Dedekind
Un conjunto de homomorfismos de cuerpos $F_1 \longrightarrow F_2$ distintos
son linealmente independientes sobre $F_2$.

****** Demostracin
Desde el lema anterior, tenemos que son linealmente independientes 
una vez restringidos a $F_1^\times \longrightarrow F_2^\times$, el aadirles el $0$ no los vuelve 
dependientes.

***** 6.1.4. Acotacin del nmero de homomorfismos sobre K
Existen como mximo $[F:K]$ morfismos distintos sobre $K$ 
hacia cualquier otro cuerpo:

\[|Hom(F/K,E/K)| \leq [F:K]\]

****** Demostracin
Sea $\{u_1,\dots,u_n\}$ base de $F$, y supongamos $n+1$ homomorfismos
distintos. El siguiente sistema de ecuaciones tiene solucin 
no trivial porque tiene $n+1$ incgnitas y tiene $n$ ecuaciones.
      
\[ X_1\sigma_1(u_j) + \dots + X_{n+1}\sigma_{n+1}(u_j) = 0 
\qquad j = 1,\dots,n\]
      
Pero una solucin es una relacin de dependencia sobre toda la
base de $F$. Si son dependientes, por Dedekind son [[*6.1.3. Lema de Dedekind][iguales]].

***** 6.1.5. Grupo de extensin
Para toda extensin finita $F/K$ llamamos *grupo de la extensin* a:

\[ G(F/K) = \{ \sigma \in  Aut(F) \mid \forall u \in K : \sigma(u) = u\}\]

***** 6.1.6. Acotacin de elementos del grupo
Para toda extensin finita $F/K$ se verifica que $|G(F/K)| \leq [F : K]$.

****** Demostracin
Caso particular de la [[*6.1.4. Acotacin del nmero de homomorfismos sobre K][acotacin]] del nmero de homomorfismos
sobre el cuerpo.

***** 6.1.7. Cuerpo fijo
Sea $G < Aut(E)$, llamamos *cuerpo fijo* por $G$ al conjunto al que 
dejan fijos todos los elementos de $G$:

\[ E^G = \{ u \in E \mid \forall\sigma\in G: \sigma(u) = u\}\]

Es un *subcuerpo* de $E$.

****** Demostracin: es un subcuerpo
Trivialmente desde la definicin de automorfismo de cuerpos.

***** 6.1.8. Teorema de Artin
Para $G < Aut(E)$ finito, $[E : E^G] = |G|$.

****** Demostracin
Ya tenemos $n = |G| \leq [E : E^G]$. Supongamos la desigualdad estricta 
con $u_1,\dots,u_{n+1} \in E$ independientes sobre $E^G$. Y tenemos el sistema 
de $n+1$ incgnitas y $n$ ecuaciones, sobre los $\sigma_j$ de $G$:

\[ X_1\sigma_j(u_1) + \dots + X_{n+1}\sigma_j(u_{n+1}) = 0 \qquad
j = 1,\dots,n\]
      
Sea $a_1,\dots,a_{n+1}$ una solucin no trivial con nmero mnimo de 
elementos no nulos. Suponemos s.p.g. que $a_1 \neq 0$ y despejamos para 
tener:

\[\sigma_j(u_1) = b_2\sigma_j(u_2) + \dots + b_n\sigma_j(u_{n+1}) 
\qquad j = 1,\dots,n\]
      
En particular, en el caso $\sigma_j = id$, tenemos:

\[u_1 = b_2u_2 + \dots + b_{n+1}u_{n+1}\]

que obliga a que uno de los coeficientes no est en $E^G$. Supongamos 
s.p.g. que $b_2 \notin E^G$, y sea $\tau \in G$ tal que $\tau(b_2) \neq b_2$. Si aplicamos ahora
$\tau$ a cada una de las ecuaciones y restamos tenemos:

\[0 = (b_2-\tau(b_2))\sigma_j(u_2) + \dots + (b_n-\tau(b_n)\sigma_j(u_{n+1}))
\qquad j = 1,\dots,n\]

Esta solucin es no trivial porque $(b_2-\tau(b_2)) \neq 0$, pero tiene ms 
elementos nulos que la anterior.

***** 6.1.9. Extensin de Galois
Una extensin finita $E/K$ es *de Galois* cuando:
     
\[\exists Gal(E/K) < Aut(E): E^{Gal(E/K)} = K\]

Llamamos a $Gal(E/K)$ el *grupo de Galois* de la extensin.

***** 6.1.10. Caracterizacin de extensin de Galois
Una extensin finita es de Galois ssi es normal y separable.

****** Demostracin
Sea $Gal(E/K) = G$, entonces cada automorfismo se extiende a un 
homomorfismo $\sigma' : E/K \longrightarrow \overline{K}/K$, luego $[E:K]_S \geq |G| = [E:K] \geq [E:K]_S$, 
y por tanto la extensin es separable. Como adems el nmero total 
de homomorfismos es $[E:K]_S = |G|$, son todos automorfismos y la 
extesin es normal.

Sea $E/K$ normal y separable. Tenemos $n = [E:K]_S = [E:K]$ 
homomorfismos $\tau : E \longrightarrow \overline{K}$ sobre $K$, con $\tau(E) = E$. Entonces 
$G = G(E/K)$ tiene orden $n$. Por Teorema de Artin, 
$[E:E^G] = n = [E:K]$, luego $[E^G:K] = 1$.

***** 6.1.11. Caracterizacin para extensiones finitas
Sea $F/K$ una extensin separable finita y sea $E/K$ su clausura 
normal. Entonces $E/K$ es una extensin finita de Galois.

****** Demostracin
La clausura normal de una extensin separable es [[*5.3.11. La clausura normal de una separable es separable][separable]].

**** 6.2. Correspondencia de Galois, caso finito
***** Correspondencia
Definimos una correspondencia entre los subgrupos de una 
extensin de Galois y los cuerpos intermedios como:

\[ H^\ast = E^H = \{u \in E \mid \forall\sigma\in H: \sigma(u)=u\}\]
\[F^\ast = Gal(E/F) = \{\sigma\in G \mid \forall u\in F: \sigma(u) = u\}\]

***** 6.2.1. Contenidos de cuerpos
Sean $F_i$ cuerpos intermedios de $E/K$ y $H_i$ subgrupos de $Gal(E/K)$.
Se cumple:

 1. Si $F_1 \subset F_2$, entonces $F_1^\ast \supset F_2^\ast$.
 2. Si $H_1 \subset H_2$, entonces $H_1^\ast \supset H_2^\ast$.
 3. $F \subset F^\ast^\ast$; $H < H^\ast^\ast$.
 4. $F^\ast = F^\ast^\ast^\ast$; $H^\ast = H^\ast^\ast^\ast$.

****** Demostracin
1. Trivial.
2. Trivial.
3. Trivial.
4. Componiendo el apartado 3 con el 2 y el 1.

***** 6.2.2. Correspondencia de Galois
El par de aplicaciones $\ast$ se llama *correspondencia de Galois*.

***** 6.2.3. Teorema fundamental
Sea $E/K$ una extensin de Galois finita con $G = Gal(E/K)$:

  1. La correspondencia es biyeccin, ${\cal F}(E/K) \cong {\cal S}(G)$.
  2. $A \supset B$ ssi $B^\ast \subset A^\ast$.
  3. La correspondencia es un antiisomorfismo de retculos, 
     $(F_1 \cdot F_2)^\ast = F_1^\ast \cap F_2^\ast$ y $(F_1 \cap F_2)^\ast = F_1^\ast \vee F_2^\ast$.
  4. Las extensiones $F_1/K$ y $F_2/K$ son conjugadas ssi los subgrupos
     $F_1^\ast$ y $F_2^\ast$ son conjugados en $G$.
  5. La extensin $F/K$ es normal ssi $F^\ast$ es un subgrupo normal de $G$.
     En este caso $Gal(F/K) \cong G/F^\ast$.
  6. Para $H<G$ se verifica $|H| = [E:H^\ast]$ y $[G:H]=[H^\ast:K]$. 
     Para $F \in {\cal F}(E/K)$ se verifica $[E:F] = |F^\ast|$ y $[F:K] = [G:F^\ast]$.
 
****** Demostracin de 6 para grupos
Por [[*6.1.8. Teorema de Artin][teorema de Artin]] tenemos $|G| = [E:K]$ y $|H| = [E : H^\ast]$.
Por teorema de Lagrange y teorema del grado tenemos:

\[ |G| = [G:H] |H| \]
\[ [E:K] = [E:H^\ast][H^\ast : K] \]

Simplificando obtenemos $[G:H] = [H^\ast : K]$.

****** Demostracin de 6 para cuerpos intermedios
Como $E/F$ es de Galois, $|F^\ast| = [E:F]$ y sabemos $|G| = [E:K]$.
Volvemos a aplicar Lagrange y teorema del grado.

****** Demostracin de 1
Tenemos la torre $G > H^\ast^\ast > H$ y:

\[ [G : H^\ast^\ast] = [H^\ast^\ast^\ast : K] = [H^\ast : K] = [G : H] \]

Tenemos la torre $E \supset F^\ast^\ast \supset F$ y:

\[ [E:F] = |F^\ast| = |F^\ast^\ast^\ast| = [E : F^\ast^\ast] \]

****** Demostracin de 2 y 3
Se cumple por ser biyeccin y la proposicin anterior. Trivial
desde esto el antiisomorfismo de retculos.

****** Demostracin 4
Sean $F_2 = \sigma(F_1)$, para $\tau \in F_1^\ast$, tenemos $\sigma\tau\sigma^{-1} \in F_2^\ast$.
Luego $\sigma F_1^\ast \sigma^{-1} \subset F_2^\ast$. Aplicando lo mismo sobre $\sigma^{-1}$ llegamos
a la otra igualdad. Dando la vuelta al razonamiento, tenemos
que $\sigma F_1^\ast \sigma^{-1} = F_2^\ast$ nos da $F_2 = \sigma(F_1)$.

****** Demostracin 5
Desde el cuarto apartado, se conserva normalidad.

Si aplicamos primer Teorema de Isomorfa a la restriccin
$\Phi : Gal(E/K) \longrightarrow Gal(F/K)$:

\[ \frac{Gal(E/K)}{F^\ast} 
= \frac{Gal(E/K)}{\ker(\Phi)} 
\cong \im(\Phi) 
= Gal(F/K) \]

El que $\im(\Phi) = Gal(F/K)$ usa la normalidad de $F$.

**** 6.4. Propiedades de las extensiones de Galois
***** 6.4.1. Subgrupos en Galois
Sean $E \supset F \supset K$ con $E/K$ Galois finita. Entonces $E/F$ es Galois
finita y $Gal(E/F)$ es subgrupo de $Gal(E/K)$.

****** Demostracin
La finitud se tiene trivialmente. La normalidad se tiene
sobre cuerpos [[*5.2.3. Propiedades de las extensiones normales][intermedios]] y la separabilidad [[*5.3.10. Propiedades de extensiones separables][tambin]]. Y sabemos
que normal y separable es de [[*6.1.10. Caracterizacin de extensin de Galois][Galois]].

Que uno es subgrupo de otro est claro por las propiedades de la
[[*6.2.3. Teorema fundamental][correspondencia]].

***** 6.4.2. Extensiones abelianas, cclicas y solubles
Una extensin finita se dice *abeliana, cclica o soluble* si es
de Galois y su grupo lo es.

***** 6.4.3. Subgrupos abelianos, cclicos y solubles
Sea $E\supset F\supset K$ con $E/K$ finita y *abeliana, cclica o soluble*,
entonces $E/F$ tambin es abeliana, cclica o soluble, respectivamente.

****** Demostracin
Tenemos que el subgrupo de un abeliano, cclico o soluble
es tambin abeliano, cclico o soluble.

***** 6.4.4. Subextensiones finitas abelianas y cclicas
Sean $K \subset F \subset E$ torre de extensiones *finitas*:

 1. Si $E/K$ es Galois abeliana, $F/K$ es Galois abeliana.
 2. Si $E/K$ es Galois cclica, $F/K$ es Galois cclica.

****** TODO Demostracin

***** 6.4.5. Galois para cuerpos compuestos
Sea $E/K$ Galois finita y $F/K$ extensin con $E,F \subset L$.
Entonces $EF/F$ y $E/(E\cap F)$ son extensiones finitas de Galois.
Adems la aplicacin restriccin $\sigma \mapsto \sigma|_E$ define un isomorfismo:

\[ \bullet|_E : Gal(EF/F) \longrightarrow Gal(E/(E\cap F)) < Gal(E/K) \]

****** TODO Demostracin

***** 6.4.6. Relacin de Galois con el grado
Sea $E/K$ extensin finita de Galois y sea $F/K$ con $E,F \subset L$.
Entonces $[EF:F] \mid [F:K]$.

****** TODO Demostracin

***** 6.4.8. Composicin de extensiones de Galois
Sean $E_1/K$, $E_2/K$ extensiones Galois finitas con $E_1,E_2 \subset L$.
Entonces $E_1E_2/K$ es extensin finita de Galois y existe un
monomorfismo restriccin:

\[
\lambda : Gal(E_1E_2/K) 
\longrightarrow 
Gal(E_1/K) \times Gal(E_2/K)
\]

Cuando adems tenemos $E_1 \cap E_2 = K$, $\lambda$ es un isomorfismo.

****** TODO Demostracin
***** 6.4.9. Extensin del producto
Sean $E_i/K$ extensiones contenidas en un $L$ con grupos de Galois
$G_1,G_2,\dots,G_n$. Si cumplendems $E_i \cap (E_1E_2\dots E_{i-1}) = K$, entonces:

\[Gal(E_1E_2\dots E_n/K) \cong G_1 \times G_2 \times \dots \times G_n\]

****** TODO Demostracin
***** 6.4.10. Cuerpos fijos del producto
Sea $E/K$ una extensin finita de Galois con grupo $G = G_1 \times \dots \times G_n$.
Sea $E_i$ el cuerpo fijo de $G_1 \times \dots \times \{1\} \times \dots \times G_n$. Entonces $E_i/K$ es
de Galois con grupo $Gal(E_i/K) = G_i$, $E_i \cap (E_1\dots E_{i-1})$ y $E=E_1\dots E_n$.

****** TODO Demostracin

*** 7. Cuerpos finitos
**** 7.1. Estructura de los cuerpos finitos
***** 7.1.1. Propiedades de un cuerpo finito
Sea $F$ cuerpo finito con $|F| = q$,

  1. $car(F) = p$ es un primo.
  2. El cuerpo primo es $\mathbb{Z}/p\mathbb{Z}$.
  3. $F/\mathbb{Z}_p$ es extensin finita.
  4. $[ F : \mathbb{Z}_p] = n$, entonces $|F| = p^n$.
  5. $F^\times$ es cclico de orden $|F|-1$.
 
****** Demostracin
******* Punto 1
No puede tener caracterstica nula por ser finito, luego debe
ser un primo.

******* Punto 2
Ya que tiene caracterstica prima.

******* Punto 3
Ya que $F$ es finito.

******* Punto 4
Si tiene una base de $n$ elementos, debe tener $p^n$ combinaciones
de elementos bsicos.

******* Punto 5
Todo subgrupo finito del grupo multiplicativo de un cuerpo es 
cclico.

***** 7.1.2. Clasificacin de cuerpos finitos
Dos cuerpos finitos del mismo cardinal son isomorfos. De hecho,
son el cuerpo de descomposicin de $X^{|F|} - X$ sobre $\mathbb{F}_p$.

****** Demostracin
Al ser [[*7.1.1. Propiedades de un cuerpo finito][cclico]] $u^{q-1} = 1$ nos da $u^q-u = 0$ con todo el cuerpo
como races.

***** 7.1.3. Existencia de cuerpos finitos
Dado $p$ primo, existe cuerpo de $p^n$ elementos.

****** Demostracin
Sea $f(x) = x^{p^n}-x$ polinomio en $\mathbb{Z}_p$. Su derivada, $-1$, no tiene races,
luego tiene slo races simples. Veamos que con slo aadir esas
races del polinomio, llega a ser cuerpo de descomposicin.

Sean $u,v$ races:

 - $(u+v)^{p^n} - (u+v) = u^{p^n}-u+v^{p^n}-v = 0$
 - $(uv)^{p^n}-uv = u^{p^n}v^{p^n} - uv = 0$
 - $(-u)^{p^n} - (-u) = 0$
 - $(u^{-1})^{p^n} - u^{-1} = 0$

***** 7.1.4. Teorema de Moore
Para cada $p^n$ existe exactamente un cuerpo con $p^n$ elementos; 
que es el cuerpo de descomposicin de $x^{p^n}-x$ sobre $\mathbb{Z}_p$. 
No existen otros cuerpos finitos.

****** Demostracin
Sabemos los cuerpos [[*7.1.1. Propiedades de un cuerpo finito][deben]] tener cardinal $p^n$ y que dos cuerpos
con el mismo cardinal son [[*7.1.2. Clasificacin de cuerpos finitos][isomorfos]]. Adems, sabemos que
[[*7.1.3. Existencia de cuerpos finitos][existe]].

***** 7.1.5. Cuerpos de Galois
Notamos por $GF(p^n)$ o $\mathbb{F}_{p^n}$ al nico cuerpo con esa cardinalidad,
lo llamamos cuerpo de Galois de orden $p^n$.

***** 7.1.6. Cuerpo extensin
Para $\mathbb{F}_q$ cuerpo finito, exste un nico cuerpo de extensin de grado $n$,
que es $\mathbb{F}_{q^n}$.

****** Demostracin
Por el teorema de Moore, $q = p^m$, y slo hay uno de $p^{nm}$ elementos.

***** 7.1.7. Grupo de automorfismos
El grupo $Aut(\mathbb{F}_{p^n}) \cong \mathbb{Z}_n$ es cclico y est generado por el [[*5.3.14. Endomorfismo de Frobenius][Endomorfismo de 
Frobenius]].

****** Demostracin
El cuerpo fijo bajo el endomorfismo de Frobenius son los $p$ 
elementos cumpliendo $a^p = a$, es decir, el cuerpo base $\mathbb{F}_p$.

El generado debe ser su grupo de Galois, ya que tiene orden $n$.

***** 7.1.8. Grupo de automorfismos relativo
Un $\mathbb{F}_{p^n}$ es subcuerpo de $\mathbb{F}_{p^m}$ ssi $n\;|\;m$. En este caso, $\mathbb{F}_{p^m}/\mathbb{F}_{p^n}$ es cclica
con $Gal(\mathbb{F}_{p^m}/\mathbb{F}_{p^n}) = \langle \phi^n \rangle$.

****** Demostracin
******* Si es subcuerpo, divide
Por Lagrange, $[\mathbb{F}_{p^n} : F] | [\mathbb{F}_{p^m} : F]$.

******* Si divide, es subcuerpo
El $Gal(\mathbb{F}_{p^m}/\mathbb{F}) \cong \mathbb{Z}_m$ tiene un nico subgrupo de orden $n$. Y debe
ser el grupo de Galois de un cuerpo de orden $m/n$, que tiene por
Moore que ser $\mathbb{F}_{p^n}$.

**** 7.2. Factorizacin de polinomios
***** 7.2.1. Listado de polinomios irreducibles
Los factores irreducibles de $X^{p^n} - X$ son exactamente los polinomios
irreducibles de $\mathbb{F}_p[X]$ con grado divisor de $n$.

****** Demostracin
******* Los factores irreducibles tienen grado n
Cuando $g(\alpha) = 0$, por ser factor tenemos $\alpha^{p^n} = \alpha$, luego $\alpha \in \mathbb{F}_{p^n}$.
As, $\mathbb{F}_{p^n} \supseteq \mathbb{F}_p(\alpha) \supseteq \mathbb{F}_p$, y por teorema del grado, $gr(g) = [\mathbb{F}_p(\alpha) : \mathbb{F}_p]$
divide a $[\mathbb{F}_{p^n} : \mathbb{F}_p]$.

******* Los irreducibles de grado divisor de n son factores
Sea $g(\alpha) = 0$, tomamos $m = [\mathbb{F}_p(\alpha) : \mathbb{F}_p] = gr(g)$, y [[*7.1.8. Grupo de automorfismos relativo][sabemos]] que
debe tenerse $\mathbb{F}_{p^m} \supset \mathbb{F}_p(\alpha)$. Por Moore $f(\alpha) = 0$ y $g \mid f$.

***** 7.2.2. Nmero de mnicos irreducibles
Para $n$ primo, el nmero de mnicos irreducibles de $\mathbb{F}_p[X]$ de grado $n$
es $(p^n-p)/n \neq 0$.

****** TODO Demostracin

***** 7.2.3. Races simples
Para $f \in \mathbb{F}_p[X]$, $f_1 = f / mcd(f,f')$ tiene todas las races simples y
$f(\alpha) = 0 \iff f_1(\alpha) = 0$.

****** Demostracin
Calculando vemos que $f = \prod_i(X-\alpha_i)^{k_i}$ da $f_1 = \prod_{i} (X- \alpha_i)$.

***** 7.2.4. Producto de factores irreducibles de grado n
El producto de todos los factores irreducibles distintos de un $f$
y cuyo grado divida a $n$ es $mcd(f, X^{p^n} - X)$.

****** TODO Demostracin

**** TODO 7.3. Ilustraciones
*** 8. Extensiones ciclotmicas
**** 8.1. Races de la unidad
***** 8.1.1. Subgrupos finitos del grupo multiplicativo
Todo subgrupo finito del grupo multiplicativo $K^\times$ es cclico.

****** Demostracin
Si $n = mcm\{ord(\alpha) \mid \alpha \in G\} = \max\{ord(\alpha) \mid \alpha \in G\}$, tenemos que
debe ser $n = |G|$. En caso contrario se tendra $X^n-1$ con ms de
$n$ races.

***** 8.1.2. Races n-simas
Si llamamos $\mu_n(K) = \{ \zeta \in K \mid \zeta^n = 1 \}$, $\mu_n(K)$ es un grupo cclico finito
con $|\mu_n(K)| \leq n$.

****** Demostracin
Trivial por el orden del polinomio $\zeta^n-1$.

***** 8.1.3. Grupo de races n-simas
Llamamos *grupo de races n-simas* de la unidad al grupo siguiente. 
Cualquier generador del grupo se llama una *raz primitiva* de la 
unidad.

\[ \mu_n(\overline{K}) = \{\zeta\in \overline{K} \mid \zeta^n = 1\} \]

***** 8.1.4. Lema de divisin
Tenemos $d\mid n$ ssi $\mu_d \subset \mu_n$.

****** TODO Demostracin
**** 8.2. Polinomios ciclotmicos
***** 8.2.1. Polinomio ciclotmico
Se llama *polinomio ciclotmico* al polinomio:

\[\Phi_n = \prod_{\zeta \text{ primitiva}} (X -\zeta)\]

***** 8.2.2. Grado del polinomio ciclotmico
Se cumple que $\operatorname{grad}(\Phi_n) = \phi(n)$.

****** Demostracin
El grupo de las races n-simas es cclico y de orden $n$, y tendr
exactamente $\phi(n)$ generadores.

***** 8.2.3. Lema al clculo de polinomios ciclotmicos
Tenemos:

\[X^n-1 = \prod_{d \mid n} \Phi_d\]

****** TODO Demostracin
***** 8.2.4. Clculo de los polinomios ciclotmicos
 Tenemos:

 \[\Phi_n  = \frac{X^n-1}{\prod_{d|n, d\neq n} \Phi_d}\]

****** Demostracin
Aplicando la frmula [[*8.2.3. Lema al clculo de polinomios ciclotmicos][anterior]].

***** 8.2.7. El polinomio ciclotmico es mnico
El polinomio ciclotmico es mnico $\Phi_n$ y tiene coeficientes en el
anillo primo.

****** TODO Demostracin
***** 8.2.8. Funcin de Mbius
Se define la *funcin de Mbius*, $\mu : \mathbb{N} \longrightarrow \mathbb{Z}$, como:

\[\mu(n) = \threepartdef
{0}{\exists p: \text{ primo con } p^2|n}
{(-1)^r}{n = p_1p_2\dots p_n \text{ primos distintos}}
{1}{n=1}\]

***** 8.2.8. Funcin de Mbius en la unidad
La funcin de Mbius verifica que:

\[ \sum_{d \mid n} \mu(d) =
\left\{\begin{array}{ll} 
1 & \mbox{if } n=1  \\
0 & \mbox{if } n \neq 1 
\end{array}
\right.
\]

****** TODO Demostracin

***** 8.2.10. Reglas de clculo de polinomios ciclotmicos
1. Si $p$ es primo $\Phi_p(X) = X^{p-1} + X^{p-2} + \dots + X + 1$.
2. $\Phi_{p^e}(x) = \Phi_p(x^{p^{e-1}})$
3. $\Phi_{p_1^{e_1}p_2^{e_2}\dots p_r^{e_r}}(x) = \Phi_{p_1\dots p_r}(x^{p_1^{e_1-1}\dots p_r^{e_r-1}})$
4. $\Phi_n = \prod_{d\mid n} (x^{n/d}-1)^{\mu(d)}$

**** 8.3. Extensiones ciclotmicas
***** 8.3.1. Extensin ciclotmica
Llamamos n-sima extensin ciclotmica de $K$ a $K(\zeta)/K$, donde
$\zeta$ es una raz primitiva de la unidad en la clausura.

***** 8.3.2. Grado en los racionales
En los racionales, $[\mathbb{Q}(\zeta) : \mathbb{Q}] = \phi(n)$.

****** TODO Demostracin

***** 8.3.3. Irreducibilidad racional del polinomio ciclotmico
$\Phi_n$ es irreducible en $\mathbb{Z}[X]$ (y en $\mathbb{Q}[X]$).

****** TODO Contraejemplo general
****** TODO Demostracin
***** 8.3.4. Irreducibilidad en cuerpo base primo
El cuerpo $\mathbb{F}_p$ contiene una raz n-sima primitiva de la unidad
ssi $p \equiv_n 1$.

****** Demostracin
Si contiene una raz n-sima primitiva, debe cumplir $\zeta^n = 1$, y a su
vez tener orden $p-1$, luego $n \mid p-1$. Si $n\mid p-1$, como $\mathbb{Z}_p^\times$ es
cclico, tiene un elemento de orden $n$, que ser raz primitiva de la
unidad.

***** 8.3.5. Primos congruentes a 1
Para todo $n$ existen infinitos primos congruentes a $1$ mdulo $n$.

****** TODO Demostracin
***** 8.3.6. Torre de extensiones ciclotmicas
Sean $n \mid m$, entonces $\mathbb{Q}(\zeta_n) \subset \mathbb{Q}(\zeta_m)$.

****** TODO Demostracin
***** 8.3.7. Producto de extensiones ciclotmicas
Sean $n,m$ y races primitivas distintas:

\[\mathbb{Q}(\zeta_n)\mathbb{Q}(\zeta_m) = \mathbb{Q}(\zeta_{mcm(n,m)})\]

****** TODO Demostracin

***** 8.3.8. Interseccin de extensiones ciclotmicas
Sean $n,m$ primos relativos, $\mathbb{Q}(\zeta_n) \cap \mathbb{Q}(\zeta_m) = \mathbb{Q}$.

****** TODO Demostracin
**** 8.4. Grupos de Galois
***** 8.4.1. Extensin ciclotmica es de Galois
La extensin ciclotmica $K(\zeta)/K$ es una extensin de Galois.

****** Demostracin
Es normal porque est generada por $X^n-1$, ya que la raz primitiva
genera a todas sus races. Como trabajamos con la hiptesis de que
$car(K) \nmid n$, todas las races de la unidad son distintas y el polinomio
es separable.

***** 8.4.2. Grupo de galois de la extensin ciclotmica
El grupo de Galois de la extensin ciclotmica es un subgrupo
de un multiplicativo, $Gal(K(\zeta)/K) < \mathbb{Z}_n^\times$.

****** Demostracin
Todo $\sigma \in Gal(K(\zeta)/K)$ est determinado por su efecto sobre $\sigma(\zeta) = \zeta^a$,
que debe llevar una raz primitiva en otra. Comprobamos que $\Lambda(\sigma) = a$
es un homomorfismo inyectivo y aplicamos Primer teorema de Isomorfa:

\[\Lambda(\sigma) = a;\; \Lambda(\tau) = b; 
\qquad
\tau\sigma(\zeta) = \zeta^{ab}\]

Donde $a \in \mathbb{Z}^\times_n$ porque debe poder invertirse por otra funcin.

***** 8.4.3. Grupo abeliano de la extensin ciclotmica
En general $Gal(K(\zeta)/K)$ es abeliano.

****** Demostracin
Es subgrupo de un abeliano.

***** 8.4.4. Grupo de la extensin ciclotmica en los racionales
Tenemos $Gal(\mathbb{Q}(\zeta)/\mathbb{Q}) \cong \mathbb{Z}_n^\times$.

****** TODO Demostracin

***** 8.4.11. Teorema de Kronecker-Weber
Toda extensin abeliana de $\mathbb{Q}$ est contenida en una extensin 
ciclotmica.

***** 8.4.12. Existencia de extensiones
Sea $G$ un grupo abeliano finito arbitrario. Existe una extensin $K/\mathbb{Q}$
tal que $Gal(K/\mathbb{Q}) \cong G$.

*** 10. Extensiones cclicas y radicales
**** 10.1. Extensiones cclicas
***** 10.1.1. Extensin cclica
Una extensin es cclica si es de Galois con grupo cclico.

***** 10.1.2. Teorema de Lagrange
Sea $K$ cuerpo y $n$ un primo relativo a $car(K)$. Supongamos que existe
una raz n-sima de la unidad en $K$:

  1. Dada $E/K$ extensin cclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ y $Irr(\alpha,K) = X^n-a$ para algn $a \in K$.
  2. Para $a \in K$, con $\alpha$ raz de $X^n-a$, se tiene $K(\alpha)/K$ cclica
     de grado $d \mid n$ y $\alpha^d \in K$.

****** Demostracin
******* Primer punto
Sea $E = K(u)$, $Gal(E/K) = \langle\sigma\rangle$ y $\zeta$ raz n-sima primitiva de la 
unidad. Llamamos *resolvente de Lagrange* a:

\[
\alpha = 
u + \zeta\sigma(u) + \zeta^2\sigma^2(u) + \dots + \zeta^{n-1}\sigma^{n-1}(u)
\]

Y por independencia lineal de los homomorfismos, sabemos $\alpha \neq 0$.
Aplicando $\sigma$ obtenemos:

\[\begin{aligned}
\sigma(\alpha) &= 
\zeta^{n-1}\sigma^n(u) + \sigma(u) + 
\zeta\sigma^2(u) + \dots + \zeta^{n-2}\sigma^{n-1}(u)
\\&=
\zeta^{-1}\alpha
\end{aligned}\]

Luego $\sigma^{i}(\alpha) = \zeta^{-i}\alpha$ y $\alpha$ tiene $n$ conjugados. Como $[K(\alpha):K] \geq n$,
tenemos $E = K(\alpha)$. Adems $\sigma(\alpha^n) = (\zeta\alpha)^n = \alpha^n$, luego $a = \alpha^n$ es
fijo bajo $\sigma$ y debe ser $a \in K$.

******* Segundo punto
******** Es de Galois
Todas las $\zeta^i\alpha$ son races disintas, luego $K(\alpha)$ es el cuerpo de
descomposicin del polinomio $X^n-a$ y es normal y separable por
ser $n$ primo relativo a $car(K)$.

******** Es cclica
Cada $\sigma \in Gal(K(\alpha)/K)$ se escribe como $\sigma(\alpha) = \omega_\sigma\alpha$ para alguna raz
de la unidad, ya que debe llevar $\alpha$ en otra raz y queda determinado
por ella. As $\sigma \longrightarrow \omega_\sigma$ es un monomorfismo en el grupo de las races 
n-simas, que slo tiene como subgrupos cclicos de orden $d \mid n$. 

Si $Gal(K(\alpha)/K)$ es cclico de orden $d$ generado por $\langle\sigma\rangle$, entonces $\omega_\sigma$ 
es raz d-sima primitiva de la unidad. Entonces:

\[\sigma(\alpha^d) = (\omega_\sigma\alpha)^d = \alpha^d\]

Quedando fijo sobre el grupo de Galois, $\alpha^d \in K$.

**** 10.2. Extensiones solubles y radicales
***** 10.2.1. Extensin soluble
Una extensin separable $F/K$ es soluble si hay una extensin $E/K$ de 
Galois con grupo soluble y $K < F < E$.

****** Definicin equivalente
Una extensin separable es soluble si su clausura normal tiene grupo
de Galois soluble.

***** 10.2.2. Extensin soluble por radicales
Una extensin $F/K$ finita separable es soluble por radicales cuando
$mcd([F:K],car(K)) = 1$ y hay una torre:

\[K = E_0 < E_1 < \dots < E_m = E\]

cumpliendo $F < E$ y siendo cada $E_{i+1}/E_i$ de una de estas dos formas:

  1. $E_{i+1} = E_i(\zeta)$ raz de la unidad.
  2. $E_{i+1} = E_i(\alpha)$ raz de un polinomio $X^n-a \in E_i[X]$, con 
     $mcd(n,car(K)) = 1$.

***** 10.2.3. Propiedades de las solubles por radicales
Sea $F/K$ soluble por radicales:

  1. Dada $L > K$, $FL/L$ es soluble por radicales.
  2. Dada $L > F > K$, $L/K$ soluble por radicales ssi $F/K, L/F$ solubles
     por radicales.
  3. $F/K, L/K$ solubles por radicales da $FL/K$ soluble por radicales.

****** TODO Demostracin

***** 10.2.4. Caracterizacin de solubilidad por radicales
Sea $F/K$ separable finita. Es soluble por radicales ssi existe:

\[L_0 < L_1 < \dots < L_m = L > F\]

Con cada paso soluble por radicales y $L/K$ Galois.

****** TODO Demostracin

***** 10.2.5. Teorema de Galois
Sea $F/K$ separable finita. Es soluble por radicales ssi es soluble.

****** TODO Demostracin

***** 10.2.6. Propiedades de las solubles
Cumplen:

  1. Dada $L > F > K$, $L/K$ soluble ssi $F/K,L/F$ solubles.
  2. Dada $F/K$ soluble $L/K$ arbitraria, $FL/L$ es soluble.
  3. Dadas $F/K,L/K$ solubles, $FL/K$ es soluble.

****** TODO Demostracin
Aplicando el [[*10.2.5. Teorema de Galois][Teorema de Galois]] a las propiedades de [[*10.2.3. Propiedades de las solubles por radicales][solubles por 
radicales]].

*** 11. Polinomios de grado 3 y 4
**** 11.1. El grupo de un polinomio
***** 11.1.1. Grupo de un polinomio
Llamamos grupo del polinomio $f$ al grupo $Gal(f/K)$, dado por las 
permutaciones de races del polinomio que da el grupo de Galois sobre
su cuerpo de descomposicin. Se tiene:

\[Gal(f/K) \lhook\joinrel\relbar\joinrel\rightarrow S_n\]

**** 11.2. Los teoremas clasificatorios
***** 11.2.1. Ceros bajo la misma rbita
Sea un polinomio con races simples factorizado $f = f_1f_2\dots f_r \in K[X]$.
Dos ceros $\alpha_i,\alpha_j$ son races del mismo $f_k$ ssi estn en la misma rbita
bajo $Gal(f/K)$.

****** Demostracin
Si estn en la misma rbita, hay morfismo que lleva una en otra, luego
son conjugadas y tienen el mismo irreducible. Si son conjugadas existe
el morfismo que lleva una en otra y estn bajo la misma rbita.

***** 11.2.2. Criterio de irreducibilidad de Galois
El polinomio $f$ es irreducible sobre $K$ ssi $Gal(f/K)$ es un subgrupo
transitivo de $S_n$.

****** Demostracin
Sern todas sus races del mismo irreducible ssi slo hay una rbita.

***** 11.2.3. Discriminante fijo bajo permutaciones pares
Supongamos que $f$ no tiene races mltiples y sea $car(K) \neq 2$. Sea:

\[\delta = \prod_{i < j} (\alpha_i - \alpha_j)\]

El cuerpo fijo bajo las permutaciones pares de $Gal(f/K)$ es $K(\delta)$.

****** Relacin con el discriminante
Observamos que $(a_n^{n-1}\delta)^2 = Disc(f)$.

****** Demostracin
Llamamos $F$ al cuerpo fijo bajo las permutaciones pares.
Para cualquier permutacin impar $\rho(\delta) = -\delta$ y para cualquiera
par $\sigma(\delta) = \delta$, as que $K \subset K(\delta) \subset F$. Tenemos dos casos:

  - $K = F$, que dara el resultado.
  - $K \neq F$, donde por Galois, $G \neq G^+$ y debera tenerse $[G : G^+] = 2$,
    luego $[F : K] = 2$. Pero como una permutacin impar cambia el signo
    del determinante, que no es nulo por definicin, $\delta \notin K$, y por
    tanto $F = K(\delta)$.

Ntese que en $car(K)=2$, el cambio de signo no hubiera movido a $\delta$.

***** 11.2.4. Determinante marcando paridad
El grupo de un polinomio es slo par $Gal(f/K) < A_n$ ssi $\sqrt{Disc(f)} \in K$.

****** Demostracin
Es lo que marca la distincin de casos en la anterior demostracin.

**** 11.3. Polinomios de grado pequeo
***** 11.3.1. Polinomios de grado 2
En un polinomio de grado 2 el discriminante vale $b^2 - 4ac$. Hay slo
dos posibilidades:

  - $\sqrt{b^2-4ac} \in K$, entonces $Gal(f/K) = 1$, y tiene dos races en el 
    cuerpo. 
  - $\sqrt{b^2-4ac} \notin K$, entonces $Gal(f/K) = S_2$, y el polinomio es 
    irreducible.

El cuerpo de descomposicin es $E = K\left(\sqrt{Disc(f)}\right)$.

****** Demostracin
Ntese que en ambos casos el cuerpo que dejan fijo las permutaciones
pares es todo el cuerpo de descomposicin del polinomio.

***** 11.3.2. Polinomios de grado 3
Un polinomio mnico $f = X^3+b_2X^2+b_1X +b_0$ puede:

  - Ser reducible, con algn factor lineal que nos lleva al caso de
    grado 2.
  - Ser irreducible.

En el caso irreducible:

  - $\sqrt{Disc(f)} \notin K$ ssi $Gal(f/K)=S_3$.
  - $\sqrt{Disc(f)} \in K$ ssi $Gal(f/K) = A_3$.

***** 11.3.3. Polinomios de grado 4
Tenemos un polinomio de grado 4 dado por:

\[
f = X^4 + a_3X^3+ a_2X^2 + a_1X + a_0 = \prod_{i=1}^4 (X - \alpha_i)
\]

****** Curtica reducible
Pueden darse dos casos:

  1. Se descompone en polinomios de grado 3 y 1; y tenemos una cbica
     como en el caso anterior.
  2. Se descompone en $f = f_1f_2$, por lo que debe ser subgrupo de
     $\langle (1\ 2),(3\ 4) \rangle$. Se distinguen dos casos usando discriminante:

     - $H = \langle (1\ 2)(3\ 4) \rangle$ cuando el discriminante est
       en el cuerpo $\sqrt{Disc(f_1)Disc(f_2)} \in K$.

     - $H = \langle (1\ 2),(3\ 4)\rangle$ cuando el discriminante no est
       en el cuerpo $\sqrt{Disc(f_1)Disc(f_2)} \notin K$.

****** Curtica irreducible
El grupo es uno de los grupos transitivos de $S_4$:

\[\begin{tikzcd}
& S_4 \dlar[no head]\drar[no head] & & \\
A_4 \drar[no head] & & D_4 \dlar[no head]\drar[no head] & \\
& V & & C_4
\end{tikzcd}\]

Para ayudarnos a resolver el polinomio debemos creamos su 
*resolvente cbica*, dados:

  - $\beta_1 = \alpha_2\alpha_3 + \alpha_1\alpha_4$
  - $\beta_2 = \alpha_1\alpha_3 + \alpha_2\alpha_4$
  - $\beta_3 = \alpha_1\alpha_2 + \alpha_3\alpha_4$

El polinomio que los tiene como races es de grado 3 y tiene
el mismo determinante. Puede calcularse con polinomios simtricos:

\[\begin{aligned}
g &= (X-\beta_1)(X-\beta_2)(X-\beta_3) \\
  &= X^3 - a_2X^2 + (a_1a_3 - 4a_0)X + (4a_2a_0 - a_3^2a_0 - a_1^2)
\end{aligned}\]

Ntese que $H < D_4$ o conjugado si $\beta_2 \in K$ o alguno de los otros.
Usando eso y que el discriminante nos da las permutaciones pares:

\[\begin{array}{ccc|c}
\sqrt{Disc(g)} & \beta_i & Gal(g/K) & Gal(f/K) \\
\hline
\notin K & \notin K & S_3 & S_4 \\
\in K & \notin K & A_3 & A_4 \\
\in K & \in K & 1 & V \\
\notin K & \in K & S_3 & D_4,C_4
\end{array}\]

******* Distincin de los ltimos casos
Observamos que $D_4 \cap A_4 = V$ es transitivo pero $C_4 \cap A_4 = \langle (13)(24) \rangle$ 
no lo es. As que $Gal(f/K) = D_4$ ssi $f$ es irreducible sobre
$K\left(\sqrt{Disc(f)}\right)$.

**** TODO 11.4. Cmo resolver una ecuacin soluble

*** A. Norma y traza
**** Norma y traza
***** Norma
Se define la *norma* de $\alpha$ relativa a $F/K$ separable como:

\[N_{F/K} = \prod \{\sigma_i(\alpha) \mid 1\leq i\leq n\} \]

para los $n$ homomorfismos que da $[F:K]_S$.

***** Traza
Se define la *traza* de $\alpha$ relativa a $F/K$ separable como:

\[T_{F/K} = \sum \{\sigma_i(\alpha) \mid 1 \leq i \leq n\}\]

para los $n$ homormorfismos que da $[F : K]_S$.

***** Norma y traza estn en el normal
Si $F/K$ es de Galois, $N_{F/K}(\alpha), T_{F/K}(\alpha) \in F$.

****** Demostracin
Al ser de Galois, los homomorfismos tienen imgenes en $F$.

***** Propiedades de norma y traza
Sea $F/K$ finita y separable de grado $n$:

  1. $N(\alpha\beta) = N(\alpha)N(\beta)$
  2. $T(\alpha+\beta) = T(\alpha) + T(\beta)$
  3. $N(a\alpha) = a^nN(\alpha)$ para cada $a \in K$
  4. $T(a\alpha) = naT(\alpha)$ para cada $a \in K$
  5. $N(\alpha) \in K$ para cada $\alpha \in F$
  6. $T(\alpha) \in K$ para cada $\alpha \in F$

****** Demostracin
******* Puntos 1 y 2
Simplemente por ser homomorfismos los que componen la suma y el
producto.

******* Puntos 3 y 4
Los homomorfismos dejan fijos los elementos del cuerpo.

******* TODO Puntos 5 y 6
Para $E$ una clausura normal $Gal(E/K)$ acta sobre $\frac{Gal(E/K)}{Gal(F/K)}$.

***** Frmulas de transitividad
Para una torre $K \subset F \subset E$ y $E/K$ finita y separable:

  1. $N_{F/K}(N_{E/F}(\alpha)) = N_{E/K}(\alpha)$
  2. $T_{F/K}(T_{E/F}(\alpha)) = T_{E/K}(\alpha)$

****** TODO Demostracin
***** Elemento de traza no nula
Sea $F/K$ finita y separable, existe $\alpha \in F$ tal que $T_{F/K}(\alpha) \neq 0$.

****** TODO Demostracin

***** Discriminante de una extensin
Sea $F/K$ extensin finita y separable. Dados $\alpha_1,\dots,\alpha_n \in F$ equivalen:

  1. $\{\alpha_1,\dots,\alpha_n\}$ base de $F$ como espacio vectorial sobre $K$.
  2. Son linealmente independientes sobre $F$ los elementos:

     \[\begin{aligned}
     \beta_1 &= (\sigma_1(\alpha_1), \dots, \sigma_1(\alpha_n)) \\
     \vdots &\\
     \beta_n &= (\sigma_n(\alpha_1), \dots, \sigma_n(\alpha_n)) \\
     \end{aligned}\]

  3. El determinante de la matriz $(T_{F/K}(\alpha_i\alpha_j))_{ij}$ es no nulo.

A este determinante lo llamamos *discriminante de la extensin* relativo
a la base $\alpha_1,\dots,\alpha_n$.

****** TODO Demostracin

*** B. Lista de temas de teora
**** 1. Galois es normal y separable
Si $E/K$ es una extensin finita, son equivalentes:

  1. $E/K$ extensin de Galois.
  2. $E/K$ extensin normal y separable.

***** Demostracin
****** Primera implicacin
Como cada $\sigma \in G = Gal(E/K)$ nos da un $\sigma : E/K \longrightarrow \overline{K}/K$, se tiene, por 
Teorema de Artin:

\[
[E:K]_S \geq |G| = [E:K] \geq [E:K]_S
\]

Por tanto, es separable. Adems, cada homomorfismo de ese tipo est
en $G$ luego es un automorfismo y el cuerpo queda fijo, siendo una
extensin normal.

****** Segunda implicacin
Sea $n = [E:K]_S = [E:K]$ por separabilidad. Cada uno de esos 
homomorfismos nos da $\sigma : E/K \longrightarrow E/K$, luego $Gal(E/K) = G$ tiene
orden $n$. Por Teorema de Artin:

\[ [E : E^G] = n = [E:K]\]

luego $[E^G : K] = 1$.

**** 2. Teorema del elemento primitivo de Steinitz
En $F/K$ extensin finita equivalen:

  1. $F/K$ tiene elemento primitivo.
  2. Existe un nmero finito de cuerpos intermedios.

***** Demostracin
****** Primera implicacin
Sea $F = K(\alpha)$. $Irr(\alpha,K)$, tiene un nmero finito de factores. Para 
cada uno de ellos, $p$, definimos el subcuerpo generado por sus 
coeficientes $K[|p|]$. Cualquier cuerpo intermedio $E$ en el que
$Irr(\alpha,E)=p$, contendr a los coeficientes $E \supset K[|p|]$, pero adems:

\[ [K(\alpha) : K[|p|] = [K(\alpha) : E]\]

Luego $E = K[|p|]$ y slo hay finitos cuerpos intermedios.

****** Segunda implicacin
******* Caso de cuerpo base finito
Como la extensin es finita, slo habr finitos elementos en ella. El
grupo multiplicativo de cualquier cuerpo es simple, as que tendr un
elemento primitivo.

******* Caso de cuerpo base infinito
Nos limitamos a probar $K(a,b)$ simple. Si consideramos los subcuerpos
de la forma $K(a+bx)$ para cada $x\in F$, como slo habr finitos,
debern coincidir algunos dos $K(a+bx) = K(a+by)$ con $x\neq y$. 

Entonces:

\[
b = \frac{(a+bx) - (a+by)}{x-y} \in K(a+bx) = K(a,b)
\]

**** 3. Caracterizaciones de extensiones normales
Para $E/K$ extensin finita equivalen:

  1. $E/K$ es una extensin normal. Es cuerpo de descomposicin de un
     polinomio.
  2. Para cada $\sigma : E/K \longrightarrow \overline{K}/K$, donde $\overline{K}$ es una clausura algebraica,
     se tiene $\sigma(E) = E$.
  3. Todo polinomio irreducible $f \in K[X]$ con una raz en $E$ descompone
     en $E$.

***** Demostracin
****** Implicacin 1 a 2
Como es una extensin finita ser de la forma $E = K(\alpha_1,\dots,\alpha_n)$.
La imagen de la raz de un polinomio deber ser una conjugada suya,
luego $\sigma(E) \subseteq E$. Como adems un endomorfismo entre extensiones
algebraicas es automorfismo, $\sigma(E) = E$.

****** Implicacin 2 a 3
Si una raz del polinomio est, existen homomorfismos que la llevan
en cada una de las conjugadas. Como cumplen $\sigma(E) = E$, se tiene que
todas las conjugadas estn en $E$ y el polinomio descompone.

****** Implicacin 3 a 1
La extensin finita es de la forma $E = K(\alpha_1,\dots,\alpha_n)$. Podemos tomar
los irreducibles de cada uno de los $\alpha_i$ y multiplicarlos. Como si una
raz est en el cuerpo todas lo estn, el cuerpo de descomposicin
de ese producto est contenido en $E$. Como tiene a todos sus $\alpha_i$, es $E$.

**** 4. Caracterizacin de la separabilidad
Sea $F/K$ una extensin finita y $\overline{K}$ una clausura algebraica de $K$ conteniendo
a $F$, entonces son equivalentes:

  1. $F/K$ es separable.
  2. $|Hom(F/K,\overline{K}/K)| = [F:K]$.

***** Demostracin
Llamamos $[F:K]_S = |Hom(F/K,\overline{K}/K)|$.

****** Caso simple
En un caso simple $K(\alpha) / K$ cada homomorfismo a la clausura queda
determinado por la imagen de $\alpha$, que debe ser a un elemento conjugado.
Tenemos que todas las races de $Irr(\alpha,K)$ tienen la misma multiplicidad
$m$, luego si es de grado $n$ habr $n/m$ races distintas.

Se da la igualdad slo si cada uno de los elementos es distinto,
esto es, si la extensin es separable.

****** Caso compuesto
Procedemos por induccin sobre el grado. Si tomamos un elemento en la
extesin $F \supseteq K(\alpha) \supseteq K$, sabemos:

\[
[F : K]_S = [F : K(\alpha)]_S [K(\alpha) : K]_S
\]

Sabemos que una extensin es separable si lo son sus subextensiones. 
Por hiptesis de induccin $[F : K(\alpha)]_S = [F : K(\alpha)]$ y por el caso base
$[K(\alpha) : K]_S = [K(\alpha) : K]$, por ser ambas separables.

**** 5. Teorema de Artin
Sea $E$ cuerpo y $G \subseteq Aut(E)$ un subgrupo finito, prueba que
$E^G = \{e \in E \mid \forall \sigma \in G: \sigma(e) = e\}$ es un subcuerpo y $[E : E^G] = |G|$.

***** Demostracin
****** Es un subcuerpo
Por definicin de morfismo de cuerpos.

****** Igualdad
Sabemos por Lema de Dedekind que $n = |G| \leq [E:E^G]$. Supongamos la
desigualdad estricta con $u_1,\dots,u_{n+1}$ independientes sobre $E^G$ y
creamos el siguiente sistema de $n+1$ incgnitas y $n$ ecuaciones:

\[
X_1\sigma_j(u_1) + \dots + X_{n+1}\sigma_j(u_{n+1}) = 0
\qquad
j = 1,\dots,n
\]

Sea $a_1,\dots,a_{n+1}$ solucin no trivial con nmero mnimo de elementos
no nulos. Suponemos s.p.g. que $a_1 \neq 0$, despejamos:

\[\sigma_j(u_1) = b_2\sigma_j(u_2) + \dots + b_{n+1}\sigma_j(u_{n+1})\]

En particular, cuando $\sigma_j = id$:

\[
u_1 = b_2u_2 + \dots + b_{n+1}u_{n+1}
\]

Por lo que alguno de los coeficientes no est en $E^G$ si queremos
mantener la independencia lineal. Sea $b_2 \notin E^G$ y $\tau(b_2) \neq b_2$. Si aplicamos
$\tau$ a cada una de las ecuaciones y restamos nos queda, sabiendo
que $\tau G = G$:

\[
0 = (b_2-\tau(b_2))\sigma_j(u_2) + \dots + (b_n-\tau(b_n))\sigma_j(u_{n+1})
\qquad
j = 1,\dots,n
\]

Esta solucin es no trivial pero tiene ms elementos nulos que la
anterior, llevando a contradiccin.

**** 6. Lema de independencia de Dedekind
Sea $F/K$ y $E/K$ extensiones de cuerpos, para cada familia no vaca ${\cal F}$ de
elementos de $Hom(F/K,E/K)$ prueba que son equivalentes:

  1. ${\cal F}$ es linealmente independiente en $Hom_K(F,E)$ sobre $E$.
  2. Todos los elementos de ${\cal F}$ son distintos.

***** Demostracin
Demostraremos que, en general $\sigma_1,\dots,\sigma_m : G \longrightarrow F^\times$ homomorfismos desde un
grupo $G$ son distintos ssi son linealmente independientes sobre $F$. El caso
$m = 1$ es trivial, y, en otro caso, podemos tomar un subconjunto mnimo
de linealmente dependientes:

\[
\sigma_s = b_1\sigma_1 + b_2\sigma_2 + \dots + b_{s-1}\sigma_{s-1}
\]

Sea $y$ tal que $\sigma_1(y) \neq \sigma_s(y)$. Evaluamos en $xy$, multiplicamos por $\sigma_s(y)$
por otro lado y restamos para tener:

\[
0 = b_1(\sigma_1(y)-\sigma_s(y))\sigma_1 + 
\dots + 
b_{s-1}(\sigma_{s-1}(y)-\sigma_{s-1}(y))\sigma_{s-1}
\]

Contraviniendo minimalidad de los linealmente independientes. Ntese
que el aadirles $0$ para tener $\sigma_1,\dots,\sigma_m : F_1 \longrightarrow F_2$ no los vuelve
linealmente dependientes o iguales.

**** 7. Caracterizacin de cuerpo algebraicamente cerrado
Para $K$ cuerpo, equivalen:

  1. Todo polinomio no constante $f \in K[X]$ tiene al menos una raz en $K$.
  2. Todo polinomio no constante $f \in K[X]$ descompone en $K$.
  3. Los polinomios no constantes irreducibles en $K[X]$ son de grado 1.
  4. $K$ no tiene extensiones algebraicas propias.

Los cuerpos que lo cumplen son *algebraicamente cerrados*.

***** Demostracin
****** Primera implicacin
Si el polinomio tiene una raz, puede descomponerse como $f = (X-\alpha)f'$.
Si $f'$ es constante, tenemos una descomposicin de $f$, si no lo es, podemos
descomponerlo a su vez.

****** Segunda implicacin
Un polinomio de grado distinto de $1$ descompone linealmente y por tanto
no puede ser irreducible.

****** Tercera implicacin
Sea $\alpha \in F/K$ algebraica. Como $Irr(\alpha,K)$ es de grado $1$, $\alpha \in K$. No puede
ser una extensin propia.

****** Cuarta implicacin
Si algn polinomio no tuviera ninguna raz en $K$, entonces l o un
divisor suyo seran irreducibles sin raz en $K$. Con ellos se genera
una extensin algebraica propia.

**** 8. Teorema de Kronecker
Sea $f \in K[X]$ un polinomio no constante, entonces existe una extensin
$F/K$ en la que $f(X)$ tiene al menos una raz.

***** Demostracin
Podemos descomponer en polinomios irreducibles $f = f_1 f_2\dots f_{n}$ y crear
la extensin siguiente con la inclusin trivial de $K$, que es cuerpo
por ser $(f_1)$ un ideal maximal:

\[
F = \frac{K[X]}{(f_1)} \supset K
\]

Y donde $X + (f_1)$ es raz del polinomio original por ser raz de la
inclusin de $f_1$:

\[
f_1(X+(f_1)) = f_1 + (f_1) = 0
\]

**** 9. Extensiones ciclotmicas de Galois
Sea $n$ entero positivo, $K$ un cuerpo y $F/K$ una extensin ciclotmica, cuerpo
de descomposicin del polinomio $X^n-1$, prueba que se verifica:

  1. $F/K$ es una extensin de Galois.
  2. $Gal(F/K)$ es isomorfo a un subgrupo del grupo multiplicativo de las
     unidades de $\mathbb{Z}_n$, por lo tanto su orden es un divisor de $\varphi(n)$.

***** Demostracin
****** Primer punto
Es el cuerpo de descomposicin de un polinomio, por lo tanto, es
normal. Adems, trabajamos con la hiptesis de que $car(K) \nmid n$, por lo
que el polinomio debe tener todas sus races distintas y ser separable.

****** Segundo punto
Ntese que si tenemos una raz primitiva, todas las races de la unidad
quedan generadas por ella, $F = K(\zeta)$, y cada elemento del grupo de Galois
queda determinado por a qu otra raz primitiva enva la $\zeta$.

Sea $\sigma(\zeta) = \zeta^a$. Tenemos que $\sigma^{-1}(\zeta) = \zeta^b$ y que $\zeta^{ab} = \zeta$, luego debe ser $a \in \mathbb{Z}^\times_n$.
Creamos entonces la funcin inyectiva $\Lambda(\sigma) = a$, que trivialmente es
un homomorfismo inyectivo:

  - $\Lambda(\sigma) = a \wedge \Lambda(\tau) = b \implies \Lambda(\sigma\tau) = ab$.
  - $\Lambda(\sigma) = 1 \implies \sigma = id$.

Y por Primer Teorema de isomorfa tenemos lo pedido. Comprobar que
adems divide a $\varphi(n)$ es trivial por ser el orden de $\mathbb{Z}_n^\times$.

**** 10. Teorema de Moore
Para cada $p^n$ potencia de primo, existe un cuerpo con $p^n$ elementos;
que es el cuerpo de descomposicin de $x^{p^n}-x$ sobre $\mathbb{F}_p$. Adems,
todo cuerpo finito de $p^n$ elementos es isomorfo a l.

***** Demostracin
Dos cuerpos finitos con el mismo cardinal son isomorfos y que adems
existe siempre un cuerpo de $p^n$ elementos.

****** Dos cuerpos finitos del mismo cardinal son isomorfos
Todo subgrupo finito del grupo multiplicativo de un cuerpo es cclico,
luego $F^\times$ ser cclico de orden $p^n-1$, y sus elementos cumplen el 
polinomio:

\[x^{p^n-1} - 1 = 0\]

As, $x^{p^n} - x$ tiene exactamente como races los $p^n$ elementos de $F$.

****** Existe un cuerpo con ese nmero de elementos
El polinomio $x^{p^n}-x$ tiene derivada $-1$, y por tanto, slo races
simples. Aadindolas a $\mathbb{F}_p$, se tiene ya un cuerpo de descomposicin.
Sean $u = u^{p^n}$ y $v = v^{p^n}$:

  - $(u+v)^{p^n} - (u+v) = 0$
  - $(uv)^{p^n} - uv = 0$
  - $(-u)^{p^n} - (-u) = 0$
  - $(u^{-1})^{p^n} - u^{-1} = 0$

**** 11. Teorema 90 de Hilbert
Sea $E/K$ extensin cclica de grado $n$ con grupo $G = Gal(E/K) = \langle \sigma\rangle$, y
sea $\beta \in E$, prueba que son equivalentes:

  1. $N_{E/K}(\beta) = 1$
  2. Existe $0 \neq \alpha \in E$ tal que $\beta = \frac{\alpha}{\sigma(\alpha)}$.

***** Demostracin
****** Primera implicacin
Los automorfismos $1,\sigma,\dots,\sigma^n$ son distintos y por tanto linealmente
independientes, luego no es la aplicacin cero:

\[
\tau 
= 
1 + \beta\sigma + (\beta \sigma(\beta))\sigma^2 + 
\dots +
(\beta \sigma(\beta)\dots \sigma^{n-2}\beta) \sigma^{n-1}
\]

Y existe $\tau(\theta) \neq 0$. Evaluando $\sigma(\tau(\theta))$ y multiplicando por $\beta$ nos queda
que $\beta \sigma(\tau(\theta)) = \tau(\theta)$.

****** Segunda implicacin
Usando que la norma es homomorfismo:

\[
N_{E/K}(\beta) = \frac{N_{E/K}(\alpha)}{N_{E/K}(\sigma(\alpha))} = 1
\]

**** 12. Races simples y derivada
Sea $f \in K[X]$ no constante. Equivalen:

  1. Todas las races de $f$ son simples.
  2. $f$ y $Df$ son primos relativos.

***** Demostracin
****** Primera implicacin
En el cuerpo de descomposicin de $f$ podemos escribir:

\[Df(X) = a \sum 
(X-\alpha_1)\dots(X-\alpha_{i-1})(X-\alpha_{i+1})\dots(X-\alpha_n)\]

Que claramente no comparte ningn factor primo $(X-\alpha_i)$ de $f$.

****** Segunda implicacin
En el cuerpo de descomposicin de $f$ podemos tomar una raz de 
multiplicidad $m > 1$. Y entonces $f = (X-\alpha)^m g$ mientras:

\[ Df = (X-\alpha)^m Dg+ m(X-\alpha)^{m-1}g\]

Por lo que no seran primos relativos en el cuerpo de descomposicin,
y por tanto, tampoco en $K$; ya que tenemos:

\[ Irr(\alpha,K) \mid f, Df\]

**** 13. Teorema de Lagrange
Sea $K$ un cuerpo, $n$ un entero positivo que es primo con la caracterstica
de $K$ (o es nula) y existe una raz n-sima primitiva de la unidad
$\xi$ en $K$, prueba que se verifica:

  1. Si $E/K$ es una extensin cclica de grado $n$, existe $\alpha \in E$ tal que
     $E = K(\alpha)$ e $Irr(\alpha,K) = X^n-a$ para algn $a \in K$.
  2. A la inversa, sea $a \in K$. Si $\alpha$ es una raz de $X^n-a$, entonces $K(\alpha)/K$
     es una extensin cclica de grado $d$, con $d\mid n$ y $a^d \in K$.

***** Demostracin
****** Primer punto
Sea $E = K(u)$ con $Gal(E/K) = \langle \sigma \rangle$ y $\zeta$ la raz n-sima primitiva de la
unidad. Creamos el *resolvente de Lagrange*:

\[
\alpha 
= 
u + \zeta\sigma(u) + \zeta^2\sigma^2(u) + \dots + \zeta^{n-1}\sigma^{n-1}(u)
\]

Que sabemos que no es nula por independencia lineal de homomorfismos
distintos, y que cumple que: $\sigma(\alpha) = \zeta^{-1}\alpha$. Luego $\sigma^i(\alpha) = \zeta^{-i}\alpha$, que son
las $n$ races conjugadas de $\alpha$. Adems $\sigma(\alpha^n) = \alpha^n$, por lo que $\alpha^n$ es un
punto fijo bajo $\sigma$ y debe ser $\alpha^n \in K$.

****** Segundo punto
******* Es extensin de Galois
Todas las $\zeta^i \alpha$ son races distintas, luego $K(\alpha)$ es el cuerpo de 
descomposicin del polinomio $X^n-\alpha$ y es normal y separable por ser
$n$ un primo relativo de $car(K)$.

******* Es cclica
Cualquier automorfismo debe llevar una raz del polinomio en otra y
queda determinado por ella. As, es de la forma $\sigma(\alpha) = \omega_\sigma \alpha$ para alguna 
raz de la unidad.

**** 14. Automorfismo de Frobenius
Sea $K$ cuerpo de caracterstica $p \neq 0$, prueba que son equivalentes:

  1. Todo polinomio irreducible no constante $f \in K[X]$ tiene todas sus 
     races simples.
  2. El endomorfismo de Frobenius es automorfismo.

***** Demostracin
****** Primera implicacin
Dado $a \in K$. Sea $X^p-a$, con una raz $\alpha$ en un cuerpo de descomposicin.
Tenemos $X^p-a = (X-\alpha)^p$. Como todos los irreducibles tienen races
simples, el nico irreducible factor del polinomio puede ser $X-\alpha$.

As $\alpha \in K$ y $a = \alpha^p$, siendo Frobenius sobreyectivo.

****** Segunda implicacin
Para que un irreducible tenga raz mltiple, debe dividir a su derivada,
que debe ser de grado menor, luego debe ser $0$. El polinomio debe ser
entonces de la forma $f(x^p)$ para que al derivarlo se anule.

Cuando Frobenius es automorfismo, podemos escribir:

\[f(x^p) = \sum a_i x^{ip} = \left( \sum \sqrt[p]{a_i} x^i \right)^{p}\]

Lo que contraviene irreducibilidad. Todos los polinomios deben tener
races simples.

**** 15. Galois es descomposicin de separable
Sea $E/K$ una extensin finita, prueba que son equivalentes:

  1. $E/K$ extensin de Galois.
  2. $E$ cuerpo de descomposicin de un polinomio separable sobre $K$.

***** Demostracin
****** Primera implicacin
Galois es normal y separable. Luego es cuerpo de descomposicin de
algn polinomio y este debe ser separable. Si no fuera separable,
tendra algn factor con alguna raz que no sera separable.

****** Segunda implicacin
El cuerpo de descomposicin de un polinomio separable debe ser normal
por cuerpo de descomposicin y separable porque todos los elementos
que lo generan lo son y la suma y producto de separables es separable.

*** Ejercicios
**** Relacin 1
***** Ejercicio 1.1
 Los polinomios simtricos en cuatro variables sern de la forma:

 \[\sum X_a = X_1+X_2+X_3+X_4\]
 \[\sum X_aX_b = X_1X_2+X_1X_3+X_1X_4+X_2X_3+X_2X_4+X_3X_4\]
 \[\sum X_aX_bX_c = X_1X_2X_3 + X_1X_2X_4 + X_1X_3X_4 + X_2X_3X_4\]
 \[\sum X_aX_bX_cX_d = X_1X_2X_3X_4\]

***** Ejercicio 1.2
 Usamos el polinomio recproco relacionando $p(x)$ con $p(\frac{1}{x})$ y usamos
 la derivada $p(x)$ para races dobles. Sea:

 \[\hat p(x) = \frac{1}{x^n}(1+a_nx+\dots+a_0x^n)\]

 Usamos entonces $\hat{\hat{p}'}$ para relacionar las races.
   
***** Ejercicio 1.3
***** Ejercicio 1.5
 Vamos a usar una ecuacin general que escribe una suma de potencias con
 otras variables en funcin de sumas de potencias de grado menor.

 \[\sum X_1^nX_2 \dots X_k = e_k\sum X_1^{n-1} - \sum X_1^{n-1}X_2 \dots X_kX_{k+1}\]

 para concluir que si la aplicamos repetidamente y llamamos 
 $s_n = \sum X^n$ obtendremos:

 \[ s_n = e_1s_{n-1} - e_2s_{n-2} + \dots + e_{n-1}s_1 - ne_n \]

 Por tanto, en los casos hasta $5$, tenemos:

 \[s_1 = e_1\]

 \[\begin{align*}
 s_2 &= e_1s_1 - 2e_2 \\
 &= e_1^2 - 2e_2
 \end{align*}
 \]

 \[\begin{align*}
 s_3 &= e_1s_2 - e_2s_1 + 3e_3 \\
 &= e_1^3 - 3e_1e_2 + 3e_3
 \end{align*}
 \]

 \[\begin{align*}
 s_4 &= e_1s_3 - e_2s_2 + e_3s_1 - 4e_4 \\
 &= e_1^4 - 3e_1^2e_2 + 3e_1e_3 - e_1^2e_2 + 2e_2^2 + e_1e_3 - 4e_4 \\
 &= e_1^4 - 4e_1^2e_2 + 4e_1e_3 - 4e_4 + 2e_2^2 
 \end{align*}
 \]

 \[\begin{align*}
 s_5 &= e_1s_4 - e_2s_3 + e_3s_2 - e_4s_1 + 5e_5 \\
 &= e_1^5 - 5e_1^3e_2 + 5e_1^2e_3 - 5e_1e_4 + 5e_1e^2_2 - 5e_3e_2 + 5e_5
 \end{align*}
 \]

 Ntese que aqu tomamos $e_m = 0$ en el caso de que haya menos de $m$ variables.

****** Solucin por grados
 Cada polinomio simtrico de grado $n$ es combinacin lineal de los que surgen
 como productos de elementales de grado $n$.

 \[x^3+y^3+z^3 = \alpha e_1^3 + \beta e_1e_2 + \gamma e_3\]

 Calculando se llega a $\alpha = 1$, $\beta = -3$, $\gamma = 3$.

***** Ejercicio 10
 Necesitamos uno que sea raz de $p'$ y de $p$.
 Sacamos las races de $p'$, que son $1$ y $\frac{5}{3}$.

 Tenemos que $1$ es raz doble cuando $k= -2$. Dividiendo por $(x-1)^2$ tenemos

 \[p(x) = (x-1)^2(x-2)\]

 Lo mismo se puede hacer con $\frac{5}{3}$, pero saldra $k \notin \mathbb{Z}$.

***** Ejercicio 11

**** Semana 1
***** Ejercicio 1.24
 Sea $M$ el conjunto de posibles /monomios/ en las variables y exponentes dados. 
 Podemos definir una funcin $S_n \longrightarrow M$ como sigue:

 \[\sigma(X_1^{e_1} X_2^{e_2} \dots X_n^{e_n}) = 
 X_{\sigma(1)}^{e_1} X_{\sigma(2)}^{e_2} \dots X_{\sigma(n)}^{e_n}
 \]

 Esto es una accin transitiva pero no fiel. El estabilizador para
 el monomio inicial, por ejemplo, son las permutaciones que mueven variables a
 variables del mismo exponente. Si hay $m_i$ variables de exponente $i$, podemos
 intercambiarlas de $m_i!$ formas distintas quedando un monomio igual. El estabilizador
 de ese monomio tiene por tanto orden $k = |Stab(x)| = m_1!m_2!\dots m_n!$. Aplicando ahora el
 Teorema de Lagrange para rbitas y estabilizadores obtenemos el nmero de
 monomios distintos:

 \[|M| = |S_n(M)| = \frac{|S_n|}{|Stab(x)|} = \frac{n!}{m_1!m_2!\dots m_n!}\]

***** Ejercicio 1.25
 Sea el polinomio $p(x) = x^3-5x-5$ con races $\alpha, \beta, \gamma$. Tenemos que el polinomio $p(x-1)$
 tendr races $\alpha+1,\beta+1,\gamma+1$:

 \[p(x-1) = (x+1)^3-5(x+1)-5 = x^3 - 3x^2 - 2x - 1\]

 Y que el polinomio recproco a l tendr races  $\frac{1}{\alpha+1}, \frac{1}{\beta+1}, \frac{1}{\gamma+1}$:

 \[q(x) = 1 - 3x - 2x^2 - x^3\]

 Trabajando con $-q(x)$, que es mnico, y con los polinomios de Cardano-Vieta sobre
 sus races tenemos que si estas fueran $u,v,w$, tendramos:

 \[(x-u)(x-v)(x-w) = x^3 - (u+v+w)x^2 +(uv+vw+wu)x - uvw\]

 Y desde aqu obtenemos el valor de los polinomios simtricos elementales sobre
 las races

 \[\begin{align*}
 e_1 &= u+v+w = -2 \\
 e_2 &= uv+vw+wu = 3 \\
 e_3 &= uvw = 1
 \end{align*}\]

 Ahora, expresamos el valor de $u^3+v^3+w^3$ como suma de polinomios elementales
 mediante el algoritmo de orden lexicogrfico de la demostracin:

 \[\begin{align*}
 \sum X_1^3 &= e_1^3 - (3\sum X_1^2X_2 + 6\sum X_1X_2X_3) \\
            &= e_1^3 - 3(e_1e_2 - 3\sum X_1X_2X_3 + 6\sum X_1X_2X_3) \\
            &= e_1^3 - 3e_1e_2 + 3e_1
 \end{align*}\]

 Y as, finalmente tenemos:

 \[u^3+v^3+w^3 = (-2)^3 - 3(-2)3 + 3 = 13\]

 # Existen cuerpos infinitos de caracterstica no nula?

**** Semana 2
***** Ejercicio 2.14
****** Punto 1
 Supongamos que se tiene $f(x) = ax+b$ con $a$ una unidad del anillo. Entonces podramos
 tomar como inversa de $\phi$ el homomorfismo de anillos que cumple $g(x) = a^{-1}(x - b)$ y que
 sobre los elementos del anillo es la identidad. Sera un isomorfismo.

 Estudiamos el caso de que $f(x)$ fuera de otra forma pero fuera isomorfismo. 
 Trivialmente su grado no podra ser $0$ para ser inyectivo sobre los elementos del
 anillo. Si $f(x)$ tuviera monomio lder $b_kx^k$
 y el monomio lder de $p$ fuera $a_mx^m$. Su imagen sera:

 \[\phi(p(x)) = a_0 + a_1f(x) + a_2f(x)^2 + \dots + a_mf(x)^m\]

 tendra un nico coeficiente lder de grado $km$ que sera 
 $a_mb_kx^{m+k} \neq 0$ por ser dominio de integridad.

 As,tenemos que $f$ no puede tener grado mayor que $1$ y debe tener un coeficiente lder unidad
 si queremos que $a_mb_kx^{m+k} = x \in img(\phi)$.

****** Punto 2
 El coeficiente lder puede anularse y la condicin ya no es suficiente.

 Sea $e$ en el nilradical de un anillo, con $e^n = 0$. Entonces se pueden tomar
 los dos homomorfismos cumpliendo:

 \[\phi(x) = x - e^{n-1}x^n\]
 \[\phi'(x) = x + e^{n-1}x^n\]

 Ntese ahora que $\phi\phi'(x) = \phi'\phi(x) = x$ y que para cualquier polinomio se comprobar
 que son dos automorfismos inversos entre s. De hecho, usando que son
 homomorfismos:

 \[\phi\phi'(p(x)) = p(\phi\phi'(x)) = p(x)\]

***** Ejercicio 2.15
****** Punto 1
 Si $f$ es irreducible en $\mathbb{Z}$, es en particular primitivo.
 Supongamos que $f = gh$ en $\mathbb{Q}$, factorizacin no trivial. Puedo escribir $g$ y $h$ como
 polinomios primitivos por una unidad de $\mathbb{Q}$: $f = ug_0h_0$. Como el producto de primitivos
 es primitivo, $g_0h_0$ lo es. Supongamos que tuviramos $u = \frac{a}{b}$, con:

 \[bf = ag_0h_0\]

 Llegamos a que $a|b$, $b|a$, ya que ninguno de los dos puede dividir a un 
 polinomio primitivo; y obtenemos $u$ unidad de $\mathbb{Z}$. Con lo cual, $f$ no sera
 irreducible en $\mathbb{Z}$.

****** Punto 2
 Como es irreducible sobre $\mathbb{Q}$, el ideal que genera es maximal y $F$ es
 por tanto un cuerpo. Las inclusiones son las triviales.

****** Punto 3
 Sea el polinomio $f(y) \in F[y]$. Tenemos que:

 \[f(X + (f(X))) = f(X) + (f(X)) = 0 + (f(X)) \]

 Por lo que es raz.

 La primera igualdad se obtiene del hecho de que las potencias y el producto
 por elementos del cuerpo respetan las clases de equivalencia; y por tanto,
 la evaluacin de un polinomio lo hace:

 \[(X + (f(X)))^n = X^n + X^{n-1}(f(X)) + \dots + (f(X)) = X^n + (f(X))\]
 \[a(X+(f(X))) = aX + (f(X))\]

***** Ejercicio 2.16
 Tenemos una extensin sobre $\mathbb{F}_2$ generada por un polinomio de grado 3. 
 Sus elementos son clases de equivalencia sobre polinomios de hasta 
 grado dos, habiendo 8 elementos. Abusando de la notacin, los escribimos como
 los representantes de su clase de equivalencia:

 \[\{0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1\}\]

 Tenemos las siguientes tablas para la suma y el producto:

 #+BEGIN_SRC sage :exports none
 R.<t> = PolynomialRing(GF(2),'t')
 I = R.ideal(t^3+t+1)
 S.<x> = R.quotient_ring(I)
 #+END_SRC
 #+RESULTS:

 #+BEGIN_SRC sage :exports results
 S.addition_table(
     names=["0","1","x","x+1","x^2","x^2+1","x^2+x","x^2+x+1"],
     elements=[0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1]
 )
 #+END_SRC
 #+RESULTS:
 #+begin_example

       +        0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
	+----------------------------------------------------------------
       0|       0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
       1|       1       0     x+1       x   x^2+1     x^2 x^2+x+1   x^2+x
       x|       x     x+1       0       1   x^2+x x^2+x+1     x^2   x^2+1
     x+1|     x+1       x       1       0 x^2+x+1   x^2+x   x^2+1     x^2
     x^2|     x^2   x^2+1   x^2+x x^2+x+1       0       1       x     x+1
   x^2+1|   x^2+1     x^2 x^2+x+1   x^2+x       1       0     x+1       x
   x^2+x|   x^2+x x^2+x+1     x^2   x^2+1       x     x+1       0       1
 x^2+x+1| x^2+x+1   x^2+x   x^2+1     x^2     x+1       x       1       0
 #+end_example

 #+BEGIN_SRC sage :exports results
 S.multiplication_table(
     names=["0","1","x","x+1","x^2","x^2+1","x^2+x","x^2+x+1"],
     elements=[0,1,x,x+1,x^2,x^2+1,x^2+x,x^2+x+1]
 )
 #+END_SRC
 #+RESULTS:
 #+begin_example

       *        0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
	+----------------------------------------------------------------
       0|       0       0       0       0       0       0       0       0
       1|       0       1       x     x+1     x^2   x^2+1   x^2+x x^2+x+1
       x|       0       x     x^2   x^2+x     x+1       1 x^2+x+1   x^2+1
     x+1|       0     x+1   x^2+x   x^2+1 x^2+x+1     x^2       1       x
     x^2|       0     x^2     x+1 x^2+x+1   x^2+x       x   x^2+1       1
   x^2+1|       0   x^2+1       1     x^2       x x^2+x+1     x+1   x^2+x
   x^2+x|       0   x^2+x x^2+x+1       1   x^2+1     x+1       x     x^2
 x^2+x+1|       0 x^2+x+1   x^2+1       x       1   x^2+x     x^2     x+1
 #+end_example

**** Semana 3
***** Ejercicio 2.17
****** Punto 1
 Tenemos el siguiente diagrama con las extensiones

 \[ \begin{tikzcd}
  & \mathbb{Q}({\sqrt{2}},\sqrt{3},\sqrt{5}) \drar[dash] \dar[dash] \dlar[dash] & \\
 \mathbb{Q}(\sqrt{2}) & \mathbb{Q}(\sqrt{3}) & \mathbb{Q}(\sqrt{5}) \\
 & \mathbb{Q} \urar[dash,swap]{2} \uar[dash]{2} \ular[dash]{2} &
 \end{tikzcd} \]

 Donde $\sqrt{2},\sqrt{3},\sqrt{5}$ son irracionales y sus polinomios irreducibles
 en $\mathbb{Q}$ son $x^2-2 = 0$, $x^2-3=0$ y $x^2-5=0$; por lo que son extensiones
 de grado $2$.

 Ahora mostramos que $\sqrt{3} \notin \mathbb{Q}(\sqrt{2})$, ya que:

 \[\sqrt{3} = a + b \sqrt{2}\]

 Y sabiendo que no puede tenerse $\sqrt{3} = a$ o $\sqrt{3} = b\sqrt{2}$:

 \[\sqrt{2} = \frac{3-a^2-b^2}{2ab}\]

 Y entones $\sqrt{2}$ sera racional. As, $\mathbb{Q}(\sqrt{2},\sqrt{3})$, sabiendo que adems 
 $\sqrt{3}^2 \in \mathbb{Q}$, debe ser una extensin de grado $2$ sobre $\mathbb{Q}(\sqrt{2})$.

 Ahora mostramos que $\sqrt{5} \notin \mathbb{Q}(\sqrt{2})(\sqrt{3})$, ya que, siendo $a,b \in \mathbb{Q}(\sqrt{2})$:

 \[\sqrt{5} = a + b\sqrt{3}\]
 \[ 5 = a^2 + 2ab\sqrt{3} + 3b^2\]

 Ahora, $ab = 0$, ya que, si no fuera as, $\sqrt{3} \in \mathbb{Q}(\sqrt{2})$; adems, $a=0$ o $b=0$, llegando
 a uno de los siguientes casos:

 \[ 5 = a^2 = x^2+y^2+2xy\sqrt{2}\]
 \[ 5 = 3b^2 = 3(x^2+y^2+2xy\sqrt{2})\]

 Donde, anlogamente, llegaramos a contradiccin con $\frac{5}{3} \notin \mathbb{Q}$.
 Como adems $\sqrt{5}^2 \in \mathbb{Q}$, es una extensin de grado $2$.

 Resumiendo, tenemos:

 \[ \begin{tikzcd}
  & \mathbb{Q}({\sqrt{2}},\sqrt{3},\sqrt{5}) & \\
  \mathbb{Q}(\sqrt{2},\sqrt{3}) \urar[dash]{2} & & \\
 \mathbb{Q}(\sqrt{2}) \uar[dash]{2} & \mathbb{Q}(\sqrt{3}) \ular[dash]{2} & \mathbb{Q}(\sqrt{5}) \arrow[uul,dash] \\
 & \mathbb{Q} \urar[,dash,swap]{2} \uar[dash]{2} \ular[dash]{2} &
 \end{tikzcd} \]

 Y aplicando la frmula de grado de las extensiones llegamos
 a que $[\mathbb{Q}(\sqrt{2},\sqrt{3},\sqrt{5}) : \mathbb{Q}] = 8$.

****** Punto 2
 Tenemos a $1,\sqrt{2},\sqrt{3},\sqrt{5},\sqrt{6},\sqrt{10},\sqrt{15},\sqrt{30}$ sistema de generadores del espacio,
 y por ser de dimensin $8$, sabemos que forman una base. Veamos que $1,\alpha,\alpha^2,\dots,\alpha^7$ es una base 
 del mismo espacio comprobando independencia lineal sobre la base inicial.

 #+BEGIN_SRC sage :exports none
   A = FreeAlgebra(QQ,3,'i')
   F = A.monoid()
   a,b,c = F.gens()
   mons = [ F(1), a,b,c,a*b,a*c,b*c,a*b*c ]
   M = MatrixSpace(QQ,len(mons))
   mats = [
       M([0,1,0,0,0,0,0,0,
          2,0,0,0,0,0,0,0,
          0,0,0,0,1,0,0,0,
          0,0,0,0,0,1,0,0,
          0,0,2,0,0,0,0,0,
          0,0,0,2,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,0,0,0,0,0,2,0
       ]),
       M([0,0,1,0,0,0,0,0,
          0,0,0,0,1,0,0,0,
          3,0,0,0,0,0,0,0,
          0,0,0,0,0,0,1,0,
          0,3,0,0,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,0,0,3,0,0,0,0,
          0,0,0,0,0,3,0,0
       ]),
       M([0,0,0,1,0,0,0,0,
          0,0,0,0,0,1,0,0,
          0,0,0,0,0,0,1,0,
          5,0,0,0,0,0,0,0,
          0,0,0,0,0,0,0,1,
          0,5,0,0,0,0,0,0,
          0,0,5,0,0,0,0,0,
          0,0,0,0,5,0,0,0
       ])
   ]
   P3.<a,b,c> = A.quotient(mons,mats)
 #+END_SRC

 #+RESULTS:

 Para ello escribo los coeficientes de cada $\alpha^n$ en la
 base inicial formando la siguiente matriz y compruebo que son linealmente independientes.

 #+BEGIN_SRC sage :exports results
 M = matrix([ ((a+b+c)^n).vector() for n in range(0,8) ]).transpose()
 M
 #+END_SRC

 #+RESULTS:
 : 
 : [    1     0    10     0   224     0  6160     0]
 : [    0     1     0    26     0   784     0 23024]
 : [    0     1     0    24     0   664     0 18976]
 : [    0     1     0    20     0   520     0 14720]
 : [    0     0     2     0    80     0  2448     0]
 : [    0     0     2     0    64     0  1904     0]
 : [    0     0     2     0    56     0  1584     0]
 : [    0     0     0     6     0   200     0  5936]

 Si calculamos el rango de esta matriz, obtenemos que es invertible.

 #+BEGIN_SRC sage :exports both
 M.rank()
 #+END_SRC

 #+RESULTS:
 : 8

****** Punto 3
 Usando la matriz anterior, obtengo un polinomio que tiene por raz
 a $\sqrt{2}+\sqrt{3}+\sqrt{5}$. Para ello escribo los coeficientes de $\alpha^8$ en
 funcin de la base anterior de la matriz.

 #+BEGIN_SRC sage :exports both
 M.solve_right(vector(QQ,((a+b+c)^8).vector()))
 #+END_SRC

 #+RESULTS:
 : (-576, 0, 960, 0, -352, 0, 40, 0)

 As que tengo el polinomio siguiente del que $\alpha$ es raz:

 \[t^8-40*t^6+352*t^4-960*t^2+576\]

 # Checking the answer
 #+BEGIN_SRC sage :exports none
 t = sqrt(2)+sqrt(3)+sqrt(5)
 (-40*t^6+352*t^4-960*t^2+576+t^8).expand()
 #+END_SRC

 #+RESULTS:
 : 0

****** Punto 4
 Por el diagrama de extensiones del ejercicio $1$ sabemos que $\mathbb{Q}(\sqrt{2},\sqrt{3})$ es una extensin
 de grado 4. Como ya sabemos que $\mathbb{Q}(\sqrt{2}+\sqrt{3}) = \mathbb{Q}(\sqrt{2},\sqrt{3})$, tenemos que $\sqrt{2}+\sqrt{3}$ es 
 un elemento de grado 4 sobre $\mathbb{Q}$.
**** Semana 4
***** Ejercicio 3.11
****** Punto 1
 Sea el polinomio $f\in \mathbb{F}_2[X]$ con una raz $\lambda$; comprobamos que tambin
 es raz $\lambda^2$:

 \[\begin{aligned}
 f(\lambda^2) 
 &= a_n\lambda^{2n} + a_{n-1}\lambda^{2(n-1)} + \dots + a_1\lambda^2 + a_0 \\
 &= (a_n\lambda^n + a_{n-1}\lambda^{n-1} + \dots + a_1\lambda + a_0)^2 \\
 &= f(\lambda)^2
 \end{aligned}
 \]

 Donde usamos que:

 \[a_p\lambda^{2p} + a_q\lambda^{2q} = 
 a^2_p\lambda^{2p} + 2a_pa_q\lambda^p\lambda^q + a^2_q\lambda^{2q} =
 (a_p\lambda^p + a_q\lambda^q)^2\]

 Aplicando esto varias veces llegamos a que $\lambda,\lambda^2,\lambda^4,\dots$ son races.

****** Punto 2
 Sea el polinomio $f(x) = x(x^2+x+1) = x^3+x^2+x$, que tiene como raz en 
 $K \cong \frac{\mathbb{F}_2[X]}{(x^2+x+1)}$ a $\lambda = x + (x^2+x+1)$; ntese que tiene como raz tambin a $0$, que no es
 potencia de $\lambda$.

****** Punto 3
 Siendo $\beta$ una raz primitiva, genera el cuerpo y una base de $K$ sobre su cuerpo
 base debe estar generada por $\beta$ y formada por  
 $\{1,\beta,\beta^2,\dots,\beta^{n-1}\}$; supongamos que el grado de $f$ fuera
 menor que $n$, entonces tendra una relacin de dependencia lineal entre la base:

 \[ 0 = f(\beta) = a_0 +a_1\beta + \dots + a_{n-1}\beta^{n-1} \]

 Lo que nos dara una contradiccin.

**** Semana 5
***** Ejercicio 4.17
#+begin_statement
Sea $K \subseteq E \subseteq F$ una torre de cuerpos y supongamos que $\alpha_1,\dots,\alpha_r$ son algunas de las 
races de $f(X) \in K[X]$ y $E = K(\alpha_1,\dots,\alpha_r)$. Demuestra que $F$ es el cuerpo de 
descomposicin de $f(X)$ sobre $K$ si, y slo si, $F$ es el cuerpo de descomposicin de
$f(X)$ sobre $E$.
#+end_statement

Antes que nada, podemos descomponer $f$ en la clausura algebraica $\overline{K}$ como factores
lineales con races $\alpha_1,\dots,\alpha_n$. Vamos a fijarnos en el hecho de que el cuerpo de 
descomposicin de un polinomio sobre un cuerpo es el cuerpo resultante de aadirle
sus races en la clausura; esto es debido que cumple trivialmente la propiedad del 
cuerpo de descomposicin, y adems es minimal porque cualquier otro debe contener a 
sus races y, por tanto, contenerlo l.

Ahora veamos que ambos cuerpos de descomposicin que se plantean en el ejercicio 
son iguales. Por un lado, el cuerpo de descomposcin de $f$ sobre $K$ debe ser
$K(\alpha_1,\dots,\alpha_n)$; y por otro, el cuerpo de descomposicin de $f$ sobre
$E$, que tambin tiene como clausura algebraica a $K$, debe ser: 

\[\begin{aligned}
E(\alpha_1,\dots,\alpha_n) &= K(\alpha_1,\dots,\alpha_r)(\alpha_1,\dots,\alpha_n) \\
&= K(\alpha_1,\dots,\alpha_r)(\alpha_{r+1},\dots,\alpha_n) \\
&= K(\alpha_1,\dots,\alpha_n) 
\end{aligned}\]

***** Ejercicio 4.18
#+begin_statement
Sea $a \in \mathbb{Q}$ y $n$ un nmero entero positivo impar tal que
$\sqrt[n]{a} \in \mathbb{R}/\mathbb{Q}$. Demuestra que la extensin $\mathbb{Q}(\sqrt[n]{a})/\mathbb{Q}$ no es normal.
#+end_statement

Tengo que $\sqrt[n]{a}$ es raz de $x^n-a$. Eso quiere decir que ser mltiplo de 
$\operatorname{Irr}(\sqrt[n]{a},K)$, y que por tanto, toda raz de su polinomio irreducible ser raz 
de $x^n-a$. En $\mathbb{C}$, las races de ese polinomio son de la forma $\{\zeta^i_n\sqrt[n]{a}\}$,
con los $\zeta$ races de la unidad; y, siendo $n$ impar, slo una ser real.

Por otro lado, si queremos que sea una extensin normal, el polinomio irreducible
debera tener todas sus races en la extensin y factorizar linealmente en ellas;
pero como slo hay una real y la extensin est contenida en los reales, slo
podra tener una raz, el polinomio sera lineal y entonces se tendra $\sqrt[n]{a} \in \mathbb{Q}$.

***** Ejercicio 4.19
#+begin_statement
Sea $E/K$ una extensin normal y $f(X) \in K[x]$ un polinomio (mnico) irreducible. Si
$f(X)$ se factoriza en $E$ como producto de dos polinomios (mnicos) irreducibles 
$f_1(x)$ y $f_2(x)$. Demuestra que existe un homomorfismo $\sigma : E/K \longrightarrow E/K$ tal que
$f^\sigma_1(x) = f_2(x)$.
#+end_statement

Sea $\alpha$ raz de $f_1$ y $\beta$ raz de $f_2$. Ambos son los polinomios irreducibles de sus races
en $E$. Como ambas adems son races de $f$, son conjugadas sobre $K$
y existe un automorfismo sobre $K$ que lleva $\sigma(\alpha) = \beta$. Ese isomorfismo cumple 
que $\sigma(E) = E$ por normalidad. Ahora, por irreducibilidad:

\[f_2 | f_1^\sigma\]

Y tenemos que:

\[ f_1f_2 = f = f^\sigma = f_1^\sigma f_2^\sigma\]

Esto quiere decir que $f_1 = f_2^\sigma$ y que $f_2 = f_1^\sigma$; ya que estamos en un dominio de 
factorizacin nica y ambos son mnicos.
**** Semana 6
***** Ejercicio 5.10
#+begin_statement
Sea $K$ cuerpo de caracterstica $p \neq 0$ y $t$ una indeterminada sobre $K$. Prueba que el
polinomio $X^p-t^p \in K(t^p)[X]$ es irreducible.
#+end_statement

Por binomio de Newton, en $K(t)[X]$ tenemos $x^p-t^p = (x-t)^p$. Sus divisores son de la
forma $(x-t)^q$ para $q<p$; y ninguno puede estar en $K(t^p)[X]$ porque implicara que
estuviera su ltimo coeficiente $(-t)^q \in K(t^p)[X]$, con lo que ya no sera una 
indeterminada porque se podra escribir $t^q$ relacionado con $t^p$.

***** Ejercicio 5.11
#+begin_statement
Estudiar si son o no ciertas las siguientes afirmaciones:

 - $\sqrt[3]{-1}$ es separable sobre $\mathbb{F}_9$.
 - $\sqrt[3]{-1}$ es separable sobre $\mathbb{F}_{49}$.
 - $\sqrt[7]{5}$ es separable sobre $\mathbb{F}_{7^7}$.
 - $t$ es separable sobre $\mathbb{F}_{p^2}(t^p)$, siendo $p$ un nmero entero primo positivo y $t$ una
   indeterminada sobre $\mathbb{F}_{p^2}$.

$\quad$
#+end_statement

Las tres primeras son extensiones finitas sobre cuerpos perfectos (por ser finitos),
luego todas son separables. Para el ltimo caso, $x^p-t^p = 0$ es irreducible y por 
tanto polinomio mnimo de $t$, pero tiene races mltiples, luego $t$ es un elemento 
no separable.

***** Ejercicio 5.12
#+begin_statement
Sea $E$ un cuerpo y $\{\varphi_1,\dots,\varphi_n\}$ un conjunto de $n$ automorfismos distintos de $E$.
Llamamos $K = \{e \in E \mid \varphi_i(e) = e, 1 \leq i \leq n\}$. Demuestra que $[E:K]\geq n$.
#+end_statement

Dada la extensin $E/K$. Tenemos dos casos:

 - $E$ es infinita sobre $K$, luego $[E:K] \geq n$.
 - $E$ es finita sobre $K$, por el corolario al lema de Dedekind, tenemos:
   \[ [E:K] \geq |Hom(E/K,E/K)| \geq n\]

**** Semana 7
***** Ejercicio 7.25
#+begin_statement
Sea $f \in K[X]$ un polinomio sin races mltiples; y
$G = \operatorname{Gal}(f/K)$. Prueba que son equivalentes:

 1. $f(X)$ es irreducible.
 2. $G$ acta transitivamente sobre las races de $f$.

$\quad$
#+end_statement

Sea $f$ irreducible. Cualesquiera dos de sus races tienen a $f$ como polinomio 
irreducible; luego son conjugadas y existe un automorfismo de la clausura que
lleva una en otra, $\sigma : \overline{K} \longrightarrow \overline{K}$. Como la extensin $f/K$ es normal ser la extensin
de descomposicin de un polinomio irreducible $f$, tenemos que $\sigma|_{f/K} \in G$.

Sea $G$ actuando transitivamente sobre las races de $f = gh$, descomposicin
en $K[X]$. Una raz no puede estar
repetida en $g$ y en $h$, porque conllevara races mltiples. Sea $a$ raz de $g$, y
sea un $\sigma : f/K \longrightarrow f/K$ que la lleve en $b$ raz de $h$. Entonces

\[ h(a) = h(\sigma(b)) = \sigma(h(b)) = 0\]

contraviniendo que no existan races mltiples.
**** Semana 8
***** Ejercicio 7.26
    #+begin_statement
    Se considera el producto semidirecto $G = \mathbb{Z}_8\rtimes_\theta\mathbb{Z}_2$, siendo $\theta(1)(1)=3$.
    Observa que $G$ es un grupo de orden 16. Supongamos que $G$ es el grupo de Galois
    de una extensin $E/K$.

    1. Cuntos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $8$?
       Cuntos con un grupo de Galois $Gal(F/K)$ isomorfo a $\mathbb{Z}_8$?
    2. Cuntos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $4$?
       Cuntos con un grupo de Galois $Gal(F/K)$ isomorfo a $\mathbb{Z}_4$? y
       cuntos con grupo de Galois isomorfo al grupo de Klein?
    3. Cuntos cuerpos intermedios $F/K$, con $K\subset F\subset E$, existen de grado $2$?
       Cuntos con grupo de Galois $Gal(E/F)$ isomorfo a $\mathbb{Z}_8$?
    4. Determina el retculo de subgrupos de $\mathbb{Z}_8 \rtimes_\theta\mathbb{Z}_2$.
    #+end_statement
    
    Lo que estamos buscando en cada uno de esos casos, gracias a la correspondencia
    de Galois, son subgrupos. Si calculamos el orden de los elementos en este
    producto semidirecto, tenemos:

    | Elemento | Orden |
    |----------+-------|
    | (0,0)    |     0 |
    | (1,0)    |     8 |
    | (2,0)    |     4 |
    | (3,0)    |     8 |
    | (4,0)    |     2 |
    | (5,0)    |     8 |
    | (6,0)    |     4 |
    | (7,0)    |     8 |
    | (0,1)    |     2 |
    | (1,1)    |     4 |
    | (2,1)    |     2 |
    | (3,1)    |     4 |
    | (4,1)    |     2 |
    | (5,1)    |     4 |
    | (6,1)    |     2 |
    | (7,1)    |     4 |

****** Punto 1
     Isomorfo a $\mathbb{Z}_8}$ es:

     \[<(1,0)>\]

     Que como contiene a todos los dems elementos de orden $8$, nos asegura que no 
     hay ms isomorfos a $\mathbb{Z}_8$.

     Tenemos adems uno isomorfo a $\mathbb{Z}_2\times\mathbb{Z}_4$, que es:

     \[<(2,0),(0,1)>\]
     
     Y otro isomorfo al grupo de los cuaternios, que es:

     \[<(4,0),(2,0),(1,1),(7,1)>\]

     No encontramos ninguno isomorfo a $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2$, que necesitara de $7$ elementos
     de orden $2$.

****** Punto 2
     Isomorfos al grupo de Klein:

     \[\{(0,0),(2,1),(4,0),(6,1)\}\]
     \[\{(0,0),(0,1),(4,1),(4,0)\}\]

     Cclicos de grado $4$:

     \[<(2,0)>\]
     \[<(1,1)>\]
     \[<(3,1)>\]

****** Punto 3
     Subgrupos de grado $2$ son los que genera cada elemento de grado $2$. Hay
     cinco elementos de grado $2$.

***** Ejercicio 7.26 (Usando sage)
    Usamos Galois para tener correspondencia con un problema de grupos

    #+BEGIN_SRC sage
sage: C8 = CyclicPermutationGroup(8)
sage: alpha = PermutationGroupMorphism(C8,C8,[C8.gen()**3])
sage: phi = [[(1,2)],[alpha]]
sage: G = CyclicPermutationGroup(2).semidirect_product(C8,phi)
sage: G
Permutation Group with generators [(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]
sage: G.order()
16
sage: G.subgroups()

[Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [()],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,5)(4,8)(7,9)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,7)(4,10)(6,8)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(1,2)(3,9)(5,7)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,9)(5,7)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,4,7,8)(5,10,9,6)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,7)(4,8)(5,9)(6,10), (1,2)(3,10,7,6)(4,5,8,9)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,4,5,6,7,8,9,10), (3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(3,4,7,8)(5,10,9,6)],
 Subgroup of (Permutation Group with generators 
[(3,4,5,6,7,8,9,10), (1,2)(4,6)(5,9)(8,10)]) generated by [(3,4,5,6,7,8,9,10), (3,5,7,9)(4,6,8,10), (3,7)(4,8)(5,9)(6,10), (1,2)(4,6)(5,9)(8,10)]]
    #+END_SRC

**** Semana 9
***** Ejercicio 7.27
    #+begin_statement
    Prueba que los subgrupos transitivos de $S_4$ son los subgrupos siguientes:
    
      1. $S_4$, que es normal.
      2. $A_4$, que es normal.
      3. $D_4 = \langle(1234),(13) \rangle$, y todos sus conjugados.
      4. $C_4 = \langle (1234) \rangle$, y todos sus conjugados.
      5. $V = \{1,(12)(34),(13)(24),(14)(24)\}$, que es normal.
    
    El retculo de subgrupos transitivos de $S_4$ es:

    \[ \begin{tikzcd}
    & & S_4 & \\
    & A_4 \urar & & D_4 \ular \\
    V \urar & & C_4 \ular \urar &
    \end{tikzcd} \]

    Como consecuencia, si $f(X)\in \mathbb{Q}[X]$ es un polinomio irreducible de grado cuatro,
    el grupo de Galois de $\mathbb{Q}(f)/\mathbb{Q}$ es isomorfo a uno de stos.
    #+end_statement

    El grupo de Galois de un polinomio *irreducible* de grado cuatro debe poder
    permutar entre las $4$ races del polinomio, por lo que debe ser un subgrupo
    transitivo de $S_4$. Para que un subgrupo sea transitivo, su orden debe ser mayor
    que $4$.

    Comprobamos que:

      - De orden 24, el nico es $S_4$.
      - De orden 12, el nico es $A_4$.
      - De orden 8, el nico es $D_4$, con tres conjugados.
      - De orden 6, el nico es isomorfo a $S_3$, con cuatro conjugados.
      - De orden 4, los nicos son $C_4$ y $V$, con seis conjugados.
	
    De esta lista retiramos a $\langle (12),(23),(13) \rangle$ y sus cuatro conjugados por no ser
    transitivos. El resto se comprueban transitivos.

***** Ejercicio 7.28
    #+begin_statement
    Sea $f(X)\in K[X]$ un polinomio separable y $g$ un factor irreducible de $f$. Acta
    transitivamente $G = \operatorname{Gal}(f/K)$ sobre las races de $g$?
    #+end_statement
    
    Como $g$ es el polinomio irreducible de cualesquiera dos races suyas, estas son
    conjugadas y existe un isomorfismo $\sigma : \overline{K} \longrightarrow \overline{K}$. Como $f/K$ entendemos que es
    normal, ese isomorfismo se restringe a $f/K$.
**** Semana 10
***** Ejercicio 7.29
****** Punto 1
Si es irreducible, tenamos por el ejercicio de Semana 9 que
su grupo sera un subgrupo transitivo de $S_4$.

Como si $\alpha$ es raz lo es $-\alpha$, tenemos que como mucho habr $8$ automorfismos.
Fijada la imagen de $\alpha$ entre las cuatro posibles, queda fijada la imagen
de $-\alpha$, as, slo quedan dos posibles imgenes para $\beta$. No puede ser
isomorfo por tanto a $S_4$ o a $A_4$.

****** Punto 2
Estamos en el caso del punto anterior por el polinomio $(x^2-n)(x^2-m)$.
El grupo no es trivial porque $\sqrt{n},\sqrt{m}$ no son racionales. No puede
tener automorfismos que lleven $\sqrt{n}$ en $\sqrt{m}$ porque $\sqrt{nm}$ no es un
cuadrado y entonces se tiene $n \neq m$.

Fijada la imagen de $\sqrt{n}$ entre dos posibles, slo queda la imagen de 
$\sqrt{m}$ entre dos posibles. No puede ser por tanto $D_4$, y no puede ser
un grupo cclico porque tiene elementos de orden $2$. Debe ser $V$.

****** Punto 3
Como $\mathbb{Q}(\sqrt{n}+\sqrt{m})$ genera una extensin de grado 4, ser de grado 4
su polinomio irreducible, ya que hemos dicho que $\sqrt{nm}$ no es racional
y tenemos que:

\[ \frac{\sqrt{nm}}{\sqrt{n}+\sqrt{m}} = \frac{1}{\sqrt{1/n}+\sqrt{1/m}}\]

Ambos irreducibles por serlo $\sqrt{n}+\sqrt{m}$.

Por ltimo, comprobamos que es un polinomio que lo tiene como raz:

\[ x^4 - 2(n+m) x^2 + n^2 -2nm + m^2\]

A este polinomio llegamos simplemente manipulando algebraicamente
las representaciones de $(\sqrt{n}+\sqrt{m})^2$ y $(\sqrt{n}+\sqrt{m})^4$.

****** Punto 4
Si tomamos un elemento en $u \in F-\mathbb{Q}$, tenemos que $[F:\mathbb{Q}(u)]$ podra
ser $2$ o $1$. Si fuera $1$, entonces $\{1,u,u^2,u^3\}$ es base y $[F : Q(u^2)]$ sera
de grado $2$. Tendramos un cclico. Si fuera $2$, tenemos $u^2 \in \mathbb{Q}$,
como buscamos.

****** Punto 5
Tomamos $f_1(x) = (x^2-2)(x^2-3)$, que hemos demostrado en el punto
2 que funciona. $f_2(x) = x^4+3$ tiene grupo isomorfo a $D_3$.
En el punto 7 tenemos un ejemplo para $f_3$ en $x^4+5x^2+5$, que es
irreducible por Eisenstein en mdulo 2.

****** Punto 6
Si tengo races $u,-u,v,-v$, tengo $\sqrt{c} = \pm uv$ racional. Cualquier
automorfismo de grado cuatro de los posibles llevara $u \mapsto v$
$v \mapsto -u$, por lo que cambiara el signo de un racional.

****** Punto 7
Si resolvemos la ecuacin de grado $4$ tenemos:

\[ \sqrt{c} = uv \]
\[ \sqrt{b^2-4c} = (u^2-v^2)\]

El producto de ambas es racional, pero uno de los automorfismos de
grado dos que est en $V$ y en $D_4$, que lleva $u \mapsto v$, $v \mapsto u$, cambiara
el signo de un real.

** Ecuaciones diferenciales II
*** Apuntes de Andrs
# Estas notas salen de los apuntes de Andrs Herrera para la misma
# asignatura el ao anterior.
**** 1. Introduccin
***** 1.1. Notacin
****** Ecuacin diferencial ordinaria (EDO)
****** Solucin de una EDO
****** Problema de valores iniciales o de Cauchy (PVI)
***** 1.2. Unicidad de solucin y soluciones maximales
****** Propiedad de unicidad local
****** Propiedad de unicidad en intervalo
****** Propiedad de unicidad global
****** Local en cualquier condicin ssi global en cualquier condicin
La demostracin usa que el conjunto donde coinciden debe ser abierto por
propiedad local y cerrado por ser ambas funciones continuas.
****** Prolongacin
****** Maximalidad
****** Toda solucin es prolongable a una maximal
Por Lema de Zorn.
****** Unicidad global ssi nica solucin maximal
***** 1.3. Ecuacin integral de Volterra
****** Ecuacin de Volterra (EIV)
\[
x(t) = x_0 + \int_{t_0}^t f(s,x(s)) \;ds 
\]
****** Equivalencia con PVI
**** 2. Existencia y unicidad de solucin
***** 2.1. Variables separadas
****** EDO de variables separadas
****** Propiedades de EDO de variables separadas
***** 2.2. Unicidad en el futuro y en el pasado. Teorema de Peano
****** Unicidad en el futuro y en el pasado
****** Teorema de Unicidad de Peano
******* TODO Demostracin
****** Ecuacin dual en el tiempo
****** Propiedad de la ecuacin dual
***** 2.3. Teorema de Picard-Lindelf
****** Teorema de Picard-Lindelf
Para $f$ continua y localmente lipschitziana respecto de la segunda
variable, el PVI tiene solucin y unicidad global.

******* TODO Demostracin
****** Funcin localmente lipschitziana
******* Continuamente diferenciables y Lipschitzianas
******* Globalmente Lipschitziana
****** Operador integral de Volterra
\[
V(y)(t) = x_0 + \int_{t^0}^t f(s,y(s))\;ds
\]
******* Soluciones con el operador integral
****** Demostracin de Picard-Lindelf
***** 2.4. Solucin general
***** 2.5. Teorema de Cauchy-Peano
**** 3. EDOs autnomas escalares
****** EDO autnoma escalar (AE)
****** rbita de una AE
**** 4. Prolongacin y acotacin de soluciones
***** 4.3. Acotacin de soluciones. Funciones gua
**** 5. Continuidad y diferenciabilidad de una solucin
***** 5.1. Preliminares
****** Entornos tubulares
\[
T_{\rho}(J,\varphi) =
\left\{
 (t,x) \in J \times \mathbb{R}^d \mid
 \|x-\varphi(t)\| \leq \rho
\right\}
\]
***** 5.3. Dependencia continua respecto a parmetros
***** 5.5. Linealizacin de ecuaciones y aproximacin
**** 6. Estabilidad en el sentido de Lyapunov
***** 6.1. Estabilidad de EDOs lineales
***** 6.2. Primer mtodo de Lyapunov
***** 6.3. Segundo mtodo de Lyapunov
***** 6.4. Sistemas gradientes
\[
x' + \nabla G(x) = 0.
\]
**** 7. Generalizacin de la teora cualitativa
***** 7.1. Teorema de Arzel-Ascoli

** Topologa II
*** 1. El grupo fundamental
**** 1. Espacios conexos por arcos
***** Arcoconexin
*Arcoconexin*. Las curvas definen relacin de equivalencia cuando
unen dos puntos.

 \[\exists f\ \text{arco}: f(0) = x, f(1) = y \Rightarrow x \sim y\]

Cada componente de esta particin es una *componente arcoconexa*. Un
espacio es *arcoconexo* cuando tiene una sola componente.

***** Operaciones en arcos y arcoconexin como equivalencia
Las propiedades de la relacin de equivalencia se cumplen por:

 - 1. *Reflexividad*. Arco constante, $f(t) = x$, lleva a $x \sim x$.
 - 2. *Simetra*. Arco inverso, $\widetilde f(t) = f(1-t)$, lleva a $x\sim y \Rightarrow y \sim x$.
 - 3. *Transitividad*. Composicin de arcos $f \ast g$.

La composicin de arcos se define como:

\[f \ast g = \twopartdef{f(2t)}{t \leq \frac{1}{2}}{g(2t-1)}{t \geq \frac{1}{2}}\]

***** Arcoconexin y conexin
Un espacio *arcoconexo es conexo*. Un espacio *conexo localmente arcoconexo 
es arcoconexo*, que es conexo y donde todo punto posee un entorno arcoconexo.

****** Demostracin
Dado un punto en un espacio arcoconexo, los caminos a los dems sern conexos y
compartirn un punto, luego su unin ser conexa. Por otro lado, en un localmente
arcoconexo, todo punto est dentro de un abierto (tiene un entorno arcoconexo),
luego cada componente arcoconexa ser abierta y si hubiera varias, contravendra
la conexin.

****** Contraejemplo del recproco
Hay un contraejemplo de espacio conexo no arcoconexo en el
[[https://es.wikipedia.org/wiki/Seno_del_top%25C3%25B3logo][seno del toplogo]].

**** 2. Grupo fundamental
***** Homotopa de lazos
Un arco con $f(0) = f(1) = x$ es un *lazo* alrededor de $x$. Dos lazos son *homotpicos*
y escribimos $f \sim g$ cuando $\exists H: [0,1] \times [0,1] \longrightarrow X$, cumpliendo:

  - $H$ continua.
  - $H(t,0) = f(t)$
  - $H(t,1) = g(t)$
  - $H(0,s) = H(1,s) = x$

lo escribimos como $H : f \simeq g$.

***** Clases de homotopa
La homotopa es una relacin de equivalencia entre lazos:

 - *Reflexividad*. Definiendo $H(t,s) = f(t)$, tenemos $H : f \simeq f$.
 - *Simetra*. Dada $G : g \simeq f$, definimos $H(t,s) = G(t,1-s)$, tenemos $H : f \simeq g$.
 - *Transitividad*. Dadas $F : f \simeq g$, $G : g \simeq h$, definimos
    \[H(t,s) = \twopartdef{F(t,2s)}{0\leq s \leq 1/2}{G(t,2s-1)}{1/2 \leq s \leq 1}\]
    Y tenemos $H : f \simeq h$.

Llamamos *clase de homotopa* $[f]$ a la clase de equivalencia de un lazo $f$.

***** Producto de clases de homotopa
El producto de lazos est bien definido entre las clases de homotopa. Sean 
$H : f_1 \simeq f_2$ y $G: g_1 \simeq g_2$; entonces definimos $F: f_1 \ast g_1 \simeq f_2 \ast g_2$ como:

\[ F(t,s) = \twopartdef{H(2t,s)}{0\leq t \leq 1/2}{G(2t-1,s)}{1/2 \leq t \leq 1}\]

***** El grupo fundamental
Comprobamos que las clases de homotopa sobre un $x$ forman un grupo con el producto:

\[\Pi(X,x) = \{[f] \mid f \text{ lazo alrededor de } x\}\]

****** Asociatividad
Para la *asociatividad*, definimos $H : (f \ast g) \ast h \simeq f \ast (g \ast h)$:

\[H(t,s) = \threepartdef
{f\left(t \frac{4}{1+s}\right)}{0\leq t\leq \frac{1+s}{4}}
{g\left(4t-1-s\right)}{\frac{1+s}{4}\leq t \leq \frac{2+s}{4}}
{h\left(t\frac{4}{2-s}-1\right)}{\frac{2+s}{4}\leq t\leq 1}\]

****** Elemento neutro
Como *elemento neutro* tomaremos el lazo constante $f_x(t)=x$. Y definimos  
$H : f_x \ast f \simeq f$:

\[ H(t,s) = \twopartdef
{f(t\frac{2t}{1+s})}{0\leq t\leq \frac{1+s}{2}}
{x}{\frac{1+s}{2}\leq t \leq 1}\]

****** Elemento inverso
Como *elemento inverso* tendremos el lazo $\hat{f}(t) = f(1-t)$. Y definimos 
$H : f \ast \hat{f} \simeq f$:

\[H(t,s) = \threepartdef
{f(2t)}{0\leq t\leq\frac{1-s}{2}}
{f(1-s)}{\frac{1-s}{2}\leq t\leq \frac{1+s}{2}}
{\hat{f}(2t-1)}{\frac{1+s}{2}\leq t\leq 1}\]

***** El grupo fundamental como funtor
Sea $\Phi : (X,x) \longrightarrow (Y,y)$ /continua/, entonces tenemos una aplicacin bien definida 
por:

\[\Phi_\ast ([f]) = [\Phi \circ f] \]

Que es un homomorfismo de grupos. Podemos comprobar fcilmente que $Id_\ast = Id$ y que
$(\Psi\circ\Phi)_\ast = \Psi_\ast\circ\Phi_\ast$. Es decir, el grupo fundamental es un funtor de la categora de 
los espacios topolgicos punteados a la de los grupos.

****** Demostracin
Sean $H: f \simeq g$, veamos que $\Phi\circ H: \Phi f \simeq \Phi g$. Tenemos que:

  - $\Phi\circ H$ continua
  - $\Phi\circ H(t,0) = \Phi\circ f(t)$
  - $\Phi\circ H(t,1) = \Phi\circ g(t)$
  - $\Phi \circ H(0,s) = \Phi \circ H(1,s) = y$

El que respeta el producto se tiene por $\Phi\circ (f \ast g) = \Phi\circ f \ast \Phi\circ g$.

***** Homotopa de arcos
Decimos que dos arcos cumpliendo $f(0)=g(0)$, $f(1)=g(1)$ son homotpicos cuando 
existe una funcin continua con caractersticas similares a la dada para lazos.

****** Propiedades
De demostracin similar al caso de lazos:

  - Hay un arco simtrico $\tilde{f}$ tal que $f\ast \tilde{f} \simeq f_x$.
  - El producto es asociativo por homotopa $f \ast (g \ast h)\simeq (f\ast g)\ast h$-
    
***** Isomorfismo entre grupos fundamentales en distintos puntos
Sea un arco $\gamma : [0,1] \longrightarrow X$ cumpliendo $\gamma(0) = x$, $\gamma(1)=y$. Entonces se tiene un 
isomorfismo entre $\Pi(X,x)$ y $\Pi(X,y)$:

\[ F_\gamma([f]) = [\tilde\gamma\ast f\ast\gamma]\]

Por tanto, el grupo fundamental es el mismo en cualquier punto de la componente
arcoconexa.

****** Demostracin
Para ver que est bien definido basta notar:

\[f \simeq g \Rightarrow 
\gamma\ast f\ast\tilde\gamma\simeq \gamma\ast g\ast\tilde\gamma\]

Que es homomorfismo se tiene viendo $F([f]\ast [g]) = F([f]) \ast F([g])$, y que es biyectivo
porque tiene inversa $G_\gamma([f]) = [\gamma\ast f\ast \tilde\gamma]$.

***** El grupo fundamental del producto
Dado el producto de dos espacios topolgicos $X\times Y$ con proyecciones $\pi_1,\pi_2$. Tenemos
un isomorfismo entre grupos fundamentales:

\[F: \Pi(X\times Y, (x,y)) \longrightarrow \Pi(X,x)\times\Pi(Y,y)\]

Dado por:

\[F([f]) = (\pi_1([f]), \pi_2([f]))\]

**** 3. El grupo fundamental del crculo
***** Clculo del grupo fundamental del crculo
Usaremos la teora de recubridores que se probar luego.

Probamos que $\pi : \mathbb{R} \longrightarrow \mathbb{S}$ es un recubridor con $\pi(t) = e^{it}$; podemos tomar como entorno
fundamental de $p$ a $\mathbb{S}-\{p\}$, que tiene en la preimagen componentes arcoconexas 
homeomorfas a l. Siendo $t_0 \in \pi^{-1}(p)$:

\[V_m = (t_0 + 2\pi m, t_0 + 2\pi(m+1))\]

Definimos ahora el grado de un lazo en el crculo como:

\[\operatorname{deg}(f) = \frac{\hat{f}(1) - \hat{f}(0)}{2\pi} \]

Y comprobamos que est bien definido entre las clases de homotopa levantando
las homotopas y viendo que debe ser constante el punto final para que se proyecte
en un punto constante. Es decir $f \simeq g \Rightarrow \hat{f}(0) = \hat{g}(0)
\Rightarrow \hat{f}(1) = \hat{g}(1)$.

Como el levantamiento de la composicin es la composicin de levantamientos
y levantando de forma que $\hat{g}(0) = \hat{f}(1)$:

\[ \operatorname{deg}(f \ast g) =
   \frac{\widehat{f\ast g}(1) - \widehat{f\ast g}(0)}{2\pi} = 
   \frac{\hat{f}(1) - \hat{g}(0) + \hat{g}(1) - \hat{f}(0)}{2\pi} =
   \operatorname{deg}(f) + \operatorname{deg}(g) \]

Siendo un homomorfismo del grupo fundamental del crculo con $\mathbb{Z}$.

***** Teorema fundamental del lgebra
*Teorema fundamental del lgebra*. Todo polinomio con coeficientes
en $\mathbb{C}$ de grado $n$ tiene $n$ races en $\mathbb{C}$.

****** Demostracin
Supongamos un $P$ que no tuviera raz en $\mathbb{C}$.

Fijado un $r$, restringimos el polinomio desde la circunferencia de
radio $r$ a la circunferencia unidad, girndolo
adems para que en $0$ valga $1$.

\[f_r(t) = \frac{|P(r)|}{P(r)} \frac{P(re^{2\pi it})}{|P(re^{2\pi it})|}\]

Tenemos una homotopa de este lazo al constante, definida como:

\[H(t,s) = f_{(1-s)r}(t)\]

Y por tanto, $deg(f_r) = 0$.

Por otro lado, sea ahora $R > 1, \sum |a_i|$, y tomemos $|z| = R$, tenemos
por un lado:

\[|z^n| 
 = R^n > R^{n-1}\left(\sum |a_i|\right) 
 \geq |a_1z^{n-1} + \dots + a_n|\]

Y por otro lado, si tomo un $t \in [0,1]$, puedo definir una familia
de polinomios $P_s(z) = z^n + t(a_1z^{n-1} + \dots + a_n) = 0$, que no tienen races
porque, por otro lado:

\[|z^n| = |t||a_1z^{n-1} + \dots + a_n| \leq |a_1z^{n-1} + \dots + a_n|\]

Luego esta familia de polinomios no tiene races en el crculo 
de radio $R$. Podemos ahora definir otra homotopa:

\[H(t,s) = \frac{P_s(Re^{2\pi it})}{|P_s(Re^{2\pi it})|}  \frac{|P_s(R)|}{P_s(R)}\]

Que es homotopa entre $e^{2\pi int}$ y $f_R(t)$. Luego $deg(f_R) = n$.

***** Lema al punto fijo de Brower
No existe aplicacin continua $f : D^2\longrightarrow \mathbb{S}$ tal que $f|_\mathbb{S} = id$.

****** Demostracin
Estamos buscando una aplicacin cumpliendo:

\[ \begin{tikzcd}
\mathbb{S} \rar[hook]{i} & D^2 \rar{f} & \mathbb{S}
\end{tikzcd} \]

Aplicando el funtor obtendramos:

\[ \begin{tikzcd}
\mathbb{Z} \rar[hook] & 0 \rar & \mathbb{Z}
\end{tikzcd} \]

Pero as es imposible obtener la identidad como composicin.

***** Teorema del punto fijo de Brower
Toda funcin continua $f : D^2 \longrightarrow D^2$ tiene un punto fijo.

****** Demostracin
Si no lo hubiera, para cada $x$ tomo $f(x)$ y la interseccin de la recta que los une
con el crculo ms cercana a $x$. Tengo una aplicacin cuya restriccin es la 
identidad.

***** Grupos topolgicos
Un grupo topolgico es un grupo en la categora de espacios punteados. Esto es,
tal que la funcin producto y la funcin inverso son continuas.
***** Grupos topolgicos y grupo fundamental
El producto en un grupo topolgico respeta clases de homotopa:

\[ [f]\cdot [g] = [f\cdot g]\]

Y adems, acta sobre ellas igual que la composicin:

\[ [f]\ast [g] = [f] \cdot [g]\]

**** 4. Tipo de homotopa. Equivalencias homotpicas
***** Aplicaciones homotpicas
Sean $F,G : X \longrightarrow Y$ continuas. Las decimos *homotpicas* si existe 
$H : X \times [0,1] \longrightarrow Y$ tal que $H(x,0) = F(x)$ y $H(x,1) = G(x)$. Lo notamos
por $H: F\simeq G$.

***** Grupo fundamental entre dos puntos
Entre cualesquiera puntos de dos funciones homotpicas $F(x_0)$, $G(x_0)$; tenemos un 
arco $\gamma = H(x_0,t)$. Se cumple que:

\[ \begin{tikzcd}
& \Pi(Y,F(x_0)) \arrow[leftrightarrow]{dd}{F_\gamma}\\
\Pi(X,x_0) \urar{F_\ast}\drar{G_\ast} \\
& \Pi(Y,G(x_0))
\end{tikzcd} \]

****** Demostracin
Sea $f \in \Pi(X,x_0)$. Si defino la funcin $\hat{H}(t,s) = H(f(t),s)$ tengo una homotopa como
la siguiente:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f$} ++ (-1, 0)
-- node [left]  {$\gamma$} ++ (0, -1)
-- node [below] {$F f$} ++ (1, 0)
-- node [right] {$\gamma$} ++ (0, 1);
\end{tikzpicture}

Rotndola obtengo:

\begin{tikzpicture}
\draw (A) -- node [above] {$G f \circ \gamma$} ++ (-1, 0)
-- node [left]  {$F(x_0)$} ++ (0, -1)
-- node [below] {$\gamma \circ F f$} ++ (1, 0)
-- node [right] {$G(x_0)$} ++ (0, 1);
\end{tikzpicture}

Lo que me da $[Gf \circ \gamma] = [\gamma \circ Ff]$, y por tanto $[Gf] = [\gamma \circ Ff \circ \tilde{\gamma}]$.

***** Equivalencia homotpica
Una *equivalencia homotpica* es una aplicacin continua $F$, para la que
existe $G$ cumpliendo $F \circ G \simeq G \circ F \simeq Id$.

***** Propiedades de la equivalencia homotpica
Cumple:

1. Los homeomorfismos son equivalencias homotpicas.
2. La inversa de una equivalencia homotpica es equivalencia homotpica.
3. La composicin de equivalencias homotpicas es equivalencia homotpica.

***** Conservacin del grupo fundamental por equivalencia homotpica
Sea $F: X\longrightarrow Y$ equivalencia homotpica:

\[\forall x\in X : F_\ast : \Pi(X,x) \longrightarrow \Pi(Y,F(x))\]

Es un isomorfismo

****** Demostracin
Por ser equivalencia homotpica tengo que $F \circ G \simeq Id$, luego se cumple:

\[ \begin{tikzcd}
& \Pi(X,F\circ G(x_0)) \arrow[leftrightarrow]{dd}{\cong}\\
\Pi(X,x_0) \urar{(F\circ G)_\ast}\drar{Id} \\
& \Pi(X,x_0)
\end{tikzcd} \]

As, $(F\circ G)_\ast$, y de la misma forma $(G\circ F)_\ast$ son isomorfismos. Tenemos por tanto:

\[ \begin{tikzcd}
\Pi(X,x) \rar{F_\ast} \arrow[bend left=20]{rr}{\cong}
& \Pi(Y,F(x)) \rar{G_\ast} \dlar{\cong}
& \Pi(X,(G\circ F)(x)) \dlar{\cong}
\\
\Pi(Y,F(x)) \rar{F_\ast} \arrow[bend right=20]{rr}{\cong}
& \Pi(X,(G\circ F)(x)) \rar{F_\ast}
& \Pi(X,(G\circ F)(x))
\end{tikzcd} \]

Demostrando ambas filas que $F_\ast$ y $G_\ast$ son isomorfismos.

***** Lema a Borsuk-Ulam
No existe $F: \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ continua respetando antpodas.

\[F(-x) = -F(x)\]

****** TODO Demostracin
***** Teorema de Borsuk-Ulam
Sea $F:\mathbb{S}^2 \longrightarrow \mathbb{R}^2$ continua, entonces:

\[\exists x\in\mathbb{S}^2 : F(-x) = F(x)\]

****** Demostracin
Supongamos que no se cumpliera, definimos:

\[G(x) = \frac{F(x)-F(-x)}{|F(x)-F(-x)|}\]

Y entonces $G$ sera continua respetando antpodas.

***** Teorema del sandwich de jamn
Sean $A,B\subset \mathbb{R}^2$ compactos y conexos. Existe una recta dividiendo a ambos en dos
trozos de igual rea.

****** TODO Demostracin
***** Espacio proyectivo
En $\mathbb{S}^n$ defino la ralacin de equivalencia $p \sim q$ ssi $p = \pm q$. Definimos el 
espacio proyectivo como el cociente bajo esta relacin:

\[\mathbb{RP}^n = \mathbb{S}^n}/\sim\]

**** 5. Teorema de Seifert-Van Kampen
***** Producto libre de grupos
Si definimos el *producto libre* de grupos en trminos de palabras; podemos 
llamar *grupo libre sobre un conjunto de generadores* al producto libre del 
grupo libre generado por cada uno de ellos.

***** Subgrupo normal generado
El *subgrupo normal generado* por un subgrupo $B$ o por un conjunto de 
generadores es:

\[ \{g \cdot b \cdot g^{-1} \mid g\in G, b\in B\}\]

***** Producto libre amalgamado
Sean tres grupos $A$, $G_1$, $G_2$ y dos proyecciones de $A$ en ellos, llamadas 
$\Phi_1,\Phi_2$. Definimos el *producto libre amalgamado* como:

\[G_1 \ast_{A} G_2 =
\frac{G_1 \cdot G_2}{N} = \frac{G_1 \cdot G_2}{\{\Phi_1(a)=\Phi_2(a)\}}\]

Donde estamos dividiendo por $N$, el subgrupo normal generado por 
$\{\Phi_1(a)\Phi_2(a)^{-1} \mid a \in A\}$. Es decir, imponemos la relacin $\Phi_1(a) = \Phi_2(a)$.

***** Teorema de Seifert-Van Kampen
Sea $X$ espacio topolgico con $U,V$ abiertos arcoconexos no vacos de $X$ tales 
que $X = U \cup V$ y $U\cap V$ son arcoconexos. Existe un isomorfismo:

\[\Theta : \Pi(U,x) \ast_{\Pi(U\cap V,x)} \Pi(V,x) \longrightarrow \Pi(X,x)\]

donde se amalgama usando $i_\ast$, $j_\ast$, homomorfismos dados por las inclusiones.

***** Seifert-Van Kampen para interseccin simplemente conexa
En las condiciones del teorema, con $U\cap V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)\ast\Pi(V,x)\]

***** Seifert-Van Kampen para abierto simplemente conexo
En las condiciones del teorema, con $V$ simplemente conexo, se tiene:

\[\Pi(X,x) \cong \Pi(U,x)/N\]

Con $N$ es el subgrupo normal generado por $i_\ast(\Pi(U\cap V,x))$.

**** Extra: Teora de categoras
***** El grupo fundamental como funtor
El grupo fundamental $\Pi$ es un funtor entre las categoras:

- =Top.= de los espacios topolgicos con un punto base, usando como morfismos
  las funciones continuas respetando punto base.
- =Grp= de los grupos con los homomorfismos de grupos.

Estamos llamando $f_\ast$ a los morfismos creados por el funtor, $\Pi(f)$.

***** Producto categrico
El producto de dos espacios con un punto base es, usando la topologa producto:

\[(X,x) \times (Y,y) \cong (X\times Y, (x,y))\]

El funtor lo lleva al producto de grupos.

***** Coproducto categrico
El coproducto de dos espacios con un punto es la suma directa de los espacios
identificando el punto. Intuitivamente, consiste pegar los dos espacios por ese
punto.

\[ X \wedge Y \cong (X \amalg Y)/(x\sim y)\]

Cuando adems tenemos espacios localmente contractibles, el coproducto se lleva
al coproducto de grupos, esto es, al producto libre:

\[\Pi(X \wedge Y) \cong \Pi(X) \ast \Pi(Y)\]

Ntese que esto es un caso particular de Seifert-Van Kampen.

***** TODO Seifert-Van Kampen
*** 2. Recubridores
**** 1. Introduccin
***** Localmente arcoconexo
Un espacio es *localmente arcoconexo* si todo punto posee una base de 
entornos arcoconexos.

/Durante este tema tomamos los espacios como arcoconexos y localmente 
arcoconexos/.

***** Recubridores
Un *recubridor* de $X$ es un par $(Y,p)$ donde $p : Y \longrightarrow X$ es continua; 
cumpliendo que todo $x\in X$ tiene un entorno abierto $U$, llamado *entorno 
fundamental* tal que toda componente arcoconexa de $p^{-1}(U)$ se aplica 
homeomrficamente por $p$ sobre $U$.

***** Ejemplos de recubridores
Ejemplos bsicos de recubridores son:

- Cualquier homeomorfismo $p : Y \longrightarrow X$
- $p : \mathbb{S}^1\longrightarrow\mathbb{S}^1$, con $p(z) = z^n$

***** Homeomorfismos locales
Un *homeomorfismo local* es una aplicacin continua $f : Y \longrightarrow X$ tal que para 
todo $y\in Y$ existe $y \in V\in\tau_Y$ tal que $f|_V$ es homeomorfismo.

***** Propiedades de un recubridores
Sea $(Y,p)$ recubridores de $X$. Entonces:

1. $p$ es sobreyectiva.
2. $p$ es una aplicacin abierta.
3. $p$ es un homeomorfismo local.

****** Demostracin
La sobreyectividad es trivial por la definicin. Dado un abierto $y\in O$; 
tengo $y \in V_y \cong U_x$ su entorno abierto, luego $p(O\cap V_y)$ es abierto. De esta 
forma,

\[p(O) = \bigcup_{y\in O} p(O \cap V_y)\]

es abierto.

**** 2. Grupo fundamental y levantamiento de aplicaciones al recubridor
***** Levantamiento de arcos
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y_0 \in p^{-1}(x_0)$. Sea $f : [0,1]\longrightarrow X$ arco 
continuo con $f(0) = x_0$, entonces existe un nico arco continuo $\check{f}$ cumpliendo:

  - $\check{f}(0) = y_0$
  - $p \circ \check{f} = f$

    Llamado el *levantamiento* de $f$.

****** Existencia
Tomo $\{f^{-1}(U^x) \mid x\in X\}$, que recubre por abiertos a $[0,1]$. Sabemos que 
existir una particin del intervalo cumpliendo:

\[\exists 0 < t_1 <\dots < t_n < 1: f([t_i,t_{i+1}]) \subseteq U^{x_i}\]

La correspondiente $y_i \in V^{y_i}$ nos da un isomorfismo $p_i$ que nos 
deja definir $\check{f} : [t_i,t_{i+1}] \longrightarrow V^{y_i}$ mediante $\check{f} = (p|_{V^{y_i}})^{-1} \circ f$. Ntese que para 
tomar cada $y_i$ necesitamos usar la componente arcoconexa de la ltima $\check{f}(t_{i-1})$.

****** Unicidad
Sean dos levantamientos $g_1,g_2$. Su conjunto ecualizador es cerrado:

\[ A = \{ t \mid g_1(t) = g_2(t)\} \neq \varnothing\]

Pero tambin es abierto porque dado un punto donde coincidan, puedo tomar la 
componente arcoconexa que es isomorfa por $p$ a un entorno abierto; y las 
curvas deben coincidir en l.

***** Levantamiento de homotopas
Sea $(Y,p)$ recubridor con $x_0\in X$ y $y \in p^{-1}(x_0)$. Sea $H : [0,1]\times[0,1] \longrightarrow X$ 
continua con $H(0,0) = x_0$, entonces existe una nica aplicacin
continua $\check{H} : [0,1]\times [0,1] \longrightarrow Y$ cumpliendo:

  - $p \circ \check{H} = H$
  - $\check{H}(0,0) = y_0$

    Llamada el *levantamiento* de $H$.

****** Existencia
Tomamos las $\{ H^{-1}(U^x) \mid x \in X \}$ y tenemos recubrimiento por abiertos de $[0,1]^2$. 
Tendremos alguna particin cumpliendo:

\[\exists 0 < t_1 < \dots < t_n < 1 : 
H([t_i,t_{i+1}]\times[s_i,s_{i+1}]) \subset U^{x_i}\]

En la correspondiente $y_i \in V^{y_i}$ podemos definir 
$\check{H} = (p|_{V^{y_i}}^{-1})\circ H$. Ntese que tenemos que usar en cada paso la componente arcoconexa
del ltimo lado unido a nuestro cuadrado, que no puede salirse de esa componente
por ser arcoconexa.

****** TODO Unicidad
***** Hojas del recubridor
Sea $p : Y\longrightarrow X$ recubridor. Los cardinales de los $p^{-1}(x)$ son un invariante 
llamado el *cardinal de hojas del recubridor*.

****** Demostracin
Puedo definir una biyeccin entre $p^{-1}(x_1)$ y $p^{-1}(x_2)$ tomando un arco entre 
ellas $\gamma$, y levantndolo en cada componente. Los arcos arriba me relacionan 
los dos conjuntos. La biyeccin se obtiene levantando $\tilde\gamma$, que s que es $\tilde{g}$ 
porque ella ya es un levantamiento y es nico.

***** Los recubridores crean monomorfismos
Sea $p: Y \longrightarrow X$ recubridor, entonces $p_\ast : \Pi(Y,y) \longrightarrow \Pi(X,x)$ es monomorfismo.

****** Demostracin
Supongamos $p_\ast[h] = 0$; tengo una homotopa $H : p \circ h \simeq f_x$ que puedo levantar tomando
$\check{H}(0,0)=y$ y sabiendo $p \circ \check{H} = H$. Tengo:

\[ p \circ \check{H} (t,0) = H(t,0) = (p\circ h)(t)\]
\[ p \circ \check{H} (t,1) = H(t,1) = f_x(t) = x\]

Luego $\check{H}(t,0) = h(t)$ porque son levantamientos de lo mismo y $\check{H}(t,1) = y$ para poder
ser levantamiento. Esto me da $\check{H} : h \simeq f_y$.

***** Conjugacin y recubridores
Si $p : Y \longrightarrow X$ es recubridor y $x\in X$, entonces la familia de subgrupos:

\[ \left\{p_\ast(\Pi(Y,y)) \mid y\in p^{-1}(x)\right\}\]

forma exactamente una clase de conjugacin de subgrupos de $\Pi(X,x)$.

****** Demostracin
Sea $\gamma$ camino entre $y_1,y_2 \in p^{-1}(x)$ con el isomorfismo $F_\gamma([f]) = [\tilde\gamma \ast f \ast \gamma]$, construimos 
el diagrama:

\[ \begin{tikzcd}
\Pi(Y,y_1) \rar{F_\gamma} \dar{p_\ast} & \Pi(Y,y_2) \dar{p_\ast} \\
\Pi(X,x) \rar{F_{p \circ \gamma}}& \Pi(X,x)
\end{tikzcd} \]

Que es conmutativo:

\[ \begin{tikzcd}
\math{[f]} \rar{F_\gamma} \dar{p_\ast} & 
\math{[\tilde\gamma \ast f \ast\gamma]} \dar{p_\ast} \\
\math{[p\circ f]} \rar{F_{p \circ \gamma}} & 
\math{[p(\tilde\gamma) \ast p(f) \ast p(\gamma)]}
\end{tikzcd} \]

Y que nos da por tanto:

\[ p_\ast(\Pi(Y,y_2)) = 
F_{p\circ\gamma}(\Pi(Y,y_1)) =
[p(\tilde\gamma)] \ast \Pi(Y,y_1) \ast [p(\gamma)]
\]

Ahora, sea una clase de conjugacin de la proyeccin de un grupo fundamental
$H = [g]^{-1} \ast p_\ast(\Pi(Y,y)) \ast [g]$. El levantamiento $\check{g}$ da un camino entre dos puntos de 
$p^{-1}(x)$, y vemos que:

\[ \begin{aligned}
H &= \{[g]^{-1} \ast [p\circ h] \ast g \mid [h] \in \Pi(Y,y)\} \\
&= \{[p\circ \tilde{\check{g}} \ast p\circ h \ast p \circ \check{g}] \mid [h] \in \Pi(Y,y)\} \\
&= p_\ast(F_{\check{g}}(\Pi(Y,y))) = p_\ast(\Pi(Y,y'))
\end{aligned} \]

***** Levntamiento de aplicaciones
Sea $\Phi : Z \longrightarrow X$ continua con $x_0 = \Phi(z_0)$, $y_0 \in p^{-1}(x_0)$. Tenemos que
$\exists! \Psi : Z \longrightarrow Y$ continua cumpliendo:

- $\Psi(z_0) = y_0$
- $p \circ \Psi = \Phi$

ssi $\Phi_\ast(\Pi(Z,z_0)) \subset p_\ast(\Pi(Y,y_0))$.

****** Demostracin
Definimos:

\[\check\Phi(z) = \widehat{\Phi \circ f}(1)\]

Siendo el levantamiento de la imagen de una curva que tena $f(1)=z$, $f(0)=z_0$.
Esta es una funcin que lo cumple; debemos demostrar que est *bien definida* y
que es continua. Esto es, $\widehat{\phi \circ g}(1) = \widehat{\phi\circ f}(1)$, para otro $g$ cumpliendo lo mismo que $f$.

Como tenemos por la condicin que $\phi_\ast[f \ast\tilde{g}] = p_\ast(\alpha)$, tenemos que ambas
$H : \phi(f \ast \tilde{g}) \simeq p\circ \alpha$. Tomamos $[f \circ \tilde{g}]$ para ver:

\[ p(\widehat{\phi\circ f} \ast \widehat{\phi\circ g}) = 
\phi\circ f \ast \widetilde{\phi\circ g}\]

Y usando eso, levantamos la homotopa, para tener 
$\check{H} : \widehat{\phi\circ f} \ast \widehat{\phi \circ \tilde{g}} 
\simeq \alpha$. Pero como $\alpha$ es lazo, tengo que es lazo lo primero.

Para ver que es *continua*, sea $\check{\Phi}(z) \in O$, abierto. Tenemos $p(O)$ abierto y tomamos
$W$ como la arcocomponente de la preimagen de $U^{\Phi(z)}$ en la que est $\check{\Phi}(z)$. Ahora
sea $\Phi(z) \in p(W \cap O)$, abierto por homeomorfismo; y sea

$\Phi(\hat{O}) \subset p(W \cap O)$, que existe por continuidad de $\Phi$ y es abierto arcoconexo. 

Veamos que $\Phi(\hat{O}) \subset \check{\Phi}^{-1}(O)$. Si $\hat{z} \in \hat{O}$, entonces hay un arco $g$ que une $z$ y $\hat{z}$; y tenemos
$\Phi(g) \subset p(W\cap O)$; como hay homeomorfismo, su levantamiento est en $W \cap O$, y
se tiene:

\[\check{\Phi}(z) = \widehat{\Phi(g)}(1) \in O\]

***** Estructura de grupo topolgico
Sea $G$ un grupo topolgico con neutro $e$. Sea $(\check{G},p)$ un recubridor y 
$\check{e} \in p^{-1}(e)$. Entonces $\check{G}$ admite una estructura de grupo topolgico que tiene
a $\check{e}$ como elemento neutro y a $p$ como homomorfismo de grupos.

**** 3.1. Isomorfismos de recubridores
***** Homomorfismos
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ recubridores. Un *homomorfismo de recubridores* es
$\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ continua con $p_2 \circ \Phi = p_1$.

\[ \begin{tikzcd}
Y_1 \drar[swap]{p_1} \arrow{rr}{\Phi} & & Y_2 \dlar{p_2} \\
& X &
\end{tikzcd} \]

***** Propiedades de los homomorfismos de recubridores
Los homomorfismos de recubridores cumplen:

   1. La composicin de homomorfismos es homomorfismo.
   2. La identidad $Id : Y \longrightarrow Y$ es homomorfismo.
   3. El inverso de isomorfismo es isomorfismo.

      Llamamos $Aut(Y,p)$ al *grupo de automorfismos* de un recubridor.
      # Forman una categora! Debe ser algo como una "slice category".

***** Puntos fijos de los automorfismos de recubridores
Sean dos homomorfismos de recubridores $\Phi,\Psi$ con $\Phi(y) = \Psi(y)$ en algn punto; 
entonces $\Phi = \Psi$. Por tanto, todo automorfismo distinto de la identidad acta 
sin puntos fijos.

***** Existencia de homomorfismos
Existe un homomorfismo de recubridores $\Phi : (Y_1,p_1) \longrightarrow (Y_2,p_2)$ con $\Phi(y_1) = y_2$ ssi
$p_1_\ast(\Pi(Y_1,y_1)) \subseteq p_2_\ast(\Pi(Y_2,y_2))$. Es isomorfismo en el caso de igualdad.

***** Existencia de isomorfismos
Dos recubridores son isomorfos ssi las clases de conjugacin asociadas a sus 
proyecciones al grupo fundamental son iguales:

\[\{ p_1_\ast(\Pi(Y_1,y)) \mid y\in p_1^{-1}(x)\}
= \{ p_2_\ast(\Pi(Y_2,y)) \mid y\in p_2^{-1}(x)\}\]

***** Ejemplos de recubridores
****** Espacios simplemente conexos
Slo se admiten a s mismos como recubridores.
****** Circunferencia unidad
Grupo fundamental isomorfo a $\mathbb{Z}$ y abeliano. Sus subgrupos son de la forma $m\mathbb{Z}$,
as que, salvo isomorfismos, sus recubridores son de la forma:

\[ p_0 : \mathbb{R} \longrightarrow \mathbb{S}^1,\ p(t) = e^{it} \]
\[p_m : \mathbb{S}^1 \longrightarrow \mathbb{S}^1,\ p_m(z) = z^m\]

****** Espacio proyectivo
Como $\mathbb{R}\mathbb{P}^n$ tiene grupo fundamental $\mathbb{Z}_2$, tiene slo a $(\mathbb{RP}^n,Id)$ y a $(\mathbb{S}^n,p)$ 
como recubridores.

***** Recubridores de recubridores
Sean $(Y_1,p_1)$, $(Y_2,p_2)$ dos recubridores, y sea $\Phi : Y_1 \longrightarrow Y_2$ un homomorfismo de 
recubridores. Entonces $(Y_1,\Phi)$ es un recubridor de $Y_2$.

***** Recubridores universales
Un recubridor $(\check{X},p)$ de $X$ es *universal* si $\check{X}$ es simplemente conexo.

**** 3.2. Automorfismos de recubridores
***** Accin del grupo fundamental
Sea $(Y,p)$ un recubridor y $x$ punto de $X$ definimos la accin

\[ (\cdot) : p^{-1}(x) \times \Pi(X,x) \longrightarrow p^{-1}(x) \]

construyendo $y \cdot \alpha$ como sigue: sea $\alpha = [f]$, tomamos $\check{f}(0) = y$ y llamamos 
$y \cdot \alpha = \check{f}(1)$.

****** TODO Est bien definida
****** TODO Es una accin transitiva
****** TODO Espacios homogneos.
***** ndice y hojas del recubridor
Sea $(Y,p)$ recubridor; su nmero de hojas es el ndice del subgrupo  $p_\ast(\Pi(Y,y))$ 
en $\Pi(X,x)$; donde $y \in p^{-1}(x)$.

***** Automorfismos del espacio homogneo
Un *automorfismo del espacio homogneo* $p^{-1}(x)$ es una biyeccin
$\varphi : p^{-1}(x) \longrightarrow p^{-1}(x)$ tal que:

\[ \varphi(y \cdot \alpha) = \varphi(y) \cdot \alpha\]

***** Automorfismos del espacio homogneo y automorfismos de recubridores
Como dado un automorfismo de recubridores $\Phi\in Aut(Y,p)$, tenemos que 
$\Phi(y\cdot \alpha) = \Phi(y)\cdot\alpha$, tenemos $\Phi|_{p^{-1}(x)}$ un automorfismo del espacio homogneo.
De hecho, es isomorfismo de grupos:

\[ ( \bullet |_{p^{-1}(x)}) : Aut(Y,p) \longrightarrow Aut(p^{-1}(x))\]

****** Demostracin
******* La restriccin es automorfismo en el espacio homogneo
Sea $y\in p^{-1}(x)$, tenemos $p(\Phi(y)) = p(y) = x$, luego $\Phi(y) \in p^{-1}(x)$.

******* Los automorfismos de recubridor respetan la accin de grupos
Sea $[f]=\alpha$, y sea $\check{f}$ su levantamiento en $y$; si considero $\Phi(\check{f})$ puedo 
comprobar que $\Phi(\check{f})(0) = \Phi(y)$ y que $p \circ \Phi (\check{f}) = f$, luego es el levantamiento
de $f$ en $\Phi(y)$. As:

\[\Phi(y)\cdot\alpha = \Phi(\check{f})(1) = \Phi(y \cdot \alpha)\]

******* Es inyectiva
Llamamos $F = (\bullet |_{p^{-1}(x)})$. Sea $\Phi\in\ker(F)$, entonces $\Phi|_{p^{-1}(x)} = Id$; pero dos
homomorfismos de recubridores coindiciendo en un punto son iguales.

******* Es sobreyectiva
Sea $\varphi\in Aut(p^{-1}(x))$. Por el lema de existencia:
       
\[\exists \phi\in Aut(Y,p): \phi(y) = \varphi(y) \Leftrightarrow
p_\ast(\Pi(Y,y)) = p_\ast(\Pi(Y,\varphi(y))\]
       
Pero tenemos la igualdad de estos dos grupos de isotropa por:
       
\[\begin{aligned}
H_{\varphi(y)} 
&= \{\alpha\in\Pi(X,x) \mid \varphi(y)\cdot\alpha = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid \varphi(y\cdot\alpha) = \varphi(y)\} \\
&= \{\alpha\in\Pi(X,x) \mid y\cdot\alpha = y\} = H_y\\
\end{aligned}\]
       
***** Identificacin de automorfismos de un espacio homogneo
Dado $E$ espacio homogneo sobre $G$, existe el isomorfismo:

\[ Aut(E) \cong N(H)/H \]

donde $H = \operatorname{Stab}(y)$ y $N(H)$ es su normalizador, el mayor 
grupo en el que es normal.

***** Identificacin de automorfismos del recubridor
Aplicando las dos identificaciones anteriores:

\[Aut(Y,p) \cong N(p_\ast(\Pi(Y,y))) / p_\ast(\Pi(Y,y))\]

***** Recubridores regulares
Un recubridor es *regular* cuando $p_\ast(\Pi(Y,y))$ es subgrupo normal de 
$\Pi(X,x)$ siendo $y \in p^{-1}(x)$. Equivalen, por conjugacin:

- $\exists x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.
- $\forall x\in X, y \in Y: p_\ast(\Pi(Y,y))$ subgrupo normal en $\Pi(X,x)$.

***** Propiedades de recubridores regulares
Sea $(Y,p)$ un recubridor regular:

1. $Aut(Y,p) \cong \Pi(X,x)/p_\ast(\Pi(Y,y))$
2. Si es el universal, $Aut(Y,p) \cong \Pi(X,x)$. Y el nmero de hojas es 
   el orden de $\Pi(X,x)$.

***** Ejemplos de recubridores
****** Circunferencia, recubridor universal
Tenemos el recubridor $(\mathbb{R},p)$ de $\mathbb{S}$, que tiene como automorfismos:

\[Aut(\mathbb{R},p) = \{\Phi_n(t) = t + 2\pi n \mid n \in \mathbb{N}\}\]

****** Espacio proyectivo
Siendo $(\mathbb{S}^n,p)$ un recubridor de dos hojas de $\mathbb{RP}^n$, sus automorfismos 
vienen dados por:

\[Aut(\mathbb{RP}^n,p) = \{Id, -Id\}\]

****** Circunferencia, otros recubridores
Sean los recubridores $(\mathbb{S}^1,p_n)$ de $\mathbb{S}^1$. Sus grupos de automorfismos son:

\[Aut(\mathbb{S}^1,p_n) = \left\{\Phi_k(z) = e^{\frac{2\pi k}{n}i}z 
\mid k = 0,1,\dots,n-1 \right\}\]

***** Teorema de Borsuk-Ulam
No existe una aplicacin continua $F : \mathbb{S}^2 \longrightarrow \mathbb{S}^1$ respetando antpodas, es decir,
$F(-x) = -F(x)$.

**** 4. Recubridores regulares y espacios cocientes
***** Accin transitiva de automorfismos de recubridores regulares
$Aut(Y,p)$ acta transitivamente sobre $p^{-1}(x)$ ssi $(Y,p)$ es regular.

***** Acciones discontinuas
Un $G \subset Homeo(Y)$ *acta discontinuamente* si:
 
\[\forall y\in Y: \exists V_y\text{ entorno}: \forall \Phi \in G:\quad
\Phi \neq Id \Rightarrow \Phi(V) \cap V = \varnothing\]

***** Recubrimiento de cocientes
Sea $G \subset Homeo(Y)$ actuando propia y discontinuamente sobre $Y$. Si
$p : Y \longrightarrow Y/G$ es proyeccin al cociente, $(Y,p)$ es recubridor regular de $Y/G$, 
con $Aut(Y,p) = G$.

***** Espacios lente
Sean las aplicaciones $\Phi_k : \mathbb{S}^{2n+1} \longrightarrow \mathbb{S}^{2n+1}$ definidas por:

\[\Phi_k(z) = e^{\frac{2\pi ik}{p}}z\]

Entonces $G_p = \{\Phi_0,\Phi_1,\dots,\Phi_{p-1}\}$ acta discontinuamente. Llamamos *espacio 
lente* al cociente:

\[ L_p^{2n+1} = \mathbb{S}^{2n+1}/G_p\]

**** 5. Existencia de espacios recubridores
***** Caso del recubridor universal
Si $X$ admite recubridor universal, toda clase de conjugacin de subgrupos de
$\Pi(X,x)$ est asociada a un recubridor.

***** Espacios semilocalmente simplemente conexos
Todo $x$ posee un entorno abierto y arcoconexo $U_x$ tal que el homomorfismo 
inducido por la inclusin $\Pi(U_x,x) \longrightarrow \Pi(X,x)$ es trivial.

****** Contraejemplo
El espacio formado por infinitos crculos de radio cada vez menor y unidos 
en un punto:

\[ X = \bigcup_{n>0} \left\{(x,y) \in \mathbb{R}^2 \mid 
\left(x-\frac{1}{n}\right)^2 + y^2 = \frac{1}{n^2} \right\}\]

cumple que cualquier entorno del $(0,0)$ contiene un lazo no trivial.

***** Existencia del recubridor universal
Un espacio semilocalmente simplemente conexo tiene recubridor universal.

***** Teorema de existencia de recubridores
Sea $X$ semilocalmente simplemente conexo. Para toda clase de conjugacin de 
subgrupos de $\Pi(X,x)$, existe un recubridor que la tiene asociada.

****** Demostracin
Sea $C$ clase de conjugacin de algn $H < \Pi(X,x)$. Sea $Y$ recubridor universal 
de $X$, que existe por ser semilocalmente simplemente conexo, cumpliendo 
$Aut(Y,p) \cong \Pi(X,x)$; puedo tomar $G < Aut(Y,p)$ cumpliendo $G \cong H$.

Los automorfismos del recubridor actan discontinuamente, as que $Y/G$ es un 
espacio del que es $Y$ recubridor. Induciendo la siguiente aplicacin:

\[ \begin{tikzcd}
Y \rar{p} \dar{q} & X \\
Y/G \urar{\hat{p}} &
\end{tikzcd} \]

Que est bien definida por respetar la relacin y es continua. Veamos que es 
un recubridor. Sea $U^x$ entorno fundamental, las arcocomponentes de su 
preimagen cumplen:

\[ p^{-1}(U) = \bigcup_{\phi\in Aut(Y,p)} \phi(V) \]

Si tenemos en cuenta que $\forall \phi \in G: q(\phi(V)) = q(V)$, tendremos:

\[\hat{p}^{-1}(U)
= \bigcup_{\phi \in Aut(Y,p)/G} q(\phi(V)) \]

Donde hay $[G:H]$ componentes. Ahora intentamos ver que $\hat{p}_\ast(\Pi(Y/G,-))$ genera
la clase de conjugacin de $C$. Recordando cmo actuaban los caminos en el 
espacio base sobre los puntos del recubridor, buscamos los $\alpha\in\Pi(X,x)$ que 
cumplan $q(y)\cdot\alpha = q(y)$, es decir $\exists \phi\in G: y\cdot\alpha = \phi(y)$; luego tenemos $\alpha\in H$. Si 
tengo otro $\beta \in H$, debe cumplir $\phi(y) = y\cdot\beta$ para algn $\phi\in G$, y entonces
$q(y)\cdot\alpha = q(y)$, siendo de los buscados. Tenemos:

\[\hat{p}(\Pi(Y/G, q(y)) = \operatorname{Stab}(q(y)) = H\]

***** Clasificacin de recubridores del crculo
El crculo $\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene como 
subgrupos a $n\mathbb{Z}$.

- $0$ tiene a la *recta* como recubridor universal $\mathbb{R}$ con $p(t) = e^{2\pi it}$.
- $n\mathbb{Z}$ tiene al *crculo* como recubridor $\mathbb{S}^1$ de $n$ hojas con $p(z) = z^n$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

***** Clasificacin de recubridores del toro
El toro $\mathbb{S}^1\times\mathbb{S}^1$ tiene como grupo fundamental a $\mathbb{Z}\times\mathbb{Z}$, que tiene como subgrupos 
a los generados por un generador $<(a,b)>$ o a los generados por dos, de la 
forma $<(a,b),(0,d)>$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},e^{2\pi iy})$.
- $<(a,b)>$ tiene al *cilindro* como recubridor $\mathbb{S}\times\mathbb{R}$ con $p(z,y) = (az, bze^{2\pi iy})$.
- $<(a,b),(0,d)>$ tienen al *toro* como recubridor $\mathbb{S}\times\mathbb{S}$ con
  $p(z,w) = (z^a,z^bw^d)$.

***** Clasificacin de recubridores del cilindro
El cilindro $\mathbb{S}\times\mathbb{R}$ tiene como grupo fundamental a $\mathbb{Z}$, que es abeliano y tiene 
como subgrupos a $n\mathbb{Z}$.

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ con $p(x,y) = (e^{2\pi ix},y)$.
- $n\mathbb{Z}$ tiene al *cilindro* como recubridor universal con $p(z,y) = (e^{2\pi inz},y)$.
- $\mathbb{Z}$ tiene al recubridor *identidad*.

***** Clasificacin de recubridores de la cinta de Mbius.
La cinta de Mbius tiene tipo de homotopa del crculo y por tanto grupo 
fundamental $\mathbb{Z}$. 

- $0$ tiene al *plano* como recubridor universal $\mathbb{R}^2$ sobre el que acta el grupo
  $\phi_n(x,y) = (x+n, (-1)^ny)$ discontinuamente.
- $n\mathbb{Z}$ con $n = 2m$ par tiene al *cilindro* recubrindose a s mismo $m$ veces y 
  un recubrimiento de dos hojas del *cilindro* a la banda de Mbius.
- $n\mathbb{Z}$ con $n$ impar tiene a la *banda de Mbius* como recubridor.
- $\mathbb{Z}$ tiene al recubridor *identidad*.
*** 3. Superficies compactas
**** 3.0. Clasificacin de variedades 1-dimensionales
***** Variedad 1-dimensional
Una variedad topolgica 1-dimensional es un espacio topolgico que
sea:

  - Conexo.
  - $T_2$, [[https://en.wikipedia.org/wiki/Hausdorff_space][Hausdorff]].
  - 2AN, [[https://en.wikipedia.org/wiki/Second-countable_space][segundo axioma de numerabilidad]].

y tal que:

\[\forall x \in X : \exists x \in U_x \in \tau:\quad
U_x \cong\: ]a,b[\]

***** Ejemplos
****** Los reales y el crculo
$\mathbb{R}$ es variedad trivialmente. El crculo $\mathbb{S}^1$ es tambin una variedad.

****** Contraejemplo: lemniscata
Un espacio que se cruza consigo mismo formando una lemniscata
es un contraejemplo. No hay abierto homeomorfo a un entorno del cruce.

[[file:./images/lemniscata.svg]]

****** Contraejemplo: folium
Una curva inyectiva y continua que se aproxima a un punto sin contenerlo.
Ninguno de los entornos del punto crtico tiene un entorno abierto
homeomorfo a un intervalo.

#+begin_center
#+attr_latex: :width 50px
[[./images//folium.png]]
#+end_center

****** Contraejemplo de 2AN
No existe una base numerable para el punto $(0,0)$ si usamos la
topologa que une la recta izquierda con cada una de las rectas
derechas de forma separada, no podemos encontrar una base
numerable.

\[
X
=
\{(x,0) \mid x<0\}
\cup
\left(
\bigcup_{y \in \mathbb{R}\setminus\{0\}}
\{(x,y) \mid x \geq 0\}
\right)\]

#+begin_center
#+attr_latex: :width 50px
[[./images//2an.png]]
#+end_center

***** Clasificacin de variedades topolgicas en dimensin 1
Toda variedad topolgica 1-dimensional es homeomorfa a $\mathbb{R}$ o a $\mathbb{S}^1$.

**** 3.1. Variedades topolgicas
***** Espacio localmente eucldeo
Un espacio $X$ es *localmente eucldeo* cuando cada punto admite un
entorno abierto homeomorfo a un abierto de $\mathbb{R}^n$.

****** Definicin equivalente
Cada punto admite un entorno abierto homeomorfo a una bola 
abierta de $\mathbb{R}^n$.

****** Carta
Cada entorno con su homeomorfismo forma una *carta local* $(U_x,\phi)$.

****** Bola eucldea
Carta homeomorfa a la bola unidad eucldea.

***** Variedad topolgica
Una variedad topolgica es un espacio topolgico cumpliendo:

  1. Localmente eucldeo.
  2. Hausdorff $T_2$.
  3. Segundo axioma de numerabilidad 2AN.

A una variedad de dimensin 2 la llamamos *superficie*.

****** Axioma de Hausdorff
Todo par de puntos distintos tienen entornos que los separan. Es decir,
para $x \neq y$, existen $U_x \cap V_y = \varnothing$.

****** Segundo axioma de numerabilidad
Un espacio es 2AN si tiene una base numerable. Es decir, existe un
conjunto $\{U_n\}_{n \in \mathbb{N}}$ tal que todo abierto es unin de ellos.

***** Ejemplos de variedades topolgicas
****** Los espacios eucldeos
****** Las esferas n-dimensionales
****** Recubridores de espacios localmente eucldeos
****** Recubiertos por espacios localmente eucldeos
***** Teorema de la invarianza de la dimensin
Si $U \subseteq \mathbb{R}^n$ y $V \subseteq \mathbb{R}^m$ son abiertos homeomorfos, $n=m$.
Por tanto cada variedad tiene una dimensin asignada.

****** Demostracin
Puede demostrarse comprobando grupos de homologa distintos para una
bola a la que retiramos un punto.

***** Base de las cartas
Los dominios de las cartas forman una base de la topologa.

****** Demostracin
Usamos simplemente que la interseccin de un abierto con
una carta es una carta con el homeomorfismo restriccin.

Dado un abierto, cada punto suyo tiene un entorno que es
una carta. Al intersecarlo con el abierto da otra carta,
y finalmente el abierto inicial es unin de todas las
cartas en cada punto.

***** Bola regular eucldea
Sea $B \subseteq X$ una bola eucldea, es regular cuando:

  1. Existe $B' \subseteq X$ bola eucldea con $\overline{B} \subseteq B'$.
  2. Existe $r > 0$ y una carta $\phi : B' \longrightarrow \mathbb{D}(0,2)$ tal que $\phi(\overline{B}) = \overline{\mathbb{D}(0,1)}$.

****** Contraejemplos
Una esfera sin un punto es una bola eucldea pero no una bola
regular eucldea.

***** Base de las bolas regulares eucldeas
Las bolas regulares eucldeas forman una base de la topologa de una
variedad topolgica.

****** Existencia de bola regular eucldea
En una variedad topolgica sea $p \in S$ y $U \subseteq S$ entorno de $p$ abierto.
Existe una bola regular eucldea con $p \in B \subseteq U$.

******* Demostracin
Es localmente eucldeo, luego localmente habr una bola centrada
en la imagen de $p$ y otra de mitad de radio. Su preimagen ser
regular eucldea.

****** Demostracin
En cualquier entorno existe una bola regular eucldea entre
el punto y el entorno.

***** Autohomeomorfismo de superficies conexas
Sea $S$ superficie conexa con $p,q \in S$. Entonces existe $f : S \overset{\cong}\longrightarrow S$
con $f(p) = q$.

****** Lema al endomorfismo
Existe una constante $\varepsilon \in ]0,1]$ tal que dado $x \in B(0,\varepsilon)$, existe
un $F : \mathbb{R}^2 \overset{\cong}\longrightarrow \mathbb{R}^2$ con:

  1. $F(0) = x$.
  2. $F|_{\mathbb{R}^2\setminus D(0,2)}$ es la identidad.

******* Demostracin
Tenemos funciones infinitamente diferenciables y no nulas que nos
permiten crear funciones que muevan un punto en otro dejando todo
el resto del plano igual.

******** TODO Construccin explcita
****** Demostracin
Consideremos la relacin de equivalencia $pRq$ cuando $\exists f : S \cong S$
con $f(p) = q$. Veamos que $[p]$ es abierta por $p$ arbitrario y por
tanto, $[p] = S$.

******* La clase de equivalencia es abierta
Dado $p$, tenemos $O$ disco [[*Base de las bolas regulares eucldeas][regular]] centrado en l y $O'$ disco 
eucldeo cubriendo su clausura y cumpliendo:

\[
\exists \phi : O' \overset{\cong}\longrightarrow D(0,\varepsilon)
\]

con $\phi(O) = \overline{D(0,\varepsilon/2)}$. El lema nos da una $F_x(0) = x$.

Definimos $D_0 = \phi^{-1}(D(0,\varepsilon)) \subset D'$, abierto cubriendo a $p$. Y para
cualquier $y \in D_0$, definimos la funcin $G_y : S \cong S$ como:

\[
G_y(z) = \left\{\begin{array}{ll} 
z & \mbox{if } z \notin O'  \\
\phi^{-1} \circ F_{\phi(y)} \circ \phi& \mbox{if } z \in O'
\end{array} 
\right.
\]

Lo que nos da $D_0 \subseteq [p]$, hacindolo abierto.

***** Recubridor de una superficie
Sea $\pi : \widetilde{X} \longrightarrow X$ recubridor:

  1. Si $\widetilde X$ es una superficie y $A_\pi = \{(x,y) \in \widetilde{X} \times \widetilde{X} \mid \pi(x) = \pi(y) \}$
     es cerrado, entonces $X$ es superficie.
  2. Si $X$ es superficie, $\widetilde{X}$ es superficie.

****** Demostracin
******* Localmente eucldea
La aplicacin recubridora es localmente homeomorfismo, por lo
que lleva en ambas direcciones el ser localmente eucldeo.

******* TODO Hausdorff

******* TODO Axioma de numerabilidad

**** 3.2. Complejos simpliciales
***** P-smplice
Sean $v_1,\dots,v_p \in \mathbb{R}^n$ afnmente independientes. Se define el *p-smplice*
generado como:

\[
\langle v_0,\dots,v_p \rangle
=
\left\{\;
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 \leq \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\;\right\}
\]

Llamamos a los $v_i$ *vrtices* del p-smplice y al entero $p$ se le llama
*dimensin* del p-smplice.

****** P-smplice abierto
Se define el *p-smplice abierto* como:

\[
{\cal O}(\langle v_0,\dots,v_p \rangle)
=
\left\{
\sum_{j=0}^p \lambda_jv_j 
\;\middle|\;
0 < \lambda_j \leq 1, \sum_{j=0}^p \lambda_j = 1
\right\}
\]

Observemos que en general no es igual al interior de un p-smplice,
que puede ser vaco en una dimensin alta.

****** Caras de un p-smplice
Las *caras* de un p-smplice $\sigma$ son los k-smplices generados por $k+1$ 
de sus vrtices. Se notan por $\tau < \sigma$.

Llamamos *aristas* a las caras de dimensin 1 y *tringulos* a las 
caras de dimensin 2.

***** Complejo simplicial
Coleccin de smplices $K$ en algn $\mathbb{R}^n$ cumpliendo:

  1. $\tau < \sigma, \sigma \in K \implies \tau \in K$.
  2. $\sigma,\tau \in K,\; \sigma \cap \tau \neq \varnothing$ $\implies$ $\sigma \cap \tau < \sigma$ y $\sigma \cap \tau < \tau$.
  3. Todo punto en el smplice tiene un entorno abierto que corta a
     una cantidad finita de smplices en $\bigcup_{\tau \in K}\tau \subseteq \mathbb{R}^n$.

Llamamos *dimensin* de $K$ a la dimensin del mayor smplice que 
contiene.

****** Subcomplejo simplicial
Llamamos subcomplejo simplicial a $K' \subseteq K$ complejo simplicial.

***** Poliedro
Dado $K$ complejo simplicial, llamamos *poliedro* de $K$ al espacio
topolgico formado por la unin de todos los smplices de $K$ con 
la topologa inducida:

\[|K| = \bigcup_{\tau \in K} \tau \subseteq \mathbb{R}^n\]

***** Un compacto corta una cantidad finita de smplices
Sea $G \subseteq |K|$ compacto, entonces $G$ corta a una cantidad finita de
smplices de $K$. En particular $|K|$ compacto tiene una cantidad 
finita de smplices.

****** Demostracin
Supongamos $\{\tau_n\}$, tomamos $\{p_n\} \in G \cap \tau_n$. Por compacidad habra 
una parcial convergente $\{p_n\} \longrightarrow p_\infty \in G \subseteq |K|$.

Pero por definicin de complejo simplicial, este $p_\infty$ tiene un
entorno que corta slo a una cantidad finita de smplices y por
tanto, de los $p_n$.

***** Aplicaciones simpliciales
Una $f : |K|\longrightarrow |L|$ entre complejos simpliciales es *aplicacin simplicial* 
si:

  1. $f$ lleva smplices de $K$ en smplices de $L$.
  2. La restriccin de $f$ a cada smplice es afn $Ax+b$.

****** Homeomorfismos simpliciales
Una aplicacin simplicial homeomorfismo la llamamos 
*homeomorfismo simplicial*.

****** Categora de las aplicaciones simpliciales
La inversa de un homeomorfismo simplicial es homeomorfismo simplicial;
as como la identidad y la composicin de funciones. Las aplicaciones
simpliciales forman una categora.

******* TODO Demostracin

***** Superficies triangulables
Una superficie topolgica $S$ se dice *triangulable* si existe algn
complejo simplicial de dimensin $2$ con $S \cong |K|$.

***** Teorema de Rad
Toda superficie admite una triangulacin por un complejo simplicial
eucldeo de dimensin 2 donde cada 1-smplice es cara de exactamente
dos smplices.

****** Recproco falso
No todo complejo simplicial es triangulacin de una superficie.

***** Caracterizacin de triangulaciones
Un complejo simplicial $K$ de dimensin 2 es triangulacin de una
superficie ssi:

  1. Todo smplice es cara de un 2-smplice.
  2. Todo 1-smplice es cara de exactamente dos 2-smplices.
  3. Si $\forall v \in K^{(0)}$ definimos $st(v) = \{ \tau \in K \mid v < \tau \}$ y

     \[ L(v) = \{ \tau \in K \mid \exists \sigma \in K : v < \sigma, \tau < \sigma, v \not< \tau
     \}
     \]

     y tenemos que $|st(v)| \cong \overline{D}$ y $|L(v)|$ es conexo.

****** Demostracin
No se explica en la asignatura.

**** 3.3. Suma convexa
***** Curva de Jordan
Una curva de Jordan en $\mathbb{R}^n$ es una curva cerrada y simple.

****** Definicin equivalente
Una curva de Jordan es la imagen de $f : \mathbb{S}^1 \longrightarrow \mathbb{R}^n$ que sea
homeomorfismo sobre su imagen.

***** Homeomorfismo que preserva la orientacin
Sean $C_1,C_2 \subseteq \mathbb{R}^2$ dos curvas de Jordan y $f : C_1 \overset{\cong}\longrightarrow C_2$ un homeomorfismo.
Decimos que $f$ *preserva la orientacin* si $\exists \alpha : [0,1] \longrightarrow C_1$ parametrizacin
tal que $\alpha$ recorre $C_1$ en el sentido de las agujas del reloj y $f \circ \alpha$
recorre $C_2$ en el sentido de las agujas del reloj.

***** Teorema de Jordan-Schnflies
Sean $C_1,C_2$ curvas de Jordan con $f : C_1 \cong C_2$. Entonces existe una
$F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_{C_1} = f$. Adems, 

  1. Si $f$ preserva la orientacin y $U \subseteq \mathbb{R}$ es un subconjunto 
     homeomorfo a $\mathbb{D}$ disco, con $U \supseteq C_1 \cup C_2$, entonces existe
     un $F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_{C_1} = f$ y $F|_{\mathbb{R}^2\setminus U} = Id$.
  2. Si $f$ revierte la orientacin y $U \subseteq \mathbb{R}^2$ con $U \supseteq C_1 \cup C_2$
     con $U \cong \mathbb{D}$ disco, puedo tener $F$ con: $F|_{\mathbb{R}^2\setminus U}(x,y) = (x,-y)$.

****** Demostracin
No trivial

******* Segundo punto desde el primero
Si tengo $f : C_1 \cong C_2$, revirtiendo la orientacin, puedo tomar
la curva reflejada en el eje Y:

\[\widetilde{C_2} = \{(x,y) \mid (x,-y) \in C_2 \}\]

Y definir una $\widetilde{f} : C_1 \cong \widetilde{C_2}$ como $\widetilde{f} = (f_1,-f_2)$, que preserva la 
orientacin. El teorema nos da entonces una $\widetilde{F}$ desde la que podemos
definir $F = (\tilde F_1, \tilde F_2)$, la buscada.

***** Teorema de la curva de Jordan
Sea $C$ curva de Jordan en $\mathbb{R}^2$. Entonces, $\mathbb{R}^2\setminus C$ tiene exactamente
dos componentes conexas, una de ellas acotada (*interior* de $C$) y
la otra es no acotada (*exterior* de $C$).

****** Demostracin
Dado un $f : C \cong \mathbb{S}^1$ homeomorfismo, por Jordan-Schnflies, tenemos
una $F : \mathbb{R}^2 \cong \mathbb{R}^2$ extendindola, lo que nos da $\mathbb{R}^2\setminus C_1 \cong \mathbb{R}^2 \setminus \mathbb{S}^1$.

****** Contraejemplo en dimensiones superiores: esfera de Alexander
La [[https://es.wikipedia.org/wiki/Esfera_cornuda_de_Alexander][esfera cornuda de Alexander]] es una 2-esfera embebida en $\mathbb{R}^3$
cuyo exterior no es homeomorfo al exterior de la 2-esfera en $\mathbb{R}^3$.

***** Teorema de Jordan-Schonflies para la esfera
Sean $C_1,C_2$ dos curvas de Jordan en $\mathbb{S}^2 \subseteq \mathbb{R}^3$ y $f : C_1 \overset{\cong}\longrightarrow C_2$.
Entonces $\exists F : \mathbb{S}^2 \cong \mathbb{S}^2$ con $F|_{C_1} = f$.

****** Demostracin
Si tomamos $p \in \mathbb{S}^2 \setminus \{C_1 \cup C_2\}$, tenemos $\mathbb{S}^2 \setminus \{p\} \cong \mathbb{R}^2$ por la proyeccin
estereogrfica. Tomamos el $F$ que da el teorema de Jordan-Schnflies
y lo componemos con la inversa de la proyeccin para tener el $F$.

Dividimos en los dos casos para ver que el $F$ es continuo en el
punto impropio.

***** Suma conexa
Sean $S_1,S_2$ dos superficies convexas. Sean $D_1 \subseteq S_1$, $D_2 \subseteq S_2$ discos
regulares eucldeos y sea $\varphi : \partial D_1 \longrightarrow \partial D_2$ homeomorfismo. 

Denotemos $S'_i = S_i \setminus D_i$. En $S'_1 \sqcup S_2'$ definimos $R_{\varphi}$ relacin de equivalencia 
entre el borde y su imagen:

\[ x\; R_\varphi \; \varphi(x)\quad \forall x \in \partial D_1\]

Tenemos una superficie topolgica conexa que es independiente de los
discos y el homeomorfismo elegidos. La llamamos *suma conexa*:

\[
S_1 \# S_2
=
S_1' \sqcup S_2' / R_\varphi
\]

***** La suma es independiente de los discos
Para $D_1,D_3 \subseteq S'$ discos regulares eucldeos centrados en $p_1$, tenemos
que:

\[S_1 \setminus D_1 \cong S_1 \setminus D_3\]

****** Demostracin
Sin prdida de generalidad, $\overline{D_1} \subset D_3$. Sea $\psi$ el que hace bola [[*Bola regular eucldea][regular]]
a $D_3$. Definimos:

\[ C_3 = \psi(\partial D_3)\]
\[C_1 = \psi(\partial D_1)\]

Tomamos un $f : C_1 \cong C_3$ y Jordan-Schnflies nos da un $F$.

Definimos ahora por partes $\widetilde F$ como:

\[\widetilde{F}|_{D_3'} = \psi^{-1} \circ F \circ \psi\]
\[\widetilde{F}|_{S_1 \setminus D_3'} = Id\]

Comprobamos que est bien definida y es homeomorfismo, por lo que
tenemos $\widetilde F : S_1\setminus D_1 \cong S_3 \setminus D_3$.

***** La suma es independiente de los centros
Los puntos en los que centramos la suma conexa. Tomando $p_1 \neq p_3 \in S_1$,
con $D_1,D_3$ discos regulares eucldeos centrados en ellos:

\[S_1 \setminus D_1 \cong S_3 \setminus D_3\]

****** Demostracin
Ya tenemos que hay un [[*Autohomeomorfismo de superficies conexas][automorfismo]] que centra un punto en otro.
Como los discos regulares son base de la topologa, existir un
$\overline{D_3''} \subseteq D_3$ y suficientemente pequeo para que $F(D_3'') \subseteq D_1$.

Como $F(D_3'')$ es disco regular eucldeo:

\[
S_1/D_3 \cong 
S_1/D_3'' \cong
S_1/F(D_3'') \cong
S_1/D_1
\]

***** La suma es independiente del homeomorfismo
El homeomorfismo no influye. Dados $\varphi, \xi : bD_1 \longrightarrow bD_2$ homeomorfismos,
queremos ver:

\[
S_1 \sqcup S_2 / R_\varphi \cong S_1 \sqcup S_2 / R_\xi
\]

****** Demostracin
Suponemos s.p.g. que $\xi \circ \varphi^{-1}$ preserva la orientacin. Como $D_2$ es disco
regular eucldeo, hay un $D_2' \subset S_2$ eucldeo con $\psi_2 : D_2' \longrightarrow \mathbb{D}(0,2)$:

\[
\psi_2(D_2') = \overline{\mathbb{D}(0,1)}
\]

Llamamos:

  1. $C = \psi_2(bD_2) = \mathbb{S}^1$, curva de Jordan.
  2. $f = \psi_2 \circ \xi \circ \varphi^{-1} \circ \psi_2^{-1} : C \cong C$.
  3. $U = \mathbb{D}(0,3/2)$.

Por [[*Teorema de Jordan-Schnflies][Jordan-Schnflies]], tenemos un $F : \mathbb{R}^2 \cong \mathbb{R}^2$ con $F|_G = f$, $F|_{\mathbb{R}^2-U} = Id$.

Definimos ahora $\widetilde F : S_2 \cong S_2$ cumpliendo $\widetilde F|_{D_2'} = \psi_2^{-1} \circ F \circ \psi$ y teniendo
tambin $\widetilde F|_{S_2-D_2'} = Id$.

Finalmente definimos $\widehat F : S_1 \sqcup S_2 \cong S_1' \sqcup S_2'$ con $\widehat F|_{S_1'} = Id, \widehat F|_{S_2'} = \widetilde F$.
El siguiente diagrama nos da el homeomorfismo:

\[\begin{tikzcd}
S_1' \sqcup S_2'           \rar{\widehat F}\dar{p_\xi}& 
S_1' \sqcup S_2'           \dar{p_\varphi} \\
S_1' \sqcup S_2'/R_\varphi \rar[dashed] & 
S_1' \sqcup S_2'/R_\xi
\end{tikzcd}\]

Ya que dados dos puntos $x,y$, si estn fuera del borde su relacin es
trivial, y si estn en el borde cumplen $y = \varphi(x)$:

  - $\widehat F(x) = x \in bD_1 \subseteq S_1'$
  - $\widehat F(y) = \widetilde F(y) \in bD_2 \subseteq S_2'$

Luego basta comprobar que:

\[\widetilde F(y) = 
\widetilde F(\varphi(x)) =
\psi_2^{-1} (F(\psi_2(\varphi(x)))) =
\psi_2^{-1} (f(\psi_2(\varphi(x)))) =
\xi (x)
\]

***** La suma conexa de superficies conexas es superficie conexa
La suma conexa de dos superficies topolgicas conexas es una
superficie topolgica conexa.

****** Demostracin
Sean $S_1,S_2,D_1,D_2,\varphi$ las superficies y los discos que definen
la suma conexa:

\[
S_1 \# S_2 =
S_1' \sqcup S_2' / R_\varphi
\]

******* Es localmente eucldea
******** Fuera de los discos
En los puntos fuera de los discos, es trivial por ser $S_1,S_2$
localmente eucldeas. Sea $p : S_1' \sqcup S_2' \longrightarrow S_1 \# S_2$, como es un 
homeomorfismo fuera del borde, llamamos:

\[
V_i = p(S_i' - bD_i') \subseteq S_1 \# S_2
\]

Y como tenemos por otro lado:

\[
p^{-1}(V_i) = S_i'-bD_i = (S_i-\overline{D_i})\cap S_i'
\]

Llegamos a que $p^{-1}(V_i)$ es abierto en $S_i'$ y por tanto $V_i$ es abierto
en $S_1 \# S_2$. Tenemos $V_i \cong S_i' - bD_i$ localmente eucldeo.

******** TODO En los discos
Sea $q \in p(bD_1) = p(bD_2)$. Como son discos regulares eucldeos, se
tienen $D_1',D_2'$ con cartas $\psi_i(D_1') = \mathbb{D}(0,2)$, $\psi(D_1) = \overline{\mathbb{D}(0,1)}$.

Pegamos ambos discos y comprobamos que son homeomorfos a un abierto
del plano.

******* Cumple Hausdorff
El nico caso no trivial es el de $x \in V_0$, $y \in V_1 - V_0$. Como podemos tomar
$V_0$ abitrariamente pequeo, tenemos s.p.g. $y \notin \overline{V_0}$. As, hay un abierto de $y$
que no corta a $\overline{V_0}$, y como $V_0$ era un abierto, hay otro abierto de $x$ que
queda dentro de l.

******* Cumple axioma de numerabilidad
El que exista una proyeccin abierta, continua y sobreyectiva desde un
espacio 2AN hace al espacio 2AN.

**** 3.4. Presentacin poligonal de superficies
***** Polgono homeomorfo
Toda superficie topolgica compacta es homeomorfa a un polgono con lados
identificados 2 a 2.

****** Idea de demostracin
Dada $S$ compacta, por un teorema que no demostramos, $S \cong |K|$.
Por [[*Teorema de Rad][Rad]], podemos triangularlo y por compacidad, tiene un nmero
finito de caras. Ese polgono puede desplegarse.

***** Regin poligonal
Un $P \subseteq \mathbb{R}^2$ es regin poligonal si:

  1. Es compacta.
  2. Tiene por borde una curva poligonal (complejo de dimensin 1).
  3. Cada $v \in \operatorname{b}(P)$ vrtice admite entorno $U \subseteq \mathbb{R}^2$ tal que:

     \[U \cap P = U \cap H_1 \cap H_2\]

     donde $H_1,H_2$ son semiplanos cerrados con $H_1 = H_2$ o $\operatorname{b}H_1 \cap \operatorname{b}H_2 = \{v\}$.

****** Ejemplos
******* Polgonos regulares
Toda regin compacta, convexa y bordeada por una curva poligonal
es una regin poligonal.

******* Contraejemplo: polgono no convexo
Un polgono no convexo no cumple la propiedad 3 en cualquier
vrtice que no est en la envolvente.

***** Superficie de una regin poligonal
Sea $P \subseteq \mathbb{R}^2$ regin poligonal con un nmero par de aristas. Si $R$ es relacin 
de equivalencia, identificando cada arista con exactamente otra arista
mediante homeomorfismo simplicial, $P/R$ es una superficie topolgica 
compacta.

****** Demostracin
******* Compacta
Sabemos que $P$ es compacta, como $p$ es continua y sobreyectiva,
tenemos $P/R$ compacto.

******* Localmente eucldea
Consideramos tres casos:

******** Interior del polgono
Tenemos que la proyeccin es homeomorfismo local.

******** Interior de las aristas
Tenemos $q_i \in a_i$ identificadas por un homeomorfismo simplicial.
Podemos crear un disco centrado en $\mathbb{R}^2$ uniendo dos discos y que
la relacin que define esa proyeccin sea la misma que la que
define la equivalencia de aristas.

******** Vrtices
Trabajamos dependiendo de con cuntos puntos est identificado
$p^{-1}(x) = \{v_1,\dots,v_k\}$. Sean $D_i$ discos abiertos en $\mathbb{R}^2$ para cada 
vrtice cumpliendo $\overline{D_i} \cap \overline{D_j} = \varnothing$ y llamamos $U_i = D_i$.

Creamos un disco uniendo todos las partes de disco y comprobamos
que la relacin que defina sea la misma que la de la proyeccin.

******* TODO Segundo axioma de numerabilidad

******* TODO Espacio de Hausdorff

***** Presentacin poligonal
Llamamos presentacin a una expresin de la forma:

\[\langle A;\; W_1,\dots,W_n \rangle\]

donde $W_i$ son palabras con todos los smbolos $\langle A \rangle$ de longitud mayor 
que 3. Permitimos adems los casos especiales:

  - $\langle \{a\}, aa \rangle$
  - $\langle \{a\}, aa^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a^{-1} \rangle$
  - $\langle \{a\}, a^{-1}a \rangle$

***** Presentacin de un complejo simplicial
Dado un complejo simplicial $K$ donde cada smplice es cara de un
2-smplice, tenemos una presentacin poligonal asignando a cada
2-smplice una palabra de longitud 3.

***** Realizacin geomtrica de una presentacin
Cada $P = \langle A; W_1,\dots,W_n \rangle$ determina $|P|$, una topologa de la forma:

  1. Para cada $W_i$ tomamos un polgono $P_i$ de n-lados.
  2. Biyeccin entre lados y aristas de $P_i$ en sentido antihorario.
  3. Identificamos cada arista con la que tiene el mismo nombre en
     el sentido marcado por la inversa.

Tomamos la unin por esta relacin $|P| = \bigsqcup P_i / R$.

***** Extensin a homeomorfismo
Para $P_1,P_2$ polgonos convexos con el mismo nmero de aristas.
El $f : \operatorname{b}P_1 \longrightarrow \operatorname{b}P_2$ homeomorfismo simplicial se extiende a un 
homeomorfismo $F : P_1 \longrightarrow P_2$.

****** TODO Demostracin

***** Presentacin de superficie
Una presentacin $\langle A; W_1,\dots,W_n \rangle$ es de superficie si 
cada smbolo de $A$ aparece exactamente dos veces en los $W_i$.

***** Presentacin asociada a una superficie
Si $S$ es superficie compacta y $|P| \cong S$, llamamos a $P$ una
*presentacin* de $S$.

***** Presentaciones topolgicamente equivalentes
Dos presentaciones $P_1,P_2$ son topolgicamente equivalentes si:

\[ |P_1| \cong |P_2|\]

***** Transformaciones elementales de presentaciones poligonales
Dado $\langle A; W_1,\dots,W_n \rangle$, podemos definir las siguientes transformaciones
elementales.

****** 1. Renombrar
Cambiar un smbolo $a \in A$ por $e \notin A$ para cada palabra.

****** 2. Subdividir
Sustituir $a \mapsto ae$ y $a^{-1} \mapsto e^{-1}a^{-1}$.

****** 3. Consolidar
Inversa de subdividir.

****** 4. Reflejar
Cambiar orden de una palabra $a_1\dots a_m \mapsto a_m^{-1}\dots a_1^{-1}$.

****** 5. Rotar
Empezar una palabra en otro vrtice $a_1\dots a_m \mapsto a_2\dots a_ma_1$.

****** 6. Cortar
Partir dos palabras $W_1W_2 \mapsto W_1e,e^{-1}W_2$.

****** 7. Pegar
Inversa de cortar.

****** 8. Doblar
Anular dos lados adyacentes $W_1ee^{-1} \mapsto W_1$.

****** 9. Desdoblar
Inversa de doblar.

***** Transformaciones elementales preservan la realizacin
Las transformaciones elementales de una presentacin poligonal
producen una presentacin poligonal equivalente.

****** Demostracin
******* Renombrar
Trivialmente.

******* TODO Subdividir/Consolidar
******* Reflejar
Una aplicacin que lleve cada arista en la inversa del mismo nombre
respetar vrtices.

******* Cortar/Pegar
Probaremos que $\langle A; W_1W_2 \rangle \cong \langle A\cup \{e\} ; W_1e,e^{-1}W_2 \rangle$. Llamamos $P'$ al 
smplice generado por la primera y $P_1,P_2$ a los generados por las
segundas. Sea $f$ una aplicacin simplicial que une la arista de corte:

\[\begin{tikzcd}
P_1 \sqcup P_2 \dar{p} \rar{f} & 
P' \dar{p'}
\\
\lvert P\rvert \rar{\widetilde f} &
\lvert P' \rvert
\end{tikzcd}\]

Sabemos que $f$ baja al cociente de manera continua y $\widetilde f$ es cerrada
por ir de un compacto a un cerrado. Adems es biyectiva y por
tanto homeomorfismo.

En caso de que hubiera ms de dos palabras podramos extenderla
por la identidad y seguir el mismo razonamiento.

******* Doblar/Desdoblar
******** Caso triangular
Definimos una aplicacin simplicial respetando el nombre de las
aristas:

#+begin_center
#+attr_latex: :width 50px
[[./images//doblartransformacion.png]]
#+end_center

Esa aplicacin simplicial baja de forma continua y genera una
aplicacin biyectiva entre compacto y cerrado.

******** Caso general
Podemos cortar o subdividir para llegar al caso triangular.

***** Presentacin poligonal de la suma
Dadas $S_1,S_2$ con presentaciones $P_1 = \langle A_1; W_1 \rangle$ y $P_2 = \langle A_2;W_2 \rangle$ con
$A_1 \cap A_2 = \varnothing$. Entonces una presentacin de $S_1 \# S_2$ es:

\[
\langle A_1 \cup A_2 ; W_1 W_2 \rangle
\]

****** Demostracin
Desdoblamos y cortamos para llegar a la presentacin:

\[
\langle W_1c^{-1}b^{-1}a^{-1}, abc \rangle
\]

De donde salen dos complejos simpliciales $P$ y $Q$. El segundo de
ellos se proyecta a un disco regular eucldeo.

\[ D_1 = p'(\mathring Q) \subseteq |P'| \]

Mientras que el primero se proyecta al polgono sin un disco cuyo
borde es $bD_1 = p(c^{-1}b^{-1}a^{-1})$.

\[
p'(P) \cong S_1 \setminus D_1
\]

Aplicando el mismo argumento a $W_2$, llegamos a una presentacin de
$S_2\setminus D_2$, que al identificar ambos bordes permite unirlos pegando
y doblando:

\[
\langle W_1c^{-1}b^{-1}a^{-1}, abc W_2 \rangle \cong
\langle W_1W_2 \rangle
\]

***** Presentaciones modelo
****** Esfera
La presentacin de la esfera $\mathbb{S}^2$ es:

\[P_0 = \langle a \mid aa^{-1} \rangle\]

****** Suma de toros
La presentacin de la suma de toros $\mathbb{T}^{\#n} = \mathbb{T} \# \overset{n}\dots \#\mathbb{T}$ es:

\[
P_n = \langle
a_1,b_1,\dots,a_n,b_n 
\mid 
a_1b_1a_1^{-1}b_1^{-1}\dots a_nb_na_n^{-1}b_n^{-1} 
\rangle
\]

****** Suma de planos proyectivos
La presentacin de la suma de planos proyectivos $\mathbb{RP}^{2\#n}$ es:

\[ Q_n =
\langle a_1,\dots,a_n \mid a_1a_1\dots a_na_n \rangle
\]
**** 3.5. Clasificacin de superficies compactas I
***** Aristas retorcidas y complementarias
Un par de aristas en una presentacin se dicen retorcidas si
aparecen como $a$ y $a$; y complementarias si aparecen como $a$ y $a^{-1}$.

***** Lema: botella de Klein
La botella de Klein $K$ es homeomorfa a la suma conexa de dos planos
proyectivos:

\[
K \cong \mathbb{RP}^2 \# \mathbb{RP}^2
\]

****** Demostracin
Simplemente comprobando que sus presentaciones son equivalentes:

\[
\langle abab^{-1} \rangle \cong \langle ccbb \rangle
\]

***** Lema: suma de toro y plano proyectivo
La suma conexa de un toro y un plano proyectivo es homeomorfa a la 
suma conexa de 3 planos proyectivos:

\[
\mathbb{T} \cong \mathbb{RP}^2 \# \mathbb{RP}^2 \# \mathbb{RP}^2
\]

****** Demostracin
Comprobando que sus presentaciones son equivalentes:

\[
\langle aba^{-1}b^{-1}cc \rangle \cong \langle aabbcc \rangle
\]

Podemos usar el [[*Lema: botella de Klein][lema]] anterior y ver que:

\[\begin{aligned}
\langle abab^{-1}cc \rangle 
&=
\langle cabd^{-1},dab^{-1}c \rangle 
\\&=
\langle abd^{-1}ba^{-1}d^{-1} \rangle
\\&=
\langle a^{-1}d^{-1}abe,e^{-1}d^{-1}b \rangle
\\&=
\langle a^{-1}d^{-1}abe,e^{-1}d^{-1}b \rangle
\\&=
\langle a^{-1}d^{-1}abe,b^{-1}de \rangle
\\&=
\langle ea^{-1}d^{-1}ade \rangle
\end{aligned}\]

***** Teorema de clasificacin de presentaciones de superficies compactas
Cualquier presentacin poligonal de una superficie compacta y conexa
es equivalente a una de las siguientes:

  1. $P_0$, presentacin de $\mathbb{S}^2$.
  2. $P_n$, presentacin de $\mathbb{T}^{\#n}$.
  3. $Q_n$, presentacin de $\mathbb{RP}^{2\#n}$.

****** Demostracin
Sea $S$ superficie con presentacin $P$.

******* Paso 1: Reducir a una cara
Como el cociente es arcoconexo, si hay ms de una palabra, comparten
entre s alguna letra. Rotamos, reflejamos si es necesario y pegamos
para tener una sola cara.

******* Paso 2: Retirar complementarias adyacentes
Dos lados adyacentes pueden retirarse.

******* Paso 3: Colocar aristas retorcidas adyacentes
Dada una palabra de la forma $WaVa$:

  1. Cortamos: $Wab^{-1},bVa$.
  2. Reflejamos y rotamos: $b^{-1}Wa, a^{-1}V^{-1}b^{-1}$.
  3. Pegamos y rotamos: $b^{-1}b^{-1}WV^{-1}$.

******* Paso 4: Identificar todos los vrtices
Fijado un vrtice, puedo cortar un tringulo que lo contenga y
volver a pegar por uno de sus lados para identificar otro vrtice
con l.

******* Paso 5: Las complementarias tienen complementarias intercaladas
Para un par de complementarias $a,a^{-1}$, hay otro par de complementarias
intercalado como: $a \dots b \dots a^{-1} \dots b^{-1}$.

Si no fuera as, tendramos $aXa^{-1}Y$ sin forma de relacionar ningn
vrtice de $X$ con un vrtice de $Y$.

******* Paso 6: Las intercaladas pueden presentarse en bloques
Si tenemos una palabra de la forma $WaXbYa^{-1}Zb^{-1}$:

  1. Cortando antes de $b$ y pegando por $a$: $XcWZb^{-1}c^{-1}bY$.
  2. Cortando antes de $c$ y pegando por $b$: $d^{-1}WZYXcdc^{-1}$.

Luego tenemos: $WaXbYa^{-1}Zb^{-1} \longrightarrow WZYXcdc^{-1}d^{-1}$.

******* Paso 7: Nos queda suma de planos proyectivos y toros
Nos acaba quedando una palabra de la forma: 

\[aabb\dots cdc^{-1}d^{-1}\dots\]

Suma conexa de toros y planos proyectivos. Por el [[*Lema: suma de toro y plano proyectivo][lema]],
sabemos que ser suma de toros o suma de planos proyectivos.

***** Preclasificacin de superficies compactas
Toda superficie compacta y conexa es homeomorfa a al menos una de las 
siguientes:

  1. $\mathbb{S}^2$
  2. $\mathbb{T}^{\#n}$
  3. $\mathbb{RP}^{2\#n}$

****** Demostracin
Cada superficie compacta es triangulable por [[*Teorema de Rad][Rad]], con cada 1-smplice
siendo cara de dos 2-smplices. Todo complejo simplicial tiene despus
una [[*Presentacin de un complejo simplicial][presentacin poligonal]]. La compacidad da la finitud.

Podemos reducir su [[*Teorema de clasificacin de presentaciones de superficies compactas][presentacin]] a una de las de estas superficies
mediante transformaciones equivalentes. 
**** 3.6. Clasificacin de superficies compactas II
***** Grupo fundamental de la presentacin
Sea $S$ compacta y convexa determinada por la presentacin $P$, entonces
su grupo fundamental tiene la misma presentacin de $P$.

Es decir cociente del libre por la clausura normal de las $W$:

\[\Pi(S) = \frac{F(A)}{N_W}\]

****** Demostracin
Aplicando Seifert-Van Kampen sobre una cara tenemos las aristas
como generadores y las palabras como relaciones entre ellas.

***** Conmutador
Dado $G$ se define su conmutador $[G,G]$ como el subgrupo normal de $G$ que
contiene las clases de conjugacin, de la forma:

\[
[G,G] 
= 
\langle aba^{-1}b^{-1} \mid a,b \in G \rangle\]

***** Abelianizado
El conmutador cumple:

  1. $[G,G] \cong \{e\}$ $\iff$ $G$ abeliano.
  2. $Ab(G) = G/[G,G]$ es abeliano, llamado el *abelianizado* de $G$.

****** Demostracin
Primer punto trivial. Para el segundo, comprobamos $ab[G,G] = ba[G,G]$.

***** Abelianizados de los grupos fundamentales de los modelos
Los abelianizados de los grupos de los modelos son:

  1. $Ab(\pi_1(\mathbb{S}^2)) = \{1\}$.
  2. $Ab(\pi_1(\mathbb{T}^{\#n}) \cong \mathbb{Z}^{2n}$.
  3. $Ab(\pi_1(\mathbb{RP}^{2\#n})) \cong \mathbb{Z}^{n-1} \times \mathbb{Z}_2$.

Distintos entre s.

****** Demostracin
******* Grupo abelianizado del toro
Podemos definir una funcin sobre el grupo libre:

  - \[\varphi(a_i) = (0,\dots,\overset{i}1,\dots,0)\]
  - \[\varphi(b_i) = (0,\dots,\overset{n-i}1,\dots,0)\]

Y comprobar que respeta las relaciones de abelianidad y de la
palabra. Adems de dar un homomorfismo invertible.

******* Grupo abelianizado del plano proyectivo
Volvemos a definir sobre el grupo libre:

  - \[\varphi(a_i) = (0,\dots,\overset{i}1,\dots,0,0)\]
  - \[\varphi(a_n) = (-1,\dots,-1,1)\]

Volvemos a comprobar que tiene una inversa despus de bajarla al
cociente.

****** Los productos de enteros son distintos
Trivial. Puede comprobarse dividiendo y por induccin.

****** El producto por el cclico de orden 2 los hace distintos
Claramente, el producto por el cclico de orden 2 aade un elemento de
orden 2 al grupo que antes no estaba.

***** Clasificacin de superficies compactas
Una superficie topolgica compacta $S$ es homeomorfa a una sola
de las siguientes:

  1. $\mathbb{S}^2$.
  2. $\mathbb{T}^{\#n}$.
  3. $\mathbb{RP}^{2\#n}$.

Dos superficies compactas son homeomorfas ssi sus grupos 
fundamentales son isomorfos.

**** 3.7. Caracterstica de Euler y orientabilidad
***** Gnero
Se define el gnero de $S$ superficie compacta conexa:

\[ g(S) =
\left\{\begin{array}{ll} 
0 & \mbox{if } S \cong \mathbb{S}^2 \\
n & \mbox{if } S \cong \mathbb{T}^{\#n} \mbox{  } S \cong \mathbb{RP}^{2\#n}
\end{array} 
\right.
\]

***** Caracterstica de Euler
Se define la caracterstica de Euler de $S$ superficie compacta conexa:

\[\chi(P) = C-A+V\]

donde $C,A,V$ son los nmeros de caras, aristas y vrtices.

***** La caracterstica de Euler es invariante a transformaciones
La caracterstica de Euler es invariante a transformaciones
elementales.

****** Demostracin
Podemos comprobar que cada transformacin elemental preserva la
caracterstica aunque aada caras, aristas o vrtices.

***** Orientabilidad
Una superficie es orientable si admite una presentacin orientada.

****** Presentacin orientable
Una presentacin poligonal es orientable si no tiene ningn par
de aristas retorcidas.

***** La orientabilidad de superficies compactas es un invariante
Una superficie compacta conexa es orientable ssi es homeomorfa a
la esfera o a la suma de planos proyectivos.

***** Bicolorabilidad                                             :extra:
Una presentacin es *bicoloreable* si podemos colorear sus palabras
con dos colores de forma que las dos ocurrencias de una arista:

  - tengan distinto color y mismo signo
  - o tengan el mismo color y distinto signo

***** Bicolorabilidad invariante a transformaciones elementales   :extra:
La bicolorabilidad es invariante a transformaciones elementales.

****** Demostracin
******* Renombrar
Trivialmente manteniendo la coloracin.

******* Subdividir
Trivial por la misma coloracin por cumplirlo la subdividida.

******* Consolidar
Trivial por cumplirlo ambas aristas involucradas.

******* Reflejar
Cambiando la coloracin de la palabra.

******* Rotar
Trivial, mantiene coloracin.

******* Cortar
Manteniendo el mismo color en las dos palabras.

******* Pegar
Ambas palabras deben tener el mismo color.

******* Doblar
Anular dos lados adyacentes no cambia nada.

******* Desdoblar
Las dos partes estn en la misma palabra y tienen el mismo color.

***** Bicolorabilidad coincide con orientabilidad                 :extra:
La bicolorabilidad coincide con la orientabilidad.

****** Demostracin
Coincide en los modelos y por ende en todas las dems superficies.

***** Algoritmo de bicolorabilidad                                :extra:
Podemos calcular la bicolorabilidad de una presentacin simplemente
eligiendo un color para la primera cara y coloreando a partir de
ella.

****** Demostracin
Asignado el color de la primera cara, queda determinado el color
de todas las caras que contengan una arista de ella. Como toda
cara est conectada a la inicial por conexin, toda cara queda
determinada.

Si esta coloracin cumple las condiciones de bicolorabilidad,
hemos encontrado una forma de bicolorear. Si no lo cumple, ninguna
bicoloracin es posible.

***** Clasificacin por invariantes                               :extra:
Tabla de clasificacin de superficies compactas por invariantes:

|------------+--------+----------+----------------|
| Superficie | Gnero | C. Euler | Orientabilidad |
|------------+--------+----------+----------------|
| S          | 0      | 2        | Orientable     |
| T^n        | n      | 2-2n     | Orientable     |
| RP^n       | n      | 2-n      | No orientable  |
|------------+--------+----------+----------------|

Y podemos calcular el gnero desde la orientabilidad y la caracterstica:

  - $S$ orientable: $g(S) = \frac{1}{2}(2-\chi(S))$
  - $S$ no orientable: $g(S) = 2-\chi(S)$

*** Ejercicios
**** Relacin de problemas 1
***** Ejercicio 1
Trabajando en el grupo fundamental $\Pi(X,x)$.

***** Ejercicio 2
****** Punto 1
Trivial trabajando en el grupo fundamental.
****** Punto 2
La condicin es $\gamma\beta \in {\cal Z}(\Pi(X,x))$.

***** Ejercicio 3
Calculamos usando Seifert-Van Kampen.

***** Ejercicio 6
Por Seifert-Van Kampen haciendo tres grupos, uno con equivalencia homotpica al
crculo y otro trivial. Sale $\mathbb{Z}$.

***** Ejercicio 7
Equivalencia homotpica a un crculo en el que se identifican antpodas, que es
homeomorfo a un crculo. Sale $\mathbb{Z}$.

***** Ejercicio 8
Por Van Kampen, teniendo un trozo con equivalencia homotpica a la esfera y otro
que es un simple disco abierto. Grupo fundamental trivial.

***** Ejercicio 9
Por el Van Kampen que aplicamos en estos casos, es $\mathbb{Z}_3$.

***** Ejercicio 10
Homeomorfo al anterior.
**** Relacin de problemas 2
***** Ejercicio 1
****** Punto 1
     Trivial
****** Punto 2
     Subiendo la interseccin del entorno abierto que es isomorfo a $\mathbb{R}^n$ con el 
     entorno abierto que nos da el recubridor.
****** Punto 3
     Probamos la caracterizacin, que es ser semilocalmente simplemente conexo. Cada
     punto tiene un entorno homeomorfo a un abierto de $\mathbb{R}^n$, as que puedo tomar una bola
     abierta en el punto y que sea homeomorfa a un abierto en el punto en el que el
     grupo fundamental sea trivial.
****** Punto 4
     Las esferas.

***** Ejercicio 2
    #+begin_statement
    Sea $\{a,b\}$ una base de $\mathbb{R}^2$ y $R$ la relacin de equivalencia en $\mathbb{R}^2$ dada por:

    \[ qRq' \text{ si }\ q'-q = ma+nb,\quad m,n\in\mathbb{Z}\]

    Sea $T_{a,b}$ el espacio topolgico cociente.
    #+end_statement

****** Punto 1
Usamos el recubrimiento de cocientes que surgen de acciones discontinuas para
el grupo de acciones de los $\phi_{n,m}(z) = z + (n,0) + (0,m)$ con $n,m\in\mathbb{Z}$.

**** Ejercicios de clase
***** Clculo del espacio proyectivo con Van-Kampen
Para calcular el grupo de $\mathbb{R}\mathbb{P}^2$, lo definimos como una proyeccin desde la bola 
cerrada $C$ y tomamos abiertos en l.

 #+begin_center
 #+attr_latex: :width 50px
 [[./img/rpvankampen.png]]
 #+end_center

Aplicaremos Van Kampen sobre los siguientes abiertos:

 \[ U = \pi(C-\{p\})\]
 \[ V = \pi(B(p,\epsilon))\]
 \[ U \cap V = \pi((C-\{p\}) \cap B(p,\epsilon)) = \pi (B(p,\epsilon)) - \{p\}\]

Y tenemos que el grupo de $V$ es trivial. Para calcular el grupo de $U$ usar que
tiene el mismo tipo de homotopa que su borde, que es isomorfo a un crculo y
por tanto tiene grupo fundamental $\mathbb{Z}$.

De la interseccin tomaremos un generador $f$ y lo llevaremos al borde para tener:

 \[ f \simeq \alpha \ast c \ast a \ast \tilde\alpha\]

Que proyectando mientras sabemos que el generador de $U$ es 
$g = [\pi(\alpha \ast c \ast \tilde\alpha)]$ nos da finalmente que:

\[ [\pi(f)] \simeq 
 [\pi(\alpha\ast c \ast\tilde\alpha \ast \alpha \ast a \ast \tilde\alpha)] \simeq
 [g] \ast [g] \simeq 2[g]\]

Y el clculo del grupo nos da:

\[\frac{<g>}{<2g>} \cong \mathbb{Z}_2\]

**** Examen 13 enero 2016
****** Ejercicio 3
******* Punto 1     
      Sabemos que todos los $\Phi_n$ son homeomorfismos. Dado un punto $(a,b)$ tomamos un
      disco abierto de radio $1/4$ alrededor de l, y comprobamos que $(a+n,(-1)^nb)$
      est siempre a distancia mayor a $n$ y mayor a $1/2$. Llamando a la bola $V$, 
      tenemos:
      
      \[\phi(V) \cap V = \varnothing\]

******* Punto 2
      Como $G$ acta propia y discontinuamente sobre $\mathbb{R}^2$, tenemos que es un 
      recubridor regular.

******* Punto 3
      Como $G$ es ahora el grupo de automorfismos de un recubridor regular sobre $M$,
      tenemos que:
      
      \[ G \cong \Pi(M,x)\]

      Con lo que su grupo fundamental es $\mathbb{Z}$.

******* Punto 4
      Trivial desde lo anterior.

******* Punto 5
      Podemos definir una funcin de $C$ a $M$ desde las representaciones en $\mathbb{R}^2$,
      vemos luego que es identificacin y que por tanto hay homeomorfismo entre
      la imagen y el cociente por la relacin que define. Comprobamos que ese
      cociente es igual al que define el grupo.

******* Punto 6
      Tengo ya al cilindro como recubridor y al plano. Faltan las cintas de Mbius
      en el caso impar que se realizarn como en el ejercicio 5.
      
**** Relacin de problemas 3
***** Ejercicio 1
#+begin_statement
Prueba que un espacio topolgico conexo es arco-conexo si y slo si
cada punto tiene un entorno arco-conexo. Demuestra que todo espacio
topolgico localmente eucldeo es conexo si y slo si es arco-conexo.
#+end_statement

Si es arcoconexo, claramente se tiene localmente arcoconexo.  Si es
localmente arcoconexo, una componente arcoconexa debe ser abierta y
cerrada, porque cada punto al que se pueda llegar tiene un entorno al
que se puede llegar. Y cada punto al que no se pueda llegar tiene un
entorno al que no se pueda llegar.

***** Ejercicio 3
#+begin_statement
Estudia si el subespacio topolgico de $\mathbb{R}^3$ dado por:

\[ X = \{(x,y,z) \in \mathbb{R}^3 \mid z^2 = x^2+y^2\}\]

es una superficie topolgica.
#+end_statement

Si $z=0$ se tiene $x,y = 0$, as, el nico punto en ese plano es 
el $0$. Cualquier entorno suyo, si quitamos ese punto, tiene dos
componentes conexas y no puede ser homeomorfo a un disco.

El espacio no es localmente eucldeo.

***** Ejercicio 4
Ambos son localmente eucldeos.

***** Ejercicio 5
#+begin_statement
Prueba que el p-smplex generado por $\{a_1,\dots,a_n\}$ es la envolvente
convexa del conjunto $\{a_1,\dots,a_n\}$.
#+end_statement

La envolvente convexa debe contener a todos los puntos y a sus
combinaciones convexas, luego debe contener a todo el simplex.

El simplex es convexo trivialmente:

\[
t \sum \lambda_i v_i + (1-t) \sum \lambda_i' v_i =
\sum t \lambda_i v_i + \sum (1-t) \lambda_i' v_i
\]

Y entonces la suma de los coeficientes suma la unidad, usando
que lo cumplen ambos elementos del smplice:

\[
\sum t\lambda_i + \sum (1-t)\lambda_i' = t + (1-t) = 1
\]

***** Ejercicio 6
#+begin_statement
Dado un vrtice de un complejo simplicial $K$ se define la estrella 
abierta de $v$ como $ost(v) = \{o(\sigma) \mid \sigma \in st(v)\}$. Prueba que $ost(v)$ es un
entorno abierto de $v$ en $|K|$ y la coleccin de todas las estrellas 
abiertas es un recubrimiento abierto de $|K|$.
#+end_statement

Todo punto aqu pertenece a algn $x \in o(\sigma), \sigma \in st(v)$. Una bola cerrada
alrededor suya es compacta y slo contiene a una cantidad finita de
smplices. Un smplice $\tau$ que contenga a $x$ se corta con $\sigma$, nos da
$\sigma \cap \tau < \sigma$. Tenemos dos casos:

  - $\sigma \cap \tau = \sigma$, entonces $v \in \tau$.
  - $\sigma \cap \tau < \sigma$, que dara que $x$ est en una cara de $\sigma$ y no pueda estar
    en $o(\sigma)$.

As, no hay ningn vrtice que no contenga a $v$ tocando a $x$. Todos estn
a distancia mayor que $0$, y puedo tomar el mnimo de las distancias (que
son un conjunto finito) y tener una bola cerrada que slo corta smplices
de la estrella. La bola abierta slo cortar a los smplices abiertos.

[[./images/starcomplex.png]]

Imagen de [[http://math.stackexchange.com/questions/633307/definition-of-star-in-a-simplicial-complex][Math.SE: Definition of star in a simplicial complex]].

***** Ejercicio 7
#+begin_statement
Describe una triangulacin del toro, el plano proyectivo y la botella
de Klein.
#+end_statement

Ntese que la triangulacin debe cumplir los requisitos de los complejos
simpliciales, especialmente, que cada interseccin debe ser vaca o cara
de ambos factores.

***** Ejercicio 8
#+begin_statement
Describe una triangulacin del espacio topolgico cociente que se
obtiene cuando en un toro identificamos un meridiano a un punto.
#+end_statement

Ntese primero que esto no es una superficie compacta porque el punto
en el que hemos identificado el meridiano no es localmente eucldeo.

***** Ejercicio 9
#+begin_statement
Demuestra que la suma conexa de uno o ms planos proyectivos contiene un
subespacio que es homeomorfo a una banda de Mbius.
#+end_statement

Podemos obtener en la presentacin poligonal, uniendo con una banda
dos aristas identificadas, una banda de Mbius.

***** Ejercicio 10
#+begin_statement
Para cada una de las siguientes presentaciones de superficies calcula
la caracterstica de Euler y determina a cul de las superficies modelo
es homeomorfa:

  1. $\langle a,b,c \mid abacb^{-1}c^{-1} \rangle$.
  2. $\langle a,b,c \mid abca^{-1}b^{-1}c^{-1} \rangle$.
  3. $\langle a,b,c,d,e,f \mid abc,bde,c^{-1}df,e^{-1}fa \rangle$.
#+end_statement

****** Superficie 1
Calculamos Euler:

\[\chi(S) = 1 - 3 + 1\]

Y vemos que no es orientable. Es $\mathbb{RP}^{2\#3}$.

****** Superficie 2
Es un toro.

****** Superficie 3
Calculamos Euler:

\[\chi(S) = 4 - 5 + 3 = 2\]

Y a la vez que sacamos los vrtices comprobamos que es orientable.

***** Ejercicio 12
#+begin_statement
Prueba que la caracterstica de Euler de la suma conexa de dos
superficies compactas es igual a la suma de sus caractersticas de
Euler menos dos.
#+end_statement

Si unimos las dos mediante cualquier triangulacin razonable:

****** Triangulacin 1
Se pierden 2 caras para cortar, se pegan con 3 caras, y 3 aristas.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion1.png]]
#+end_center

****** Triangulacin 2
Perdemos dos caras e identificamos 3 aristas y 3 vrtices.

#+begin_center
#+attr_latex: :width 50px
[[./images//sumatriangulacion2.png]]
#+end_center
**** Clasificacin de superficies compactas
***** Calcular la orientabilidad
Un algoritmo que usa la caracterizacin de bicolorabilidad para
determinar si una superficie es orientable o no:

#+BEGIN_SRC haskell
  import Text.ParserCombinators.Parsec
  type Letra = (Char,Bool)
  type Palabra = [Letra]
  type Color = Bool
  type Presentacion = [Palabra]
  type Coloracion = [(Palabra,Color)]

  orientable :: Presentacion -> Bool
  orientable presentacion = any esBuenaColoracion (posiblesColoraciones presentacion)

  posiblesColoraciones :: Presentacion -> [Coloracion]
  posiblesColoraciones [] = [[]]
  posiblesColoraciones (w:presentacion) =
    map ([(w,False)] ++) (posiblesColoraciones presentacion) ++
    map ([(w,True)] ++) (posiblesColoraciones presentacion)
  
  esBuenaColoracion :: Coloracion -> Bool
  esBuenaColoracion c = compruebaColores $ concat $ map (\(w,l) -> map (\x -> (x,l)) w) c

  compruebaColores :: [(Letra,Color)] -> Bool
  compruebaColores [] = True
  compruebaColores (vt : xs) = (all (\ut -> buenaArista ut vt) xs) && compruebaColores xs

  buenaArista :: (Letra,Color) -> (Letra,Color) -> Bool
  buenaArista ((x,u),v) ((y,w),z) = (x /= y) || (u == w && v /= z) || (u /= w && v == z)

  main :: IO ()
  main = return ()


  esOrientable :: String -> Bool
  esOrientable s = either undefined orientable (parse pres "" s) 

  pres :: Parser Presentacion
  pres = word `sepBy` (char ',')

  word :: Parser Palabra
  word = many letra

  letra :: Parser Letra
  letra = try letrainvertida <|> do
    l <- letter
    return (l,True)
  
  letrainvertida :: Parser Letra
  letrainvertida = do
    l <- letter
    _ <- char '*'
    return (l,False)
#+END_SRC
** lgebra moderna
*** 1. Construccin de anillos
**** 1.1. Anillos
***** Anillos
Un *anillo* es $(R,+,\times,1)$ siendo:

 1) $(R,+)$ un grupo aditivo abeliano.
 2) $(R,\times,1)$ monoide multiplicativo.
 3) $\times$ distributivo con $+$.

Llamamos $0$ al elemento neutro de la suma.

****** Anillos conmutativos
Llamamos *anillo conmutativo* a un anillo con $\times$ conmutativo.

****** Propiedades en anillos
Sea $r_1,r_2 \in R$ anillo:

 - $0r=0=r0$
 - $r_1(-r_2) = -r_1r_2 = (-r_1)r_2$
 - $r(r_1-r_2) = rr_1-rr_2$
 - $r_1+r_2=r_2+r_1$

******* Demostracin
Usando distributividad se prueban trivialmente.

***** Morfismos de anillos
Un $f : R \to S$ es homomorfismo de anillos cuando:

  - $f(r_1+r_2) = f(r_1)+f(r_2)$
  - $f(r_1r_2) = f(r_1)f(r_2)$
  - $f(1) = 1$

****** Categora de los anillos
La composicin de dos morfismos de anillos es morfismo de anillos y
la identidad es morfismo de anillos. Los anillos unitales forman as
una categora $\mathtt{Ring}$.

****** Isomorfismos de anillos
***** Subanillos
***** Retculo de subanillos
***** Ideales
***** Ideales extendidos y contraidos
***** Retculo de ideales
***** Ejemplo: Matrices infinitas
***** Ejemplo: lgebra de Weyl
Se llama *lgebra de Weyl* al anillo de operadores en los polinomios
generado por $X$ (multiplicacin por la indeterminada) y $\frac{\partial}{\partial x}$ (diferenciacin);
con la composicin como producto.

****** Caracterizacin
El lgebra de Weyl es isomorfa a:

\[
\frac{K[X,Y]}{(YX-XY-1)}
\]

***** Ejemplo: Anillo de un monoide
Dado un monoide multiplicativo $M$, definimos $R[M]$ como los polinomios que
usan como exponentes los elementos de $M$. Es decir,

\[
\sum_i r_i[m_i]
\]

Y forma un lgebra definiendo:

  - Suma: $\sum_i r_i[m_i] + \sum_i r_i'[m_i] = \sum_i (r_i+r_i')[m_i]$
  - Producto: $\left(\sum_i r_i[m_i]\right)\left(\sum_i r_i'[m_i]\right) = \sum_k \left(\sum_{m_im_j=m_k} (r_ir_j')[m_k]\right)$

****** Generaliza al anillo de polinomios
Ntese que generaliza al anillo de polinomios en una variable cuando 
el monoide es $\mathbb{N}$, y que generaliza al anillo de polinomios en varias 
variables cuando el monoide es $\mathbb{N}^n$.

***** TODO Monoide libre
**** 1.2. Construccin de anillos
***** Anillo cociente
****** Proyeccin
***** Propiedad universal del anillo cociente
***** Primer teorema de isomorfa
***** Segundo teorema de isomorfa
***** Tercer teorema de isomorfa
***** Producto directo
***** Caracterizacin del producto por ortogonales centrales idempotentes
***** Anillo opuesto
***** Centro
***** Propiedad universal del anillo de un monoide
***** Anillo de polinomios
***** Propiedad universal del anillo de polinomios
**** 1.3. Mdulos
***** R-mdulos
****** Caracterizacin por anillo opuesto
***** Morfismo de R-mdulos
***** Submdulos
****** Ideales como submdulos 
***** Mdulo cociente
***** Propiedad universal del mdulo cociente
***** Retculo de submdulos
****** Interseccin de submdulos
****** Suma de submdulos
***** Submdulos maximales
**** TODO 1.4. Categoras y funtores
**** 1.5. La categora Mod-R
***** Caracterizacin de monomorfismos y epimorfismos
***** Primer teorema de isomorfa
***** Segundo teorema de isomorfa
***** Tercer teorema de isomorfa
***** Producto directo
***** Suma directa
***** Lmites
***** Colmites
***** Ejemplos de lmite
***** Cambios de anillo
https://en.wikipedia.org/wiki/Change_of_rings
*** 2. Construccin de mdulos
**** 2.1. Producto tensor
***** Aplicaciones bilineales
Sean $M$ un R-mdulo derecho y $N$ un R-mdulo izquierdo. Un homomorfismo de
grupos es R-bilineal si:

  - $\varphi(m_1+m_2,n) = \varphi(m_1,n) + \varphi(m_2,n)$
  - $\varphi(m,n_1+n_2) = \varphi(m,n_1) + \varphi(m,n_2)$
  - $\varphi(mr,n) = \varphi(m,rn)$

***** Producto tensor
Construimos el grupo producto tensor como el grupo libre generado por
los elementos del producto cartesiano, dividido por el grupo generado 
por las relaciones de bilinealidad:

\[
M \otimes_R N = \frac{\langle
(m,n) \mid m \in M, n \in N
\rangle}{B}
\]

Donde $B$ est generado por:

  - $(m_1+m_2,n) - (m_1,n) - (m_2,n)$
  - $(m,n_1+n_2) - (m,n_1) - (m,n_2)$
  - $(mr,n)-(m,rn)$

Ntese que adems tenemos la proyeccin $b : M \times N \to M \otimes N$.

***** Propiedad universal del producto tensor
Sean $M_R, _RN$ mdulos con $f : M \times N \to X$ bilineal, existe un
nico homomorfismo de grupos $\overline{f} : M \oplus_R N \to X$ tal que conmuta:

\[\begin{tikzcd}
M \times N \rar{b}\drar[swap]{f} & 
M \otimes_R N \dar[dashed]{\exists! \overline{f}} \\
& X
\end{tikzcd}\]

****** TODO Demostracin

***** Neutro del producto tensor
Se cumple $M \otimes R \cong M$ y $R \otimes N \cong N$.

***** TODO Producto tensor en anillos conmutativos
***** Producto tensor de lgebras
Si $R,S$ son dos A-lgebras, su producto tensor lo es con el producto
dado por:

\[
(r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2)\otimes(s_1s_2)
\]

****** TODO Inclusiones en el producto tensor de lgebras

***** TODO Producto tensor de lgebras como coproducto
**** 2.2. Mdulos a dos lados
***** Mdulos a dos lados
Un $M$ R-mdulo izquierda y S-mdulo derecha se llama *(R;S)-mdulo a dos lados*
si cumple:

\[
r(ms)=(rm)s
\]

***** TODO Caracterizacin de mdulos a dos lados
***** TODO Mdulos a dos lados balanceados y fieles
***** TODO Propiedad universal del producto tensor como mdulo a dos lados
**** 2.3. El retculo de submdulos
***** Categora de los conjuntos parcialmente ordenados
Tomamos la *categora de los conjuntos parcialmente ordenados* ${\cal P}$, siendo 
sus morfismos las aplicaciones crecientes:

\[
x \leq y \implies f(x) \leq f(y)
\]

****** Submdulos como conjuntos parcialmente ordenados
Existe el funtor covariante retculo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada mdulo 
en su retculo de submdulos y cada homomorfismo de mdulos lo aplica sobre
cada submdulo del retculo:

\[
{\cal L}(f)(N) = f(N)
\]

Y existe el funtor contravariante retculo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada
mdulo en su retculo y cada homomorfismo de mdulos lo aplica de manera
inversa sobre cada submdulo del retculo:

\[
{\cal L}(f)(N) = f^{-1}(N)
\]

***** Retculos
Un *retculo* es un conjunto parcialmente ordenado donde todo par de
elementos tiene supremo e nfimo, llamados $a \vee b$ y $a \wedge b$.

***** Propiedades del retculo
En todo retculo $({\cal L}, \leq)$ se verifican:

 1) Idempotencia, $a \vee a = a$
 2) Conmutatividad, $a \vee b = b \vee a$
 3) Asociatividad, $a \vee (b \vee c) = (a \vee b) \vee c$
 4) Absorcin, $a \vee (a \wedge c) = a$

Y sus duales:

 1) Idempotencia, $a \wedge a = a$
 2) Conmutatividad, $a \wedge b = b \wedge a$
 3) Asociatividad, $a \wedge (b \wedge c) = (a \wedge b) \wedge c$
 4) Absorcin, $a \wedge (a \vee c) = a$

***** Retculo abstracto
Llamamos *retculo abstracto* a un conjunto $L$ con operaciones $\vee,\wedge$ que
cumplen las propiedades de retculo.

****** Orden en un retculo abstracto
Un retculo abstracto determina una relacin de orden, y adems
se cumple en l:

\[
a \vee b = b \iff a \wedge b = a
\]

******* TODO Demostracin
******** Relacin de orden
******** Propiedad
****** Homomorfismo de retculos abstractos
Un homomorfismo de retculos abstractos es una aplicacin preservando
supremos e nfimos.

\[
f(a\wedge b) = f(a) \wedge f(b) \qquad f(a\vee b) = f(a) \vee f(b)
\]

****** Categora de retculos abstractos
La categora de retculos abstractos contiene a los retculos y los
homomorfismos de retculos entre ellos. Es una categora isomorfa
a la categora de conjuntos parcialmente ordenados.

***** Retculo de submdulos de un mdulo
Los submdulos forman un retculo con:

  - $N \vee N' = N + N'$
  - $N \wedge N' = N \cap N'$

***** Retculos acotados
Un retculo con cero y uno se llama acotado, donde:

  - El elemento cero cumple: $a \wedge 0 = 0$
  - El elemento uno cumple:  $a \vee 1 = 1$

***** Retculos modulares
Llamamos retculo modular al que cumple la *ley modular*:

\[
N_1 \vee (N_2 \wedge N_3) = (N_1 \vee N_2) \wedge N_3
\]

****** El retculo de submdulos es modular
Los submdulos forman retculos modulares.

******* TODO Demostracin

***** Retculos completos
Un retculo en el que existe el supremo e nfimo de cualquier familia de
submdulos se dice *completo*.

****** El retculo de submdulos es completo
El retculo de submdulos es completo, siendo el supremo e nfimo de
cada familia $\{ N_i \mid i \in I\}$:

  - $\bigvee N_i = \sum N_i$

  - $\bigwedge N_i = \bigcap N_i$

***** TODO Retculos superiormente continuos y compactamente generados
**** 2.5. Mdulos finitamente generados
***** TODO Mdulos finitamente generados
***** TODO Construccin de finitamente generados
***** TODO Submdulo maximal
***** TODO Caracterizacin de finitamente generados
***** TODO Homomorfismos a la suma directa
***** TODO Conmutacin con sumas directas
***** TODO Compacidad
***** TODO Mdulos noetherianos
***** TODO Mdulos noetherianos: propiedades
**** TODO 2.6. Mdulos noetherianos
*** 3. Sumas directas y productos directos de mdulos
**** 3.1. Biproducto de mdulos
***** Biproducto de mdulos
Se llama *biproducto de mdulos* a la terna $(M_1\oplus M_2, \{p_1,p_2\}, \{q_1,q_2\})$,
con las proyecciones e inclusiones de producto y coproducto.

****** Propiedades del biproducto
Las composiciones de proyecciones e inyecciones cumplen:

 - $p_1q_1 = id_1$
 - $p_2q_2 = id_2$
 - $p_1q_2 = 0$
 - $p_2q_1 = 0$
 - $q_1p_1 + q_2p_2 = id$

**** TODO 3.2. Independencia y sumas directas
**** TODO 3.3. Mdulos libres
**** TODO 3.4. Descomposicin de anillos
*** Ejercicios
**** Semana 1
#+begin_statement
Prueba que los ideales (bilteros) del anillo $M_n(R)$ son de la forma
$M_R(\mathfrak{a})$, para un ideal (biltero) $\mathfrak{a} \subseteq R$.
#+end_statement

Llamamos $E_{ij}$ a la matriz que tiene todas sus entradas nulas excepto
la entrada $i,j$. Dada $N$, una matriz con elementos $N = (n_{ij})_{i,j}$, el
producto de matrices es:

\[
E_{ia}NE_{bj} = n_{ab}E_{ij}
\]

Es decir, si una matriz $N$ est en un ideal biltero $J$, todas las 
matrices de la forma $n_{ab}E_{ij}$ estarn tambin en el ideal.

Esto nos da por un lado que los elementos que aparecen en matrices 
del ideal forman un ideal $I$, si $a,b$ estn en el ideal, $(a+\alpha b)E_{ij}$ 
estar en el ideal. Y adems, cualquier matriz de la forma $xE_{ij}$ para
$x \in I$ est en el ideal. As, el ideal es de la forma:

\[
J = M_R(\mathfrak{a})
\]

**** Semana 2
#+begin_statement
Prueba que $A[|X|]$, el anillo de las series formales de potencias en una
indeterminada $X$, es isomorfo al lmite inverso del sistema de anillos
dirigido inferiormente $(\{\frac{A[X]}{(X^n)}\}, \{f_{n,m}\}_{n \geq m})$, donde $f_{n,m} : \frac{A[X]}{(X^n)} \to \frac{A[X]}{(X^m)}$ es
el homomorfismo de anillos definido por $f_{n,m}(\overline{X}) = \overline{X}$, si $n \geq m$.
#+end_statement

***** Subanillo isomorfo
Empezamos definiendo un subanillo del producto de los anillos $\frac{A[X]}{(X^n)}$.
Ntese que es subanillo por ser las funciones $f_{i,j}$ morfismos de anillos:

\[
H = \left\{
(p_i)_i \in \prod_i \frac{A[X]}{(X^i)}
\;\middle|\;
f_{i,j}(m_i) = m_j
\right\}
\]

Comprobaremos que es isomorfo a $A[|X|]$; para ello definimos la funcin
siguiente:

\[
g(a_0+a_1X+a_2X^2+\dots) = (a_0,a_0+a_1X,a_0+a_1X+a_2X^2,\dots)
\]

Es trivialmente inyectiva porque si $p \neq q$, se diferenciarn en el primer
polinomio en el que tengan un coeficiente distinto. Es trivialmente
sobreyectiva porque si tengo un elemento de la forma $(u_0,u_1,\dots) \in H$,
se debe tener $u_n = u_{n-1} + a_n X_n$, para $u_{n-1}$ de grado $n-1$. Esto asegura
que el elemento ser de la forma:

\[
(a_0,a_0+a_1X, a_0+a_1X+a_2X^2,\dots) = g(a_0+a_1X+a_2X^2+\dots)
\]

***** Lmite inverso
Para probar que es lmite inverso, probaremos que si existiera un $Z$ con
morfismos $\phi_n : Z \to \frac{A[X]}{(X^n)}$ cumpliendo $\phi_m = f_{n,m} \circ \phi_n$, existira un nico 
morfismo $Z \to H$ haciendo conmutar el diagrama:

\[\begin{tikzcd}
\frac{A[X]}{(X^0)} \rar &
\frac{A[X]}{(X^1)} \arrow{rr} &&
\frac{A[X]}{(X^2)} \rar &
\dots \\
&&
H \arrow{ull} \ular \urar \arrow{urr}
& & \\
& &
Z
\arrow[bend left]{uull} \arrow[bend left]{uul}
\arrow[bend right]{uurr} \arrow[bend right]{uur}
\uar[dashed]{!\exists}
&&
\end{tikzcd}\]

Ahora bien, dado $Z$ y los morfismos $\phi_n$, por propiedad universal del
producto directo, tenemos que existe un nico morfismo $h: Z \to \prod_i \frac{A[X]}{(X^i)}$,
cumpliendo adems que $\phi_n = \pi_n \circ h$. Aplicando $f_{n,m}$ tenemos:

\[
f_{n,m} \circ \pi_n \circ h = f_{n,m} \circ \phi_n =
\phi_m = \pi_m\circ h
\]

Lo que nos da que $im(h) \subseteq H$ y por tanto el morfismo buscado, que hereda
la unicidad.

**** Semana 3
***** Ejercicio 1.5.
#+begin_statement
Sea $R$ un anillo y $0 \neq e \in R$ un elemento idempotente; llamamos $f = 1-e$.

 1. Prueba que $eRe$ y $fRf$ son anillos.
 2. Prueba que $eRf$ es un $(eRe;fRf)$ mdulo, y $fRe$ es un $(fRf,eRe)$ mdulo.
 3. Prueba que existe un homomorfismo inyectivo de anillos

    $\lambda : R \longrightarrow 
    \begin{pmatrix}
    eRe & eRf \\
    fRe & fRf 
    \end{pmatrix}$, definido: $\lambda(r) = \begin{pmatrix} ere&erf\\fre&frf \end{pmatrix}$ para cada $r \in R$.

 4. Prueba que existe un isomorfismo de grupos abelianos
    $Hom_R(eR_R,fR_R) \cong fRe$, y un isomorfismo de anillos $End_R(eR_R) \cong eRe$.
 5. Prueba que:

    \[
    R \overset{\beta}\cong End_R(R_R) = 
    End_R((eR\oplus fR)_R) \cong \begin{pmatrix} eRe&eRf\\fRe&fRf \end{pmatrix}
    \]

    siendo $\beta(r)(x) = rx$. Como consecuencia $\lambda$ es un isomorfismo de anillos.

$\quad$
#+end_statement

****** Punto 1
Por propiedad distributiva, son cerrados con la misma suma que $R$. Son
trivialmente cerrados con el producto y nos falta comprobar que contiene
un elemento unidad, que es $e$ y es neutro gracias a ser idempotente:

\[
e(ere) = ere = (ere)e
\]

Ntese que $f$ es tambin idempotente y se repite el razonamiento.

****** Punto 2
Comprobamos que $eRf$ es cerrado para la suma, y adems:

 - $(ese)(erf) = e(ser)f$
 - $(erf)(ftf) = e(rft)f$

Por lo que es un mdulo a izquierda para $eRe$ y a derecha para $fRf$.

Ntese que el caso de $fRe$ es simtrico.

****** Punto 3
Ntese que $\lambda$ preserva sumas trivialmente. Debemos comprobar que respeta
la unidad y el producto. Notamos primero gracias a que $ef=0$ tenemos:

\[
\lambda(1) = \begin{pmatrix}e&0\\0&f\end{pmatrix}
\]

Que se comprueba trivialmente que es el uno de su anillo, ya que es neutro
respecto al producto:

\[\begin{pmatrix}e&0\\0&f\end{pmatrix}\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix} =\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix}\]

Por ltimo comprobamos que el producto se preserva:

\[\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}\begin{pmatrix} ese & esf \\ fse & fsf \end{pmatrix}
= \begin{pmatrix}erse&ersf\\frse&frsf\end{pmatrix}\]

Donde usamos crucialmente que $erese+erfse=er(e+f)se=erse$.

****** Punto 4
******* Isomorfismo de grupos abelianos
Suponiendo que se consideran los homomorfismos como mdulos a derecha
de $R$, podemos llevar cada homormofismo $\lambda$ a $\lambda(e)e$ y cada elemento $fre$
al homomorfismo $\psi(x) = (fre)x$.

Comprobamos que esto da una biyeccin para elemento cualquiera $fre \in fRe$
y $\lambda \in Hom(eR,fR)$ comprobando que la composicin es la identidad:

\[
fre \mapsto \psi_{fre} \mapsto \psi_{fre}(e)e = freee = fre
\]
\[
\lambda(ex) \mapsto \lambda(e)e \mapsto \lambda(e)e(ex) = \lambda(ex)
\]

Donde hemos usado en el ltimo paso que $\lambda$ es homomorfismo de R-mdulos
a derecha. Que esto preserva la suma es trivial.

******* Isomorfismo de anillos
En este caso tenemos un isomorfismo de grupos abelianos dado por el
caso anterior. Adems, es operacin multiplicativa al tenerse:

\[
(\psi\circ\varphi)(e)e = \psi(e)\varphi(e)e
\]

Por ser homomorfismos de mdulos a derecha. Y es unital por tenerse:

\[
id(e)e = e
\]

****** Punto 5
******* Primer isomorfismo
Trivialmente $\beta$ es inyectivo porque $\beta(r)$ aplica la unidad en $r$.
Que es sobreyectivo es trivial porque cada funcin est determinada
por dnde lleva la unidad. Por ser homomorfismo de R-mdulos:

\[
\varphi(r) = \varphi(1)r
\]

******* Segundo isomorfismo
Ntese que dada una $\varphi \in End_R(eR\oplus fR)$, podemos descomponer su aplicacin
a cualquier elemento como:

\[
\varphi(er+fr) = \varphi(er)+\varphi(fr) = e\varphi(er)+f\varphi(er)+
e\varphi(fr)+f\varphi(fr)
\]

Por lo que queda determinada por dos endomorfismos entre $eR$ y $fR$ y
dos homomorfismos de $eR$ a $fR$ y de $fR$ a $eR$; y se puede escribir como:

\[
\varphi(ex+fy) = \begin{pmatrix}f_1&f_2\\f_3&f_4\end{pmatrix}\begin{pmatrix}ex\\fy\end{pmatrix}
\]

Con los isomorfismos anteriores tenemos lo buscado.

******* Isomorfismo de anillos
Notamos trivialmente que el isomorfismo as determinado es $\lambda$.
Dado $r$, podemos ver que se divide como:

\[
rx = erex + erfx + frex + frfx
\]

Donde cada elemento pertenece al buscado.

***** Ejercicio 1.6.
#+begin_statement
Sea $R$ un anillo, $0\neq e \in R$ un elemento idempotente, y $f = 1 - e$. Para cada
R-mdulo derecha $M$ se define $Me = \{me \mid m \in M\}$, y $Mf = \{mf \mid m \in M\}$.

 1. Prueba que $Me$ es un $eRe$ mdulo derecha y $Mf$ un $fRf$ mdulo derecha.
 2. Prueba que $Me \times Mf$ es un $\begin{pmatrix}eRe&eRf\\fRe&fRf\end{pmatrix}$ mdulo derecha con estructura
    dada por,

    \[
    (m_1e, m_2f)
    \begin{pmatrix}em_{11}e&em_{12}f\\fm_{21}e&fm_{22}ff\end{pmatrix} =
    (m_1em_{11}e + m_2fm_{21}e, m_1em_{12}f + m_2fm_{22}f)
    \]

 3. Prueba que $h : M \longrightarrow Me \times Mf$, definido $h(m) = (me,mf)$, es un isomorfismo
    de R-mdulos derecha, donde la estructura de $Me \times Mf$ est dada va $\lambda$.
    Observa que $Me$ y $Mf$ son subgrupos de $M$, pero no necesariamente submdulos.

$\quad$
#+end_statement

****** Punto 1
Siendo $me \in Me$, tenemos que $me(ere) = (mer)e \in Me$, donde usamos que
$M$ es mdulo a derecha. De la misma forma se cumple para $f$, que es
idempotente.

****** Punto 2
Simplemente tenemos que comprobar que la aplicacin de multiplicar por
la matriz es lineal en $(m_1,m_2)$, y adems, que los elementos vuelven
a estar en $Me \times Mf$ por escribirse como:

 - $(m_1em_{11})e + (m_2fm_{21})e$
 - $(m_1em_{12})f + (m_2fm_{22})f$

Usando de nuevo que $M$ es mdulo a derecha.

****** Punto 3
Tenemos que cada elemento se escribe de forma nica como $m = me+mf$.
Si tuviramos otra suma $m = ae + bf$, se tendra $me=ae$ y $mf=bf$ al
multiplicar por cada uno de los idempotentes.

Tenemos por tanto una biyeccin, que adems es lineal y preserva la
multiplicacin por la derecha:

\[
(mre,mrf) = (me,mf)\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}
\]

Observamos que $Me$ y $Mf$ son cerrados para la suma. Pero no tienen por
qu ser cerrados como mdulo. Ntese que puede darse el caso de que
$mer \notin Me$, como ocurre en las matrices, donde hay idempotentes no
centrales:

\[ e\begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
a & b \\ 0 & 0
\end{pmatrix}\]

Que no puede pertenecer al $Me$ porque cambia al multiplicarla a la derecha
por $e$.
**** Semana 4
***** Ejercicio 1.7.
#+begin_statement
Si $K$ es un cuerpo, se considera el anillo:

\[
R = \begin{pmatrix}
K & K \\ 0 & K
\end{pmatrix}
\]

 1) Estudia los ideales derecha de $R$.
 2) Estudia los ideales izquierda de $R$.
 3) Estudia los ideales bilteros de $R$.

Ver tambin ejercicios anteriores.
#+end_statement

****** Ideales derecha
La multiplicacin por un elemento del ideal sera:

\[\begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix}\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix}  = \begin{pmatrix}
k_1a & k_2a+k_3b \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinacin de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0$, $\langle\begin{pmatrix}0 & k \\ 0 & 1\end{pmatrix}\rangle$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$, $\begin{pmatrix}0 & 0 \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

****** Ideales izquierda
La multiplicacin por un elemento del ideal es:

\[\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix} \begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix} = \begin{pmatrix}
k_1a & k_1b+k_2d \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinacin de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0$, $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$ $\begin{pmatrix}K & 0 \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

****** Ideales bilteros
Buscamos los ideales que lo son a izquierda y derecha:

$\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$

***** Ejercicio 1.8.
#+begin_statement
Estudia los ideales derecha e izquierda del anillo:

\[
R = \begin{pmatrix}\mathbb{Q}&\mathbb{R}\\0&\mathbb{R}\end{pmatrix}
\]

 1) Prueba que $R$ es un anillo artiniano derecha y noetheriano derecha.
 2) Prueba que $R$ no es un anillo artiniano izqierda ni noetheriano izquierda.

$\quad$
#+end_statement

****** Ideales derecha
Los ideales no triviales a la derecha son los siguientes:

- $\begin{pmatrix} 0 & 0 \\ 0 & \mathbb{R} \end{pmatrix}$

- $\langle\begin{pmatrix} 0 & k \\ 0 & 1 \end{pmatrix}\rangle$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & 0 \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Habiendo slo una cantidad finita de ideales, el anillo ser artiniano
y noetheriano.

****** Ideales izquierda
Considerando de nuevo los casos y teniendo esta vez en cuenta que el
primer coeficiente est en $\mathbb{Q}$.

- $\begin{pmatrix} \mathbb{Q} & \mathbb{K} \\ 0 & 0 \end{pmatrix}$, para cualquier $\mathbb{K}$ extensin de cuerpos $\mathbb{Q}\subset \mathbb{K}\subset\mathbb{R}$.

- $\begin{pmatrix} 0 & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Comprobamos que no es artiniano ni noetheriano porque podemos crear
cadenas que rompen la condicin de cadena ascendente y descendente.
Sabiendo que los reales tienen dimensin infinita sobre los racionales
como espacio vectorial, creamos ambas cadenas aadiendo y retirando
progresivamente vectores de la base.

**** Semana 6
#+begin_statement
Sea $M$ un grupo abeliano finitamente generado y libre de torsin.
Prueba que $M$ es un grupo libre.
#+end_statement

Si no fuera libre, cada conjunto de generadores
$\left\{ m_1,\dots,m_{n} \right\}$ debera cumplir ecuaciones de la forma

\[n_1m_1+ \dots + n_tm_t = 0,\]

y entre todos los posibles conjuntos de generadores de cardinalidad
mnima y combinaciones, podemos elegir una que minimice $|n_1|+\dots + |n_t|$.
Ahora, si hay una combinacin en la que $|n_i|<|n_j|$ para dos $i\neq j$,
podemos usar que

\[
n_im_i + n_jm_j = (n_i-n_j)m_i + n_{j}(m_j-m_i)
\]

para reescribir la relacin, teniendo otro sistema de generadores
equivalente $\left\langle m_1,\dots,m_i,m_j,\dots,m_{t} \right\rangle = \left\langle m_1,\dots,m_i,m_j-m_i,\dots,m_t \right\rangle$ que
tiene un $|n_1|+\dots + |n_t|$ menor. As, en el mnimo, $|n_i| = d$ para cualquier
ndice. Pero este $d$ no puede ser mayor que $1$ porque si no se tendra un
elemento de torsin

\[
d \left( \frac{n_1}{d}m_1 + \dots + \frac{n_t}{d}m_t \right) = 0.
\]

As, hemos llegado a una relacin en la que un generador puede ponerse
como suma y diferencia de los otros, 

\[
m_1 = \pm m_2 \pm m_3 \pm \dots \pm m_{t},
\]

contraviniendo la minimalidad del
sistema de generadores

**** Semana 7
#+begin_statement
Sea $R$ un anillo con un nico ideal izquierda maximal $\mathfrak{a}$.

 1) Prueba que $\mathfrak{a}$ es un ideal biltero.
 2) Prueba que $\mathfrak{a}$ es el nico ideal derecha maximal.
 3) Prueba que $R/\mathfrak{a} = {\cal U}(R) = R^{\times}$, el conjunto de los elementos 
    invertibles de $R$.

Un anillo con un nico ideal derecha maximal se llama *anillo local*.
#+end_statement

Ntese que por Teorema de Krull, todo ideal propio (izquierda,
derecha, biltero) est contenido en un ideal maximal (izquierda,
derecha, biltero). Todo elemento no unidad est contenido en un
ideal maximal (izquierda, derecha, biltero).

***** Primer punto
Si $x \in \mathfrak{a}$, sabemos que no puede ser unidad; as, $xy$ tampoco puede serlo 
para ningn $y \in R$, y como no puede serlo, debe estar contenido en algn
ideal maximal izquierda, que debe ser $\mathfrak{a}$.

***** Segundo punto
Usando el tercer punto, cualquier elemento que estuviera en un ideal
derecha maximal que no estuviera en el nico ideal biltero que existe
debera ser una unidad.

***** Tercer punto
Si hubiera algn $x + \mathfrak{a}$ no invertible, se tendra que $\left\langle x \right\rangle$ generara un
ideal propio que debera estar contenido en un maximal. Este maximal
debera ser $\mathfrak{a}$, y por tanto $x = 0$.

**** Semana 8
#+begin_statement
Sea $R$ un anillo y $e \in R$ un elemento idempotente

 1) para cada ideal derecha $\mathfrak{a} \subseteq R$ prueba que $\mathfrak{a} \cap Re = \mathfrak{a}e$.
 2) para cada ideal $\mathfrak{A} \subseteq R$ prueba que $\mathfrak{A} \cap Re = \mathfrak{A}e$.
 3) $eRe$ es un anillo y $\mathfrak{A} \mapsto e\mathfrak{A}e$ define una aplicacin sobreyectiva que respeta
    el orden del retculo de los ideales de $R$ en el retculo de los ideales de
    $eRe$.
 4) prueba que tenemos un funtor $\text{Mod-}R \to \text{Mod-}eRe$, definido $M \mapsto Me$.
 5) si $M$ es un $R\text{-mdulo}$ derecha simple, prueba que $Me = 0$  $Me$ es un
    $eRe\text{-mdulo}$ derecha simple.
 6) se conservan los $R\text{-mdulos}$ derecha proyectivos?
 7) se conservan los $R\text{-mdulos}$ izquierda inyectivos?
#+end_statement

***** Punto 1
Sea $x \in \mathfrak{a} \cap Re$, entonces $x = xe \in \mathfrak{a}e$. Sea $ae \in \mathfrak{a}e$, es trivial que $ae \in \mathfrak{a} \cap Re$.

***** Punto 2
Un ideal es un ideal derecha.

***** Punto 3
Se comprueba que $eRe$ es anillo con unidad $e$. El producto de dos elementos
sigue siendo bilineal con $ere \cdot ese = erese$. Si $S \subseteq R$, es claro que $eSe \subseteq eRe$.
Es sobreyectiva porque si $I$ es $eRe\text{-ideal}$, podemos comprobar que $RIR$ es un
$R\text{-ideal}$ y que $eRIRe = eReIeRe = I$.

***** Punto 4
El funtor llevar $f \colon M \to N$ a $\widetilde f \colon Me \to Ne$ definida como

\[\widetilde f(me) = f(m)e.\]

Es funtor por cumplir $\widetilde g \circ \widetilde f (me) = (g \circ f(m))e$.

***** Punto 5
$Me$ sera un submdulo, as que podra ser $Me = 0$ o $Me = M$.
En el segundo caso sera un $eRe\text{-mdulo}$ por ser un $R\text{-mdulo}$,
y en ese caso, como $M = Me$, se tendra que si hubiera un
submdulo $A$ de $M$ como $eRe\text{-mdulo}$, sera de $M$ como $R\text{-mdulo}$
por tenerse $AR = ((Ae)R)e = A(eRe) = A$.

***** Punto 6
Si tenemos $P \oplus H \cong R^{(I)}$, multiplicando, $Pe \oplus He \cong (Re)^{(I)}$. Pero
sabemos que $Re \cong eRe$ como $eRe\text{-mdulo}$.

***** Punto 7
Si $Q$ es un submdulo izquierda inyectivo, para cualquier $R\text{-mdulo}$ $M$
con $Q \leq M$ existe un $Q \leq K$ tal que $K \oplus Q = M$, como producto directo
interno.

Sea ahora un $eRe\text{-mdulo}$ $N$ tal que $Qe \leq N$. Tenemos que $Ne = N$ por
ser $e$ unidad del anillo. Como $Q$ es inyectivo, existe un $K$ tal que
$Q \cap K = \left\{ 0 \right\}$ y $Q + K = Q + N$. Si multiplicamos por $e$ tenemos

\[
Qe + Ke = Qe + N = N.
\]

De aqu se tiene que $Ke \cap N = Ke$. Entonces, $Ke \subset K \cap N$ y dado $l \in K \cap N$,
se tiene que como $l \in N$, $le=l$, luego $l \in Ke$. As, $Ke = K \cap N$, tenemos

\[
Qe + K \cap N = N,
\]

y como $Q \cap K = \left\{ 0 \right\}$, se tiene $Qe \cap K = \left\{ 0 \right\}$ y por tanto $Qe \cap (K\cap N) = \left\{ 0 \right\}$.

**** Semana 9
#+begin_statement
Sea $R$ un anillo y $M$ un $R\text{-mdulo}$ derecha. Se considera el anillo $S=M_n(R)$ y
el grupo abeliano $M^n$.

 1) Prueba que $M^n$ es un $S\text{-mdulo}$ derecha con accin dada por
    $(m_i)_i(a_{ij})_{ij} = \left( \sum_i m_ia_{ij} \right)_j$.
 2) Prueba que $M \mapsto M^n$, extendiendo para homomorfismos en la forma obvia,
    define un functor $F \colon \text{Mod-}R \to \text{Mod-}S$.
 3) Se considera el idempotente $e_{11} \in M_n(R)$, la matriz que tiene $1$ en el
    lugar $(1,1)$, y $0$ en el resto. Observa que $e_{11}Se_{11} \cong R$. Tenemos entonces un
    funtor $G \colon \text{Mod-}S \to \text{Mod-}e_{11}Se_{11} = \text{Mod-}R$.
 4) Prueba que para cada $R\text{-mdulo}$ derecha $M$ se tiene un isomorfismo
    $\theta_M\colon M \cong GF(M)$, y que si $f\colon M_1\to M_2$ es un homomorfismo de $R\text{-mdulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $R\text{-mdulos}$.

    \[\begin{tikzcd}
    M_1 \rar{f} \dar[swap]{\theta_{M_1}} & M_2 \dar{\theta_{M_2}} \\
    GF(M_1) \rar{GF(f)} & GF(M_2) 
     \end{tikzcd}\]

 5) Prueba que para cada $S\text{-mdulo}$ derecha $N$ se tiene un isomorfismo
    $\nu_N\colon N \cong FG(N)$, y que si $g\colon N_1 \to N_2$ es un homomorfismo de $S\text{-mdulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $S\text{-mdulos}$.

    \[\begin{tikzcd}
    N_{1} \rar{g} \dar[swap]{\nu_{N_1}} & N_{2} \dar{\nu_{N_2}} \\
    FG(N_{1}) \rar{FG(g)} & FG(N_{2})
    \end{tikzcd}\]

 6) Prueba que si $M$ es un $R\text{-mdulo}$ derecha simple (resp. proyectivo,
    inyectivo), tambin $F(M)$ lo es.
#+end_statement

***** Punto 1
Comprobaremos que cumple la definicin de mdulo, es decir,

 * hay una *identidad* dada por $(m_i)_i(\delta_{ij})_{ij} = (m_{j})_{j}$.
 * el *producto* es bilineal
   $(m_i+n_i)_i(a_{ij})_{ij} = (\sum_i (m_i+n_i)a_{ij})_j = (\sum m_ia_{ij} + \sum n_ia_{ij})_j$ y
   $(m_i)_i(a_{ij}+b_{ij})_{ij} = (\sum m_i(a_{ij}+b_{ij}))_j = \sum m_ia_{ij} + \sum m_ib_{ij}$.
 * y es *asociativa* con el producto de matrices usual
   $((m_i)_ia_{ij})(b_{ij}) = (\sum_j (\sum_i m_ia_{ij})b_{jk})_{k} = (\sum_i m_i\sum_{j}a_{ij}b_{jk})_k$.

***** Punto 2
Si los extendemos de forma obvia aplicando el homomorfismo a cada una de las
entradas de la matriz, es obvio que se conserva la composicin de funciones
como

\[
g(f((m_{i})_i)) = (gf(m_i))_i,
\]

y que la indentidad se preserva por la extensin.

***** Punto 3
Notamos que podemos llevar cada matriz a su nica entrada $e_{11}(r_{ij})e_{11} \mapsto r_{11}$.
La suma es por componentes y por tanto se respeta por la aplicacin; el
producto de matrices de una entrada coincide con el producto del anillo.

***** Punto 4
Ntese que $F(M) = M^n$ y que $GF(M) = (M\ 0\ 0\ \dots )$, donde adems hay un
isomorfismo $e_{ii}Se_{11} \cong R$. El isomorfismo de mdulos lleva $m$ en $(m\ 0\ 0\ \dots)$,
y se comprueba trivialmente que la multiplicacin funciona de la misma
manera.

Dado un homomorfismo de mdulos, tenemos que $GF(f)$ aplicar el homomorfismo
sobre el nico elemento llevando $GF(f)(m\ 0\ 0\ \dots) = (f(m)\ 0\ 0\ \dots)$.

***** Punto 5
Tenemos por ser idempotente que $G(Ne_{11}) = G(N)$, pero 

\[FG(N) \cong FG(Ne_{11}) \cong Ne_{11} \oplus Ne_{22} \oplus \dots \cong N\]

por ser $Ne_{11}\cong Ne_{22}$ como $R\text{-mdulos}$ y ser $\left\{ e_{1},\dots,e_{n} \right\}$ un conjunto de
idempotentes centrales.

Una funcin $g\colon N_1 \to N_2$ est unvocamente determinada por cmo acta
sobre cada sumando directo, por lo que conmuta su actuacin antes y
despus de aplicarla explcitamente sobre cada sumando directo.

***** Punto 6
Los dos puntos anteriores han definido dos isomorfismos naturales
que constituyen una equivalencia de categoras.

**** Semana 10
#+begin_statement
Se considera la categora de grupos abelianos; en este caso $R = \mathbb{Z}$.

 1) Prueba que $\mathbb{Z}$ es un grupo abeliano uniforme. Determina todos los grupos
    cclicos uniformes.
 2) Prueba que el grupo $\mathbb{Z}_{p^{\infty}}$ es un grupo uniforme y no es un grupo cclico.
    Se consideran $\mathbb{Q}$ y $\mathbb{R}$; es alguno uniforme?
 3) Determina todos los grupos abelianos inyectivos indescomponibles.
 4) Si $M$ es un grupo abeliano finitamente generado sabemos que 
    $M \cong \left( \bigoplus^t_{i=1} \mathbb{Z}_{p^{n_i}} \right) \oplus \mathbb{Z}^n$, para $n,n_1,\dots,n_t \in \mathbb{N}$. Cul es la descomposicin
    de $E(M)$ como suma de inyectivos indescomponibles?
#+end_statement

***** Punto 1
Dados dos submdulos de $\mathbb{Z}$, que estarn generados por dos enteros, podemos
comprobar que se intersecarn en su mnimo comn mltiplo.

***** Punto 2
Para comprobar que el grupo $\mathbb{Z}_{p^{\infty}}$ es uniforme tomamos un mdulo no 
nulo que tenga al menos un elemento $a/p^n$ y otro con $b/p^m$; 
para $a,b$ coprimos con $p$.  Existirn $x,y,p$ tales que
$xp a/p^n = 1/p^{n+p} = y b/p^{m}$, por lo que ser uniforme.

Comprobamos que $\mathbb{R}$ no es uniforme porque tiene, por ejemplo $(\pi) \cap (1) = 0$.
Sin embargo $\mathbb{Q}$ s lo es porque si tenemos dos mdulos y cada uno contiene
al menos un elemento no nulo $a/b$ y $c/d$; tenemos que $cb \cdot a/b = ad \cdot c/d$.

***** Punto 3
Los inyectivos indescomponibles estn en correspondencia con los ideales
primos. Tenemos para $p$ primo que $E(\mathbb{Z}_p) = \mathbb{Z}_{p^{\infty}}$, ya que es extensin esencial
y es inyectivo. Para el ideal primo $\{0\}$ tenemos a su vez que $E(\mathbb{Z}) = \mathbb{Q}$, ya
que es inyectivo y uniforme.

***** Punto 4
Como $\mathbb{Z}$ es noetheriano, tenemos $\bigoplus E(M_i) = E \left( \bigoplus M_i \right)$, as que la suma
debe ser

\[
E(M) = \left( \bigoplus_{i=1}^t \mathbb{Z}_{p^{\infty}} \right) \oplus \mathbb{Q}^n
\]

considerando los sumandos con exponente no nulo.

*** Trabajos
**** Funtores adjuntos
***** Transformaciones naturales
#+begin_definition
Dados dos funtores $S,T : A \to B$, una *transformacin natural* $\tau : S \Longrightarrow T$ 
es una funcin asignando a cada objeto $a \in A$ un morfismo $Sa \to Ta$ y 
cumpliendo el siguiente diagrama conmutativo:

\[\begin{tikzcd}
a \dar{f} & & Sa \rar{\tau_a}\dar{Sf} & Ta \dar{Tf} \\
a' & & Sa' \rar{\tau_{a'}} & Ta'
\end{tikzcd}\]

En este caso, decimos que $\tau_a$ es /natural en/ $a$.
#+end_definition

#+begin_definition
Llamamos *isomorfismo natural* a la transformacin natural en la que
cada componente $\tau_a$ tiene una inversa. Podemos definir una transformacin
natural inversa $\tau^{-1}$ que tiene por componentes a cada una de las inversas.
#+end_definition

****** Composicin vertical de transformaciones naturales
#+begin_definition
Dados funtores $R,S,T : {\cal A} \to {\cal B}$ y transformaciones naturales $\tau : S \Longrightarrow T$
y $\sigma : R \Longrightarrow S$, podemos componerlas componente a componente para formar
una *transformacin naturalcomposicin vertical* $\tau \circ \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90] &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90] \\
Sc \rar{Sf} \dar{\tau_c} & Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf} & Tc' 
\end{tikzcd}
\]

#+end_definition

Ntese que la naturalidad se preserva, ya que si los dos cuadrados
pequeos son conmutativos, conmuta todo el diagrama.

****** Composicin horizontal de transformaciones naturales
#+begin_definition
Dados funtores $S,T : {\cal A} \longrightarrow {\cal B}$ y $S',T' : {\cal B} \longrightarrow {\cal C}$ y dadas transformaciones
naturales $\tau : S \Longrightarrow T$ y $\tau' : S' \Longrightarrow T'$, podemos crear una transformacin
natural entre los funtores compuestos, $\tau' \ast \tau$:

\[\begin{tikzcd}
S'Sx \arrow{rr}{(\tau' \ast \tau)_x} \dar &&
T'Tx \dar \\
S'Sy \arrow{rr}{(\tau' \ast \tau)_y} &&
T'Ty
\end{tikzcd}\]

Cada componente se crea aprovechando la siguiente igualdad:

\[
(\tau' \ast \tau) = T'\tau \circ \tau' = \tau' \circ S'\tau
\]
#+end_definition

Y puede comprobarse que constituye una transformacin natural.

****** Categora de los funtores
#+begin_definition
Dadas ${\cal A},{\cal B}$ categoras, los funtores entre ellas forman una *categora de funtores* 
que llamaremos $Funct({\cal A},{\cal B})$ y que tiene como morfismos a las transformaciones 
naturales con la composicin vertical:

\[
Nat(S,T) = \{ \tau \mid \tau : S \Longrightarrow T \}
\]
#+end_definition

Ntese que la composicin es asociativa y que consta de una identidad
en la transformacin natural de cada funtor consigo mismo que tiene
como componentes identidades en cada objeto.

***** Definicin de funtores adjuntos por naturalidad
#+begin_definition
Una *adjuncin* entre categoras ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con una familia de isomorfismos $\varphi_{a,b} : Hom(Fa,b) \cong Hom(a,Gb)$
que determinan transformaciones naturales en ambas componentes.
#+end_definition

Notamos al par de funtores adjuntos como $F \dashv G$. Llamamos a $F$ adjunto
izquierdo y a $G$ adjunto derecho.

****** Condiciones de naturalidad
Las condiciones de naturalidad de esa familia de isomorfismos equivalen
a que los siguientes diagramas conmuten:

\[\begin{tabular}{cc} \begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{f_\ast} & 
Hom(a,Gb) \dar{(Gf)_\ast} \\
Hom(Fa,b') \rar{\varphi_{a,b'}} &
Hom(a,Gb')
\end{tikzcd} &
\begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{(Fg)^\ast} & 
Hom(a,Gb) \dar{g^\ast} \\
Hom(Fa',b) \rar{\varphi_{a,b'}} &
Hom(a',Gb)
\end{tikzcd} \end{tabular}\]

Ntese que cada uno de ellos expresa la naturalidad entre los dos bifuntores
cuando se fija un argumento. Es decir, hay dos isomorfismos naturales

 1) $Hom(F-,b) \Longrightarrow Hom(-,Gb)$.
 2) $Hom(Fa,-) \Longrightarrow Hom(a,G-)$.

***** Definicin por unidad y counidad
#+begin_definition 
Una *adjuncin* entre categoras ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con dos transformaciones naturales:

  - La *unidad*:   $\eta : 1_{\cal A} \Longrightarrow GF$
  - La *counidad*: $\epsilon: FG \Longrightarrow 1_{\cal B}$

Cumpliendo que las composiciones siguientes dan la identidad:

 - $F \overset{F \eta} \Longrightarrow FGF \overset{\varepsilon F}\Longrightarrow F$
 - $G \overset{\eta G} \Longrightarrow GFG \overset{G \varepsilon}\Longrightarrow G$
#+end_definition

Demostraremos que esta definicin es equivalente a la anterior.

****** Equivalencia de definiciones: desde familia de isomorfismos a unidades
#+begin_theorem
Dada una adjuncin en trminos de una familia de isomorfismos, podemos
construir una adjuncin en trminos de unidad y counidad.
#+end_theorem

#+begin_proof
/Paso 1: Construccin de la unidad y la counidad./

Supongamos que tenemos la familia de transformaciones naturales
$\varphi_{a,b} : Hom(Fa,b) \to Hom(a,Gb)$. Particularizaremos los cuadrados de
naturalidad en los dos casos $b = Fa$ y $a = Gb$ para crear la unidad y
la counidad.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{(Ff)^\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(f)^\ast} \\
Hom(Fa', Fa) \arrow{r}{\varphi} &
Hom(a',GFa)
\end{tikzcd}\]

Si tomamos la identidad $1_{Fa}$ y llamamos $\eta_a = \varphi(1_{Fa})$, tenemos que
$\eta \circ f = \varphi(Ff)$ por conmutatividad.

Si damos la vuelta al isomorfismo $\varphi$ para tomar $\varphi^{-1}$, llamarlo de la
misma forma y repetir el mismo proceso:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(Ff)^\ast} & 
Hom(Gb,Gb) \arrow{d}{(f)^\ast} \lar[swap]{\varphi} \\
Hom(FGb', b) &
Hom(Gb',Gb) \lar{\varphi}
\end{tikzcd}\]

Ntese que aqu usamos $\varphi$ para notar un isomorfismo y su inversa;
depender slo del contexto determinar cul estamos usando.
Si tomamos la identidad $1_{Gb}$ y llamamos $\varepsilon_b = \varphi(1_{Gb})$, tenemos que
$\varepsilon \circ Ff = \varphi(f)$.

Aplicamos el mismo proceso al segundo cuadrado natural.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{g_\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(Gg)_\ast} \\
Hom(Fa, Fa') \arrow{r}{\varphi} &
Hom(a,GFa')
\end{tikzcd}\]

Y volvemos a tomar la identidad para tener $\varphi(g) = Gg \circ \eta$. Volviendo a
dar la vuelta a los isomorfismos llegamos a:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(g)_\ast} & 
Hom(Gb,Gb) \arrow{d}{(Gg)_\ast} \lar[swap]{\varphi} \\
Hom(FGb,b') &
Hom(Gb,Gb') \lar{\varphi}
\end{tikzcd}\]

Que nos da, tomando la identidad, $\varphi(Gg) = g \circ \varepsilon$.

/Paso 2: Naturalidad de la unidad y la counidad./

Una vez tenemos definidas la unidad y la counidad, podemos comprobar
su naturalidad desde las ecuaciones que hemos obtenido:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

Y la naturalidad de $\eta$ y $\varepsilon$ se deduce desde ah por la conmutatividad de los
siguientes diagramas, con $\eta \circ f = GFf \circ \eta$ y $g \circ\varepsilon = \varepsilon\circ FGg$:

\[\begin{tabular}{cc}\begin{tikzcd}
GFa  \arrow{r}{GFf} & 
GFb \\
a \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & 
b \arrow{u}{\eta_Y}
\end{tikzcd} & \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}\end{tabular}\]

/Paso 3: Comprobar la condicin de composicin./

Por ltimo tenemos los dos tringulos siguientes, cuya conmutatividad
equivale a la condicin de que la composicin deba ser la identidad.

\[\begin{tabular}{cc} \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd} & \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}\end{tabular}
\]

Para ello usamos las identidades anteriores comprobando que:

\[\begin{aligned}
\epsilon \circ F\eta &= \varphi(\eta) = 1 \\
G\epsilon \circ \eta &= \varphi(\epsilon) = 1
\end{aligned}\]

$\quad$
#+end_proof

****** Equivalencia de definiciones: desde unidades a familia de isomorfismos
#+begin_theorem
Dada una adjuncin en trminos de unidad y counidad, podemos construir
una adjuncin en trminos de familia de isomorfismos.
#+end_theorem

#+begin_proof
/Paso 1: Definicin de los isomorfismos./

Por las condiciones sobre la composicin de unidad y counidad,
tenemos:

\[\begin{aligned}
\varepsilon \circ F\eta &= 1 \\
G\varepsilon \circ \eta &= 1
\end{aligned}\]

Y por las condiciones de naturalidad de ambas transformaciones, se
tiene:

\[\begin{aligned}
\eta \circ f &= GFf \circ \eta \\
g \circ \varepsilon &= \varepsilon \circ FGg
\end{aligned}\]

Definimos el isomorfismo y su inversa, que seguimos notando igual,
como:

\[\begin{aligned}
\varphi(f) &= \varepsilon \circ Ff \\
\varphi(g) &= Gg \circ \eta
\end{aligned}\]

Se comprueba trivialmente que es isomorfismo por las condiciones
anteriores. Tenemos as las igualdades:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

/Paso 2: Naturalidad de los isomorfismos./

Demostraremos que el isomorfismo es natural en cada una de sus
componentes. La naturalidad aqu se deduce de que la definicin
de $\varphi$ nos da las siguientes ecuaciones para cualesquiera $f,g,h$:

\[\begin{aligned}
\varphi(f \circ h)   &= Gf \circ \varphi(h) \\
\varphi(h \circ Fg) &= g \circ \varphi(h)
\end{aligned}\]

Que nos dan la naturalidad de $\varphi$ en ambas componentes.
#+end_proof

***** Unicidad del adjunto
#+begin_theorem
El adjunto es esencialmente nico, es decir,
si tenemos funtores $F : {\cal A} \to {\cal B}$ y $G,G' : {\cal B} \to {\cal A}$ y son ambos adjuntos por la
derecha al primero, $F \dashv G, F \dashv G'$; entonces existe un isomorfismo natural
$\tau : G \cong G'$.
#+end_theorem

#+begin_proof
/Paso 1: Definiendo el isomorfismo natural./

Por ser ambas adjunciones, tenemos un isomorfismo natural en ambas
variables $X,Y$ dado por $\varphi : Hom(X,GY) \cong Hom(X,G'Y)$, ya que
ambos eran isomorfos a $Hom(FX,Y)$.

Tomamos para cada $A$, la componente de nuestro isomorfismo natural
en $A$ como $\tau_A = \varphi_A(id_{GA})$.

/Paso 2: Probando la naturalidad./

Aplicamos dos veces la naturalidad de $\varphi$ para tener, dado un
$f : A \to B$:

\[\begin{tabular}{cc}
\begin{tikzcd}
Hom(GA,GA)\rar{\varphi} \dar[swap]{f^\ast} & Hom(GA,G'A) \dar{(Gf)^\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd} & \begin{tikzcd}
Hom(GB,GB)\rar{\varphi} \dar[swap]{(Gf)_\ast} & Hom(GB,GB') \dar{(Gf)_\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd}\end{tabular}\]

Obtenemos, tomando de la identidad en ambos diagramas, que $\tau \circ Gf = \varphi(Gf)$
y que $G'f \circ \tau = \varphi(Gf)$. Y uniendo ambas igualdades tenemos la condicin de
naturalidad de la transformacin $\tau$. Por ser la imagen por un isomorfismo 
natural del isomorfismo identidad, todas sus componentes son isomorfismos.
#+end_proof
***** Continuidad
#+begin_theorem
Todo funtor que es un adjunto derecho (equivalentemente, que tiene un
adjunto izquierdo) es *continuo*; es decir, preserva lmites
categricos. Por otro lado, todo functor que es un adjunto izquierdo
es *cocontinuo* y preserva colmites categricos.
#+end_theorem

#+begin_proof
Sea $a$ el lmite de un funtor en la categora $A$ y sea $G : A \to B$ un
funtor con adjunto a la izquierda $F \dashv G$. Comprobaremos que si existiera
otro cono desde $x$, descompondra de forma nica por $Ga$, hacindolo lmite.

\[\begin{tabular}{ccc}\begin{tikzcd}
a \dar[d]\dar[d,shift left=1, bend left]\dar[d,shift right=1, bend right] \\
\dots
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}
x
\arrow[in=70, out=290]{dd}
\arrow[bend left, shift left=1]{dd}
\arrow[bend right, shift right=1]{dd} \\
Ga 
\dar[d]\dar[d,shift left=1, bend left]
\dar[d,shift right=1, bend right] \\
G\dots
\end{tikzcd}\end{tabular}\]

Pero entonces, por la adjuncin, por cada $x \to Gi$ tenemos un $Fx \to i$, y estas
aplicaciones generan un cono que conmuta con el diagrama por tenerse

\[\begin{tabular}{ccc}\begin{tikzcd}[column sep=0.5em]
& x \dlar[swap]{\alpha}\drar{\beta} & \\
Gi \arrow{rr}{Gf} & & Gj
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}[column sep=0.5em]
& Fx \dlar[swap]{\overline{\alpha}}\drar{\overline{\beta}} & \\
i \arrow{rr}{f} & & j
\end{tikzcd}\end{tabular}\]

y por las condiciones de naturalidad de la transformacin
$Hom(F-,-) \cong Hom(-,G-)$ tenemos que

\[
\beta = Gf \circ \varphi(\overline{\alpha}) = 
\varphi(f \circ \overline{\alpha}) = \varphi(\overline{\beta})
.\]

As, como $a$ es lmite, tenemos un nico $Hom(Fx,a)$ que hace conmutar a los
diagramas. Como slo existe uno, slo existe un $Hom(x,Ga)$, lo que conlleva
que sea $Ga$ efectivamente el lmite.

El caso de cocontinuidad se obtiene aplicndolo a la categora dual.
cite:lane78categories
#+end_proof

***** Ejemplos
****** Mdulos libres
Un *funtor de olvido* es aquel que proyecta estructuras en una
categora de estructuras ms generales, "olvidando" en el proceso
parte de su estructura. En nuestro caso particular de R-mdulos,
tenemos el funtor de olvido que lleva cada mdulo a su conjunto
subyacente y cada homomorfismo a su aplicacin de conjuntos:

\[
U : R\mathtt{-Mod} \longrightarrow \mathtt{Set}
\]

Sobre cada conjunto puede generarse un R-mdulo libre, y cada
aplicacin de conjuntos puede extenderse directamente por linealidad
a todo el mdulo libre. Esto nos da el *funtor de mdulo libre*:

\[
F : \mathtt{Set} \longrightarrow R\mathtt{-mod}
\]

Definido como, 

\[F(S) = <S> \qquad F(f)\left(\sum rx\right) = \sum rf(x)\]

Hay una *adjuncin* entre el funtor libre y el funtor de olvido
$F \dashv U$, ya que tenemos la correspondencia natural entre homomorfismos
dada por, para un conjunto $X$ y un R-mdulo $M$:

\[
Hom(FX,M) \cong Hom(X,UM)
\]

Que hace corresponder a cada aplicacin entre conjuntos su extensin
lineal, que est biunvocamente determinada.

La naturalidad se tiene por tenerse para cada $x \in X$:

\[\begin{aligned}
\varphi(g\circ f)(x) = g(f(x)) =& Ug \circ f(x) \\
\varphi(Ff \circ g)(x) = Ff(g(x)) =& f(\varphi(g)(x))
\end{aligned}\]

****** Otros funtores libres y de olvido
De la misma forma que funciona el funtor de olvido entre
mdulos y conjuntos, funciona con otras estructuras algebraicas,
como por ejemplo:

 - Grupos a conjuntos.
 - Grupos abelianos a grupos.
 - K-lgebras a K-mdulos.

****** Funtor diagonal
******* Categora producto
#+begin_definition
Dada una categora ${\cal C}$ con productos y coproductos ($\mathtt{Set}$, por ejemplo) 
definimos ${\cal C}\times{\cal C}$ como la categora que tiene como objetos a pares de 
objetos de ${\cal C}$ y morfismos a pares de morfismos que se componen componente
a componente:

\[
(f,g)\circ(h,i) = (f\circ h, g\circ i)
\]
#+end_definition

En la categora producto, tenemos un *funtor diagonal* $\Delta : {\cal C} \to {\cal C}\times{\cal C}$, que 
lleva cada objeto $A$ a $A\times A$ y cada morfismo $f$ a $(f,f)$.

******* Producto como adjunto derecho
Si definimos el *funtor producto*, $\times : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en $A\times B$
y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo producto
x$f \times g : A\times B \to C \times D$, dado por el nico que hace conmutar:

\[\begin{tikzcd}
& A\times B \dlar[swap]{\pi}\drar{\pi}\dar[dashed] & \\
A\dar[swap]{f} & C \times D \dlar[swap]{\pi}\drar{\pi} & B\dar{g} \\
C & & D \\
\end{tikzcd}\]

Este funtor es adjunto derecho al funtor diagonal. Ntese que se
tiene:

\[
Hom(\Delta A, (B,C)) \cong Hom(A, B \times C)
\]

Y utilizamos la propiedad universal del producto para llevar dos
morfismos $A \to B$ y $A \to C$ a un morfismo al producto $A \to B \times C$.
Y puede comprobarse la naturalidad.

******* Coproducto como adjunto izquierdo
Si definimos el *funtor coproducto* $\coprod : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en
$A \coprod B$ y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo
coproducto, dado por el nico que hace conmutar:

\[\begin{tikzcd}
A\dar{f}\drar{i} & & B\dar{g}\dlar[swap]{i} \\
C\drar{i} & A \coprod B \dar[dashed] &D\dlar[swap]{i} \\
& C \coprod D &
\end{tikzcd}\]

Y este funtor es adjunto izquierdo al funtor diagonal. Tenindose
el isomorfismo siguiente y la naturalidad por la propiedad universal
del coproducto:

\[
Hom\left(A \coprod B, C\right) \cong Hom((A, B), \Delta C)
\]

****** Tensor-Hom
Existe una adjuncin entre los funtores *tensor y Hom*. cite:kan58adjoint
Si $R,S$ son dos anillos y fijamos un (R;S)-mdulo $X$, tenemos los dos funtores

\[\begin{aligned}
F : \mathtt{Mod-}R \longrightarrow \mathtt{Mod-}S
&\qquad&
F(Y) = Y \otimes_R X\\
G : \mathtt{Mod-}S \longrightarrow \mathtt{Mod-}R
&\qquad&
G(Z) = \mathrm{Hom}(X,Z)
\end{aligned}\]

y tenemos el isomorfismo natural

\[
\mathrm{Hom}_{S}(Y \otimes_{R} X, Z) \cong
\mathrm{Hom}_{R}(Y, \mathrm{Hom}_{S}(X,Z))
\]

dado por $\widehat{f}(y)(x) = f(y \otimes x)$.

bibliographystyle:unsrt
bibliography:math.bib
**** Retculos
**** Mdulos libres
# Pgs 167 Aluffi -> Definicin de mdulos libres
# Pgs 349 Aluffi -> Clasificacin de mdulos libres sobre PIDs
# Pgs 359 Aluffi -> Endomorfismos de mdulos libres

***** Definicin de mdulo libre
#+begin_definition 
Definimos el *R-mdulo libre* cite:aluffi09_rings sobre $A$ como un mdulo $F^R(A)$ 
con una inclusin $j : A \to F^R(A)$ como aquel que cumple que para cualquier 
aplicacin $f : A \to M$ a un R-mdulo, existe un nico homomorfismo de 
R-mdulos $\varphi:F^R(A) \to M$ que hace conmutar el diagrama

\[\begin{tikzcd}
F^R(A) \rar[dashed]{\exists!\varphi} & M \\
A \uar{j}\urar[swap]{f} &
\end{tikzcd}\]
#+end_definition

Sabemos por ser una propiedad universal que si existe, ser nico salvo
isomorfas y que $j\colon A \to F^R(A)$ ser inyectivo.

****** Construccin
#+begin_definition
Dado un conjunto $A$, definimos la *suma directa indexada* sobre l como
las aplicaciones de soporte finito

\[
N^{\oplus A}
=
\left\{ \alpha\colon A \to N 
\mid 
\alpha(a) \neq 0 \text{ slo para un nmero finito de elementos} \right\}
\]

a las que les damos estructura de R-mdulo con $(r\alpha)a = r\alpha(a)$.
#+end_definition

Adems, existe una inclusin $j\colon A \to R^{\oplus A}$ definida como

\[
j(a)(x) = \left\{\begin{array}{ll} 
1 & \mbox{if } x = a  \\
0 & \mbox{if } x \neq a 
\end{array} 
\right. .
\]

#+begin_theorem
El as definido es el mdulo libre sobre $A$. Es decir, $F^R(A) \cong R^{\oplus A}$.
#+end_theorem

#+begin_proof
Ntese que podemos escribir realmente los elementos de esta suma directa
indexada como

\[
\sum_{a \in A} r_aa,
\]

adems de forma nica y en un nmero finito de sumandos, uno para cada
elemento en el que la aplicacin sea no nula. Esto que nos lleva a que,
una vez definida la imagen de cada elemento $a$, queda definida la imagen
que debe tener $\varphi$ sobre toda el anillo de forma nica.
#+end_proof

***** Independencia lineal y bases
#+begin_definition
Decimos que un conjunto indexado $i \colon I \to M$ es *linealmente independiente*
(respectivamente *sistema generador*) si el homomorfismo natural desde su
mdulo libre, $\varphi\colon F^{R}(I) \to M$, haciendo conmutar

\[\begin{tikzcd}
F^{R}(I) \rar{\varphi} & M \\
I \uar{j}\urar[swap]{i} &
\end{tikzcd}\]

es inyectivo (respectivamente sobreyectivo). cite:aluffi09_linear
#+end_definition

#+begin_definition
Un conjunto indexado $I \to M$ es una base cuando es linealmente
independiente y genera $M$.
#+end_definition

#+begin_lemma
Un conjunto indexado $B \to M$ es una base si y slo si el homomorfismo
natural desde su mdulo libre es un isomorfismo $R^{\oplus B} \cong M$. As, un
$R\text{-mdulo}$ es libre si y slo si admite una base.
#+end_lemma

#+begin_proof
Trivial si combinamos las definiciones de linealmente independiente y
sistema generador.
#+end_proof

***** Caso de los espacios vectoriales
#+begin_theorem
Los mdulos sobre un cuerpo son necesariamente libres. Podemos
probarlo usando la caracterizacin anterior por bases. De hecho, dado un
subconjunto de vectores linealmente independientes en un espacio
vectorial, existe una base del espacio contenindolos.
#+end_theorem

La nocin de dimensin de un espacio vectorial nos permite recuperar
la cardinalidad de la base sobre la que es mdulo libre.

***** Clasificacin de mdulos libres en dominios de integridad
#+begin_theorem
Sea $M$ un $R\text{-mdulo}$ libre para $R$ dominio de integridad con
$B$ un conjunto linealmente independiente maximal. Para cualquier $S$
linealmente independiente,

\[ \# S \leq \# B.
\]

En particular, cualesquiera dos conjuntos linealmente independientes
maximales tienen la misma cardinalidad.
#+end_theorem

# Completar la parte de cuerpos de fracciones.
#+begin_proof
Empezamos tomando cuerpos de fracciones y pasamos a considrear el caso
de $R$ un cuerpo y $M$ un espacio vectorial.

Comprobaremos que podemos ir reemplazando elementos de $B$ por
elementos de $S$ sucesivamente para ir creando sucesivos $B'$ y
seguir manteniendo independencia lineal y la maximalidad. Si tomamos
$B' \cup \{v\}$ para algn $v \in S$, por maximalidad tenemos una
dependencia lineal

\[
c_0v + c_1b_1 + \dots + c_tb_t = 0
\]

con $c_0 \neq 0$ para no contravenir la independencia de $B$; adems, no slo
pueden existir elementos no nulos de $S$, porque contravendra su independencia.
Debe existir un $c_1 \neq 0$ con $b_1 \in B' \setminus S$ y podemos intercambiar $b_1$ por $v$
teniendo de nuevo un conjunto linealmente independiente maximal, ya que

\[
v = -c_0^{-1}c_1b_1 - \dots - c_0^{-1}c_tb_t.
\]

Si aplicamos induccin transfinita bajo una buena ordenacin de $S$, podemos
asegurar que se llega a un conjunto de cardinalidad $\#B$ que contiene a
los elementos de $S$.
#+end_proof

#+begin_corollary
Para $R$ un dominio de integridad y dos conjuntos $A,B$,

\[
F^R(A) \cong F^R(B) \iff A \cong B.
\]
#+end_corollary

#+begin_corollary
Para $R$ un dominio de integridad se satisface la propiedad IBN

\[
R^m \cong R^n \iff m = n.
\]
#+end_corollary

***** Clasificacin de mdulos libres en dominios de ideales principales
#+begin_lemma
Sea $R$ un dominio de ideales principales y $F$ un mdulo libre finitamente
generado sobre l. Entonces existen $a\in R, x\in F, y\in M$ con $y = ax$ y
$M' \subseteq M,F' \subset F$ con $M' = F' \cap M$ submdulos cumpliendo

\[
F = \left\langle x \right\rangle \oplus F',
\qquad
M = \left\langle y \right\rangle \oplus M'.
\]
#+end_lemma

#+begin_proof
La familia de ideales $\left\{ \varphi \in \mathrm{Hom}(F,R) \mid \varphi(M) \right\}$ es no vaca. Como los PID son
noetherianos, tiene un elemento maximal $\alpha(M) = (a)$, para algn $\alpha(y) = a$.

Dado cualquier $\varphi(y)$, si tomamos el generador $(b) = (a,\varphi(y))$ tenemos que

\[
b = ra + s\varphi(y)
\]

y que si definimos $\psi = r\alpha + s\varphi$, tenemos $b = \psi(y) \in \psi(M)$, luego
$(a) \subseteq (b) \subseteq \psi(M)$, y por maximalidad, $a \mid \varphi(y)$.

Si vemos $y = \left( s_1,\dots,s_n \right)$ como elemento de $F\cong R^{\oplus n}$, tenemos $a \mid \pi_i(y) = s_i$,
as que sabemos $s_i = ar_i$, y definimos

\[
x = \left( r_1,\dots,r_n \right).
\]

Ahora tomamos $F' = \mathrm{ker}(\alpha)$ y comprobamos las sumas directas.
#+end_proof

#+begin_proposition
Sea $R$ un dominio de ideales principales y $F$ un mdulo libre finitamente
generado sobre l. Todo submdulo $M \subset F$ ser libre.
#+end_proposition

#+begin_proof
Aplicamos el lema anterior a los sucesivos $M^{(i)}$ que genere. Tendremos
que eventualmente $M^{(i)} = 0$, ya que los $y^{(i)}$ son independientes y $F$ es
finitamente generado.
#+end_proof

****** Resoluciones en PIDs
#+begin_proposition
Sea $R$ dominio de integridad. Ser dominio de ideales principales si y slo
si para cualquier epimorfismo a un mdulo finitamente generado

\[
R^{m_0} \overset{\pi_0} \longrightarrow M \longrightarrow 0,
\]

existe un mdulo libre haciendo exacta la secuencia

\[
0 \longrightarrow 
R^{m_1} \overset{\pi_1} \longrightarrow
R^{m_0} \overset{\pi_0} \longrightarrow
M \longrightarrow
0.\]
#+end_proposition

***** Anillo de endomorfismos
#+begin_proposition
Los endomorfismos de un $R\text{-mdulo}$ $F$, $\mathrm{End}(F)$ forman un lgebra con la
composicin.
#+end_proposition

****** Semejanza
#+begin_definition
Dos matrices $A,B \in {\cal M}_n(R)$ son *semejantes* si representan el mismo
endomorfismo $F \to F$, diferencindose en la eleccin de la base.
#+end_definition

#+begin_proposition
Dos matrices $A,B$ son semejantes si y slo si

\[
B = PAP^{-1}.
\]
#+end_proposition
# Sacar demostracin de pgina 360.

#+begin_definition
Dos endomorfismos $\alpha,\beta \colon F \to F$ son *semejantes* si existe un
automorfismo $\pi \colon F \to F$ cumpliendo

\[
\beta = \pi \circ \alpha \circ \pi^{-1}.
\] cite:aluffi09_linear
#+end_definition

****** Semejanza y acciones de anillos de polinomios
#+begin_proposition
Una transformacin lineal de $F$ es exactamente lo mismo que una estructura
como $R[X]\text{-mdulo}$ compatible con la estructura de $R\text{-mdulo}$.
#+end_proposition

Si tenemos una transformacin lineal $\alpha$, podemos definir la accin de
un polinomio como

\[
\left( r_mt^m + \dots + r_1t + r_0 \right)(v) =
r_{m}\alpha^m(v) + \dots r_1\alpha(v) + r_0v.
\]

Y por la propiedad universal del anillo de polinomios, toda estructura
de $R[t]\text{-mdulo}$ quedar determinada por el endomorfismo que asignemos a $t$.

#+begin_lemma
Dadas transformaciones lineales $\alpha,\beta$ de $F$; las estructuras como $R[t]\text{-mdulo}$
son isomorfas si y slo si $\alpha$ y $\beta$ son semejantes.
#+end_lemma
#+begin_proof
Si llamamos $F_{\alpha}$, $F_{\beta}$ a las dos estructuras como $R[t]\text{-mdulo}$, tendremos que
un isomorfismo $\pi\colon F_{\alpha}\to F_{\beta}$ ser lo mismo que una transformacin invertible
$\pi\colon F \to F$ cumpliendo $\beta = \pi\circ\alpha\circ\pi^{-1}$.

Ntese de hecho que un isomorfismo entre mdulos debe comportarse como

\[
\pi\circ\alpha (v) = \pi(tv) = t\pi(v) = \beta\circ\pi(v),
\]

por lo que $\pi\circ\alpha = \beta\circ\pi$ es la condicin que lo distingue de cualquier
otra transformacin lineal.
#+end_proof

#+begin_corollary
Hay una correspondencia biyectiva entre clases de semejanza de transformaciones
lineales de un $R\text{-mdulo}$ libre $F$ y clases de isomorfa de estructuras de
$R[t]\text{-mdulo}$ en $F$.
#+end_corollary

Ntese que esto se expande a las matrices en el caso finito-dimensional.

***** Proyectividad
#+begin_theorem
Todo mdulo libre es proyectivo.
#+end_theorem
#+begin_proof
Supongamos que tenemos un mdulo libre $F$ sobre el conjunto $A$. Dado
un epimorfismo $\varphi\colon M \to N$, tendremos la situacin siguiente, donde
podemos definir una aplicacin de $A$ a $M$ por ser $\varphi$ epimorfismo.
Dado cualquier $\alpha\colon F \to N$ se tiene

\[\begin{tikzcd}
& A\dar{i}\ar{ddl} \\
& F\dar{\alpha}\dlar[dashed] \\
M\rar{\varphi} & N \\
\end{tikzcd}\]

tales que conmutan el tringulo exterior y el superior. As tenemos
que ambas funciones coinciden sobre la base y por tanto coinciden
para todo el mdulo libre.
#+end_proof
***** Referencias
bibliographystyle:unsrt
bibliography:math.bib
**** Categoras abelianas
***** Objeto nulo
#+begin_definition
En una categora, un *objeto nulo* es aquel que es a la vez inicial y final.
#+end_definition

Ntese que no todas las categoras tienen por qu tener un objeto nulo.
La categora $\mathtt{Set}$, por ejemplo, tiene objetos inicial y final no isomorfos.

#+begin_definition
En una categora con objeto nulo llamamos *morfismo cero* entre dos
objetos, $0_{a,b}\colon a \to b$, al que resulta de componer el nico morfismo $a \to 0$ con 
el nico morfismo $0 \to b$.
#+end_definition

***** Ncleos y concleos
#+begin_definition
En una categora con objeto nulo, el *ncleo* de un morfismo
$f \colon a \to b$ es un morfismo $k \colon \mathrm{ker}(f) \to a$ tal que $f\circ k = 0$ y que es universal 
respecto a esa propiedad; es decir, para cualquier otro $h$ cumpliendo 
que $f \circ h = 0$, se tiene el diagrama

\[\begin{tikzcd}
c \dar[dashed]{\exists! h'}\ar[bend right=90,swap]{dd}{h}\arrow[bend left=45]{ddr}{0} &   \\
\mathrm{ker}(f) \dar{k}\drar{0} &   \\
a\rar{f} & b & .\\
\end{tikzcd}\]
#+end_definition

De otra forma, podramos definirlo como el *ecualizador* del morfismo $f$ con
el morfismo cero, es decir, como el universal respecto al diagrama

\[\begin{tikzcd} \mathrm{ker}(f) \rar{k} & 
a \rar[bend left]{f}\rar[bend right,swap]{0} & b
\end{tikzcd},\]

y por tanto, es un lmite finito y es nico salvo isomorfismo. cite:aluffi09_linear

#+begin_definition
En una categora con objeto nulo, se define el *concleo*, $c \colon b \to \mathrm{coker}(f)$
de manera dual al ncleo, como universal segn el siguiente diagrama 
conmutativo

\[\begin{tikzcd}
c  &   \\
\mathrm{coker}(f)  \uar[dashed]{\exists! h'} &   \\
a \ar[bend left=90]{uu}{0}\uar{0} \rar{f} & b \ular[swap]{c} \arrow[bend right=45,swap]{uul}{h} \\
\end{tikzcd}\]
#+end_definition

****** Propiedades del ncleo
#+begin_proposition
Cualquier ncleo es un monomorfismo. Dualmente, cualquier concleo es
un epimorfismo.
#+end_proposition
#+begin_proof
Si se tienen dos $m,n\colon d \to \mathrm{coker}(f)$, entonces sabemos que $m \circ k$ y $n \circ k$,
por propiedad universal, hacen que exista un nico $h \circ k = m\circ k=n\circ k$.
Debe tenerse por tanto $h=m=n$.
#+end_proof

Ntese que el converso no tiene por qu ser cierto. En general, no todo
monomorfismo es ncleo ni todo epimorfismo es concleo.

****** Ejemplo: grupos
En la categora $\mathtt{Grp}$, el objeto cero es el grupo trivial. El ncleo de
cualquier morfismo es lo que llamamos usualmente ncleo, como se puede
comprobar trivialmente. Ntese que todos los ncleos son normales en un 
grupo pero que no todas las inclusiones lo son como subgrupo normal, por 
lo que no todos los monomorfismos sern aqu ncleos.

***** Categoras preaditivas
#+begin_definition
Una *categora preaditiva* es aquella en la que cada conjunto de morfismos
$\mathrm{hom}(a,b)$ es un grupo abeliano y la composicin es bilinear respecto a la
operacin de grupo.
#+end_definition

#+begin_proposition
Para un objeto en una categora preaditiva, $z \in {\cal A}$, equivalen:

  1) $z$ es inicial.
  2) $z$ es final.
  3) $\mathrm{id}_z$ es el elemento neutro de $\mathrm{hom}(z,z)$.
  4) $\mathrm{hom}(z,z)$ es el grupo trivial.
#+end_proposition
#+begin_proof
Si $z$ es inicial o final, se tiene un nico $\mathrm{id}_z = 0$, que da el grupo trivial.
Si se tiene $\mathrm{id}_z=0$, entonces para cualquier morfismo $f\colon a \to z$, se tendr

\[
f = \mathrm{id}_z \circ f = 0\circ f = 0
\]

por la bilinealidad de la composicin. Dualmente se ver que es inicial.
#+end_proof

****** Biproductos
#+begin_definition
Un *biproducto* para dos objetos en una categora preaditiva $a,b \in A$ es un
$c$ con morfismos

\[\begin{tikzcd}
a \rar[bend right,swap]{i_{1}} &
c \rar[bend left]{p_2} \lar[bend right,swap]{p_1} &
b \lar[bend left]{i_2}
\end{tikzcd}\]

cumpliendo las identidades $p_1i_1 = \mathrm{id}_a$, $p_2i_2 = \mathrm{id}_b$, y $i_1p_1 + i_2p_2 = \mathrm{id}_{c}$.
#+end_definition

#+begin_theorem
Dos objetos en una categora preaditiva $a,b \in A$ tienen producto (o coproducto) 
si y slo si tienen un biproducto, que ser a su vez producto y coproducto.
#+end_theorem

***** Categoras abelianas
#+begin_definition
Una *categora abeliana* es una categora preaditiva cumpliendo que

 1) tiene un objeto nulo.
 2) tiene biproductos finitos.
 3) todo morfismo tiene ncleo y concleo.
 4) todo monomorfismo es ncleo y todo epimorfismo es concleo.
#+end_definition

****** Factorizacin de un morfismo
#+begin_proposition
En una categora abeliana, cada morfismo se factoriza como $f = m\circ e$,
donde $m = \mathrm{ker}(\mathrm{coker}(f))$ y $e = \mathrm{coker}(\mathrm{ker}(f))$. 
Adems, esta factorizacin cumple que, dada cualquier otra factorizacin
de la forma $f' = m'e'$ con $m'$ monomorfismo, $e'$ epimorfismo y con morfismos
de la forma

\[\begin{tikzcd}
\cdot \rar{f}\dar[swap]{g} & \cdot \dar{h} \\
\cdot \rar[swap]{f'} & \cdot &,
\end{tikzcd}\]

existe un nico $k$ cumpliendo

\[\begin{tikzcd}
\cdot \arrow[bend left]{rr}{f}\dar[swap]{g} \rar{e}& 
\cdot\rar{m}\dar{k} & \cdot \dar{h} \\
\cdot \arrow[bend right,swap]{rr}{f'} \rar{e'} & \cdot\rar{m'} & \cdot
\end{tikzcd}\]
#+end_proposition
#+begin_proof
Tomamos $m = \ker(\operatorname{coker} f)$. Como $(\operatorname{coker} f)\circ f = 0$, por propiedad universal
del ncleo sabemos que $f$ se escribe como $f = me$ para algn $e$. Como puede
demostrarse que $e$ ser epimorfismo, luego $e = \operatorname{coker}(\ker f)$.

Dadas $f=me$ y $f'=m'e'$ con $g,h$ del diagrama, consideramos
$u = \ker f = \ker e$ y entonces tenemos que $0 = hfu = m'e'gu$, luego $e'gu = 0$.
Por ser $u$ ncleo, $e'g$ factoriza en $e = \operatorname{coker}(u)$ como $e'g = ke$ para algn
$k$ que adems debe ser nico. As, $m'ke = hme$ y $m'k = hm$, dando la
conmutatividad del diagrama.
#+end_proof

#+begin_definition
La *imagen* y *coimagen* de un morfismo $f = me \colon a \to b$ se definen como

 * $\operatorname{im} f = m$
 * $\operatorname{coim} f = e$
#+end_definition

La proposicin anterior se usa para comprobar que son nicas salvo
isomorfismo.

***** Secuencias exactas
****** Exactitud
#+begin_definition
Un par de morfismos componibles es *exacto* en el objeto que comparten
cuando $\operatorname{im} f = \operatorname{ker} g$. Equivalentemente, cuando $\operatorname{coker} f = \operatorname{coim} g$.
#+end_definition

****** Complejos de cadenas
#+begin_definition
En una categora abeliana, un *complejo de cadenas* es una secuencia

\[\begin{tikzcd}
\dots \rar &
c_{n+1} \rar{\partial_{n+1}} &
c_n \rar{\partial_n} &
c_{n-1} \rar &
\dots
\end{tikzcd}\]

cumpliendo que $\partial_n\partial_{n+1} = 0$.
#+end_definition

****** Secuencias exactas cortas
#+begin_definition
Una *secuencia exacta corta* es un diagrama

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

que es exacto en $a$,$b$ y $c$.
#+end_definition

#+begin_definition
Un *morfismo de secuencias exactas cortas* est formado por tres morfismos
$f,g,h$ que hacen conmutar el diagrama

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

Las secuencias exactas cortas de una categora abeliana $A$ con estos 
morfismos forman la categora $\mathtt{Ses}(A)$, que se hace preaditiva sumando
las tres componentes de cada morfismo.
#+end_definition

***** Resultados en categoras abelianas
****** Manipulacin elemental en categoras abelianas
#+begin_proposition
Si dados dos morfismos $f,g$ hacia $c$ calculamos su producto fibrado
(/pullback/) tendremos que $f$ epimorfismo nos da $f'$ epimorfismo en

\[\begin{tikzcd}
s\rar{f'} \dar[swap]{g'} & d \dar{g} \\
b\rar{f} & c
\end{tikzcd}\]

donde adems, el ncleo de $f$ factoriza como $\mathrm{ker}(f) = g'\circ \mathrm{ker}(f')$.
#+end_proposition
#+begin_proof
El producto fibrado se construye formando la secuencia exacta

\[\begin{tikzcd}
0\rar&s\rar{m}&b\oplus d\rar{fp_1-gp_2}& c
\end{tikzcd}\]

y tomando $g' = p_1m$ y $f'=p_2m$. Probaremos que $fp_1-gp_2$ es un
epimorfismo, para lo que basta comprobar que si $h(fp_1-gp_2) = 0$
entonces

\[
0 = h(fp_1-gp_2)i_1 = hfp_1i_1 = hf,
\]

y por ser epimorfismo $f$, $h = 0$. Ahora probaremos que $f'$ es
epimorfismo; si $uf'=up_2m=0$, por exactitud, es de la forma
$up_2 = u'(fp_1-gp_2)$. Ahora tenemos

\[
0 = up_2i_1 = u'f
\]

llegndose a $u'=0$ por ser $f$ epimorfismo.
#+end_proof

#+begin_definition
Definimos un *miembro* de $a$ como un morfismo con codominio $a$. Existe
una equivalencia $x \equiv y$ entre dos miembros cuando existen epimorfismos
$u,v$ tales que $xu=yv$.
#+end_definition
#+begin_proof
Para demostrar la transitividad de esta relacin de equivalencia,
debemos aplicar la proposicin anterior al diagrama siguiente,

\[\begin{tikzcd}
\cdot \rar\dar & 
\cdot \rar\dar& 
\cdot \dar{x}\\
\cdot \rar\dar& 
\cdot \rar{y}\dar{y}&
a \\
\cdot \rar{z} &
a &&,\\
\end{tikzcd}\]

donde probamos que si $x \equiv y$ y $y \equiv z$, entonces $x \equiv z$.
#+end_proof

Dado un morfismo $f \colon a \to b$, cada $x \in a$ da lugar a $f \circ x \in b$; y adems,
$x \equiv y$ implica $f x \equiv f y$. Gracias a esto, podemos tratar a los miembros
de un objeto en una categora abeliana de la misma manera de la que
tratamos a los elementos de un conjunto. La aplicacin de funciones
se comporta de la misma manera y preserva la relacin de equivalencia
de los miembros.

#+begin_proposition
En cualquier categora abeliana cite:lane78categories

 1) $f \colon a \to b$ es /monomorfismo/ ssi para $x \in a$, $f(x) \equiv 0 \implies x \equiv 0$.
 2) $f \colon a \to b$ es /monomorfismo/ ssi para $x,y \in a$, $f(x) \equiv f(y) \implies x\equiv y$.
 3) $g\colon b \to c$ es /epimorfismo/ ssi para $z\in c$, existe $y \in b$ con $g(y) \equiv z$.
 4) $h\colon r \to s$ es /nulo/ ssi para $x \in r$, $hx \equiv 0$.
 5) $a \overset{f}\to b\overset{g}\to c$ es /exacta/ ssi $gf = 0$ y para cada $g(y)\equiv 0$ existe un
    $x \in a$ tal que $f(x) \equiv v$.
 6) Si existen $g(x) = g(y)$, existe $g(z) = 0$; adems cualquier $f(x) \equiv 0$
    implica $f(y) \equiv f(z)$ y cualquier $h(y)\equiv 0$ implica $h(x) \equiv -h(z)$.
#+end_proposition
#+begin_proof
Se tienen (1) y (2) por definicin de monomorfismo. Se tiene adems
(3) por construccin del producto fibrado y (4) por definicin.

Si factorizamos $f = me$, por exactitud se tendr $\operatorname{ker} g = m$. Si $g y \equiv 0$,
$y \equiv my'$, y si construimos el producto fibrado

\[\begin{tikzcd}
\cdot\dar[dashed]{y''}\rar[dashed]{e'} & \cdot\dar{y'}\drar[bend left=45]{y} \\
\cdot\rar{e} & \cdot\rar{m} & \cdot &,
\end{tikzcd}\]

como $e'$ es epimorfismo, $y \equiv fy''$.

A la inversa, si para $y \in b$ existe $k = \ker g$, entonces $k \in b$ y $gk \equiv 0$.
Existe entonces $x \in a$ con $fx \equiv k$, es decir, $ku \equiv mexv$. Esto lleva
a $\operatorname{im} f \geq \ker g$ y a $gf = 0$, la exactitud.
#+end_proof

****** Lema de los cinco
#+begin_theorem
En un diagrama conmutativo con filas exactas

\[\begin{tikzcd}
a_1 \rar{g_1} \dar{f_1} & 
a_2 \rar{g_2} \dar{f_2} &
a_3 \rar{g_3} \dar{f_3} & 
a_4 \rar{g_4} \dar{f_4} & 
a_5 \dar{f_5} \\
b_1 \rar{h_1} &
b_2 \rar{h_2} &
b_3 \rar{h_3} &
b_4 \rar{h_4} &
b_5 & ,
\end{tikzcd}\]

si $f_2,f_4$ son isomorfismos, $f_1$ es epimorfismo y $f_5$ es monomorfismo, $f_3$ es isomorfismo.
#+end_theorem
#+begin_proof
Usando la manipulacin de diagramas cuyas reglas hemos escrito en
la proposicin anterior, demostraremos que $f_3$ es monomorfismo.
La dualidad servir para demostrar a su vez que es epimorfismo.

Explcitamente, si hubiera un elemento en $a_3$ que diera un cero en
$b_3$, habra un cero en $b_4$, por ser isomorfismo, habra un cero en
$a_4$, y entonces existira, por exactitud, un elemento en $a_2$ cuya
imagen sera el elemento original en $a_3$. Por isomorfismo, este
debera dar un elemento en $b_2$ cuya imagen sera cero, as que
por exactitud existira un elemento en $b_1$ del que sera imagen.
Como $f_1$ es epimorfismo, existira un elemento en $a_1$ del que
sera imagen, y entonces el elemento original sera la imagen
por la composicin de dos morfismos en secuencia exacta del
primer elemento. Debera ser cero, quedando probado $f_3$ como
monomorfismo.
#+end_proof

****** Lema de la serpiente
#+begin_theorem
Dado un morfismo de secuencias exactas cortas $f,g,h$; existe un morfismo
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ tal que la secuencia siguiente es exacta

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
El diagrama extendido que tenemos es

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

y desde l, manipulando de nuevo el diagrama podemos construir primero
el morfismo $\delta$ y demostrar despus que efectivamente es exacto.

Explcitamente, lo que haramos sera tomar un elemento en $\mathrm{ker}(h)$.
Este elemento pasara a $c$ y luego, como un cero a $c'$. Como $e$ es
sobreyectiva, existira un elemento en $b$, y luego uno en $b'$ que
hara conmutar el diagrama. Pero como este elemento ira hacia
un cero al aplicar $e'$, debera estar en la imagen de $m'$, as slo
deberamos pasar de $a$ a $\mathrm{coker}(f)$ para terminar la construccin de
$\delta$.

Ntese que si el elemento procede de $\mathrm{ker}(g)$, entonces sera nulo en $b'$,
y de ah sera nulo en $a'$ y en $\mathrm{coker(f)}$; y que la imagen de un
elemento que hubiera llegado desde $\delta$, al pasar a $\mathrm{coker}(g)$ debera ser
$0$ por provenir desde $b$. Esto demuestra la exactitud del diagrama.
#+end_proof

***** Referencias
bibliographystyle:unsrt
bibliography:math.bib

** Anlisis funcional
# Exportaba con config.setup

*** 1. Espacios normados
**** Espacios normados
***** Norma y seminorma
*Norma*. Funcin $\|\cdot\| : X \longrightarrow \mathbb{R}$ verficando:

  - $\|x\| = 0 \Leftrightarrow x = 0$
  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Seminorma
Cuando $\|x\| = 0$ no implica $x = 0$, se llama *seminorma*. Define
una norma en un espacio cociente.

  - $\|ax\| = |a| \|x\|$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Sublineal
Cuando adems $\|\alpha x\| = \alpha\|x\|$ slo se cumple para reales positivos, 
se llama funcional *sublineal*.

  - $\|ax\| =  a \|x\|$ para $a \in \mathbb{R}^+$
  - $\|x+y\| \leq \|x\|+\|y\|$

****** Distancia de la norma
Desde la norma se puede definir una *distancia* asociada 
$d(x,y) = \|x-y\|$, que hace a $X$ un *espacio mtrico*. La distancia 
cumple:

  - $d(x+a,y+a) = d(x,y)$
  - $d(\lambda a) = |\lambda| d(a)$

****** Topologa de la norma
La distancia hace a un espacio normado un *espacio topolgico*
con abiertos:

\[\tau = \{G \subset X \;|\; \forall a \in G: \exists r > : B(a,r) \subset G\}\]

Dos normas que generan el mismo espacio topolgico son 
*equivalentes*.

****** Equivalencia proporcional
Dos normas $\|.\|$ y $\|.\|_\ast$ generan topologas equivalentes cuando:

\[\exists m,M \in \mathbb{R^+}:\; m \|x\| \leq \|x\|_\ast \leq M \|x\|\]

******* Demostracin
Se demuestra por mutua inclusin de bolas.

***** Espacios vectoriales topolgicos
Cualquier espacio vectorial sobre $\mathbb{R}$ o $\mathbb{C}$ es normado.

****** Demostracin
Dada una base \(\{e_i\}\) del espacio, podemos escribir $x = \sum \alpha_i e_i$ 
y definirla como:

\[ \|x\| = \sum |\alpha_i|\]

La suma es finita por definicin de base.

***** Continuidad de la norma, suma y producto
La norma es continua en su espacio por ser lipschitziana:

\[ |\|x\| -  \|y\|| \leq \|x-y\| \]

****** Continuidad de suma y producto
La suma y el producto por escalares son continuos, usando que la
convergencia en el producto equivale a la convergencia por
coordenadas.

****** Continuidad de homotecias y translaciones
Como corolario, lo son las *homotecias* y *translaciones*, todas las
bolas cerradas son homeomorfas a la bola unidad.

***** Operaciones sobre conjuntos
Para $X$ espacio normado:

  1. $A$ abierto $\Rightarrow$ $A+B$ abierto.
  2. $A$ cerrrado, $B$ compacto $\Rightarrow$ $A+B$ cerrado.
  3. $A,B$ compactos $\Rightarrow$ $A+B$ compacto.
  4. $M$ subespacio $\Rightarrow$ $\overline{M}$ subespacio.

****** Demostracin de 1
Es la unin de abiertos, $A + B = \bigcup_{b \in B} (b + A)$.

****** Demostracin de 2
Sea $x \in \overline{A+B}$, $\exists \{a_n,b_n\} : \{a_n,b_n\} \longrightarrow x$, por compacidad
tenemos $\{b_{\sigma_n}\} \longrightarrow b \in B$ y por tanto $\{a_{\sigma_n}\} \longrightarrow x-b \in A$.

****** Demostracin de 3
Se tiene $A\times B$ compacto, y la suma es continua, luego
$A+B$ es compacto.

****** Demostracin de 4
Usando la continuidad de la suma y del producto por 
escalares:

\[(+)(\overline{M}\times\overline{M}) 
= (+)\overline{(M\times M)}
\subset \overline{(+)(M \times M)}\]
\[(*)(\mathbb{K}\times\overline{M})
= (*)\overline{(\mathbb{K}\times M)}
\subset \overline{(*)(\mathbb{K} \times M)}\]
      
****** Contraejemplo de suma de cerrados
La suma de dos cerrados puede no ser cerrado:

\[\left\{n + \frac{1}{n} \mid n \in \mathbb{N}\right\} + 
\left\{-n \mid n \in \mathbb{N}\right\} = 
\left\{\frac{1}{n} \mid n \in \mathbb{N}\right\}\]

***** Conexin de espacios normados
Todo espacio normado es *conexo* y *localmente arcoconexo*;
por tanto *arcoconexo*. De hecho, la bola unidad es *convexa*.

***** Espacios de Banach
Un *espacio de Banach* es un espacio normado completo.

**** Desigualdades bsicas
***** Desigualdad de Young
Para $a,b\in\mathbb{R}^+$ y $p>1$ con $\frac{1}{p}+\frac{1}{q} = 1$ se tiene:

\[ab \leq \frac{a^p}{p}+\frac{b^q}{q}\]

****** Demostracin
Se demuestra aplicando desigualdad de Taylor al logaritmo con 
pesos $1/p$ y $1/q$.

\[\log(ab) = \frac{1}{p}\log(a^p) + \frac{1}{q}\log(b^q) \leq 
\log\left(\frac{a^p}{p} + \frac{b^q}{q}\right)\]

***** Desigualdad de Hlder
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$ con $\frac{1}{p} +\frac{1}{q} = 1$ se verifica:

\[\sum a_kb_k \leq \left(\sum a_k^p\right)^{1/p}\left(\sum b_k^q\right)^{1/q}\]

****** Demostracin
Se demuestra aplicando Young a la divisin de ambos lados y
cuidando el caso $0$. Llamamos $\alpha = \left(\sum_k a^p_k\right)^{1/p}$, $\beta = \left(\sum_k \beta^q_k\right)^{1/q}$:

\[\frac{a_kb_k}{\alpha\beta}
\leq \frac{a_k^p}{p\alpha^p} + \frac{b_k^q}{q\beta^q}\]

Sumando cada desigualdad tenemos:

\[\frac{1}{\alpha\beta} \sum a_kb_k \leq 
\frac{1}{p\alpha^p}\sum a_k^p +
\frac{1}{q\beta^q}\sum b_k^q = 1\]

***** Desigualdad de Minkowski
Para $a_1\dots a_nb_1\dots b_n \in \mathbb{R}^+_0$, $p>1$, se verifica:

\[\left(\sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum_{k=1}^n a_k^p \right)^{1/p} + 
\left(\sum_{k=1}^n b_k^p \right)^{1/p} \]

Dicho de otra forma:

\[\|a+b\|_p \leq \|a\|_p + \|b\|_p\]

****** Demostracin
Aplicando Hlder con $p$, $1 - 1/p$ para tener:

\[\begin{aligned}
\left( \sum_{k=1}^n (a_k+b_k)^p \right)^{1/p} 
&=
\left( \sum_{k=1}^n (a_k+b_k)(a_k+b_k)^{p-1} \right)^{1/p}
\\&=
\left( \left( \sum_{k=1}^n a_k^p \right)^{1/p} + \left( \sum_{k=1}^n b_k^p \right)^{1/p} \right)
\left( \sum_{k=1}^n (a_k+b_k)^{\frac{p(p-1)}{p-1}} \right)^{1-1/p}
\end{aligned}\]

**** Ejemplos de espacios normados
***** Espacios de dimensin finita
Solemos notar por ${l}_p^n = (\mathbb{K}^n,\|.\|_p)$ al espacio de Banach sobre $\mathbb{R}^n$ o $\mathbb{C}^n$ 
que da la norma:

\[\|x\|_p = \left(\sum |x_{(k)}|^p \right)^{1/p}\]

Ntese el caso especial $l^n_\infty$ que da la norma del mximo.

****** Normas
Todas estas normas lo son gracias a la [[*Desigualdad de Minkowski][desigualdad de Minkowski]].

****** Equivalencia
Todas las normas son equivalentes y generan el mismo espacio de
Banach:

\[ \|x\|_\infty \leq \|x\|_p \leq \|x\|_1 \leq N \|x\|_\infty\]

******* Demostracin
Aplicamos la desigualdad de las medias.

***** Espacios de sucesiones
Las *sucesiones* tales que su p-suma es convergente,
con las normas $\|.\|_p$, dan los siguientes espacios de Banach:

\[\ell_p = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K} \,\middle|\,
\sum_{n=1}^\infty |x(n)|^p < \infty \right\}\]

siendo un caso particular el de la norma del supremo
sobre *sucesiones acotadas*:

\[{\cal \ell}_\infty = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ \left|\ x(n) \text{ acotada} \right\}\]

****** Forman un subespacio vectorial
Pasando la desigualdad de Minkowski al lmite, tenemos:

\[\left(\sum^\infty_{k=1} (a_k+b_k)^p \right)^{1/p} \leq 
\left(\sum^\infty_{k=1} a_k^p \right)^{1/p} + 
\left(\sum^\infty_{k=1} b_k^p \right)^{1/p} \]

Por tanto, es un subespacio vectorial y se obtiene una norma
como:

\[\|x\|_p = \left(\sum_{n=1}^\infty |x(n)|^p \right)^{1/p}\]

****** Son espacios de Banach
Como tenemos $|x_n(k)-x_m(k)| \leq \|x_n-x_m\|$, cuando $\{x_n\}$ es 
Cauchy en $\ell_p$, tambin es Cauchy $\{x_n(k)\}$. Y por tanto, es
convergente por componentes $x(k) = \lim_{n\to\infty}x_n(k)$.

Usamos $\{x_n\}$ de Cauchy para tener:

\[\exists n_0 : \forall m,n\geq n_0 :
\|x_n-x_m\| < \varepsilon\]

Es decir,

\[\sum_{k=1}^N |x_n(k)-x_m(k)|^p \leq (\|x_n-x_m\|_p)^p < \varepsilon^p\]

Tomando $m \to \infty$, y luego tomando $N \to \infty$:

\[\sum_{k=1}^\infty |x_n(k)-x(k)|^p \leq \varepsilon^p\]

As, tenemos que $x = x_n - (x_n-x) \in \ell_p$, y como $\|x_n-x\|_p \leq \varepsilon$,
tenemos $\{x_n\} \to x$.

***** Subespacios del espacio de sucesiones
El espacio de sucesiones cuenta con subespacios usando la misma 
norma:

****** Sucesiones convergentes
Es un subespacio de $\ell_\infty$ cerrado, y por tanto, de Banach.

\[c = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \text{ convergente } \right\}\]
 
****** Sucesiones nulas
Otro subespacio de $\ell_\infty$, tambin cerrado y por tanto, de Banach.

\[c_0 = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \{x(n)\} \longrightarrow 0 \right\}\]

****** Sucesiones casi-nulas o de soporte finito
Es un subespacio para todo $\ell_p$.

\[c_{00} = \left\{ x : \mathbb{N} \longrightarrow \mathbb{K}\ 
\left|\ \exists m: \forall n \geq m:\  x(n) = 0 \right\}\]

Este es un subespacio denso ya que toda sucesin es lmite de
sucesiones de soporte finito. Pero no es el total, as que no
ser completo.

***** Espacios de funciones continuas acotadas
Dado $T$ espacio topolgico, tomamos el espacio de funciones
continuas y acotadas:

\[{\cal C}_b(T) = \left\{f : T \longrightarrow \mathbb{K} \mid
f \text{ continua, acotada}\right\}\]

Y lo dotamos de la *norma del supremo*:

\[ \|f\|_\infty = \sup\{ |f(t)| \mid t \in T\}\]

Que da la *convergencia uniforme*.

****** Es espacio de Banach
Si tenemos $\{f_n\}$ de Cauchy, $\{f_n(x)\}$ es de Cauchy y converge a $f(x)$.
Como tenemos algn $n$ para el que $\forall p\geq n: \|f_n-f_p\|_\infty \leq \varepsilon$, entonces:

\[|f_n(x)-f_p(x)| \leq \|f_n-f_p\|_\infty \leq \varepsilon\]

Y tomando lmite en $p$ se tiene $|f_n(x) - f(x)| \leq \varepsilon$, luego
$\|f_n-f\|_{\infty} \leq \varepsilon$.

****** Anuladas en infinito
Sea $L$ compacto y separado. Una funcin se *anula en el infinito*
cuando:

\[\forall \varepsilon: 
\{t\in L \mid |f(t)|\geq\varepsilon\} 
\text{ es compacto}\]

Las funciones continuas que se anulan en el infinito forman 
${\cal C}_0(L)$, subespacio de ${\cal C}_b(L)$. Es espacio cerrado 
y por tanto de Banach.

****** Funciones de soporte compacto
El soporte de $f : L \longrightarrow \mathbb{K}$ para $L$ localmente compacto 
separado es:

\[sop(f) = 
\overline{\{t \in L \mid f(t) \neq 0\}} \subset
L \]

Las funciones con soporte compacto forman ${\cal C}_{00}(L)$, subespacio
vectorial de ${\cal C}_0(L)$.

****** Relacin entre ambas
Tenemos que ${\cal C}_{00}(L)$ no es completo en general y que:

\[\overline{{\cal C}_{00}(L)} = {\cal C}_0(L)\]

***** Espacios de funciones derivables
Consideraremos el espacio de funciones sobre un intervalo que sean $d$
veces derivables con derivadas continuas, ${\cal C}^n([a,b],\mathbb{K}^d)$. Escritas:

\[f^{k)} = \left(f^{k)}_1,f^{k)}_2,\dots,f^{k)}_d\right)\]

Sobre l defimos una norma del supremo sobre cada derivada
$\|f^{k)}\| = max \{\|f^{k)}_i\|_\infty\}$. La norma del espacio es la suma de la de 
cada una de las derivadas.

\[ \|f\|_\infty = \sum \|f^{k)}\|_\infty\]

****** Es espacio de Banach
Esto, por el *teorema de la convergencia uniforme* nos lleva a que una
sucesin de Cauchy converja de manera que respete la derivada. Este
ser un espacio de Banach.

***** Espacios de funciones integrables
Consideramos el *espacio de funciones p-integrables* como:

\[ L_p(\Omega) =
\left\{ f \in L(\Omega) \;\middle|\; \int_\Omega |f(t)|^p dt < \infty \right\}
\]

Normndolas con:

\[ \|f\|_p =
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}\]

Debemos /identificar funciones que coinciden c.p.d./ para
deducir $\|f\|_p = 0 \Rightarrow f = 0$. Estos espacios son siempre completos.

****** Desigualdades integrales de Hlder y Minkowski
A partir de la desigualdad de Young llegamos
a la *desigualdad integral de Hlder* para funciones
tales que $|f|^p, |g|^p$ son Lebesgue-integrables:

\[\int_\Omega |f(t)g(t)| dt \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p}
\left( \int_\Omega |g(t)|^q dt \right)^{1/q}\]

Y desde ella, la *desigualdad integral de Minkowski*:

\[\left( \int_\Omega |f(t) + g(t)|^p dt \right)^{1/p} \leq
\left( \int_\Omega |f(t)|^p dt \right)^{1/p} +
\left( \int_\Omega |g(t)|^p dt \right)^{1/p}\]

Esto nos da la naturaleza de norma.

****** Complitud en el caso real
Usando el Teorema de Riesz-Fisher.

***** Espacios de funciones esencialmente acotadas
Una funcin es *esencialmente acotada* cuando es $f : [0,1] \longrightarrow \mathbb{K}$:

\[\exists M: |f| \leq M \text{ c.p.d.}\]

Al espacio de funciones esencialmente acotadas lo llamamos ${\cal L}_\infty[0,1]$ y 
le damos una seminorma:

\[\phi_\infty(f) = \inf\{ M
 \mid |f|\leq M \text{ c.p.d.}\}\]

****** Naturaleza de seminorma
Se cumple por un lado que:

\[\phi_\infty(\alpha f) = |\alpha|\phi_\infty(f)\]

Y por otro lado que:

\[ \phi_\infty(f+g) \leq \phi_\infty(f) + \phi_\infty(g) \]

****** Estructura de espacio normado
Podemos convertirlo en espacio normado si tomamos cociente sobre:

\[ N = \{ f \in {\cal L}_\infty[0,1] \mid
\phi_\infty(f)=0 \} \]

Esto es espacio de Banach con la norma $\phi_\infty$.

**** Categora de espacios normados
***** Homomorfismos topolgicos
Los morfismos de la categora de espacios normados son los
*homomorfismos topolgicos*, operadores lineales y continuos que
adems son abiertos en su imagen. Hablamos igualmente de
*monomorfismos topolgicos*, *epimorfismos topolgicos* o de
*isomorfismos topolgicos*.

***** Producto de espacios normados
Dados $X_1,\dots,X_n$ espacios normados, podemos definir normas 
sobre su producto cartesiano $\prod X_i$:

 - *Norma del mximo*: $\|x\|_\infty = \max\{\|x_i\|\}$
 - *Norma p*: $\|x\|_p = (\sum \|x_i\|^p)^{1/p}$

****** Topologa del producto
La convergencia es trivialmente coordenada a coordenada, y
las topologas asociadas son equivalentes a la topologa
producto. El espacio es *Banach* ssi lo son las componentes.

***** Cociente de un espacio normado
Sea $M$ subespacio vectorial cerrado de $X$. Podemos hacer a $X/M$ 
normado con:

\[ \|x+M\| 
= \inf\left\{ \|x - m\| \mid m \in M \right\} 
= d(x,M)\]

****** Topologa del cociente
Este espacio es de Banach ssi $X$ es de Banach y $M$ completo. 
La topologa coincidir con la topologa cociente.

****** Proyecciones
La proyeccin $Q: X \longrightarrow X/M$ es lineal, sobreyectiva, abierta
y continua.

**** Operadores y funcionales lineales
***** Operadores lineales continuos
Para $T : X \longrightarrow Y$ lineal entre espacios normados, equivalen:

- $T$ lipschitziana
- $T$ uniformemente continua
- $T$ continua
- $T$ continua en $0$
- $\exists M: \|Tx\| \leq M\|x\|$
- $T$ preserva acotacin, $A$ acotado da $TA$ acotado
- $TB_X$ acotado
- $TS_X$ acotado

Y lo llamamos *operador lineal continuo*, $T \in L(X,Y)$.

****** Demostracin
******* Lipschitzianidad
La lipschitzianidad implica hasta la continuidad en $0$.

******* Continuidad en 0 implica acotacin
Si hay continuidad en $0$ existe $\|x\| < \delta \implies \|Tx\| \leq 1$. Tenemos
entonces:

\[ \left\|\frac{\delta}{\|x\|}x\right\| = \delta \implies
T\left( \frac{\delta}{\|x\|}x \right) \leq 1\]

Luego $\|Tx\| \leq \|x\|/\delta$.

******* Acotacin
La acotacin implica todo lo dems excepto lipschitzianidad.

******* Acotacin de la esfera implica lipschitzianidad.
Como tenemos $\frac{x-y}{\|x-y\|} \in S_X$, lo tenemos acotado por algn $\alpha$ y:

\[T(x-y) \leq \alpha\|x-y\|\]

Por lo tanto, es lispchiztiano.
****** Norma de operadores
Se define la *norma de operadores* como:

\[\begin{aligned}
\|T\| =& \sup_{x \in B_X}\left\{\|Tx\|\right\} \\
=& \sup_{x \in S_X}\left\{\|Tx\|\right\} \\
=& \min\{k \mid \|Tx\| \leq k\|x\| \}
\end{aligned}\]

Y cumple que $\|Tx\| \leq \|T\|\|x\|$.

******* TODO Est bien definida
***** Cuatro teoremas sobre la norma de operadores
Dados $X,Y$ espacios normados:

 1. $(L(X,Y),\|.\|)$ es espacio normado.
 2. $\{T_n\}\longrightarrow T$ ssi $\{T_n\}\longrightarrow T$ uniformemente en $B_X$.
 3. Si $Y$ es de Banach, $L(X,Y)$ es de Banach.
 4. Para $X \overset{T}\longrightarrow Y \overset{S}\longrightarrow Z$, se tiene $\|S \circ T\| \leq \|S\|\|T\|$.

****** Demostracin
******* Primer punto
La norma de operadores es norma porque hereda la desigualdad
triangular y la linealidad de la norma del espacio. Ntese
que si $\sup_{x \in B_X} \|Tx\|=0$, es porque $T = 0$.

******* Segundo punto
Ntese que la norma de operadores mide el supremo en la bola
unidad y por homotecias se extiende al espacio.

\[\begin{aligned}
\{T_n\} \longrightarrow T 
&\iff \{\|T_n-T\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in B_X}\{\|T_n(x) - T(x)\|\} \longrightarrow 0 
\\&\iff 
\sup_{x \in X}\left\{ \left\|T_n\left(\frac{x}{\|x\|}\right) - T\left(\frac{x}{\|x\|}\right) \right\|\right\}
\longrightarrow 0
\end{aligned}\]

******* Tercer punto
Sea $\{T_n\}$ Cauchy. Tenemos $\|T_p(x) - T_q(x)\| \leq \|T_p - T_q\|\|x\|$, por lo que
sabemos $\{T_n(x)\}$ Cauchy; por complitud  $\{T_n(x)\} \longrightarrow T(x)$. Es lineal:

\[T(\alpha x + \beta y) = 
\lim \left( \alpha T_n(x) + \beta T_n(y) \right)
\longrightarrow
\alpha T(x) + \beta T(y)
\]

Tomando lmites en la condicin de Cauchy, vemos que es acotada
la funcin $T_p - T$:

\[\|T_p(x) - T(x)\| \leq \varepsilon\]

Luego $T$ es lineal y continua. Y adems, $\{T_n\} \longrightarrow T$.

******* Cuarto punto
$\|S \circ T (x)\| \leq \|S\|\|T\|\|x\|$

***** Espacio dual topolgico
Sea $X$ normado, su *dual topolgico* es el espacio de funciones al
cuerpo con la norma de operadores:

\[ X^\ast = 
L(X,\mathbb{K}) 
= \left\{ f : X \longrightarrow \mathbb{K} \mid
f \text{ lineal y continua} \right\}
\]

***** Extensin desde un subespacio denso
Sea $M$ subespacio denso en $X$, para cada $T \in L(M,Y)$ existe
un $S \in L(X,Y)$ tal que $S|_M = T$ y $\|S\| = \|T\|$

****** Demostracin
Podemos extenderla por continuidad, y comprobamos que es lineal:

\[\begin{aligned}
S(\alpha x_n + \beta y_n) = 
T(\alpha x_n + \beta y_n) = 
\alpha Tx_n + \beta Ty_n 
\longrightarrow \alpha Sx_n + \beta Ty_n
\end{aligned}\]

Como la norma es continua y el supremo invariante a clausuras,
hay igualdad entre las normas.

***** Caracterizacin de operadores abiertos
Sea $T : X\longrightarrow Y$ lineal. Equivalen:

 - $T$ es abierta.
 - $T(B_X)$ es entorno de $0$.

****** Sobreyectividad
Una funcin lineal y abierta debe ser sobreyectiva ya que la imagen
es subespacio vectorial abierto, y por tanto el total.

****** Demostracin
Si es abierta, trivialmente $T(B_X)$ es abierto.

Sea $O \subseteq X$ abierto. Sea $x \in O$, con $B(x,r) \subseteq O$. Como $T(B_X)$ es entorno 
de $0$, tenemos $T(x) + T(B_X)r = T(B(x,r)) \subseteq T(O)$ entorno de $x$, por ser
la translacin y homotecia [[*Continuidad de homotecias y translaciones][homeomorfismos]].

***** Caracterizacin de operadores abiertos sobre la imagen
Sea $T : X \longrightarrow Y$ lineal. Equivalen:

 - $T$ abierta sobre $TX$.
 - $\exists r>0:\quad TX \cap rB_Y \subset TB_X$.
 - $\exists\alpha>0: \forall y\in TX: \exists x\in X: 
  \quad \|x\| \leq \alpha\|y\|$, cumpliendo $Tx = y$.

****** Demostracin
Aplicando la caracterizacin anterior a $TX$ tenemos que
equivalen el primer y segundo apartado.

Por el apartado 2, tengo que dado un $y$, $y\frac{\delta}{\|y\|} \in \delta B_Y$.
Por tanto, $\exists x: Tx = y \frac{\delta}{\|y\|}$. Tomamos $x' = x \frac{\|y\|}{\delta}$, y tenemos
que $T(x') = y$, y adems que $\|x'\| = \|x\|\frac{\|y\|}{\delta} \leq \frac{\|y\|}{\delta}$.

***** Descomposicin cannica: proyeccin al cociente
Sea $X$ un espacio normado, $M$ subespacio cerrado y $\pi$ la proyeccin.
Entonces $\pi \in L(X,X/M)$ es sobreyectiva y abierta, con $\|\pi\| = 1$ cuando
$M \neq X$.

****** Demostracin
******* Es continua
Por caracterizacin de [[*Operadores lineales continuos][operadores lineales continuos]]:

\[ \|\pi(x)\| = \|x+M\| \leq \|x\|\]

******* Tiene norma unidad
Para ver que tiene norma 1, tomamos $x_0 \notin M$.

\[\forall m \in M: \|x+M\| = \|\pi(x+m)\| \leq \|\pi\|\|x+m\|\]

En particular,

\[ \|x+M\| \leq \|\pi\| \inf\{\|x+m\|\} = \|\pi\|\|x+M\| \]

******* Sobreyectiva y abierta
Trivialmente es sobreyectiva. Usamos la caracterizacin de 
[[*Caracterizacin de operadores abiertos][operadores abiertos]], comprobando que:

\[\pi^{-1}(B(r,0)) = \{x \in X \mid \|x+m\| < r\} = \bigcup_{m \in M} B(r,m)\]

Por tanto, $B(r,0) \subseteq \pi(B(1,0))$ es un entorno de $0$ por contener un 
abierto.

***** Descomposicin cannica: isomorfismo
Sea $T: X\longrightarrow Y$ lineal con $\ker(T)$ cerrado. Se define:

\[\begin{tikzcd}
X \rar[two heads]{\pi} & X/\ker T \rar{\widehat T}[swap]{\cong} & \im T \rar[hook]{i} & Y
\end{tikzcd}\]

Y se tiene:

  - $\hat{T}$ continua ssi $T$ continua. En cuyo caso $\|T\| = \|\hat{T}\|$.
  - $T$ abierta en $TX$ ssi $\hat{T}$ abierta en $TX$.

****** TODO Demostracin
**** Teorema de Tychonoff. Dimensin finita
***** Lema a Tychonoff
Toda aplicacin lineal desde $\ell_2^n$ es continua.

****** Demostracin
Comprobamos que est acotada. Dada una base finita y las coordenadas
sobre ella:

\[
\|Tx\|
=
\left\|\sum_{k=1}^n T(e_k)x_k \right\| 
\leq 
\sum_{k=1}^n |x_k| \|T(e_k)\|
\leq
\|x\| \sum_{k=1}^n \|T(e_k)\|
\]

***** Teorema de Tychonoff
Sea $X$ espacio normado. Toda biyeccin lineal de $\ell^n_2$ sobre $X$ es 
isomorfismo topolgico.

****** Demostracin
Por el lema es continua. La esfera de $\ell^n_2$ es compacta; y podemos 
aplicar la caracterizacin de aplicaciones abiertas anterior.

***** Corolarios al teorema de Tychonoff
Se cumple que:

  1. $T:X\longrightarrow Y$ lineal con $dim(X) < \infty$ nos da $T$ lipschiztiana.
  2. Dos espacios de dimensin finita son isomorfos ssi tienen igual
     dimensin.
  3. En un espacio de dimensin finita, todas las normas son
     equivalentes.
  4. Todo espacio de dimensin finita es Banach.
  5. Todo subespacio de dimensin finita de espacio normado es cerrado.
  6. Un subconjunto de un espacio normado de dimensin finita es
     compacto ssi es cerrado y acotado.

****** Demostracin
******* Punto 1
Tenemos $X \cong \ell^n_2 \longrightarrow Y$, [[*Lema a Tychonoff][continua]].

******* TODO Punto 2

***** Dual topolgico en dimensin finita
Sea $X$ normado de dimensin finita, su *dual topolgico* es:

\[X^\ast =
\left\{ f:X \longrightarrow \mathbb{K} \mid
f \text{ lineal } \right\}\]

****** Demostracin
Toda lineal es continua si sale de dimensin finita.

***** Compacidad relativa y precompacidad
Llamamos $A$ *relativamente compacto* cuando $\overline{A}$ es compacto.
Llamamos $A$ *precompacto* cuando, dado un $\varepsilon$, existen $x_1,\dots,x_n$:

\[ A \subset \bigcup_{k=1}^n B(x_n,\varepsilon) \]

****** Cadena de implicaciones
Compacidad implica compacidad relativa, que a su vez implica
precompacidad, que implica acotacin.

****** Corolario de Tychonoff de compacidad
En un espacio normado de dimensin finita, un subconjuto es
relativamente compacto ssi es acotado y ssi es precompacto.

***** Corolario de caracterizacin de continuas
Sea $T : X \longrightarrow Y$ lineal con $TX$ de dimensin finita.
Equivalen:

  1. $T$ es continua.
  2. $\ker T$ cerrado en $X$.

****** Demostracin
Cuando $\ker T$ es [[*Descomposicin cannica: isomorfismo][cerrado]], $X/\ker T \cong TX$ dimensin finita. $\widehat T$ ser
continua.

***** Corolario de caracterizacin de abiertas
Sea $T : X \longrightarrow Y$ lineal con $X$ de dimensin finita.
Equivalen:

  1. $T$ es abierta.
  2. $T$ es sobreyectiva.

****** Demostracin
******* Primera implicacin
$TX$ sera abierto y [[*Corolarios al teorema de Tychonoff][cerrado]] a la vez.

******* Segunda implicacin
$T$ es continua, luego $\ker T$ [[*Corolario de caracterizacin de continuas][cerrado]]. $\widehat T : X/\ker T \cong Y$ biyeccin lineal,
que es por tanto isomorfismo topolgico y abierta.

***** Corolario de caracterizacin de la dimensin finita.
Equivalen:

  1. Todo cerrado y acotado es compacto.
  2. Bola unidad compacta.

**** Teorema de Riesz
***** Lema al teorema de Riesz
Sea $X$ espacio normado con $M$ subespacio propio cerrado. Si
$\varepsilon \in (0,1)$, existe $x \in \mathbb{S}_X$ tal que:

\[ \|x+M\| = d(x,M) > 1-\varepsilon \]

****** Demostracin
Sea $x_0 \notin X-M$. Por ser $M$ cerrado $d(x_0,M)>0$. Por ser
el nfimo, tengo que existe $m_0$ tal que:

\[\frac{1}{1-\varepsilon}\| x_0 - M\| > \| x_0-m_0 \| \]

Por tanto, tomando $x = \frac{x_0-m_0}{\|x_0-m_0\|} \in \mathbb{S}_X$, tenemos:

\[ \| x + M \| 
=  \left\| \frac{x_0-m_0}{\|x_0-m_0\|} + M \right\|
= \frac{\|x_0-M\|}{\|x_0-m_0\|} > 0\]

***** Teorema de Riesz
Son equivalentes:

1. $X$ de dimensin finita.
2. $X$ es localmente compacto.
3. $B_X$ es compacta.
4. $B_X$ es [[*Compacidad relativa y precompacidad][precompacta]].

****** Demostracin
1. Cuando la dimensin es finita, $X \cong \mathbb{K}^n$, que es localmente
   compacto.
2. Sea $U$ entorno compacto de $0$, $\exists r>0: \overline{B}(0,r) \subset U$. Por ser un cerrado
   en compacto, es compacto. Por homeomorfismo, lo es $B_X$.
3. Compacidad implica precompacidad.
4. Por ser $B_X$ precompacta,

   \[B_X \subseteq \bigcup B\left(x_i,\frac{1}{2}\right)\]
   
   Como $M = \langle x_1,x_2,\dots,x_k \rangle$ es de dimensin finita, es un subespacio 
   cerrado y propio en $X$. Por el lema de Riesz, existe $x_0 \in \mathbb{S}_X$ 
   tal que:

   \[ \|x_0 - x_i\| \leq d(x_0,M) > \frac{1}{2} \]
   
   Teniendo entonces $x \notin \bigcup B(x_i,\frac{1}{2})$, que nos lleva a 
   contradiccin.

*** 2. Principios fundamentales del anlisis funcional
**** Teorema de Hahn-Banach
***** Versin analtica de Hahn-Banach
Sea $M \subseteq X$ subespacio con $p$ sublineal y $g : M \longrightarrow \mathbb{K}$ lineal 
verificando:

\[Re(g(m)) \leq p(m)\]

Entonces existe $f : X \longrightarrow \mathbb{K}$ lineal extendindolo y verificando:

\[Re(f(x)) \leq p(x)\]

Cuando $p$ es [[*Seminorma][seminorma]], se tiene adems que $|f(x)|\leq p(x)$.

****** Demostracin
******* Primera extensin en los reales
En un primer caso, sea $\mathbb{K} = \mathbb{R}$. Podemos tomar $x_0 \notin X-M$, 
crear $Y = M\oplus x_0\mathbb{R}$ y extender como:

\[ f(m + \lambda x_0) = g(m) + \lambda\alpha\]

******* Elegir el coeficiente de la extensin
Nos falta elegir el $\alpha$. Sabemos que debe cumplir:

\[\alpha \leq \frac{1}{\lambda}\left( p(m+\lambda x_0) - g(m) \right)\]

Tomando un $\lambda$ positivo y negativo llegamos a dos 
condiciones:

\[ g(v) - p(v-x_0) 
\leq \alpha 
\leq p(u+x_0) - g(u)\]

Y tenemos un $\alpha$ cumpliendo esta condicin por ser 
equivalente a:

\[ g(u+v) \leq p(u+v) \leq p(u+x_0) + p(v-x_0)\]

Y lo sacamos partiendo la desigualdad, minimizando
y maximizando cada lado de la desigualdad, y dando
la vuelta a todas las desigualdades:

\[ g(u) - p(v-x_0) \leq \alpha \leq p(u+x_0) - g(u)\]

******* Lema de Zorn
Puedo ordenar las extensiones por inclusin, teniendo
adems que una cadena de extensiones tiene por maximal a
la unin de todos los espacios, con la funcin definida
por el primer conjunto en el que aparece el primer elemento.

Si $Y \neq X$ fuera el maximal, podra aadir $x_0 \in X-Y$ y
contravenir la maximalidad de $Y$ extendiendo una dimensin.

******* Caso complejo
Como todo espacio sobre los complejos lo es sobre los reales,
aplicamos el caso real a $g_0 = Re(g)$, y obtenemos $f_0$ cumplindolo
y siendo lineal en los reales.

Creo $f$ siendo lineal en los complejos como:

\[f(x) = f_0(x) - if_0(xi)\]

Que cumple las condiciones

******* Caso de la seminorma
Cuando $p$ es seminorma tengo, para $|\alpha|=1$ dando el giro
apropiado:

\[f(\alpha x) = |f(x)| = Re(f(\alpha x)) \leq p(\alpha x) = p(x)\]

***** Extensin equinrmica de Hahn-Banach
Sea $M \subseteq X$ subespacio vectorial, con $g \in M^\ast$. 
Existe $f\in X^\ast$ tal que $f|_M = g$ y $\|f\| = \|g\|$.

****** Demostracin
Sea $p(x) = \|g\|\|x\|$, es una seminorma y cumple $Re(g(m)) \leq p(x)$.
Por *Hahn-Banach*, tenemos una extensin $f$, cumpliendo $\|f\| \geq \|g\|$
por ser extensin y:

\[ \|f\| 
= \sup\left\{ \frac{|f(x)|}{\|x\|} \mid x\in X-\{0\}\right\} 
\leq \|g\|\]

***** Separacin en el dual topolgico
Sea $x_0 \in X$, entonces existe $f \in \mathbb{S}_{X^\ast}$, tal que $f(x_0) = \|x_0\|$.
En consecuencia:

 1. Si $x \neq y$, existe $f \in X^\ast: f(x) \neq f(y)$.
 2. $\forall x \in X: \|x\| = max_{f \in B_{X^\ast}} \{ |f(x)| \}$

****** Demostracin
Podemos aplicar Hahn-Banach a $g : x_0\mathbb{K} \longrightarrow \mathbb{K}$ con $g(\lambda x_0) = \lambda \|x_0\|$,
para obtener una extensin de norma $1$.

****** Corolario 1
Aplicamos el resultado para $f(x-y) = \|x-y\| = 0$.

****** Corolario 2
Tenemos $|f(x)| \leq \|x\|$. El mnimo se alcanza en un $f$ dado por
la proposicin.

***** Corolario para subespacios finitos
Sea $X$ un espacio normado $\{x_1,\dots,x_n\} \subseteq X$ linealmente independientes
y $\alpha_1,\dots,\alpha_n \in \mathbb{K}$, entonces existe $f \in X^\ast$ tal que $f(x_i) = \alpha_i$.

****** Demostracin
Puedo crear una funcin lineal, sobre $\langle x_1,\dots,x_n \rangle$ que lo cumpla.
Por venir de dimensin finita ser continua, as que podemos
aplicar Hahn-Banach para obtener una extensin.

***** Corolario: L(X,Y) es Banach ssi Y es Banach
El espacio $L(X,Y)$ con la norma de operadores es Banach ssi
el espacio $Y$ es Banach.

****** Demostracin
******* Primera implicacin
[[*Cuatro teoremas sobre la norma de operadores][Cuatro teoremas sobre la norma de operadores]]

******* Segunda implicacin
[[http://math.stackexchange.com/questions/1023681/y-is-a-banach-space-if-bx-y-is-a-banach-space][Y is a Banach space if B(X,Y) is a Banach spacea]]

**** Inyeccin cannica e isometras
***** Inyeccin cannica
Se define $J_X(x_0) : X^\ast \longrightarrow \mathbb{K}$ como:

\[J_X(x_0)(f) = f(x_0)\]

****** La inyeccin es isomtrica
Se verifica:

  1. $\forall x \in S_X: J_X(x)$ es lineal y de mdulo $1$.
  2. $J_X : X \longrightarrow X^{\ast\ast}$ es isomtrica y lineal.

******* TODO Demostracin
***** Completacin de un espacio
$X^\ast$ es completo para cualquier espacio normado $X$. Cuando $X$ no es 
completo, $J_X$ no es sobreyectivo y podemos completarlo como:

\[ X \subset \overline{J_X(X)} \]

Que lo ser por ser cerrado en $X^{\ast\ast}$, que s es completo.

***** Polar de un subespacio
Dado $M \subset X$, el *polar* de $M$ se define como:

\[M^0 = \left\{ f\in X^\ast \mid f(M) = \{0\} \right\}\]

****** Definicin equivalente
Para la restriccin $S : X^\ast \longrightarrow M^\ast$, $M^0 = \ker S$.

***** Primer teorema de isometra
Sea $M \subseteq X$ subespacio, \[\cdot|_M : {X^\ast}/{M^0} \longrightarrow M^\ast \] es biyeccin lineal 
isomtrica.

****** Demostracin
Tenemos $\|f|_M\| \leq \|f+M^0\|$, y hay igualdad por extensin 
equinrmica.

***** Segundo teorema de isometra
Sea $M\subseteq X$ subespacio vectorial cerrado. Para $\pi_{X/M}$ proyeccin, 
$\_ \circ \pi : (X/M)^\ast \longrightarrow M^0$ es una biyeccin lineal isomtrica.

****** Demostracin
Claramente es lineal. Tenemos que es lipschitziana por:

\[ \|T(f)\| = \| f \circ \pi \| \leq \|f\|\|\pi\| = \|f\| \]

Y por otro lado,

\[ \|T(f)\|\|x+m\| \geq 
\|T(f)(x+m)\| = 
\|f(x+M)\|\]

Por tanto, $\|T(f)\| \geq \|f\|$.

***** Funcin de aproximacin
Sea $M \subseteq X$ subespacio con $x_0 \in X-\overline{M}$. Existe $f\in X^\ast$ con $\|f\|=1$,
tal que $f \in M^0$ y $f(x_0) = d(x_0,\overline{M}) = d(x_0,M)$.

****** Demostracin
Como $\overline{M}$ es subespacio cerrado, tenemos $g \in (X/M)^\ast$ con $\|g\|=1$ y
$g(x_0+\overline{M}) = \|x_0+\overline{M}\|$. Entonces $T(g) \in \overline{M}^0$ y $T(g)(x) = g(x+\overline{M})$.
Tenemos $\|T(g)\|= \|g\|=1$ y $f(x_0) = g(x_0+\overline{M}) = \|x_0+\overline{M}\|$.

***** Clausura desde el polar
Sea $M \subseteq X$ subespacio. Entonces:

\[ \overline{M} = \bigcap_{f \in M^0} \ker(f)\]

***** Distancia a un kernel
Sea $X$ espacio normado, $f \in X^\ast - \{0\}$ y $x_0 \in X$. Entonces,

\[d(x_0,\ker(f)) = \frac{|f(x_0)|}{\|f\|}\]

****** Demostracin
Por el [[*Funcin de aproximacin][teorema de aproximacin]] con $M = \ker(f)$, tenemos una $g$ con
$\|g\| = 1$ tal que $g(x_0) = d(x_0,M)$; tenemos $\ker(f) \subseteq \ker(g)$.

\[\exists u\in X: f(u)=1\]. Para $x\in X$, tenemos $x -f(x)u \in \ker(f)$ y entonces:

\[ 0 = g(x-f(x)u) = g(x) - f(x)g(u)\]

Aplicando esto en $x_0$ tenemos $g(x_0) = g(u)f(x_0)$, que tomando mdulos,
nos da $\|g\| = \|f\| |g(u)|$.

**** Funcional de Minkowski
***** Funcional de Minkowski
Se define $p_U : X \longrightarrow \mathbb{R}^+$ para $U$ entorno de $0$ como:

\[ p_U(x) = \inf\{ \lambda \in \mathbb{R}^+_0 \mid x \in \lambda U\} \]

****** Sublinealidad
Para $U$ convexo, $p_U$ es sublineal.

***** Separacin de un punto
Sea $U$ entorno de $0$ convexo con $x_0 \notin U$, existe $f \in X^\ast$ tal que 
$Re(f(x)) \leq 1$ para todo $x \in U$; mientras $Re(f(x_0)) \geq 1$.

Se cumple adems:

\[ \{x \in X \mid p_U(x)<1\} \subset
U \subset
\{ x \in X \mid p_U(x) \leq 1\}\]

****** Demostracin
Tomamos $g : x_0\mathbb{R} \longrightarrow \mathbb{R}$ definido por $g(\alpha x_0) = \alpha p_U(x_0)$.
Aplicamos [[*Versin analtica de Hahn-Banach][Hahn-Banach]] sobre $x_0\mathbb{R}$ y tenemos un $f$ extensin de $g$
verificando que $f(x_0) = p_U(x_0) \geq 1$, y que para $x \in U$ se tiene 
$f(x) \leq p_U(x) \leq 1$.

Ahora para el caso complejo, tenemos $f_0$ lineal y continuo
cumpliendo que $f_0(x_0)\geq 1$, pero $f_0(x) \leq 1$ para todo $x \in U$.
Definimos $f(x) = f_0(x) - if_0(ix)$, y entonces es lineal en los
complejos cumpliendo lo pedido.

***** Separacin de convexos (para un abierto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ abierto. Existe $f \in X^\ast$ 
con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha \leq Re(f(b)) \quad \forall a \in A, b \in B\]

***** Existencia de funcionales de soporte
Sea $X$ normado, $A \subset X$ convexo cerrado con $\mathring{A} \neq \varnothing$. Para cada 
$x_0 \in Fr(A)$; existe $f \in X^\ast$ tal que:

  - $\|f\| = 1$
  - $Re(f(x_0)) = \max\{Re(f(x)) \mid x \in A\}$

****** TODO Demostracin

***** Separacin de convexos (para un compacto)
Sean $A,B \subset X$ convexos con $A \cap B = \varnothing$ con $A$ compacto y 
$B$ cerrado. Existe $f \in X^\ast$ con $\alpha \in \mathbb{R}$ tal que:

\[ Re(f(a)) < \alpha < Re(f(b)) \quad \forall a \in A, b \in B\]

****** TODO Demostracin

**** Lema de categora de Baire
***** Teorema de Baire
Sea $E$ espacio mtrico completo y $G_n \subset E$ abiertos densos.
$\bigcap_{n \in \mathbb{N}} G_n$ es denso.

****** Demostracin
Empezando con un abierto $G$ y con $G_1$, puedo a cada paso tomar el 
abierto anterior, tomar un abierto dentro de l como 
$\overline{B}(a_i,r_i) \subset G_i \cap B(a_{i-1},r_{i-1})$, y construir una sucesin $\overline{B}(a_n,r_n)$.

Esta sucesin podemos tomarla para que cumpla $\{r_n\} \to 0$. Desde
aqu tenemos que converge $\{a_n\} \to a \in \bigcap \overline{B}(a_n,r_n) \cap G$ por ser de 
Cauchy.

***** Corolario al teorema de Baire
Sea $E$ espacio mtrico completo y $F_n \subset E$ cerrados con:

\[E = \bigcup_{n \in \mathbb{N}} F_n\]

Entonces, $\exists n \in \mathbb{N}$ tal que $\mathring{F}_N \neq \varnothing$.

****** Demostracin
Aplicando el teorema de Baire en sus complementos.

***** Dimensin en espacios de Banach
Todo espacio de Banach tiene dimensin finita o no numerable.

****** Demostracin
Si fuera $X$ espacio de Banach con base numerable, cualquier
subespacio de dimensin finita sera cerrado, pero entonces,
tomando $F_n = \langle e_1,\dots,e_n \rangle$:

\[ X = \bigcup F_n \]

Luego para algn $n$, se tiene $\mathring{F_n} \neq \varnothing$; as que debe ser 
$X=F_n$.

**** Teorema de la aplicacin abierta
***** Teorema de la aplicacin abierta
Sean $X,Y$ Banach con $T \in L(X,Y)$ sobreyectiva. 
Entonces $T$ epimorfismo topolgico (abierta).

****** Demostracin
******* La imagen de bola tiene interior no vaco
Como $X = \bigcup_{n \in \mathbb{N}} n B_X$, tenemos que:

\[ Y 
= T\left(\bigcup_{n \in \mathbb{N}} n B_X \right)
= \bigcup_{n \in \mathbb{N}} n T(B_X) 
\subseteq \bigcup_{n \in \mathbb{N}} \overline{n T(B_X)}
= Y
\]

Aplicando corolario a Baire, $\exists N: \mathring{\overline{NT(B_X)}} \neq \varnothing$, luego
$\mathring{\overline{T(B_X)}} \neq \varnothing$. 

******* La imagen de la bola es entorno de 0
Sea ahora, $y_0 \in \mathring{\overline{T(B_X)}}$, se tendr que:

\[ 0 \in \mathring{\overline{T(B_X)}} - y_0
\subset \overline{T(B_X)} - \overline{T(B_X)}
\subset 2\overline{T(B_X)}\]

Siendo por tanto $\overline{T(B_X)}$ un entorno de 0.

******* Acotacin de la bola
Tenemos $\exists\delta > 0: \delta B_Y \subset \overline{T(B_X)}$, y en general:

\[ \forall n \in \mathbb{N}: \frac{\delta}{2^n}B_Y \subseteq \overline{T\left(\frac{1}{2^n}B_X\right)}\]

******* Sucesin
Tomamos $x_0 = 0$, $y \in \overline{T(\frac{1}{2}B_X)}$, y construimos sabiendo:

\[ y - T(x_i) \in
\frac{\delta}{2^i} B_Y \subseteq
T\left(\frac{1}{2^i} B_X\right)\]

Luego existe un $x_{i+1}$ verificando $\|x_{i+1}\|\leq \frac{1}{2^{i+1}}$ y que:

\[ \left\| y - \sum_{k=1}^{i+1} T(x_k) \right\| < \frac{\delta}{2^{i+2}} \]

******* La suma converge
Definimos la suma de la sucesin:

\[ S_n = \sum_{k=1}^n x_k \in X\]

Es de Cauchy por ser convergente $\sum_{n=1}^\infty \frac{1}{2^n}$. Por complitud,
converge, $S_n \to x$, con:

\[ \|S_n\| \leq \sum \|x_k\| \leq \sum \frac{1}{2^n} = 1 \]

Luego $\|x\| \leq 1$, $x \in B_X$. Como adems se tiene:

\[\| y - T(S_n) \| \leq  
\|y - \sum T(x_k) \| < 
\frac{\delta}{2^{n+1}} \]

Tenemos $\lim\{T(S_n)\} = T(x)$ y concluimos $y \in T(B_X)$.

******* Conclusin
Hemos probado $\overline{T(\frac{1}{2} B_X)} \subseteq T(B_X)$, y finalmente,

\[ \frac{\delta}{2} B_Y \subset \overline{T\left(\frac{1}{2} B_X\right)} \subset T(B_X)\]

As que $T(B_X)$ es un entorno de $0$ y $T$ es abierta.

***** Teorema de los isomorfismos de Banach
Sean $X,Y$ Banach con $T \in L(X,Y)$ biyectiva.
Entonces $T$ es isomorfismo topolgico.

****** Demostracin
Por [[*Teorema de la aplicacin abierta][teorema de la aplicacin abierta]] $T$ y $T^{-1}$ son abiertas;
luego $T^{-1}$ y $T$ son continuas.

***** Teorema del homomorfismo de Banach
Sean $X,Y$ espacios de Banach con $T \in L(X,Y)$. Ser homomorfismo 
topolgico ssi $TX$ es cerrado en $Y$.

****** TODO Demostracin
***** Equivalencia de normas en espacios de Banach
Sean $\|\cdot\|_1, \|\cdot\|_2$ dos normas en un espacio de Banach. Si cumplen que:

\[\exists M>0 : \|x\|_1 \leq M \|x\|_2\]

Entonces son equivalentes.

****** Demostracin
Sea $T(x)=x$ biyeccin lineal entre las dos normas. Es lipschitziana
por la condicin. Por el [[*Teorema de los isomorfismos de Banach][teorema de los isomorfismos de Banach]], es 
isomorfismo topolgico.

**** Teorema de la grfica cerrada
***** Grfica de una funcin
La *grfica* de una funcin $f$ se define como:

\[ Graf(f) = 
\{(x,f(x)) \mid x \in A\} \subseteq
A \times B\]

Una $T$ es lineal ssi $Graf(T)$ es subespacio vectorial, y
cuando $f$ es continua en Hausdorff, $Graf(f)$ es cerrada.

***** Teorema de la grfica cerrada
Sean $X,Y$ Banach con $T : X \longrightarrow Y$ lineal. Si la grfica 
de $T$ es cerrada, $T$ es continua.

****** Demostracin
Si tomamos $\|x+y\| = \|x\|+\|y\|$, que genera la topologa
producto en $X \times Y$, tenemos un Banach. Como $T$ es lineal,
$G(T)$ es subespacio lineal de $X \times Y$, y como $G(T)$ es cerrado,
es de Banach con la norma inducida.

Sea $\Phi : GT \longrightarrow X$ definida por:

\[ \Phi(x,Tx) = x\]

Como $\Phi$ es lineal, su restriccin es continua, lineal y biyectiva.
Por [[*Teorema de los isomorfismos de Banach][teorema de isomorfismo de Banach]], $\Phi^{-1}$ es continua; y entonces
$T = \pi_2 \circ \Phi^{-1}$ es continua.

***** Caracterizacin de la grfica cerrada en espacios normados
Sean $X,Y$ normados con $T: X \longrightarrow Y$ lineal. Equivalen:

- $T$ con grfica cerrada.
- Si $\{x_n\} \longrightarrow 0$ y $\{Tx_n\}\longrightarrow y$; entonces $y=0$. Cuasicontinuidad en 0.

****** TODO Demostracin

**** Teorema de Banach-Steinhaus
***** Teorema de Banach-Steinhaus para funcionales
Sea ${\cal A} \subset L(X,Y)$ para $X$ de Banach e $Y$ normado; una familia de 
operadores acotada puntualmente:

\[ \forall x : \exists M(x): \forall T \in A: \quad \|T(x)\| \leq M(x)\]

Entonces est acotada:

\[\exists M : \forall T \in A: \quad \|T\| \leq M \]

****** Demostracin
Tomamos $F_n$ como interseccin de conjuntos que son cerrados
por la continuidad de $T$:

\[F_n = \bigcap_{T \in {\cal A}} \{ x \in X \mid \|Tx\| \leq n\}\]

Como est acotada puntualmente, $\bigcup F_n = X$; as que aplicamos
el [[*Corolario al teorema de Baire][corolario a Baire]] para tener un $\mathring{F_N} \neq \varnothing$. Eso quiere decir
que $\exists a: \exists r: a + rB_X \subseteq F_n$. Para $T \in {\cal A}$ se tiene:

\[\begin{aligned}
\|Tx\| =& \frac{1}{r} \| T(a+rx) - Ta\| \\
\leq& \frac{1}{r} (\| T(a+rx) \| + \|Ta\|) \\
\leq& \frac{N}{r} + \|Ta\|\frac{1}{r} \\ 
\leq& \frac{N}{r} + M(a)\frac{1}{r}
\end{aligned}\]

Acotacin independiente de $X$.

***** Teorema del cierre de Steinhaus
Sea $X$ de Banach, $Y$ normado, y una sucesin $\{T_n\} \in L(X,Y)$ 
convergiendo puntualmente. La convergencia puntual da un operador 
lineal y continuo:

\[ T(x) = \lim_{n \longrightarrow \infty} T_n(x) \in L(X,Y)\]

****** Demostracin
La linealidad se tiene trivialmente:

\[ T(\alpha x_1 + \beta x_2) 
= \lim T_n (\alpha x_1 + \beta x_2)
= \alpha T(x_1) + \beta T(x_2) \]

Como $\{T_n\}$ es una familia acotada puntualmente por converger
puntualmente, se tiene por [[*Teorema de Banach-Steinhaus para funcionales][Banach-Steinhaus]] que est acotada.

Entonces para $x \in B_X$, tenemos $\|T_n(x)\| \leq M$, as que:

\[ \|\lim T_n(x)\| =
\lim \|T_n(x)\| \leq M\]

Luego $\|T(x)\| \leq M$, y por estar acotada en la bola unidad
y ser lineal, $T$ es continua.

***** Corolario a Banach-Steinhaus para el dual
Sea $X$ espacio de Banach y $A \subseteq X^\ast$, equivalen:

1. $A$ acotado, $\exists M>0: \forall f \in A: \|f\| \leq M$
2. $A$ puntualmente acotado, $\forall x\in X: \{f(x) \mid f \in A\}$ acotado.

****** Demostracin
Por [[*Teorema de Banach-Steinhaus para funcionales][teorema Banach-Steinhaus]] con $X^\ast = L(X,\mathbb{K})$ se tiene
la segunda implicacin. La primera se tiene simplemente por
tenerse:

\[ \|f(x)\| \leq \|f\|\|x\| \leq M \|x\| \]

***** Corolario a Banach-Steinhaus para el doble dual
Sea $X$ espacio normado con $A \subseteq X$. Equivalen:

1. $A$ acotado.
2. $\{ f(x) \mid x \in A\}$ acotado para cualquier $f \in X^\ast$.

****** Demostracin
Sabemos $J_X$ isometra, luego $J_X(A)$ est acotado. Como 
la acotacin equivale a la acotacin puntual, para cualquier
punto del espacio $f \in X^\ast$ se tiene acotado:

\[ \{J_X(x)(f) \mid x \in A \} \]

*** 3. Espacios de Hilbert I
**** Espacios prehilbertianos
***** Producto escalar
Sea $H$ un K-espacio vectorial. Un producto escalar es: $\langle \cdot,\cdot\rangle : H \times H \longrightarrow \mathbb{K}$
cumpliendo:

  1. $\langle \alpha u + \beta v, w\rangle = \alpha\langle u,w \rangle + \beta\langle v,w \rangle$, lineal en la primera variable.
  2. $\langle u,\alpha v + \beta w\rangle = \overline{\alpha}\langle u,v\rangle + \overline{\beta}\langle u,w\rangle$, conjugadalineal en la segunda variable.
  3. $\langle u,v \rangle = \overline{\langle v,u \rangle}$, hermtica.
  4. $\langle u,u \rangle \geq 0$, definida positiva.
  5. $\langle u,u \rangle = 0$ ssi $u=0$, no nula.

****** Observaciones
Cuando $\mathbb{K}=\mathbb{R}$, 3 es conmutatividad; cuando $\mathbb{K}=\mathbb{C}$, implica que 4 est 
bien definido por ser $\langle u,u \rangle$ real.

***** Espacio prehilbertiano
Llamamos espacio prehilbertiano a un espacio vectorial dotado de un 
producto escalar.

***** Ejemplos de espacios prehilbertianos
****** Espacio eucldeo complejo
Para el espacio $\mathbb{C}^n$:

\[\langle (x_1,\dots,x_n), (y_1,\dots,y_n) \rangle =
\sum_{i=0}^n x_i\overline{y_i} \]

****** Espacio de sucesiones
Para el espacio $\ell^2$, de sucesiones de cuadrado sumable:

\[\langle \{x_i\},\{y_i\} \rangle = \sum^\infty_{n=0} x_n\overline{y_n}\]

Ntese que es sumable por tenerse $2|x_n||y_n| \leq |x_n|^2+|y_n|^2$.

****** Espacio de funciones continuas
Para ${\cal C}([0,1],\mathbb{K})$ funciones continuas:

\[
\langle f,g \rangle = \int_{[0,1]} f\overline{g}
\]

****** Espacio de funciones de cuadrado integrable
Para funciones de cuadrado integrable $L^2(\mu)$, tenemos:

\[\langle f,g \rangle = \int_\Omega f\overline{g} \;d\mu\]

Donde por Hlder tenemos la integrabilidad:

\[
\int_\Omega |f\overline{g}| \;d\mu \leq
\sqrt{
\int_\Omega |f|^2 d\mu
}
\sqrt{
\int_\Omega |g|^2 d\mu
}
\]

***** Desigualdad de Cauchy-Schwarz
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[ |\langle u,v \rangle| \leq \|u\|\|v\|
\]

Con caso de igualdad $u = v$.

****** Demostracin
Elevando al cuadrado los dos nmeros positivos:

\[\begin{aligned}
0 
&\leq 
\|u\|^2\|v\|^2 - 2|\langle u,v \rangle|^2  + |\langle u,v \rangle|^2
\\ 0 &\leq
\|v\|^2 - \frac{2|\langle u,v \rangle|^2}{\|u\|^2}  + \frac{|\langle u,v \rangle|^2}{\|u\|^2}
\\ 0 &\leq
\left\langle 
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v,
\frac{\overline{\langle u,v \rangle}}{\|u\|^2}u + v
\right\rangle
\end{aligned}\]

***** Desigualdad de Minkowski
Para $H$ prehilbertiano, si notamos $\|u\| = \sqrt{\langle u,u \rangle}$,

\[
\| u + v \| \leq \|u\| + \|v\|
\]

****** Demostracin
Desarrollando llegamos a $\langle u,v \rangle + \langle v,u \rangle \leq 2\|u\|\|v\|$, que es cierto por:

\[
\langle u,v \rangle + \langle v,u \rangle \leq
2Re(\langle u,v \rangle) \leq 
2|\langle u,v \rangle| \leq
2 \|u\|\|v\|
\]

Aplicando Cauchy-Schwarz en la ltima desigualdad.

***** Espacio prehilbertiano es normado
Todo espacio prehilbertiano es normado con norma:

\[
\| u \| = \sqrt{\langle u,u \rangle}
\]

****** Cumple propiedades de la norma
Tenemos trivialmente:

  1. $\|u\| = 0 \iff u =0$
  2. $\|\alpha u\| = |\alpha| \|u\|$
  3. $\|u+v\| \leq \|u\|+\|v\|$

Donde la ltima se deduce de la desigualdad de Minkowski.

***** El producto escalar es continuo
En un espacio prehilbertiano:

\[\{u_n\} \longrightarrow u, \{v_n\} \longrightarrow v 
\implies
\{ \langle u_n, v_n \rangle\} \longrightarrow \langle u,v \rangle\]

****** Demostracin
Se tiene:

\[\begin{aligned} |\langle u_n,v_n \rangle - \langle u,v \rangle| 
&\leq |\langle u_n-u,v \rangle| + |\langle u,v_n-v \rangle| \\
&\leq \|u_n-u\|\|v\| + \|u\|\|v_n-v\| \longrightarrow 0
\end{aligned}\]

**** Identidades de polarizacin
***** Identidades de polarizacin
Sea $H$ prehilbertiano:

  1. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right)$, cuando $\mathbb{K} = \mathbb{R}$.
  2. $\langle u,v \rangle = \frac{1}{4}\left( \|u+v\|^2 - \|u-v\|^2 \right) + \frac{i}{4}\left( \|u+iv\|^2 - \|u-iv\|^2 \right)$, cuando $\mathbb{K} = \mathbb{C}$.

****** Demostracin
La segunda es trivial calculando y la primera es un caso particular.

***** Identidad del paralelogramo
Sea $H$ normado, es prehilbertiano ssi se verifica:

\[
\|u+v\|^2 + \|u-v\|^2 = 2\left( \|u\|^2 + \|v\|^2\right)
\]

Con el producto escalar dado por la [[*Identidades de polarizacin][identidad de polarizacin]]:

\[ \langle u,v\rangle = 
\frac{1}{4}\left(\|u+v\|^2-\|u-v\|^2 \right) +
\frac{i}{4}\left(\|u+iv\|^2-\|u-iv\|^2 \right)
\]

****** Demostracin
Cuando es prehilbertiano, se verifica la ecuacin trivialmente.
Cuando se verifica la ecuacin, podemos ver que la identidad de 
polarizacin nos da un producto escalar que es conjugadolineal,
hermtico, definido positivo y no nulo.

# En cul de estas comprobaciones se usa paralelogramo?
# Parecen largas de comprobar.

***** Ejemplos de normados prehilbertianos
****** Contraejemplo: funciones continuas con el mximo
El espacio ${\cal C}[0,1]$ con la norma del mximo no es prehilbertiano.
Hay un contraejemplo a la identidad del paralelogramo en $f(t) = 1$ y
$g(t) = t$.

****** Espacio de sucesiones de cuadrado sumable
El espacio $\ell_p$ es prehilbertiano ssi $p=2$, con:

\[\|x\| = \left(\sum_{i=1}^\infty |x_n|^2 \right)^{1/2}\]

******* Demostracin
Se cumple que:

\[
\sum_{n=1}^k |a_n + b_n|^2 + \sum_{n=1}^k |a_n-b_n|^2
= 2\left(\sum_{n=1}^k |a_n|^2+|b_n|^2\right)
\]

Y tomando lmites tenemos lo pedido.

**** Espacios de Hilbert
***** Espacios de Hilbert
Un espacio prehibertiano completo es un espacio de Hilbert.
Equivalentemente, un espacio de Banach con norma asociada a un producto
escalar.

***** Hilbert de dimensin finita
Todo prehilbertiano de dimensin finita es Hilbert.

****** Demostracin
Todo espacio normado de dimensin finita es de Banach.

***** Complecin de prehilbertianos
La completacin de un espacio prehilbertiano es espacio de Hilbert.

****** Demostracin
La [[*Completacin de un espacio][completacin]] restringida al espacio orginal tiene su norma. Y la
norma es [[*Continuidad de la norma, suma y producto][continua]]. Por tanto, ser prehilbertiano al cumplir la
[[*Identidad del paralelogramo][identidad del paralelogramo]]:

\[
\lim_{n \to \infty} \|u_n+v_n\|^2 + \|u_n-v_n\|^2
=
2\left(\|\lim_{n \to \infty} u_n\|^2+\|\lim_{n \to \infty} v_n\|^2\right)
\]

**** Ortogonalidad
***** Ley de los cosenos
La ley de los cosenos puede reinterpretarse como una definicin del
ngulo para espacios distintos de $\mathbb{R}^2$.

\[
cos(\theta) = \frac{\langle u,v \rangle}{\|u\|\|v\|}
\]

***** Ortogonalidad
Dos vectores se dicen *ortogonales* $u \perp v$ cuando su producto escalar 
es nulo:

\[\langle u,v \rangle = 0\]

***** Espacio ortogonal
Para $H$ hilbertiano, $S \subseteq H$; definimos el ortogonal de $S$ como:

\[
S^\perp = \left\{
u \in H \mid \forall s \in S: u \perp s
\right\}
\]

***** Propiedades del espacio ortogonal
Para $0 \subset S \subset H$, tenemos:

  1. $0 \in S^\perp$.
  2. $S \cap S^\perp \subseteq \{0\}$.
  3. $\{0\}^\perp = H$, $H^\perp = \{0\}$.
  4. $S_1 \subseteq S_2 \implies S_1^\perp \supseteq S_2^\perp$.
  5. $S^\perp$ es subespacio vectorial cerrado.
  6. $S \subseteq S^{\perp\perp}$.
 
****** Demostracin
Triviales. La quinta se tiene por ncleo de una funcin lineal y
continua.

***** Suma directa
Sea $X$ normado con $M,N$ subespacios. Se dice que hay suma directa
$X = M \oplus N$, cuando:

  1. $X = M + N$
  2. $M \cap N = \{0\}$

***** Suma directa topolgica
Se dice que hay suma directa topolgica cuando $M \oplus N$ cumplen que
$x_n = m_n + n_n$ respeta la convergencia $x = m + n$ con $m \in M, n \in N$.

****** Suma directa topolgica en Banach
En un espacio de Banach, la suma directa es topolgica cuando
ambos espacios $M,N$ son cerrados.

***** Lema de aproximacin ptima
Sea $S$ un cerrado y convexo de $H$ prehilbertiano. Hay un slo elemento
en el conjunto que realiza la mnima norma.

\[\exists! s_0 \in S:\quad \|s_0\| = \min\{\|s\| \mid s\in S\}\]

****** Demostracin
******* Existencia
Sea $t$ el nfimo. Por convexidad tenemos: $\|\frac{1}{2}(u+v)\| \geq t$. Dada una
sucesin $\{\|s_n\|\} \longrightarrow t$; vemos que es de Cauchy:

\[\begin{aligned}
\|s_n-s_m\|^2 &\leq \|s_n+s_m\|^2 + \|s_n-s_m\|^2 - 4t^2 \\&=
2(\|s_n\|^2 -t^2) + 2(\|s_m\|^2 - t^2) \longrightarrow 0
\]

Luego converge en el cerrado.

******* Unicidad
Si hubiese dos mnimos, se tendra:

\[
\|s+s'\|^2 + \|s-s'\|^2 = 2\left(\|s\|^2 + \|s'\|^2 \right) 
= 4t^2 \leq \|s+s'\|^2
\]

Por lo que $\|s-s'\| = 0$.

***** Teorema de la aproximacin ptima
Sea $H$ Hilbert, $M \subseteq H$ subespacio cerrado y $u \in H$. Entonces, existe 
una nica mejor aproximacin a $M$, esto es:

\[\exists! \pi_M(u) \in M:\quad d(u, \pi_M(u)) = d(u,M) \]

****** Demostracin
Aplicaremos el [[*Lema de aproximacin ptima][lema de aproximacin ptima]] a $u+M$. Tenemos que probar
que es convexo, y para ello:

\[\lambda (u+m) + (1-\lambda)(u+m') = u + m\lambda + m'(1-\lambda) \in u+M\]

Sea $s_0 \in u+M$ la mnima norma en $u+M$:

\[ \|s_0\| = \min\{\| u + m \| \mid m \in M\}\]

Tomamos $\pi_M(u) = u - s$, y tenemos:

\[ \| u - \pi_M(u)\| = \|s \| \leq \|u + m\|\]

La unicidad la da la unicidad en el lema de aproximacin ptima.

**** Proyecciones y proyeccin ortogonal
***** Proyecciones
Sea $H$ Hilbert y $p : H \longrightarrow H$ lineal. Se llama proyeccin cuando $p \circ p = p$.

***** Suma directa de una proyeccin
Sea $p:H \longrightarrow H$ proyeccin, entonces $H = \ker(p) \oplus \im(p)$.

****** Demostracin
Para $h \in H$ tenemos la descomposicin $p(h) + (h-p(h))$. Dado $p(g) \in \ker(p)$,
se tiene $p(g) = p(p(g)) = 0$.

***** Proyecciones ortogonales
Se dice proyeccin ortogonal a una proyeccin $p$ en la que $\ker(p) \perp \im(p)$.

***** Lemas al teorema de la proyeccin ortogonal
Sea $H$ Hilbert y $M$ subespacio cerrado. Entonces:

  1. $u-\pi_M(u) \in M^\perp$.
  2. $\pi_M(\alpha u) = \alpha \pi_M(u)$.
  3. $\pi_M(u + v) = \pi_M(u)+\pi_M(v)$.
  4. $\pi_M(\pi_M(u)) = \pi_M(u)$.

****** Demostracin
******* Punto 1
Para cualquier $t \in \mathbb{R}$ y $m \in M$ tenemos:

\[
0 \leq 
\| u - \pi u + tm \| - \| u - \pi u \| \leq
2t\; Re \langle u-\pi u, m\rangle + t^2 \|m\|^2
\]

Pero para que esto sea cierto, debe ser $Re \langle u-\pi u, m \rangle = 0$.
Tomando $im$ se tiene la parte imaginaria tambin nula, luego
debe ser $\langle u-\pi u, m \rangle = 0$.

******* Punto 2
Tenemos:

\[
\| \alpha u - m \| 
= |\alpha| \left\|u - \frac{m}{\alpha}\right\| \geq |\alpha| \|u- \pi u\|
\]

Dndose la igualdad con $m = \alpha \pi u$.

******* Punto 3
La ortogonalidad del primer punto:

\[
\|u + v - m\| = 
\|(u -\pi u) + (v - \pi v) - \widetilde m\| =
\|u - \pi u+  v - \pi v \| + \|\widetilde m\|
\]

Para el mnimo debe tenerse $\widetilde m = 0$.

******* Punto 4
Usando de nuevo la ortogonalidad del primer punto:

\[
\pi_M(u) - \pi_M\pi_M(u) \in M^\perp \cap M = \{0\}
\]

***** Teorema de la proyeccin ortogonal
Para $H$ Hilbert y $M$ subespacio cerrado:

  1. $H = M \oplus M^\perp$.
  2. La proyeccin a $M$ es la aproximacin ptima.
  3. $\|u\|^2 = \|\pi_M(u)\|^2 + \| u - \pi_M(u) \|^2$.

Anlogamente, $\pi_{M^\perp}$ da la aproximacin ptima a $M^\perp$.

****** Demostracin
Por el [[*Lemas al teorema de la proyeccin ortogonal][lema]] sabemos que $\pi_M$ es una proyeccin. Como adems tiene 
$\ker(\pi_M) = M^\perp$ e $\im(\pi_M) = M$, se tiene que es la buscada.

Por ser ortogonales:

\[
\|u\|^2 = 
\|u - \pi_M(u) + \pi_M(u)\|^2 =
\|u-\pi_M(u)\|^2 + \|\pi_M(u)\|^2
\]

***** Nota: Unicidad de la descomposicin ortogonal
Sea $H = M \oplus N$ con $\langle m, n \rangle = 0$ para $m \in M,\; n \in N$. Se tiene que $N = M^\perp$.

****** Demostracin
Tenemos $N \subseteq M^\perp$ y adems, para $m+n \in M^\perp$, se tiene 
$0 = \langle m, m+n \rangle = \|m\|^2$, luego $m = 0$.

***** Corolario: clausura del doble ortogonal
Para $H$ Hilbert, $M$ subespacio, $M^{\perp\perp} = \overline{M}$.

****** Demostracin
El espacio puede partirse de dos formas distintas como suma ortogonal 
de cerrados:

\[ H = \overline{M} \oplus \overline{M}^\perp \]
\[ H = M^{\perp\perp} \oplus M^{\perp}\]

Como $M^\perp = \overline{M}^\perp$, debe ser $\overline{M} = M^{\perp\perp}$.

***** Corolario: caracterizacin de la densidad
Para $H$ Hilbert, $M$ subespacio, $M$ es denso ssi $M^\perp = \{0\}$.

****** Demostracin
Si es denso, $M^\perp = \overline{M}^\perp = \{0\}$. 
Si $M^\perp = \{0\}$, tenemos $H = \overline{M} \oplus \{0\}$.

***** Teorema de Lindestrauss-Tzafriri
Un espacio de Banach es Hilbert ssi todo subespacio cerrado suyo admite
un complemento topolgico. Es decir, para cada $M$ cerrado hay un $N$ cerrado
tal que:

\[
X = M \overset{t}{\oplus} N
\]

****** TODO Demostracin

**** Teorema de Riesz-Frechet
***** Recordatorio: por Teorema de Hahn-Banach
Sea $X$ espacio normado sobre $\mathbb{K}$. Entonces $\exists f: X \longrightarrow \mathbb{K}$ lineal y continua
no nula. Adems, dado $x \in X\setminus\{0\}$, tenemos $\exists f \in X^\ast: f(x) \neq 0$. De hecho,

\[
\|x\| = \sup\{ |f(x)| \mid f \in X^\ast \}
\]

****** Demostracin
Hemos reenunciado la [[*Separacin en el dual topolgico][separacin en el dual topolgico]], que era 
consecuencia de la [[*Versin analtica de Hahn-Banach][versin analtica de Hahn-Banach]].

****** Relacin en el caso prehilbertiano
Cada vector tiene asociada una funcin lineal y continua en el dual
dada por su producto escalar: $v \mapsto \langle \cdot,v \rangle$.

***** Teorema de Riesz-Frchet
Sea $H$ Hilbert y $f : H \longrightarrow \mathbb{K}$ lineal y continuo. Existe un nico $v \in H$ 
tal que:

\[f(u) = \langle u,v \rangle\]

De otra forma, $v \mapsto \langle \cdot,v \rangle$ es una biyeccin conjugada-lineal de $H$ en $H^\ast$.

****** Demostracin
******* Existencia: caso nulo
En el caso $f=0$, simplemente tomamos $v=0$.

******* Existencia: caso general
Dado $f$, $\ker(f)$ ser propio, luego necesitamos $\ker(f)^\perp$ espacio propio
para que la suma directa sea el total. Sea $w \in \ker(f)^\perp$ no nulo, tenemos:

\[
0 = \langle f(u)w - f(w)u , w \rangle = \|w\|^2f(u) - f(w)\langle u,w \rangle
\]

Por lo que tenemos:

\[
f(u) = \left\langle u, \frac{f(w)}{\|w\|^2} w \right\rangle
\]

******* Unicidad: caso nulo
Debe ser un vector en $H^\perp = \{0\}$.

******* Unicidad: caso general
Simplemente notando que $f(u) = \langle u,v \rangle = \langle u,w \rangle$ nos dara $\langle u,v-w \rangle = 0$.
Un vector perpendicular a todo el espacio es nulo.

***** Corolario: el dual es de Hilbert
Si $H$ es Hilbert, $H^\ast$ con la norma de operadores es de Hilbert.

****** Demostracin
Tomamos como producto escalar:

\[
\langle f_v,f_w \rangle = \langle w,v \rangle
\]

Y comprobamos que cumple los axiomas. Ntese que es necesario invertir
el orden para que sea hermtico. Por otro lado, la norma es la misma
que la norma de operadores:

\[ \sqrt{\langle f_v,f_v \rangle} = \|v\|
\]

mientras que si $\|u\| = 1$, por Cauchy-Schwarz hay caso de igualdad en:

\[ |f_v(u)| = |\langle u,v \rangle| \leq \|v\|\]

***** Corolario: el doble dual es Hilbert
Si $H$ es Hilbert, $H^{\ast\ast}$ es Hilbert.

****** Demostracin
Componemos dos veces lo que hemos hecho con el dual. Tenemos una
biyeccin lineal en este caso.

***** Corolario: completacin de prehilbertianos
Si $H$ es prehilbertiano, $H^{\ast\ast}$ es su completacin.

****** Demostracin
Veremos que si $\widehat H$ es su completacin, $H^\ast \cong \widehat{H}^\ast$, por lo que tendr que
tenerse $H^{\ast\ast} \cong \widehat{H}^{\ast\ast} \cong \widehat{H}$.

Pero $H^\ast \cong \widehat{H}^\ast$ es cierto simplemente porque la nica extensin continua y
la restriccin sern inversas.

***** Corolario: extensin nica
Sea $H$ Hilbert con $M \subset H$ subespacio y $f \in M^\ast$. Existe una nica extensin
lineal y continua cumpliendo:

\[ \|f_H\| = \|f\| \]

****** Demostracin
******* Existencia
Podemos extender la funcin de $M$ a $\overline{M}$ por continuidad. Como es cerrado
y subespacio de Hilbert, ser Hilbert. Entonces aplicamos Riesz-Frechet
para tener que la funcin ser de la forma $f(x) = \langle x,m \rangle$ para algn
$m \in M$. Ahora, $f_m = \langle \cdot,m \rangle$ es extensin y cumple:

\[
\|f_m\| = \|m\| = \|f\|
\]

******* Unicidad
Si hubiera otra extensin $\langle \cdot,u \rangle$, se tendra $\langle \cdot,m \rangle - \langle \cdot,u \rangle = 0$ en $M$. 
Y entonces, $m - u \in M^\perp$, lo que implicara:

\[ \|u\|^2 = \|m\|^2 + \|m-u\|^2 \geq \|m\|^2\]

Con caso de igualdad slo si $\|m-u\| = 0$.

 - [[http://math.stackexchange.com/questions/332350/hilbert-spaces-and-unique-extensions-of-linear-functions][functional analysis - Hilbert spaces and unique extensions of
   linear functions. - Mathematics Stack Exchange]]

*** 4. Espacios de Hilbert II
**** Convergencia dbil
***** Convergencia dbil
En $H$ Hilbert, se dice que $\{u_n\}$ converge dbilmente a $u$ cuando:

\[\{u_n\} \overset{w}\longrightarrow u 
\iff \forall v \in H: \{\langle u_n,v \rangle\} \longrightarrow \langle u,v \rangle \]

De otra forma, $\forall f \in H^\ast: \{f(u_n)\} \longrightarrow f(u)$.

****** Unicidad del lmite dbil
La unicidad se tiene porque si $\forall v: \langle u,v \rangle = \langle u',v \rangle$, entonces $f_u = f_{u'}$,
que por [[*Teorema de Riesz-Frechet][Riesz-Frechet]] nos da $u = u'$.

***** Convergencia implica convergencia dbil
En $H$ Hilbert, la convergencia implica la convergencia dbil: 

\[\{u_n\} \longrightarrow u \implies \{u_n\} \overset{w}\longrightarrow u\]

****** Demostracin
Trivial por continuidad del producto escalar.

****** Contraejemplo del recproco
En el espacio de sucesiones cuadrado sumables $\ell_2$, sabemos que los
trminos de toda sucesin tienden a $0$, por eso:

\[ \{e_n\} \overset{w}\longrightarrow 0\]

Pero no se tiene $\{e_n\} \longrightarrow 0$.

***** Compacidad dbil
Un conjunto es dbilmente compacto si toda sucesin suya tiene una
parcial dbilmente convergente.

***** Compacidad de la bola unidad
Sea $H$ Hilbert, entonces la bola $\overline{B(0,1)}$ es dbilmente compacta.

****** TODO Demostracin

***** Espacio vectorial topolgico
Un espacio vectorial topolgico es un espacio vectorial con una topologa
que hace continuos a la norma y el producto por escalares.

**** Ortonormalidad
***** Ortogonalidad y ortonormalidad
Sea dice $S \subset H$ ortogonal cuando $\forall u,v \in S: \; u \perp v$. Se dice que es adems
ortonormal cuando $\forall u \in S : \|u\| = 1$.

***** Independencia de ortogonales
Si hay un conjunto ortogonal $S$, es linealmente independiente.

****** Demostracin
Supongamos que tenemos $e_1,\dots,e_n \in S$ y una combinacin lineal suya.
Entonces para cada $e_k$:

\[
0 = \left\langle \sum \alpha_i e_i, e_k \right\rangle
= \alpha_k \|e_k\| = \alpha_k
\]

***** Gram-Schmidt
Sea $H$ prehilbertiano de dimensin $n$, finita:

  1. $\{e_1,\dots,e_n\}$ ortogonal $\implies$ $\{e_1,\dots,e_n\}$ base
  2. Existe una base ortonormal.

****** Demostracin
******* Punto 1
Son linealmente independientes y generan un espacio de dimensin $n$,
que debe ser el total.

******* Punto 2
Sabemos que existe una base $u_1,\dots,u_n$, podemos generar una base
ortonormal tomando a cada paso:

\[ e_i = u_i - \sum_{j < i} \langle u_i,e_j \rangle e_j\]

Para tener una base ortogonal. Dividiendo por la norma para tener una
base ortonormal.

***** Base ortonormal finita
Sea $e_1,\dots,e_n$ una base ortonormal de un Hilbert. Cada elemento puede
escribirse en coordenadas de sus productos escalares:

\[
u = \sum_{i=1}^n \langle u,e_i \rangle e_i
\]

Y su norma ser:

\[
\|u\| = \sqrt{\sum^n_{i=1} |\langle u,e_i \rangle|^2}
\]

****** Demostracin
Si escribimos las coordenadas $u = \sum \alpha_ie_i$ tenemos que $\alpha_i = \langle u,e_i \rangle$.
La norma se obtiene desde la descripcin de coordenadas por 
ortonormalidad.

**** Familias sumables
***** Familia sumable
Sea $X$ normado y $\{x_i\}_{i\in I}$ familia; se dice sumable si:

\[\exists x \in X: 
\forall \varepsilon > 0:
\exists J_\varepsilon:
\forall J \text{ finito} \supseteq J_\varepsilon: 
\quad
\left\|\; \sum_{i \in J} x_i - x \;\right\| < \varepsilon
\]

Llamamos suma de la familia a $\sum_{i \in I} x_i = x$.

****** Redes
Ntese que esto es una generalizacin del concepto de sucesin.
Las [[https://es.wikipedia.org/wiki/Red_(matem%25C3%25A1tica)][redes]] son una generalizacin de las secuencias para una
cantidad no numerable de elementos.

# Quiz podramos ver que toda red es Cauchy ssi es convergente.
# Eso nos ahorrara las demostraciones posteriores de familias sumables.

***** Unicidad de la suma
La suma de una familia sumable es nica.

****** Demostracin
Si tuviera dos sumas $x$ y $x'$, tomaramos los $J_\varepsilon, J_\varepsilon'$ para tener:

\[
\| x - x' \| \leq
\left\| x - \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i \right\| +
\left\| \sum_{x_i \in J_\varepsilon \cup J_\varepsilon'} x_i - x' \right\|
\leq 2\varepsilon
\]

***** Propiedades de las familias sumables
Sea $X$ normado con $\{x_i\}_{i \in I}$ familia con suma $x$:

  1. $\sum_{i \in I} x_{\sigma(i)} = x$, para cualquier permutacin $\sigma$.
  2. $\sum_{i \in I} \alpha x_i + \beta y_i = \alpha x + \beta y$, siendo la suma lineal.
  3. $\sum_{i \in I} Tx_i = Tx$, para $T$ lineal continua.

****** Demostracin
Ntese que cuando coinciden en subsumas finitas, deben coincidir
en la suma total, por definicin.

******* Punto 1
Trivial por la definicin.

******* Punto 2
Tomando el conjunto $J_{\frac{\varepsilon}{2\alpha}}^x \cup J_{\frac{\varepsilon}{2\beta}}^y = K$, tenemos que:

\[ \left\| \alpha x + \beta y - \left(\sum_{i \in K} \alpha x_i + \beta y_i \right)\right\| 
\leq |\alpha| \left\| x - \sum_{i \in K} x_i \right\| + |\beta| \left\|y - \sum_{i \in K} y_i \right\| 
\leq \varepsilon\]

******* Punto 3
Si tomo unos $\varepsilon \longrightarrow 0$ tendr:

\[
\left\| Tx - \sum_{i \in J_\varepsilon} Tx_i \right\| = 
\left\| T\left( x - \sum_{i \in J_\varepsilon} x_i \right) \right\| \leq
\|T\|\varepsilon \longrightarrow 0
\]

***** Caracterizacin de familia sumable real
En los reales positivos, una familia $\{r_i\}_{i \in I} \in \mathbb{R}^+$ es sumable ssi:

\[\sup\left\{\;
\sum_{i \in J} r_i \;\middle|\; J \;\mtext{ finito } \subset I
\;\right\} < \infty\]

donde adems, $\sum_{i \in I} r_i$ es el supremo.

****** Demostracin
Por la definicin de supremo, dado cualquier $\varepsilon$ podemos encontrar:

\[s \geq \sum_{J} r_i \geq \sum_{J_\varepsilon} r_i\]

Cumpliendo por tanto para $J_\varepsilon \subset J$:

\[ 
\left|s - \sum_J r_i\right| \leq 
\left|s - \sum_{J_\varepsilon} r_i \right| \leq
\varepsilon\]

***** Condicin de Cauchy en familias sumables
Una familia $\{x_i\}_{i \in I}$ verifica la condicin de Cauchy cuando:

\[\forall \varepsilon > 0:
\exists J_\varepsilon \text{ finito}:
\forall J \text{ finito}: J \cap J_\varepsilon = \varnothing \implies
\left\|\; \sum_{i \in J} x_i \;\right\| < \varepsilon\]

***** Toda sumable es Cauchy
Si $\{x_i\}_{i \in I}$ es sumable, verifica la condicin de suma de Cauchy.

****** Demostracin
Suponiendo que suman $s$, podemos tomar $J_\varepsilon$ cumpliendo que, dado $J \cap J_\varepsilon = \varnothing$:

\[
\left\|\; s - \sum_{J_\varepsilon \cup J} x_i \;\right\| < \varepsilon
\]

Y por tanto, aplicando Minkowski:

\[
\left\|\; \sum_{J} x_i \;\right\|
\leq
\left\|\; \left(s - \sum_{J_\varepsilon} x_i \right) - \sum_J x_i \;\right\| +
\left\|\; s - \sum_{J_\varepsilon} x_i \; \right\|
\leq
2\varepsilon
\]

***** Toda Cauchy en un Hilbert es sumable
Si $\{x_i\}_{i \in I} \in H$ Hilbert verifica la condicin de suma de Cauchy, 
es sumable.

****** Demostracin
Primero tomamos la sucesin de Cauchy siguiente, que por complitud
del espacio es convergente:

\[
\left\{
\sum_{i \in J_{\frac{1}{n}}} x_i
\right\}
\longrightarrow
s
\]

Tenemos, para $J \supseteq J_{\frac{1}{n}}$, para $n$ suficientemente grande, que:

\[
\left\|\sum_{i \in J} x_i - s \right\| \leq
\left\|\sum_{i \in J} x_i - \sum_{i \in J_{\frac{1}{n}}} x_i \right\| +
\left\|\sum_{i \in J_{\frac{1}{n}}} x_i - s \right\| \leq 
\frac{1}{n} + \varepsilon
\]

Siendo por tanto sumable.

***** Numerabilidad de familias de Cauchy
Toda familia de Cauchy tiene $\{ i \in I \mid x_i \neq 0\}$ numerable.

****** Demostracin
Si verifica Cauchy, para cada $n$ podemos tomar, $J_n$ tal que 
para $J \cap J_n =\varnothing$:

\[\left\| \sum_{J} x_i \right\| \leq \frac{1}{n}\]

Si tenemos un $x \notin J_n$ para todo $n$, debe cumplir $\|x\| < \frac{1}{n}$, luego $x = 0$.
Como $\bigcup_{n \in \mathbb{N}} J_n$ es numerable. El conjunto de elementos no nulos es 
numerable.

***** Sumable es esencialmente numerable
En un espacio normado cualquiera equivalen:

  1. $\{x_i\}_{i \in I}$ sumable.
  2. $I_0 = \{ i \in I \mid x_i \neq 0\}$ numerable y para toda biyeccin $G : \mathbb{N} \longrightarrow I_0$:

     \[\sum_{i \in I_0} x_i = \sum_{n \in \mathbb{N}} x_{G(n)}\]

****** Demostracin
******* Primera implicacin
Si es sumable cumple la condicin de Cauchy y por tanto,
su conjunto de elementos no nulos es numerable.

Adems, si suma $s$, fijado $\varepsilon$, tengo un conjunto finito $J$.
Como $\{0,1,\dots,\max_{j \in J}\{G(j)\},\dots,m\} \supseteq G(J)$, se tiene:

\[
\left\| s - \sum_{i=0}^m x_{G(i)} \right\| \leq \varepsilon
\]

Por lo que la suma converge a $s$ para cualquier biyeccin.

******* TODO Segunda implicacin
# Me gustara probar que la convergencia incondicional da la convergencia
# absoluta, y entonces usar directamente la convergencia absoluta para
# probar que es sumable.

***** Corolario: convergencia conmutativa
Cuando $I = \mathbb{N}$, ser sumable equivale a converger conmutativamente,
esto es:

\[
\sum_{k \in \mathbb{N}} x_k = \sum_{k \in \mathbb{N}} x_{\sigma k}
\]

****** Demostracin
Por el [[*Sumable es esencialmente numerable][teorema]] anterior.

***** Corolario: suma de particiones
En $X$ Banach, $I = \bigcup_{\lambda \in \Lambda} I_\lambda$ particin arbitraria nos da que si $\{x_i\}_{i \in I}$
es sumable, $\{x_i\}_{i \in I_\lambda}$ es sumable; adems:

\[ \sum_{i\in I} x_i = \sum_{\lambda \in \Lambda} \left(\sum_{i \in I_\lambda} x_i \right)\]

****** TODO Demostracin

**** Familias absolutamente sumables
***** Familia absolutamente sumable
Una familia $\{x_i\}_{i \in I}$ es absolutamente sumable cuando $\{\|x_i\|\}_{i \in I}$ es sumable
en $\mathbb{R}^+$:

\[
\sup_{J \subseteq I} 
\left\{ 
\sum_J \|x_i\| \;\middle|\; J \text{ finito}
\right\} < \infty
\]

***** Criterio de Abel
Sea $X$ Banach, $\{x_i\}_{i \in I} \in X$ y $\|x_i\| < |\alpha_i|$ cumpliendo $\sum |\alpha_i| < \infty$. Entonces
$\{x_i\}$ es sumable con:

\[
\left\|\sum_{i \in I} x_i\right\| \leq \sum_{i \in I} |\alpha_i|
\]

****** TODO Demostracin
***** Absolutamente sumable implica sumable
En particular, absolutamente sumable implica sumabilidad en Banach, con:

\[
\left\|\sum x_i\right\| \leq \sum \|x_i\|
\]

****** Demostracin
Trivialmente desde el [[*Criterio de Abel][criterio de Abel]].

**** Familias ortonormales
***** Suma ortogonal
Sea $\{e_i\}_{i\in I}$ familia ortogonal en un espacio de Hilbert $H$. Entonces
$\{e_i\}_{i \in I}$ es sumable ssi $\{\|e_i\|^2\}_{i \in I}$ es sumable en $\mathbb{R}^+$, en cuyo caso:

\[
\left\| \sum_{i \in I} e_i \right\| = \sqrt{\sum_{i \in I} \|e_i\|^2}
\]

****** Demostracin
Coinciden en cualquier suma finita:

\[
\left\|\; \sum_{i \in I} e_i \;\right\|^2 = \sum_{i \in I} \|e_i\|^2
\]

Por lo tanto, coinciden sobre la condicin de Cauchy.

***** Corolario: suma ortogonal con coeficientes
Sea $\{e_i\}_{i \in I}$ familia ortonormal con $f : H \longrightarrow \mathbb{K}$ aplicacin. Entonces
$\{f(e_i)e_i\}$ es sumable ssi $\{|f(e_i)|^2\}$ es sumable en $\mathbb{R}^+$; en cuyo caso:

\[
\left\| \sum_{i \in I} f(e_i) e_i \right\| =
\sqrt{\sum_{i \in I} |f(e_i)|^2}
\]

****** Demostracin
Trivial desde lo anterior viendo $\{f(e_i)e_i\}$ como familia ortogonal.

***** Corolario: suma ortogonal con productos escalares
Sea $H$ Hilbert, $\{e_i\}_{i \in I}$ familia ortonormal. Para $u \in H$ se tiene que
$\{\langle u,e_i \rangle e_i\}$ es sumable ssi $\{|\langle u,e_i \rangle|^2\}$ es sumable en $\mathbb{R}^+$.

****** Demostracin
Caso particular de lo [[*Suma ortogonal][anterior]] con $f(x) = \langle u,x \rangle$.

***** Desigualdad de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, entonces existe la suma siguiente
y est acotada:

\[
\sum_{i \in I} |\langle u,e_i \rangle|^2 \leq
\|u\|^2
\]

****** Demostracin
En el caso finito:

\[
0 \leq
\left\| u - \sum_{J} \langle u,e_i \rangle e_i \right\|^2 =
\|u\|^2 - \sum_J \langle u,e_i \rangle^2 - \sum_J |\langle u,e_i \rangle|^2  + \sum_{J} \langle u,e_i \rangle^2
\]

Por tanto:

\[\sum_J |\langle u,e_i \rangle|^2 \leq \|u\|^2\]

Pero como estamos estudiando sumabilidad en los reales, basta haber
encontrado una cota sobre el [[*Caracterizacin de familia sumable real][supremo]] para acotar la suma.

***** Corolario de Bessel
Sea $\{e_i\}_{i \in I}$ ortonormal en $H$ Hilbert, y sea $M$ el subespacio cerrado 
generado: $M = \overline{lin\{e_i \mid i \in I\}}$. Dado $u \in H$, la mejor aproximacin de $u$ a $M$ 
es:

\[ \pi_M(u) = \sum_{i \in I} \langle u,e_i \rangle e_i
\]

En consecuencia se tiene:

\[
\|u\| 
= 
\sqrt{\;\sum_{i \in I} |\langle u,e_i \rangle|^2 + 
\left\|u - \sum_{i \in I} \langle u,e_i \rangle e_i\right\|^2\;}
\]

Y adems, equivalen:

  1. \[u \in M\]
     
  2. \[u = \sum \langle u,e_i \rangle e_i\]
     
  3. \[\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2\]

****** Demostracin
******* Existe la suma
Por desigualdad de Bessel, comprobando la igualdad de ambas sumas
en los casos finitos, tenemos que existe la suma:

\[
\left\|\; \sum_{i \in I} \langle u,e_i \rangle e_i \;\right\|= 
\sqrt{\sum_{i \in I} |\langle u,e_i \rangle|^2} \leq \|u\|
\]

Ya que es una suma de positivos acotada. Ambas sumas cumplen
la misma condicin de [[*Corolario: suma ortogonal con productos escalares][Cauchy]].

******* Hay ortogonalidad
Tomamos $m = \sum_{i \in I} \langle u,e_i \rangle e_i$, y comprobamos que $u - m \in M^\perp$. Como la
familia ortonormal genera el espacio, basta comprobar que es 
ortonormal a ella:

\[
\langle u-m,e_k \rangle = 0
\]

Por tanto, tenemos una descomposicin $u = m + (u-m)$ y por teorema
de la [[*Teorema de la proyeccin ortogonal][proyeccin ortogonal]], $m$ es la mejor aproximacin, y se tiene
la igualdad dada.

******* Equivalencias
Cuando $u \in M$, l mismo es su mejor aproximacin y su norma puede
calcularse directamente. La igualdad de normas implica que la
norma de $u-m$ sea $0$, haciendo $u \in M$.
***** Existencia de familias ortonormales maximales
Existen sistemas ortonormales maximales.

****** Demostracin
Lema de Zorn.

***** Caracterizacin de bases ortonormales
En $H$ Hilbert equivalen:

  1. $u = \sum \langle u,e_i \rangle e_i$ para cualquier $u$.
  2. $\langle u,v \rangle = \sum \langle u,e_i \rangle \langle e_i,v \rangle$, identidad de Parseval.
  3. $\|u\|^2 = \sum_{i \in I} |\langle u,e_i \rangle|^2$.
  4. $\{e_i\}$ sistema ortonormal maximal.
  5. $\forall e_i : v \perp e_i \implies v =0$.
  6. $H = \overline{lin\{e_i\}}$

****** Demostracin
Directamente desde el corolario de Bessel en el caso de $M$ denso,
donde no hay ningn ortonormal a l. Podemos comprobar la implicacin
en cada uno de los puntos.

**** Bases de Hilbert
***** Base de Hilbert
Se llama base de Hilbert a una familia ortonormal maximal.

****** Desarrollo en serie de Fourier
Una familia ortonormal maximal debe tener un subespacio cerrado
generado que sea [[*Corolario: caracterizacin de la densidad][denso]], ya que si no fuera as, tendra un $M^\perp$ no 
nulo. Por tanto cumple el corolario a Bessel y se tiene:

\[ u = \sum_{i \in I} \langle u,e_i \rangle e_i\]

llamada *Serie de Fourier*.

***** Dimensin Hilbertiana
El cardinal de las bases de Hilbert de un espacio es inveriante y
se llama *dimensin Hilbertiana*.

****** Demostracin
[[http://math.stackexchange.com/questions/232166/showing-the-basis-of-a-hilbert-space-have-the-same-cardinality][Showing the basis of a Hilbert Space have the same cardinality]].

***** Isomorfa entre espacios de igual dimensin
Dos espacios de Hilbert con la misma dimensin Hilbertiana son
topolgicamente isomorfos.

****** Demostracin
Dado un isomorfismo entre las bases, definimos la aplicacin lineal
que extiende el isomorfismo. Por el desarrollo en serie de Fourier,
sabemos que es equinrmica y por tanto continua.

Por el Teorema de los [[*Teorema de los isomorfismos de Banach][isomorfismos de Banach]], son isomorfos 
topolgicamente.

**** Operadores adjuntos
***** Operadores adjuntos
Dado $T \in L(H_1,H_2)$ entre espacios de Hilbert, existe:

\[\exists! T^\ast \in L(H_2,H_1):  \langle Tx,y \rangle = \langle x,T^\ast y\rangle\]

Llamado el *operador adjunto*.

****** Demostracin
Por Riesz-Frchet, tenemos una aplicacin $T^\ast y$ nica cumpliendo:

\[\langle T \cdot, y \rangle = \langle \cdot , T^\ast y \rangle\]

******* Es lineal
La funcin es lineal ya que, aplicando unicidad de Riesz-Frchet:

\[
\langle \cdot, T^\ast( \alpha y + y') \rangle =
\langle T \cdot, \alpha y + y' \rangle =
\overline{\alpha} \langle T \cdot, y \rangle + \langle T \cdot, y' \rangle =
\langle \cdot, \alpha T^\ast y + T^\ast y' \rangle
\]

******* Es continuo
La continuidad se tiene por acotacin en la bola unidad:

\[
\| T^\ast y \|^2 \leq \|y\| \|TT^\ast y\| \leq \|T\| \|T^\ast y\|
\]

***** Propiedades de operadores adjuntos
Los adjuntos cumplen:

  1. $T^{\ast\ast} = T$.
  2. $\|T\| = \|T^\ast\| = \|TT^\ast\|^{1/2} = \|T^\ast T\|^{1/2}$.
  3. $(T_1+T_2)^\ast = T_1^\ast+T_2^\ast$
  4. $(\alpha T)^\ast = \overline{\alpha}T^\ast$.
  5. $(RT)^\ast = T^\ast R^\ast$.

****** Demostracin
******* Punto 1
Aplicando unicidad de Riesz-Frechet a:

\[\overline{\langle y, T\cdot \rangle} = \overline{\langle y, T^{\ast\ast} \cdot \rangle}\]

******* Punto 2
Tenemos $\|T\| = \|T^{\ast\ast}\| \leq \|T^\ast\| \leq \|T\|$, como acotamos anteriormente.

Adems, tenemos doble acotacin para los dos operadores:

\[\|TT^\ast\| \leq \|T\|\|T^\ast\| = \|T\|^2\]
\[\|Tx\|^2 \leq \|x\|^2 \|TT^\ast\|\]

******* Puntos 3, 4 y 5
Trivialmente por linealidad, usando la unicidad de Riesz-Frechet.

***** Relacin con el adjunto
Sea $T \in L(H,H)$; se cumple:

  1. $\ker T^\ast = T(H)^\perp$.
  2. $\ker T = T^\ast(H)^\perp$.
  3. $T^\ast$ inyectivo $\iff$ $T(H)$ denso.

****** Demostracin
******* Punto 1 y 2
Trivial por doble inclusin y por reflexividad del adjunto.

******* Punto 3
Uniendo las condiciones de densidad y ortogonalidad con la 
caracterizacin de inyectividad por ncleo nulo.

***** Operador autoadjunto
Un operador $T \in L(H,H)$ es autoadjunto si $T^\ast = T$.

***** Propiedades de los autoadjuntos
Para $T \in L(H)$:

  1. $TT^\ast,T^\ast T, T+T^\ast$ son autoadjuntos.
  2. $T$ autoadjunto da $\alpha T$ autoadjunto.
  3. $\{ T = T^\ast\}$ es cerrado.
  4. Todo operador se divide en dos partes real e imaginaria:

     \[R = \frac{T+T^\ast}{2}\qquad S = \frac{T-T^\ast}{2}\]

**** Espectro y operadores compactos
***** Espectro
El espectro de un operador es el conjunto de valores propios,
llamamos:

****** Espectro

\[G(T) = \{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ invertible}\}\]

****** Espectro puntual

\[
G_p(T) =
\{
\lambda \in \mathbb{C} 
\mid
T - \lambda I \text{ no inyectivo}
\}
\]

****** Espectro comprimido

\[G_{com}(T) 
= 
\{\lambda \in \mathbb{C} \mid T - \lambda I \mbox{ con imagen no densa}\}
\]

****** Espectro aproximado

\[G_{ap}(T) =
\{\lambda \in \mathbb{C} \mid T-\lambda I \mbox{ no acotado por debajo}\}
\]

****** Relacin
Equivalen ser invertible a tener imagen densa y estar acotado por 
debajo. As,

\[G(T) = G_{com}(T) \cup G_{ap}(T)\]

Adems, en *dimensin finita* y en compactos, equivalen inyectividad, 
sobreyectividad y biyectividad, luego:

\[G(T) = G_p(T)\]

******* TODO Demostracin

***** Rango de un operador
El rango de $T$ es $n$ cuando puede escribirse con $u_i,w_i \in H$:

\[T = \sum u_i \otimes w_i\]

Es decir, como una matriz finita de ese rango.

****** Operadores de rango finito son compactos
Los operadores de rango finito son compactos.

******* Demostracin
En dimensin finita las bolas son compactas. Al ser continuo,
la sucesin imagen es siempre acotada y con parcial convergente.

***** Operador compacto
Si $T \in L(H)$ es compacto si para cualquier acotada, la $\{T(u_n)\}$ tiene
una parcial convergente.

****** Caracterizacin de compactos
Un $T$ es compacto ssi $T(\overline{B(0,1)})$ es compacto.

****** Compactos como lmite de los de rango finito
Los operadores de rango finito son compactos. De hecho, son su clausura.
Si tenemos:

 - \[KL(H) = \{T: H\longrightarrow H \mid \mbox{ compacto}\}\]
 - \[FL(H) = \{T : H\longrightarrow H \mid \mbox{ rango finito}\}\]

Se cumple $\overline{FL(H)} = KL(H)$.

******* TODO Demostracin

****** El adjunto de un compacto es compacto
Si tenemos $T = \lim T_n$, con $T_n = \sum u_i \otimes w_i$. Podemos comprobar que
el adjunto es lmite de $T_n^\ast = \overline{\sum w_i \otimes u_i}$, de rango finito.

***** Teorema de la aplicacin espectral
Para $H$ Hilbert, un polinomio no constante puede aplicarse a operadores
para tener:

\[G(p(T)) = \{p(\lambda) \mid \lambda \in G(T)\}\]

***** Teorema del ncleo
Si $T \in L(H)$ compacto, $\ker(T - \lambda I)$ tiene dimensin finita.

****** TODO Demostracin
***** Teorema del rango
Si $T \in L(H)$ compacto, $\im(T-\lambda I)$ es cerrado.

****** TODO Demostracin
***** Biyectividad en compactos
Si $T \in L(H)$ compacto, para $\lambda \neq 0$, $T-\lambda I$ es inyectivo ssi es 
sobreyectivo ssi es biyectivo.

\[G(T) \setminus \{0\} 
=
G_p(T) \setminus \{0\}
= 
G_{ap}(T) \setminus \{0\}
\]

***** Alternativa de Fredholm
Sea $T \in L(H)$ compacto y $\lambda \neq 0$. Consideramos las ecuaciones:

  1. $(T - \lambda I)x = 0$.
  2. $(T^\ast - \overline{\lambda} I)z = 0$.
  3. $(T-\lambda I)x = y$.
  4. $(T^\ast - \overline{\lambda} I)z = w$.

Y sabemos que se cumple una de estas dos alternativas:

  - O bien $x=0,z=0$ son las nicas soluciones de 1 y 2; en
    cuyo caso 3 y 4 tienen solucin nica, que adems depende 
    continuamente.
  - O bien hay soluciones no nulas de 1 y 2 y entonces 3 tiene
    solucin si $y \perp \ker(T^\ast - \overline{\lambda} I)$ y 4 tiene solucin si $w \perp \ker(T-\lambda I)$.

****** Alternativamente
En resumen, para $T$ compacto:

  - $img(T - \lambda I) = \ker(T^\ast - \lambda I)^\perp$.
  - $img(T^\ast - \lambda I) = \ker(T-\lambda I)^\perp$.

Y si uno es nulo ambos lo son.

****** Demostracin
******* Caso sin valor propio
Si $\lambda \notin G(T)$, entonces es invertible, as como su adjunta.

******* Caso con valor propio
Si $\lambda \in G(T)$, entonces $\ker(T-\lambda I) \neq 0$ y $\ker(T^\ast-\lambda I) \neq 0$, porque
para compactos coinciden los espectros. Se tiene adems:

  - $y \in img(T - \lambda I) = (\ker(T^\ast-\lambda I)^\perp)$
  - $w \in img(T^\ast - \lambda I) = (\ker(T-\lambda I)^\perp)$

***** Diagonalizacin de autoadjuntos compactos
Sea $T \in L(H)$, compacto y autoadjunto, entonces es *diagonalizable*.
Hay una base ortonormal con \[\lambda_n \longrightarrow 0\] de vectores propios, teniendo
convergencia uniforme sobre los compactos:

\[Tu = \sum \lambda_i \langle u,e_i \rangle e_i\]

Teniendo $G_p(T) \setminus \{0\} = \{\lambda_1,\dots,\lambda_n\}$, y coincide la dimensin del 
espacio propio y el nmero de veces que aparece $\lambda_i$.

**** Extra
***** Extra: El espectro de un autoadjunto es real
***** Extra: El espectro del adjunto es el conjugado en caso finito
****** Contraejemplo caso infinito
Pero en el caso general no. Un ejemplo es el siguiente:

\[
T(a_1,a_2,\dots) = (a_2,a_3,\dots)
\]

Que tiene cualquier valor en el espectro mientras su adjunto
no tiene ningn valor propio.

***** Extra: En el caso finito, el adjunto es la conjugada de la traspuesta
***** Extra: [[https://en.wikipedia.org/wiki/Spectral_theorem][Teorema espectral]]
*** Ejercicios
**** 1. Espacios normados
***** Ejercicio 3
La sucesin no puede tener ninguna parcial convergente a $0$, porque si no, 
al ser de Cauchy, convergera a $0$. Por tanto, a partir de un cierto $n$, 
todos los trminos deben alejarse de $0$ ms de un determinado $\alpha$.

Sean ahora $\|x - y\| \leq \epsilon$, por desigualdad triangular inversa tenemos:

\[ \bigg|\|x\|-\|y\|\bigg| \leq \|x-y\| \leq \epsilon\]

Y por tanto:

\[1 - \frac{\epsilon}{\|x\|} \leq \frac{\|x\|}{\|y\|} \leq 1 + \frac{\epsilon}{\|x\|}\]

Ahora, por otro lado, comprobaremos que podemos demostrar a la funcin 
$f(x) = \frac{x}{\|x\|}$ uniformemente continua:

\[ 
\bigg| \frac{x}{\|x\|} - \frac{y}{\|y\|} \bigg| =
\frac{1}{\|x\|} \|(x-y) + \left(1 - \frac{\|x\|}{\|y\|}y\right) \leq
\frac{\epsilon}{\|x\|} + \frac{\|y\|}{\|x\|} \left|1-\frac{\|x\|}{\|y\|}\right|
\]

Pero como tenemos acotaciones uniformes de $\|x\|^{-1}$ y de $\frac{\|y\|}{\|x\|}$, hemos 
terminado.
***** Ejercicio 4
#+begin_statement
Sea $X$ espacio normado. Probar que equivalen:

  1. $X$ completo.
  2. $B_X$ completo.
  3. $S_X$ completo.
#+end_statement

****** Primera y segunda implicaciones
Cerrados dentro de un completo.

****** Tercera implicacin
Sea $\{x_n\}$ una sucesin de Cauchy. Descartamos el caso $\{\|x_n\|\} \longrightarrow 0$, 
que lleva a la convergencia a $0$. Podemos asumir $\|x_n\| \geq 0$ para
alguna cola de la sucesin.

La sucesin $\left\{\frac{x_n}{\|x_n\|}\right\}$ es de Cauchy (puede comprobarse acotando en el
caso en el que hemos descartado el $0$). Por tanto converge. Ntese
que las normas tambin son de Cauchy y tambin convergen. As,
podemos escribir un $x/\|x\|$ al que converja la sucesin sobre $S_X$.

La distancia de cada elemento queda acotada por la distancia sobre
la bola unidad y la distancia en norma:

\[
\|x_n-x\| \leq
\|x_n\| 
\left( 
\left\| \frac{x_n}{\|x_n\|} - \frac{x}{\|x\|} \right\| +
\left\| \frac{x}{\|x\|} - \frac{x}{\|x_n\|} \right\|
\right)
\leq
\varepsilon
\]

El teorema es que si algo converge en la bola unidad y converge en
norma a distinto de $0$, converge a eso.

***** Ejercicio 7
#+begin_statement
Probar que, en un espacio normado, el interior de un subespacio
vectorial propio es vaco.
#+end_statement

Simplemente notando que si $B(m,r) \subseteq M$, entonces $B(0,1) \subseteq M$, y eso
lleva a $X = M$.

***** Ejercicio 16
****** Punto a
     Es de hecho una isometra por tenerse: 

     \[\|Tx\| = \left(\sum_{n=0} |Tx_n|^p\right)^{1/p} = 
     0 + \left(\sum_{n=1} |x_n|^p\right)^{1/p} =
     \|x\|\]

     As que es continua y su norma es $1$.

****** Punto b
     Vemos que es lipschitziana trivialmente con $\|Tx\| \leq \|x\|$. Como adems realiza la cota
     sobre la bola unidad al tener: $\|T(0,1,0,\dots)\| = \|(1,0,\dots)\| = 1$.

****** Punto c
     Vemos que es isometra $\|Tx\| = \|x\|$, por lo que es continua y de norma $1$.
**** 2. Hahn-Banach
***** Ejercicio 1
#+begin_statement
Sea $X$ espacio vectorial sobre $\mathbb{K}$, y sean $p_1,p_2 : X \longrightarrow \mathbb{R}$ seminormas.
Probar que si $f : X \longrightarrow \mathbb{K}$ es un funcional lineal verificando que 
$|f(x)|\leq p_1(x)+p_2(x)$ para todo $x\in X$, entonces existen $f_1,f_2 : X\longrightarrow\mathbb{K}$
funcionales lineales tales que $f = f_1+f_2$, y $|f_1(x)|\leq p_1(x)$, $|f_2(x)|\leq p_2(x)$
para todo $x\in X$.
#+end_statement

Sobre el espacio $X \times X$ definimos una seminorma desde las
dos seminormas anteriores:

\[ p(x,y) = p_1(x) + p_2(x)\]

Por otro lado, consideramos el subespacio diagonal:

\[ \Delta = \{(x,x) \mid x \in X\} \]

Y definimos sobre l un funcional lineal:

\[ h(x,x) = f(x) \leq p(x,y)\]


Ahora, podemos aplicar Hahn-Banach para obtener una extensin
de $h$ definida para todo el espacio cumpliendo:

\[ |h(x,y)| \leq p(x,y)\]

Ahora, si definimos $f_1(x) = h(x,0)$ y $f_2(x) = h(0,x)$, las 
desigualdades se obtienen trivialmente desde la anterior.

***** Ejercicio 2
#+begin_statement
Sean $X$ un espacio normado, $M$ un subespacio vectorial de $X$, y
$u \in X$. Probar que existe $f \in X^\ast$ tal que $|f(x)| \leq dist(x,M)$ para todo
$x \in X$ y $f(u) = dist(u,M)$.
#+end_statement

Sobre el espacio $\langle u \rangle$ definimos el funcional $g(x) = dist(x,M)$, que es
lineal y continuo. Y por otro lado, definimos la seminorma $p(x) = dist(x,M)$
en todo el espacio. Por Hahn-Banach, existe un funcional que extiende
a $g$ y que cumple adems:

\[ |f(x)| \leq dist(x,M) \]

***** Ejercicio 3
#+begin_statement
Para cada $n \in \mathbb{N}$, sea $T_n : \ell_\infty \longrightarrow \mathbb{K}$ definido por $T_n(x) = \frac{1}{n}(x_1+\dots+x_n)$.
Sea $M = \{x \in \ell_\infty : \{T_n(x)\}\text{ converge} \}$ y definamos $T(x) = \lim\{T_n(x)\}$ sobre l.

 1. Probar que $T_n \in (l_\infty)^\ast$ y que $\|T_n\| = 1$ para todo $n \in \mathbb{N}$.
 2. Probar que $M$ es un subespacio vectorial de $\ell_\infty$ que contiene al espacio
    $c$ de las sucesiones convergentes.
 3. Probar que $T \in M^\ast$ con $\|T\| = 1$ y que $T(x) = \lim\{x_n\}$ para todo $x \in c$.
 4. Sea $\tau(x) = (x_2,x_3,\dots)$ para todo $x \in l_\infty$. Probar que 
    $x - \tau(x) \in \ker(T) \subseteq M$ para todo $x \in l_\infty$.
 5. Deducir que existe $S \in (l_\infty)^\ast$, extensin de $T$ tal que $\|S\| = 1$ y
    $S(x) = S(\tau^n(x))$ para todo $x \in l_\infty$ y para todo $n \in \mathbb{N}$.
 6. Probar que $S(0,\frac{1}{2},0,\frac{1}{2},\dots) = \frac{1}{4}$.
#+end_statement

****** Punto 1
Tenemos que demostrar que es lineal y continua. Pero sabemos
que es suma y multiplicacin por escalar de las proyecciones, que
lo son. Por otro lado, por desigualdad de las medias sabemos:

\[ \frac{1}{n}(x_1+\dots+x_n)
\leq \max\{x_1,\dots,x_n\}
\leq \|x_n\|_\infty\]

Por tanto $x \in B_{\ell_\infty}$ implica $T(x) \leq 1$. Y la desigualdad se realiza
en el caso $(1,1,1,\dots)$.

****** Punto 2
Tenemos que es subespacio vectorial porque si $T_n(x)$ y $T_n(y)$ convergen,
tambin lo hace $T_n(x+\alpha y) = T_n(x) + \alpha T_n(y)$ por ser lineal.

****** Punto 3
El $T$ es el lmite puntual de los $T_n$. Por teorema del cierre de
Steinhaus, $T$ es lineal y continuo. Veamos que tiene norma unidad.
Por desigualdad de las medias la norma no puede ser mayor que $1$.
Tenemos para $x \in S_M$:

\[ T_n(x) \leq 1 \Rightarrow T(x) \leq 1\]

Y adems, para $u = (1,1,1,\dots)$ se tiene que $T_n(u) \to 1 = T(u)$.

****** Punto 4
Se ve que est en el ncleo.

****** Punto 5
Por extensin equinrmica de Hahn-Banach.

****** Punto 6
Sale desde la $T$.

***** Ejercicio 4
#+begin_statement
Fijado $n \in \mathbb{N}$, probar que existe un funcional lineal y continuo $f$ en
${\cal C}[0,1]$ tal que $f(p) = p'(0)$ para todo polinomio $p$ de grado menor o igual
que $n$. Probar que no existe un funcional lineal y continuo $f$ en ${\cal C}[0,1]$
tal que $f(p) = p'(0)$ para todo polinomio $p$.
#+end_statement

Fijado $n \in \mathbb{N}$ podemos crear una base del subespacio de polinomios
de grado menor o igual que $n$ y definir un $f$ sobre ella que cumple
lo pedido. Por Hahn-Banach, lo extenderemos a todo ${\cal C}[0,1]$. Es decir,

\[ \{1,x,x+x^2,x+x^3,\dots,x+x^n\} \overset{f}\longrightarrow \{0,1,1,\dots,1\}\]

Supongamos que existiera el funcional que lo cumple para todo polinomio.
Comprobamos que no es continuo, ya que si lo fuera debera dejar acotada
la bola unidad. Sin embargo tenemos,

\[ \frac{d}{dx}(x-1)^n|_{x=0} = n\]

Mientras que $(x-1)^n \leq 1$ para $x \in [0,1]$; lo que nos da $\|(x-1)^n\| \leq 1$.

***** Ejercicio 5
#+begin_statement
Sean $X$ un espacio normado y $M$ un subespacio vectorial de $X$. Probar que 
para cada $T \in L(M,l_\infty)$, existe $S \in L(M,l_\infty)$ tal que $S|_M = T$ y $\|S\| = \|T\|$.
#+end_statement

Si aplico la extensin equinrmica a cada una de las $\pi_i \circ T$, obtenemos
funciones $S_i \in X^\ast$ que extienden $T$ y tienen su misma norma. Ahora, la
funcin $S(x_1,x_2,\dots) = (S_1(x_1),S_2(x_2),\dots)$ es continua y lineal por serlo por
componentes; su restriccin a $M$ es trivialmente $T$, y adems, su
norma debe ser:

\[ \|S\| = \max\{ (S_1(x_1),S_2(x_2),\dots) \mid x \in B_X\} 
         = \max\{ \|S_1\|, \|S_2\|, \dots\} = \|T\| \]

***** Ejercicio 6
#+begin_statement
Sean $A$ y $B$ subconjuntos no vacos, abiertos, convexos y disjuntos de un 
espacio normado $X$. Probar que existen $f \in X^\ast$ con $\|f\| = 1$ y $\alpha \in \mathbb{R}$ tales
que $Re(f(a)) < \alpha < Re(f(b))$ para todo $a \in A$ y $b \in B$. Mostrar con un ejemplo
que, en general, no es posible encontrar $f$ tal que 
$\sup Re(f(A)) < \inf Re(f(B))$.
#+end_statement

Por el lema de separacin de convexos tenemos que existen con
$\|f\|$ no necesariamente $1$. Dividiendo por la norma obtenemos el $f$
buscado.

Podemos tomar $A$ y $B$ como los dos semiplanos de $\mathbb{R}^2$ dados por
$\{x > 0\}$ y por $\{x < 0\}$. Por continuidad de $f$ se tendra que:

$\sup Re(f(A)) \geq f(0) \leq \inf Re(f(B))$

Por lo que se tendra la igualdad.
**** 3. Teoremas fundamentales
***** Ejercicio 2
#+begin_statement

#+end_statement
***** Ejercicio 3
#+begin_statement
Sean $X$ e $Y$ espacios de Banach y $T : X\longrightarrow Y$ una aplicacin lineal y 
continua. Probar que $T$ es inyectiva y $T(X)$ es cerrado en $Y$ si y slo
si, existe $m > 0$ tal que $\|T(x)\| \geq m \|x\|$ para todo $x \in X$.
#+end_statement

****** TODO Primera implicacin
Si $T$ es inyectiva y adems $TX$ es cerrado en $Y$, entonces tenemos
que es un monomorfismo topolgico.

Si tomamos $\| x \|_2 = \|T x\|$, podemos observar que es norma porque cumple
la desigualdad triangular y la inyectividad nos da la condicin en
$0$.

****** Segunda implicacin 
Si tenemos que se cumple lo segundo, el ncleo es trivial porque
para todo $x \neq 0$, se tiene $\|T(x)\| \geq m \|x\| > 0$. Es inyectiva.

Ahora, como $T$ es inyectiva la aplicacin $T : X \longrightarrow TX$ es
biyectiva, luego es isomorfismo topolgico por el teorema de los
isomorfismos de Banach. Por el teorema del homomorfismo de
Banach, $TX$ es cerrado.

***** Ejercicio 4
#+begin_statement
Sea $M$ un subespacio cerrado de $l_p$ y de $l_q$. Probar que las normas inducidas
en $M$ por $l_p$ y $l_q$ son equivalentes.
#+end_statement

Tenemos $M$ un espacio normado y cerrado dentro de Banach, luego Banach.
Dentro de este espacio podemos usar equivalencia de normas en espacios
de Banach para tener que ambas son equivalentes a la norma inducida por
la norma del mximo.

\[ \| x\|_p 
= \sqrt[p]{\sum^\infty x_i^p} 
\geq \sqrt[p]{\max\{x_i\}^p}
= \| x\|_\infty \]

***** Ejercicio 5
#+begin_statement
Sean $X,Y$ espacios de Banach, y $A \subset Y^\ast$ tal que $A$ separa los puntos de $Y$.
Probar que si $T : X \longrightarrow Y$ es una aplicacin lineal tal que $f \circ T \in X^\ast$ para
todo $f \in A$, entonces $T$ es continua.
#+end_statement

Comprobaremos que la grfica de $T$ es cerrada, y por teorema de la grfica
cerrada, tendremos que es continua. Sean $(x_i,Tx_i) \to (x,y)$; si fueran
distintos tendramos que existe alguna funcin en $A$ que separe $f(y) \neq f(Tx)$.

Pero como $f \circ T$ es continua y $f$ es continua, tenemos:

\[ f(T(x_i)) \longrightarrow f(T(x))\]
\[f(Tx_i) \to f(y)\]

Por lo que deben ser iguales, contraviniendo separacin.

***** Ejercicio 6
#+begin_theorem
Sea $X$ un espacio de Banach real. Dada una aplicacin lineal 
$T: X \longrightarrow L_1([0,1])$ se considera, para cada $A \subset [0,1]$ medible, el funcional
lineal $T_A : X \longrightarrow \mathbb{R}$ definido por:

\[ T_A(x) = \int_A T(x)\]

Probar que si $T_A \in X^\ast$ para todo $A \subset [0,1]$ medible, entonces $T$ es continua.
#+end_theorem

****** Familia de funcionales que separan
Definimos $i_A \in L_1[0,1]^\ast$ para cualquier $A \subset [0,1]$ medible como:

\[ i_A(f) = \int_A f \]

Y comprobamos que separa las funciones de $L_1[0,1]$, ya que si dos funciones
integran igual en cualquier conjunto medible, su diferencia integra $0$ en
todo conjunto medible. Cuando esto ocurre, si fuera distinta de $0$ en un
conjunto de medida no nula, sera mayor que algn $\varepsilon$ en un conjunto de medida
no nula, luego su integral no sera nula.

****** Desarrollo
Ahora aplicamos el ejercicio anterior, siendo $i_A$ la familia que separa
los puntos de $L_1[0,1]$. Como $i_A \circ T$ son todas lineales continuas, entonces
$T$ es continua.

***** Ejercicio 7
#+begin_statement
Sean $X$ un espacio de Banach sobre $\mathbb{K}$ e $I$ un conjunto no vaco. Dada una
aplicacin lineal $T: X \longrightarrow l_\infty(I)$ se considera, para cada $i \in I$, el funcional
lineal $T_i : X \longrightarrow \mathbb{K}$ definido por:

\[ T_i(x) = T(x)(i)\]

Probar que si $T_i \in X^\ast$ para todo $i \in I$, entonces $T$ es continua.
#+end_statement

****** Familia de funcionales que separan
Llamamos $e_i \in l_\infty(I)^\ast$ a los funcionales lineales continuos siguientes,
definidos para cada $i \in I$:

\[ e_i(x) = x(i) \]

Trivialmente, si $x \neq y$, deben ser distintas en algn $x(i) \neq y(i)$.

****** Aplicacin del ejercicio anterior
Aplicamos el [[*Ejercicio 5][ejercicio anterior]] sabiendo $l_\infty(I)$ de Banach. Como
$e_i \circ T$ es siempre continua, se tiene $T$ continua.

***** Ejercicio 8
#+begin_statement
Sean $X$ un espacio de Banach real y $T : X \longrightarrow C([0,1],\mathbb{R})$ una aplicacin
lineal. Se considera, para cada $n \in \mathbb{N} \cup \{0\}$, el funcional lineal 
$T_n : X \longrightarrow \mathbb{R}$ definido por:

\[ T_n(x) = \int_0^1 t^n T(x)(t) dt\]

Probar que si $T_n \in X^\ast$ para todo $n \in \mathbb{N} \cup \{0\}$, entonces $T$ es continua.
#+end_statement

****** Separacin
Definimos los $e_n$ para cada natural como:

\[ e_n(f) = \int_0^1 t^n f(t) dt\]

Si una funcin fuera nula bajo todos los $e_n$ debera ser ortogonal
a todos los polinomios, que son densos en $C([0,1],\mathbb{R})$; por lo que
debera ser $0$ casi por doquier.

***** Ejercicio 9
#+begin_statement
Sean $X$ un espacio de Banach, $A \subset X$ tal que $X = \overline{Lin(A)}$, y $\{f_n\}$ una
sucesin de elementos de $X^\ast$. Probar que equivalen:

 1. $\{f_n(x)\} \longrightarrow 0$ para todo $x \in X$
 2. $\sup \{ \|f_n\| \mid n \in \mathbb{N} \} < \infty$ y $\{f_n(a)\} \longrightarrow 0$ para todo $a\in A$.
#+end_statement

****** Primera implicacin
Los $f_n$ forman una familia de operadores acotada puntualmente. Aplicando
el Teorema de Banach-Steinhaus a $X$ Banach, sabemos que debe estar 
acotada. Particulariza para los elementos de $a \in A$.

****** Segunda implicacin
La convergencia a cero se mantiene por combinaciones lineales finitas,
as que se tiene para cualquier $a \in Lin(A)$. Ahora, para $b \in \overline{Lin(A)}$, 
sea $a_n \longrightarrow b$; tenemos:

\[ \|f_n(b)\| 
\leq \|f_n(b - a_m)\| + \|f_n(a_m)\|
\leq M \|b - a_m\| + \|f_n(a_m)\| \to 0
\]

Puedo tomar un $m$ que haga suficientemente pequeo el primer sumando
y luego tomar un $n$ que haga suficientemente pequeo el segundo.

***** Ejercicio 10
#+begin_statement
Sea $\{x_n\}$ una sucesin de escalares tal que la serie $\sum x_n y_n$ es convergente
para toda sucesin $\{y_n\} \in c_0$. Probar que $\{ x_n \} \in l_1$.
#+end_statement

Definimos los funcionales $f_n \in c_0^\ast$ tales que:

\[ f_n(\{y_i\}) = \sum^n_{k=0} |x_k|y_k \leq \sum^\infty_{k=0} x_k \left(y_k \frac{x_k}{|x_k|} \right)\]

Donde usamos que si $y_k$ es convergente a $0$ tambin lo ser si la 
multiplicamos por escalares de valor absoluto $1$.

Como estn acotados puntualmente, se tiene por Banach-Steinhaus que estn
acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} |x_k|y_k \middle| \|\{y_i\}\|_\infty = 1 \right\} 
= M < \infty\]

Y ahora, tenemos que las sucesiones con los $n$ primeros trminos iguales
a $1$ y el resto nulos, estn en la bola unidad y hacen que:

\[ \sum^n_{k=1} |x_k| \leq M < \infty\]

Dando as,

\[ \sum^\infty_{k=1} |x_k| < \infty\]

***** Ejercicio 11
#+begin_statement
Sea $\{x_n\}$ una sucesin de escalares tal que la serie $\sum x_ny_n$ es convergente 
para toda sucesin $\{y_n\} \in l_1$. Probar que $\{x_n\} \in l_\infty$.
#+end_statement

Tenemos funcionales $f_n \in l_1^\infty$ definidos como:

\[ f_n(\{ y_n \}) = \sum_{k=0}^n x_ky_k \leq \sum_{k=0}^\infty x_ky_k < \infty \]

Que por estar acotados puntualmente y ser $l_1$ un espacio de Banach, se
tiene por Banach-Steinhaus que estn acotados. Esto es:

\[ \sup\left\{ \sum^n_{k=0} x_ky_k \middle| \|\{y_i\}\|_\infty = 1 \right\}
= M < \infty\]

En particular, si tomamos $g_i$ sucesiones con todos los elementos
nulos pero $g_{ii} = \frac{\overline{x_i}}{|x_i|}$, como $g_i \in \mathbb{S}_{l_\infty}$ tenemos que:

\[ |x_i| < \| f_n(g_n) \| \leq M \]

Tenindose as que $|x_i|$ est acotada.

***** Ejercicio 12
#+begin_statement
Sea $\{x_n\}$ una sucesin de escalares tal que la serie $\sum x_ny_n$ es
convergente para toda sucesin $\{y_n\} \in l_p$ $(1<p<+\infty)$. Probar
que $\{x_n\} \in l_q$, siendo $\frac{1}{p} + \frac{1}{q} = 1$.
#+end_statement

Tomamos los funcionales $f_n \in l_p^\ast$ definidos por:

\[f_n(\{y_k\}) = \sum_{k=0}^n x_ky_k < \sum_{k=0}^\infty x_ky_k \]

Que estn acotados y vienen de espacio de Banach, por lo que, por
Banach-Steinhaus, se tiene que:

\[ \sup\left\{ \|f_n\|_p \right\}
= M < \infty\]

Por desigualdad de Hlder, tenemos una cota para la norma de los
operadores, sea $\{y_i\} \in S_{l_p}$:

\[ \|f_n\| \leq \sum^{n}_{k=0} |x_k||y_i| \leq \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \| \{y_i\}\|_p
 = \left(\sum^n_{k=0} |x_k|^q\right)^{1/q} \]

Y comprobamos que se realiza tomando el vector siguiente:

\[
\frac{1}{\left( \sum^n_{k=0} |x_k|^q \right)^{1/p}}
( |x_1|^{q-1}, |x_2|^{q-1}, \dots, |x_n|^{q-1}, 0,0,\dots )
\]

Que tiene imagen de norma:

\[ \left( \sum_{k=0}^n |x_k|^q  \right)^{1/q}\]

Mientras que l tiene norma $1$.

**** 4. Espacios de Hilbert I
***** Ejercicio 2
#+begin_statement
Demustrese que si $H$ es un espacio prehiilbertiano respecto de dos productos
escalares $\langle \cdot,\cdot\rangle_1$ y $\langle \cdot,\cdot\rangle_2$ entonces ambos productos coinciden salvo conjugacin
ssi sus normas asociadas coinciden.
#+end_statement

****** Si coinciden, coinciden las normas
Si llamamos a las normas $\|\cdot\|_1$ y $\|\cdot\|_2$, tenemos:

\[\|u\|_1 = \sqrt{\langle u,u \rangle_1} 
= \sqrt{\overline{\langle u,u \rangle_2}} = \|u\|_2\]

Donde usamos que el producto escalar es hermtico.

****** Si coinciden las normas, coinciden
# Por qu salvo conjugacin?
Por la identidad de polarizacin, tenemos:

\[
\langle u,v \rangle_1 = 
\frac{1}{4}\left( \|u+v\|^2-\|u-v\|^2+i\|u+iv\|^2-i\|u-iv\|^2 \right) =
\langle u,v \rangle_2
\]

***** Ejercicio 3
#+begin_statement
Sea $H$ un espacio prehilbertiano real. Probar que si $\|u+v\|^2 = \|u\|^2+\|v\|^2$,
entonces $u$ y $v$ son ortogonales. Se verifica esta propiedad en todo espacio
prehilbertiano complejo?
#+end_statement

En un espacio real, esto implica $2\langle u,v \rangle = 0$. En un espacio complejo,
slo tenemos $\langle u,v \rangle + \langle v,u \rangle = 0$, as que podemos buscar un ejemplo en el que
no se cumpla:

\[2 = \|1+i\|^2 = \|1\|^2 + \|i\|^2 \]

Pero $\langle 1,i \rangle = -i \neq 0$.

***** Ejercicio 4
#+begin_statement
Sea $H$ un espacio prehilbertiano sobre $\mathbb{{K}}$. Sean $u,v \in H$ y $\alpha \in \mathbb{K}$. Probar que
$u$ y $v$ son ortogonales ssi, $\|u+\alpha v\| = \|u-\alpha v\|$.
#+end_statement

Sea $\alpha \neq 0$, tenemos que $u \perp v \iff u \perp \alpha v$. As, podemos demostrar que son
ortogonales ssi $\|u+v\| = \|u-v\|$. Pero esto slo ocurre en $\mathbb{R}$, donde el ser
hermtico da simetra al producto escalar, en $\mathbb{C}$ tenemos un contraejemplo
trivial en $u=1,v=i$, que no son ortogonales.

***** Ejercicio 15
#+begin_statement
Demostrar que el espacio ${\cal C}[-1,1]$ es suma directa del espacio de las funciones
pares y del espacio de las funciones impares. Son ortogonales dichos 
subespacios? Encontrar los complementos ortogonales de los siguientes 
conjuntos:

  - las funciones que se anulan en $[-1,0]$.
  - las funciones que se anulan en $x = 0$.
#+end_statement

****** Es suma directa
Sea $f \in {\cal C}[-1,1]$. Podemos escribirla como:

\[
f(x) = \frac{f(x) + f(-x)}{2} + \frac{f(x) - f(-x)}{2}
\]

Siendo cada sumando par e impar. Supongamos un $f$ par e impar, entonces se
tiene $f(x) = f(-x) = -f(-x) = 0$.

****** Es ortogonal
Usando que el producto de par e impar es impar:

\[
\int_{-1}^1 f(x)g(x) dx = \int_0^1 fg - \int_0^1 fg = 0x
\]

****** Complemento de las anuladas en [-1,0]
******* Slo son ortogonales si se anulan en [0,1]
Para cada intervalo definimos las funciones:

\[
u_{[a,b]}(x) = \left\{\begin{array}{ll} 
(x-a)\frac{2}{b-a}& \mbox{if } a \leq x \leq \frac{a+b}{2} \\
(b-x)\frac{2}{b-a}& \mbox{if } \frac{a+b}{2} \leq x \leq b \\
0 & \mbox{otherwise}
\end{array} 
\right.
\]

Una $f$ ortogonal a las que se anulan en $[-1,0]$ debe ser nula en $(0,1)$. Si
no lo fuera en $x \in (0,1)$, existira un intervalo $[a,b] \subset (0,1)$ donde la funcin
preservara el signo. Y entonces,

\[
\int f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad.

******* Si se anulan en [0,1] son ortogonales
Por otro lado, una funcin que se anulara en $(0,1)$ sera ortogonal a
cualquiera que se anulara en $[-1,0]$.
****** Complemento de las anuladas en 0
Cualquier funcin ortogonal a las anuladas en $0$ debe anularse en todo $x \neq 0$.
Se tiene que si no se anulara en algn punto distinto de $0$, existira
un intervalo $[a,b]$ en el que preservara el signo:

\[
\int^1_{-1} f(x)u_{[a,b]}(x) \;dx \neq 0
\]

contraviniendo ortogonalidad. Debe anularse en todo punto distinto de $0$,
y, por continuidad, tambin en $0$.
**** 5. Espacios de Hilbert II
***** Ejercicio 1
#+begin_statement
Demostrar que un funcional lineal sobre un espacio de Hilbert es continuo si
y slo si su ncleo es cerrado. Es cierto esto para espacios de Banach en
general?
#+end_statement
****** Si es continua, tiene ncleo cerrado
Un funcional lineal continuo debe tener siempre un ncleo cerrado 
trivialmente.

****** TODO Si tiene ncleo cerrado, es continua
En el caso de tener el ncleo cerrado, [[*Descomposicin cannica: isomorfismo][se tiene]] $\widehat{T} : H/\ker(T) \cong Im(T)$. 
Entonces $H/\ker(T)$ es de dimensin finita y un isomorfismo entre espacios 
de dimensin finita es continuo.

Por ltimo $T = \widehat{T} \circ \pi$.

****** Otra solucin
Viendo que hay suma topolgica $H = \ker(f) \oplus \mathbb{K}x_0$, ya que podemos escribir:

\[ u = (u - f(u)x_0) + f(u)x_0\]

exigiendo slo $f(x_0) = 1$.

***** Ejercicio 2
#+begin_statement
Sean $f,g \in l_2 \longrightarrow \mathbb{K}$ los funcionales dados por $f(x) = \alpha_3+\alpha_4$ y $g(x) = 4\alpha_5$,
para cada $x = \{\alpha_n\}_{n \in \mathbb{N}} \in l_2$. Demostrar que son lineales y continuos. 
Son inyectivos? Calcular $\|f\|$ y $\|g\|$. Determinar $v,w \in l_2$ tales que
$f = \langle \cdot,g \rangle$ y $g = \langle \cdot,w \rangle$. Dado $n \in \mathbb{N}$, define $h_n(x) = \sum_{k=1}^n \alpha_k$ un funcional
lineal de $l_2$?; y $h(x) = \sum^\infty_{k=1} \alpha_k$?
#+end_statement

****** Continuas
Son trivialmente lineales. Son continuos porque estn acotados ambos
en la bola unidad. Sabemos que debe tenerse $|\alpha_i| \leq 1$ para que est en la
bola unidad, porque en caso contrario, la suma de cuadrados sera mayor
que $1$:

\[ |f(x)| = |\alpha_3+\alpha_4| \leq 2\]
\[ |g(x)| = 4|\alpha_5| \leq 4\]

Son trivialmente no inyectivas.

De otra forma, las proyecciones, producto y suma son continuas.

****** Calcular la norma
******* Primer caso
Tenemos por desigualdad cuadrtica-aritmtica que $|\alpha_3| + |\alpha_4| \leq 2\sqrt{\frac{1}{2}}$. 
Y se alcanza la cota con la sucesin $f(0,0,0,\sqrt{1/2},\sqrt{1/2},0,\dots)$.

Podemos ver adems que $f = \langle \cdot,(0,0,0,1,1,0,\dots)\rangle$.

******* Segundo caso
Tenemos por $g(0,0,0,0,1,0,\dots) = 4$ que la cota anterior era correcta.
Es adems el vector por el que multiplicar para tener $g = \langle \cdot,w \rangle$.

****** Otros funcionales
******* Caso finito
Tenemos un funcional que es lineal trivialmente y que es continuo por
acotarse en la bola unidad por la desigualdad aritmtico-cuadrtica:

\[
\left| \sum^n_{k=1} \alpha_k \right| \leq
\sum_{k=1}^n |\alpha_k| \leq
n \sqrt{\frac{1}{n}\sum^n_{k=1} |\alpha_n|^2} \leq \frac{n}{\sqrt{n}}
\]

******* Caso infinito
No tiene ni por qu estar definido, la sucesin $\{1/n\}$ es cuadrado 
sumable pero no es sumable.

***** Ejercicio 3
#+begin_statement
Sea $f : \mathbb{C}^3 \longrightarrow \mathbb{C}$ el funcional $f(\alpha_1,\alpha_2,\alpha_3) = 3i\alpha_1 + 2\alpha_2 - \alpha_3$. Demostrar que $f$
est en el dual topolgico de $\mathbb{C}^3$. Calcular $v \in \mathbb{C}^3$ tal que $f = \langle \cdot,v \rangle$ y
determinar $\|f\|$.
#+end_statement

Es suma y producto por escalares de las proyecciones, as que es continua
y lineal. Comprobamos $f = \langle \cdot,(-3i,2,-1) \rangle$, y por Cauchy-Swarchz sabemos
la norma ser:

\[\|f\| = \|(3i,2,-1)\| = \sqrt{9+4+1} = \sqrt{14}\]

***** Ejercicio 4
#+begin_statement
#+end_statement

***** Ejercicio 5
#+begin_statement
Sea ${\cal P}(x)$ el espacio vectorial de los polinomios $p(x) :\mathbb{R} \longrightarrow \mathbb{R}$ con el 
producto interno dado por:

\[
\langle p,q \rangle = \int_0^1 p(t)q(t)\;dt
\]

Dar un ejemplo de un funcional lineal y continuo $\varphi : {\cal P}(x) \longrightarrow \mathbb{R}$ para el que
no exista $v(x) \in {\cal P}(x)$ tal que $\varphi = \langle \cdot,v \rangle$. Contradice este hecho el teorema
de Riesz-Frchet?
#+end_statement

Un ejemplo es:

\[
\varphi(p) = \int^1_0 e^tp(t) \;dx
\]

Es trivialmente lineal, est acotado en la bola unidad y por tanto es
continuo, de hecho, se tiene:

\[
\left| \int^1_0 e^tp(t) \;dx \right| \leq
\int^1_0 |e^tp(t)| \;dx \leq
e\int^1_0 |p(t)| \;dx = e \langle p,1 \rangle \leq e\|p\| \]

Sin embargo, no puede tenerse $\varphi = \langle \cdot,v \rangle$, porque si se tuviera, se tendra
en el espacio de las funciones un polinomio que contravendra Riesz-Frchet:

\[\int_0^1(e^t-v(t)) p(t) \;dt = 0
\]

Implicando que $e^t-v(t)$ es ortogonal a todos los polinomios. Como los
polinomios son densos en las continuas, esto implica que es ortogonal
a todas las funciones y por tanto $0$. $e^t = v(t)$, y no tenemos un polinomio
que cumpla eso.

No contradice Riesz-Frchet por no ser el espacio de los polinomios 
completo.

***** Ejercicio 6
#+begin_statement
Considrese el espacio complejo $C[0,1]$ dotado con la norma del mximo.
Sean $\varphi_1,\varphi_2,\varphi_3$ los funcionales dados por:

\[\varphi_1(f) = \int_0^1 x|f(x)|\;dx \]

\[\varphi_2(f) = \int^1_0 f(x)\;dx\]

\[ \varphi_3(f) = f\left(\frac{1}{2}\right)
\]

respectivamente, para $f \in C[0,1]$. Cules de ellos son funcionales lineales
y continuos? Cuando lo sean, determinar su norma. Repetir el ejercicio
considerando la norma dada por $\|f\| = \int_0^1 |f(x)|^2\;dx$. En qu casos existe
$g \in C[0,1]$ tal que el funcional dado es de la forma $\langle \cdot,g \rangle$?
#+end_statement

****** Con la norma del mximo
El primero no es lineal porque no cumple $\varphi_1(if) = i\varphi_1(f)$. El segundo y
el tercero son trivialmente lineales. Se comprueban continuos acotndolos
por la norma en la bola unidad. Calculamos su norma viendo que cumplen
esa acotacin en la constante:

\[\varphi_2(1) = 1;\quad \varphi_3(1) =1;\]

****** Con la norma eucldea
Por Hlder tenemos un funcional acotado en la bola unidad:

\[
\left| \int^1_0 f(x)\;dx\right| \leq
\int^1_0 |f(x)|\;dx \leq
\sqrt{\int^1_0 |f(x)|^2\;dx}
\]

Pero el otro no est acotado; podemos tomar una familia $\psi_n$ de funciones
que sean nulas excepto en $[\frac{1}{2} - \frac{1}{2n^2}, \frac{1}{2} + \frac{1}{2n^2}]$, donde crecen hasta llegar
a $\psi_n\left(\frac{1}{2}\right) = n$ y decrecen. Las podemos construir con lneas considerando
su parte imaginaria nula. Tenemos a $\varphi_3(\psi_n) = n$, arbitrariamente grande, 
mientras:

\[
\int_0^1 |\psi_n(t)|^2 \;dt \leq \frac{1}{n^2}n^2 = 1
\]

****** Aplicamos Frchet en el resto de casos
Para tener que $\varphi_2 = \langle \cdot,1 \rangle$.

***** Ejercicio 7
#+begin_statement
Sea $\varphi : L^2(\mathbb{R}) \longrightarrow \mathbb{R}$ el funcional dado por $\varphi(g) = \int_0^1 3xg(x)\;dx$. Demostrar
que $\varphi$ es un funcional lineal y acotado. Determinar $f \in L^2(\mathbb{R})$ tal que
$\varphi = \langle \cdot,f \rangle$ y calcular $\|f\|$.
#+end_statement

Es lineal trivialmente. Podemos acotarlo en la bola unidad como:

\[
\left|
\int^1_0 3xg(x)\;dx
\right| \leq 
3 \int^1_0 |x||g(x)|\;dx \leq 
3\sqrt{\int_0^1 |g(x)|^2\;dx} \leq
3\sqrt{\int_{-\infty}^\infty |g(x)|^2\;dx} \leq 3
\]

Por otro lado, tenemos que $\varphi = \langle \cdot,\psi \rangle$, siendo:

\[\psi = \left\{\begin{array}{ll} 
3x& \mbox{if } 0 \leq x \leq 1  \\
0 & \mbox{otherwise }  
\end{array} 
\right.\]

La norma de $f$ ser la de $\psi$, donde:

\[\|f\| = \int_{-\infty}^\infty \psi(x)\;dx = \frac{3}{2}\]

***** Ejercicio 10
#+begin_statement
Demostrar que los siguientes conjuntos forman una base ortonormal del 
espacio de Hilbert real $L^2[0,\pi]$.

  1. $B := \{ e_n \mid n \in \mathbb{N}_0\}$, donde $e_0 = \frac{1}{\sqrt{\pi}}$ y $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} cos (nx)$.
  2. $B := \{ e_n \mid n \in \mathbb{N}\}$ donde $e_n = \frac{\sqrt{2}}{\sqrt{\pi}} sin(nx)$.

Obtener una base ortonormal del espacio de Hilbert complejo $L^2[0,\pi]$.
#+end_statement

****** Primer punto
******* Generan el espacio
Sabemos que los polinomios son densos en el espacio de funciones
continuas en $[0,1]$, y que la funcin arcocoseno es una biyeccin en
ese intervalo. Dado un $f$, tenemos un polinomio $p$ que aproxima a
la funcin $f \circ arccos$:

\[ 
\left\| f(x) - p(cos(x)) \right\|_2 \leq
\left\| f(x) - p(cos(x)) \right\|_\infty =
\left\| f(arccos(x)) - p(x) \right\|_\infty
\]

Ahora, un polinomio sobre $cos(x)$ puede reescribirse como una 
combinacin lineal de los vectores de la base:

\[ cos(nx)cos(mx) = 
\frac{1}{2}\Big( cos((n+m)x) + cos((n-m)x)
\Big)\]

De esta forma, la clausura del espacio que generan los cosenos es
el espacio de las continuas. Si adems las continuas son densas
en $L_2[0,1]$, tenemos lo pedido.

******* Son una familia ortonormal
Como adems son familia ortonormal, forman una base ortonormal del 
espacio. Cuando $m \neq n$:

\[
\int_0^\pi cos(nx)cos(mx) \;dx = 
\frac{1}{n+m}[sen((n+m)x)]^\pi_0 +
\frac{1}{n-m}[sen((n-m)x)]^\pi_0 = 0
\]

Y cuando $m = n$, se tiene:

\[
\int_0^\pi cos(nx)^2 \;dx
=
\frac{1}{2}\int_0^\pi cos(2nx) - 1 \;dx
= \frac{\pi}{2}
\]

****** Segundo punto
******* Generan el espacio
Usaremos la derivacin. Por el teorema anterior, tenemos un $p\circ cos$ que 
aproxima con precisin $\varepsilon$ a la siguiente funcin:

\[
g(x) = \left\{\begin{array}{ll} 
\frac{f(x)}{sin(x)} & \mbox{if } x \in [0+\varepsilon,\pi+\varepsilon]  \\
\psi(x) & \mbox{otherwise } 
\end{array} 
\right.
\]

Donde $\psi(x)$ la podemos construir con rectas para que haga continua
a la funcin e integre menos de $\varepsilon$, algo como:

[[./images/epsilonint.png]]

Sea una primitiva suya el polinomio $P$:

\[\begin{aligned} 
\|f(x) - \partial (P\circ cos)(x))\|_2 
&\leq
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|f(x) - \partial (P\circ cos)(x) \right|^2\;dx \\
&\leq 
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - \frac{\partial (P\circ cos)(x)}{sin(x)} \right|^2\;dx \\
&=
K + \int_{0-\varepsilon}^{\pi-\varepsilon} 
\left|\frac{f(x)}{sin(x)} - p(cos(x)) \right|^2\;dx < \varepsilon + K\\
\end{aligned}\]

Por otro lado, tenemos que:

\[\begin{aligned}
K &= 
\int_0^\varepsilon |f(x) - \partial(P \circ cos)(x)|^2 \;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |sin(x)p(cos(x))|^2\;dx
\\&\leq
\int_0^\varepsilon |f(x)|^2\;dx + \int_0^\varepsilon |p(cos(x))|^2\;dx
\\&\leq 
\varepsilon \|f\|_\infty + \int_0^\varepsilon |p(cos(x)) - \psi(x)|^2\;dx + \int_0^\varepsilon |\psi(x)|^2\;dx
\\&\leq
\varepsilon \|f^2\|_\infty + \varepsilon + \varepsilon
\end{aligned}\]

Como $\varepsilon$ es arbitrario, se tiene lo pedido. Ntese que $\partial (P \circ cos)$ es la
derivada de una funcin polinmica en los cosenos que se puede escribir
como combinacin lineal de la base anterior. Y ntese que la derivada
lleva cada elemento de la base anterior en uno de la nueva.

******* Son una familia ortonormal
Por ltimo, como son ortonormales, forman una base ortonormal:

\[
\int^\pi_0 sin(nx)sin(mx) \;dx
= 
\int^\pi_0 cos((n-m)x) - cos((n+m)x)\;dx = 0
\]

****** Tercer punto
Toda funcin puede escribirse como:

\[
f(x) = \Re(f(x)) + i \Im(f(x))
\]

Y cada una de esas partes puede aproximarse como suma de cosenos o de
senos. As, cualquier base ortonormal del espacio real que hemos 
construido anteriormente es tambin base del espacio complejo.

***** Ejercicio 11
#+begin_statement
Demostrar que:

\[B:= \left\{
e_0(x) = \frac{1}{\sqrt{2\pi}},\;
e_n(x) = \frac{1}{\sqrt{\pi}} cos(nx),\;
e_{-n}(x) = \frac{1}{\sqrt{\pi}} sin(nx) 
\mid n \in \mathbb{N}
\right\}\]

define una base ortonormal en un espacio de Hilbert real $L^2[-\pi,\pi]$.
#+end_statement

****** Es ortogonal
Comprobamos integrando la ortonormalidad de la base.

****** Genera el espacio
Las funciones pares pueden aproximarse por la misma funcin que las
aproximaba en $[0,\pi]$ con los cosenos; las impares pueden aproximarse
por la funcin que las aproximaba en $[0,\pi]$ con senos.

Toda funcin es suma de par y de impar.

\[f(x) = \frac{f(x)-f(-x)}{2}+\frac{f(x)+f(-x)}{2}\]

As que toda funcin puede aproximarse por suma de senos y cosenos.

***** Ejercicio 12

***** Ejercicio 13
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en funcin de la base de Hilbert dada en el 
ejercicio 11, calcular el desarrollo en serie de Fourier de la funcin
$f(x) = |x|$ y deducir mediante la indentidad de Parseval que:

\[\sum^\infty_{n=1} \frac{1}{(2n-1)^4} = \frac{\pi^4}{96}\]
#+end_statement

****** Desarrollo en serie de Fourier
Usando que es funcin par

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{2\pi}} \;dx = \frac{\pi^2}{\sqrt{2\pi}}
\]

Usando que es una funcin par e integrando por partes:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} cos(nx) \;dx
=
\frac{2}{\sqrt{\pi}}\int_{0}^\pi x cos(nx) \;dx 
=
\frac{2}{\sqrt{\pi}n^2}((-1)^n-1)
\]

Usando que es una funcin impar:

\[
\int_{-\pi}^\pi |x| \frac{1}{\sqrt{\pi}} sin(nx) \;dx 
=
0
\]

****** Identidad de Parseval
Calculamos la norma de la funcin:

\[
\int_{-\pi}^\pi x^2 \;dx = \frac{2}{3} \pi^3
\]

Y tenemos finalmente, sumando cuadrados de los productos escalares
anteriores:

\[\begin{aligned}
\frac{\pi^3}{2} + \sum_{i=0}^\infty \frac{4}{\pi n^4}((-1)^n-1)^2
&=
\frac{2}{3} \pi^3
\\
\sum_{i=0}^\infty \frac{4}{n^4}((-1)^n-1)^2
&=
\frac{1}{6} \pi^4
\\
\sum_{i=1}^\infty \frac{1}{(2n-1)^4}
&=
\frac{1}{96} \pi^4
\end{aligned}\]

Considerando slo los trminos impares.

***** TODO Ejercicio 14
#+begin_statement
En el espacio $L^2[-\pi,\pi]$, en funcin de la base de Hilbert dada en el 
ejercicio 11, obtener el desarrollo en serie de Fourier de la funcin
$f(x) = x^2$. Usar dicho desarrollo para calcular:

\[\sum_{n=1}^\infty \frac{1}{n^2}\] y \[\sum_{n=1}^\infty \frac{1}{n^4}\]
#+end_statement

***** TODO Ejercicio 18
#+begin_statement
Encontrar $min_{\alpha,\beta,\gamma \in \mathbb{C}} \int_{-1}^1 |x^3-\alpha-\beta x -\gamma x^2|^2 \;dx$.
#+end_statement

Buscar la mejor aproximacin en el espacio de los polinomios de grado
menor que 2. Hay que buscar primero una ortonormalizacin de la base
con Gram-Schmitd

**** 6. Espacios de Hilbert III
***** Ejercicio 1
#+begin_statement
Sea $H$ un espacio de Hilbert y $P \in L(H)$. Demostrar que las siguientes
afirmaciones son equivalentes:

  1. $P$ es la proyeccin ortogonal de $H$ sobre un subespacio cerrado $M$.
  2. $P$ es idempotente y autoadjunto.
  3. $P$ es idempotente y $H = P(H) \oplus (I-P)(H)$ siendo los subespacios
     $P(H)$ y $(I-P)(H)$ ortogonales.
  4. $P$ es idempotente y $P(H)^\perp = \ker P$.
#+end_statement

****** Primera implicacin
Trivialmente idempotente. Es autoadjunto por tenerse:

\[\begin{aligned}
\langle u,pv \rangle &= \langle pu,v \rangle \\
\langle u-pu,pv \rangle &= \langle pu,v - pv \rangle \\
0 &= 0
\end{aligned}\]

Donde usamos que $pu \in M$, pero $u - pu \in M^\perp$.

****** Segunda implicacin
Tenemos $u = p(u) + (u - p(u))$ y son ortogonales por:

\[\langle p(u),v-p(v) \rangle = \langle u , p(v-p(v)) \rangle = 0\]

****** Tercera implicacin
Comprobamos que son iguales $(I-P)(H) = \ker P$. Tenemos que $g = g - p(g)$
para un caso y $p(g -p(g)) = p(g)-p(g) = 0$ para el otro.

****** Cuarta implicacin
Es una proyeccin sobre $P(H)$ y es ortogonal por definicin.

***** Ejercicio 2
#+begin_statement
Sea $H$ un espacio de Hilbert y $\{e_n\}$ una base ortonormal de $H$. Sea
$\{\alpha_n\}$ una sucesin acotada de nmeros complejos y:

\[\alpha = \sup_{n \in \mathbb{N}} |\alpha_n|\]

Probar que existe un nico $T\in L(H)$ tal que $Te_n = \alpha_ne_n$, para cada $n \in \mathbb{N}$,
y que $\|T\| = \alpha$. Calcular $T^\ast$ y $\|T^\ast\|$. Demostrar que $T$ es normal. Qu
condicin ha de cumplir la sucesin dada para que el operador $T$ sea
autoadjunto?y para que $T$ sea invertible?
#+end_statement

Expresando $u$ en serie de Fourier.

Autoadjunto cuando $\alpha_i = \overline{\alpha_i}$ e invertible cuando $\alpha_i \neq 0$.

***** Ejercicio 2.1
#+begin_statement
Sea $H = \mathbb{C}^3$ y sea $T \in L(H)$ el operador dado por:

\[T(\alpha_1,\alpha_2,\alpha_3) = (\alpha_1+\alpha_2,\alpha_1+\alpha_3,\alpha_3+2\alpha_1)\]

Es unitario?Es autoadjunto? Determinar el espectro de $T$.
#+end_statement

***** Ejercicio 3
#+begin_statement
Sea $H$ un espacio de Hilbert sobre $\mathbb{K}$ y $T \in L(H)$ un operador tal que
$\langle Tu,u \rangle = 0$ para cada $u \in H$. Demostrar que $T = 0$ si $\mathbb{K}=\mathbb{C}$, pero que no
puede decirse lo mismo si $\mathbb{K}=\mathbb{R}$, y buscar una condicin suficiente para
que se verifique dicha propiedad en el caso real.
#+end_statement

****** Caso complejo
Desarrollando:

\[\begin{aligned}
0
&=& 
\langle T(u+v),u+v \rangle
&=&
\langle Tu,v \rangle + \langle Tv,u \rangle\\
0
&=& 
\langle T(u+iv),u+iv \rangle
&=&
(-i)\langle Tu,v \rangle + i\langle Tv,u \rangle
\end{aligned}\]

Por tanto, $\langle Tu,v \rangle = 0$ y debe tenerse $Tu = 0$.

****** Caso real
Hay contraejemplos en el caso real. En $\mathbb{R}^2$ se tiene:

\[T(x,y) = (-y,x)\]

cumpliendo lo pedido. En general, cuando se tiene $T^\ast = -T$, tenemos:

\[\langle Tu,u \rangle = -\langle u,Tu \rangle = -\langle Tu,u \rangle = 0\]

siendo una condicin suficiente.

***** Ejercicio 4
#+begin_statement
Sea $H = \mathbb{C}^2$. Calcular el espectro y la norma del operador $T \in L(H)$ dado,
respectivamente, por cada una de las siguientes matrices:

  1. \[\begin{pmatrix} 0 & 1+i \\ 1 & 2+2i \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     cos \theta & e^{i\phi} sen \theta \\
     e^{i\phi} sen \theta & -cos \theta
     \end{pmatrix}\]
#+end_statement

Usaremos que la [[http://math.stackexchange.com/a/586835/85067][norma de la matriz]] es la raz del mayor valor propio
de $M\overline{M^T}$.

****** Primera matriz
Reduciendo la matriz, tenemos como valores propios:

\[\begin{aligned}
\lambda_1 &= 1+i+\sqrt{1+3i}\\
\lambda_2 &= 1+i-\sqrt{1+3i}
\end{aligned}\]

Calculamos:

\[M\overline{M^T} = 
\begin{pmatrix} 
2 & 4 \\ 4 & 9 
\end{pmatrix}\]

A la que le podemos encontrar los valores propios:

\[\lambda_1 = \frac{1}{2}(11-\sqrt{113})\]

\[\lambda_2 = \frac{1}{2}(11+\sqrt{113})\]

#+BEGIN_SRC sage
M = Matrix([[0,1+i],[1,2+2*i]])
(M*(M.transpose().conjugate())).eigenvalues()
#+END_SRC

#+RESULTS:
: [-1/2*sqrt(113) + 11/2, 1/2*sqrt(113) + 11/2]
: a^2 - 11*a + 18

****** Segunda matriz
Reduciendo la matriz, llegamos a los valores propios
$\lambda_1=1,\lambda_2 = -1$.

Y podemos aplicar lo mismo que en la anterior.

#+BEGIN_SRC sage
t,f = var('t f')
assume(t,'real')
assume(f,'real')
M = Matrix([[cos(t), e^(i*f)*sin(t)],[e^(i*f)*sin(t),-cos(t)]])
expand((M*(M.transpose().conjugate())).eigenvalues())
#+END_SRC

#+RESULTS:
: 
: [(cos(t)^2*e^(I*f) + (-I*e^(2*I*f) + I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f),
:  (cos(t)^2*e^(I*f) + (I*e^(2*I*f) - I)*cos(t)*sin(t) + e^(I*f)*sin(t)^2)*e^(-I*f)]

***** Ejercicio 5
#+begin_statement
Sea $T \in L(H)$ donde $H$ es un espacio de Hilbert de dimensin 3. 
Calclese el espectro de $T$ sabiendo que $T$ es autoadjunto,
que $\|T\| = 4$, que $T$ no tiene inverso, y que el rango de $T-2I$ es $2$.
#+end_statement

Sabemos que un valor propio es $2$, que otro valor propio es $0$ por no
tener inversa. Como la norma es la raz 

***** Ejercicio 6
#+begin_statement
Sea $H$ un espacio de Hilbert complejo de dimensin $n+1$, y sea
$B = \{e_0,\dots,e_n\}$ una base ortonormal. Sea $T \in L(H)$ el operador determinado
por las igualdades:

   - \[T(e_0) = 0\]
   - \[T(e_j) = \sqrt{j} e_{j-1}\]
 
Obtener los operadores $T^\ast$ y $T^\ast T$. Probar que $T^{n+1} = 0$. Calcular el espectro
de los operadores $T$, $T^\ast$ y $T^\ast T$ as como $\|T\|$ y $\|T^\ast T\|$.
#+end_statement

La solucin es:

  - $T^\ast T(e_j) = je_j$.
  - $G_p(T^\ast T) = \{0,1,\dots,n\}$.
  - $G_p(T) = \{0\}$.
  - $\|T\| = \sqrt{n}$, $\|T^\ast T\| =n$.

***** Ejercicio 7
#+begin_statement
Diagonalizar (si es posible) los operadores dados (respectivamente) por:

  1. \[\begin{pmatrix} 
     7 & -2 & 1 \\
     -2 & 10 & 2 \\
     -1 & -2 & 7
     \end{pmatrix}\]

  2. \[\begin{pmatrix} 
     2 & -2 & 3 \\
     1 & 1 & 1 \\
     1 & 3 & 1 \\
     \end{pmatrix}\]

  3. \[\begin{pmatrix} 
     2 & 2 & 1 \\
     1 & 3 & 1 \\
     1 & 2 & 2 \\
     \end{pmatrix}\]
#+end_statement
** Grupos y representaciones
*** 1. lgebras y mdulos
**** 1.1. Nocin de lgebra
***** 1.1. lgebra
Un *lgebra* sobre un cuerpo $K$ es un K-espacio vectorial dotado de una
aplicacin bilineal $(\cdot) : K \times K \longrightarrow K$. La bilinealidad se expresa como:

  1. $(a+b)c = ac+bc$
  2. $a(b+c) = ab+ac$
  3. $(\alpha a)b = \alpha(ab) = a(\alpha b)$

****** lgebra asociativa
Un lgebra es *asociativa* si $(ab)c = a(bc)$.

***** 1.2. Sublgebra
Una *sublgebra* es un subespacio vectorial de un lgebra cerrado para
el producto.

***** 1.3.a. lgebra conmutativa
Un lgebra es *conmutativa* si $ab = ba$.

***** 1.3.b. Centro de un lgebra
Se define el *centro* de un lgebra asociativa como:

\[
Z(A) = \{c \in A \mid ac = ca,\; \forall a \in A \}
\]

***** 1.4. Ideal de un lgebra
Un subespacio vectorial de lgebra, $I \subseteq A$ es *ideal* si el producto por
cualquier elemento est en el ideal $ai,ia \in I$.

***** 1.5. Cociente por un ideal
Sobre el K-espacio vectorial cociente por un ideal $A/I$, podemos definir
una K-lgebra mediante $(a+I)(b+I) = ab+I$.

****** Buena definicin
Supongamos que $a+I = a'+I$ y que $b+I = b'+I$, entonces tenemos 
que:

\[
ab- a'b' = a(b-b') - (a-a')b' \in I
\]

***** 1.6. Homomorfismos de K-lgebras
Una aplicacin lineal entre lgebras $f : A \longrightarrow A'$ es homomorfismo de
K-lgebras si respeta el producto:

\[
f(ab) = f(a)f(b)
\]

****** Isomorfismo de K-lgebras
Cuando un homormofismo de K-lgebras es biyectivo, se llama *isomorfismo*
y su inversa es tambin homomorfismo de K-lgebras.

***** 1.7. Primer teorema de isomorfa
Si $f : A \longrightarrow A'$ es homomorfismo de K-lgebras, $\mathrm{Im} f$ es sublgebra y $\ker f$
es ideal. Adems, tenemos un isomorfismo de K-lgebras cannico:

\[
\widehat f : A/\ker f \longrightarrow \im f
\]

dado por $\widehat f(a+\ker f) = f(a)$.

****** Demostracin
******* La imagen es sublgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

******* El ncleo es un ideal
El ncleo es subespacio vectorial y adems,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

******* Isomorfismo de lgebras
Comprobamos que est bien definido, ya que si $a + \ker f = b + \ker f$,
se tiene que $\widehat f(a+\ker f) - \widehat f(b + \ker f) = f(a-b) = 0$.

La funcin es lineal y preserva el producto por la definicin de
producto con la que hemos dotado al ideal. Ahora, comprobamos que
es inyectiva por tenerse:

\[
\widehat f(a+\ker f) = 
\widehat f(b+\ker f) \implies f(a-b) =
0 \implies a-b \in I
\]

Es trivialmente sobreyectiva.

***** 1.8.a. lgebras unitales
Una K-lgebra asociativa es *unital* si existe un neutro para el
producto.

\[
1_Aa = a = a1_A; \quad 1_A \neq 0
\]

****** Homormofisos de lgebras unitales
A los homomorfismos de lgebras unitales se les pide respetar la
unidad. Para $f : A \to B$, $f(1_A) = 1_B$.

****** Asuncin posterior
En el curso trabajaremos siempre con lgebras asociativas y unitales.

***** 1.9. Inclusin del cuerpo en el lgebra
Sea $A$ una K-lgebra, la inclusin $u : K \longrightarrow A$ es homomorfismo inyectivo
de K-lgebras. Como consecuencia $\im u \subseteq Z(A)$, y es una K-sublgebra.

****** Demostracin
******* Es homomorfismo
La inclusin definida por $u(k) = k1_A$ es lineal por tenerse:

\[
u(\gamma\alpha+\beta) =
(\gamma\alpha+\beta)1 =
\gamma(\alpha 1) + \beta 1 =
\gamma u(\alpha) + u(\beta)
\]

Y adems es multiplicativa:

\[
u(\alpha)u(\beta) = (\alpha 1)(\beta 1) = \alpha\beta 11 = u(\alpha\beta)
\]

Y trivialmente unital por $u(1) = 1$.

******* Es inyectivo
Si $u(k) = u(k')$ entonces $(k-k')1_A = 0$.

******* Es sublgebra del centro
Aplicando bilinealidad de la multiplicacin:

\[u(\alpha) a = 
(\alpha 1)a = 
\alpha (1a) = 
\alpha (a1) = 
a(\alpha 1) =
au(\alpha)\]

**** 1.2. La representacin regular. Unidades y divisores de cero
***** 1.11.a. lgebra de endomorfismos
Los endomorfismos de un K-espacio vectorial forman una K-lgebra con la
composicin:

\[
End_K(V) = \{ f : V \longrightarrow V \mid f \text{ es lineal}\}
\]

****** Demostracin
La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; adems, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos adems que la composicin es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definicin de suma; y
en el tercer punto usamos la linealidad de la funcin para conmutar
el elemento del cuerpo y la aplicacin de la funcin.

***** 1.11.b. Inclusin en los endomorfismos
Sea $A$ cualquier K-lgebra. La aplicacin $\lambda : A \longrightarrow End_K(A)$ que asigna
a cada $a \in A$ la aplicacin $\lambda_a : A \longrightarrow A$ definida por $\lambda_a(b) = ab$ para
todo $b \in A$ es un homomorfismo inyectivo de K-lgebras.

****** Caso finito
Toda K-lgebra de dimensin finita es isomorfa a una sublgebra de
matrices con coeficientes en $K$.

****** Demostracin
******* Es homormorfismo
Por los axiomas de K-lgebra, $\lambda_a$ es siempre lineal. Adems, la propia
$\lambda$ es lineal por tenerse:

\[
\lambda_{a+\alpha b}(c) = (a+\alpha b)c = ac + \alpha bc = 
\lambda_a(c) + \alpha\lambda_b(c) = (\lambda_a+\alpha\lambda_b)(c)
\]

Adems, es multiplicativa por asociatividad:

\[
\lambda_{ab}(c) = (ab)c = a(bc) = \lambda_a \circ \lambda_b (c)
\]

******* Es inyectiva
Si $\lambda_a = 0$, se tiene $a = \lambda_a(1) = 0$.

***** lgebra opuesta
El lgebra opuesta $A^{op}$ es la propia $A$ con el producto dado por:

\[
a \cdot b = ba
\]

***** Unidades y divisores de cero
Un $a \in A$ no nulo es *unidad* si existe $a^{-1} \in A$ tal que $aa^{-1} = 1 = a^{-1}a$.
El conjunto de las unidades, $U(A)$ forma un grupo con el producto.

****** Divisor de cero
Un $a \in A$ no nulo es *divisor de cero* si $\exists b: ab = 0$  $ba = 0$.

****** Clasificacin en unidades y divisores de cero en dimensin finita
Sea $a \in A$ no nulo para $A$ k-lgebra de /dimensin finita/:

1. Equivalen:

   - $a \in U(A)$
   - $\exists b \in A : ab = 1$
   - $\exists c \in A : ca = 1$

2. Equivalen:

   - $a \notin U(A)$
   - $\exists b \in A: ab = 0$
   - $\exists c \in A : ca = 0$

Es decir, todo elemento no nulo es una unidad o un divisor de cero.

******* Demostracin primer punto
Si $ab = 1$, $\lambda_a$ es sobreyectiva y $\lambda_b$ es inyectiva. Por ser de dimensin
finita ambas son isomorfismos. Se aplica sobre el lgebra opuesta para
llegar a la otra implicacin.

******* Demostracin segundo punto
Ssi $ab = 0$, $\lambda_a$ no es inyectiva, y por tanto no puede ser unidad.

****** Clasificacin por el determinante
Si en un lgebra de dimensin finita tomamos la representacin regular
$\lambda: A \to \mathrm{End}(A)$; podemos usar el determinante para decidir si $a \in A$ es
una unidad.

***** lgebra de divisin
Un lgebra $A$ es un *lgebra de divisin* si $U(A) = A \setminus \{0\}$. Los cuerpos
son lgebras de divisin conmutativas.

**** 1.3. Representaciones y mdulos
***** Representacin
Una *representacin* de un lgebra $A$ es un homomorfismo de k-lgebras
$\mu : A \longrightarrow End_K(V)$, donde $V$ es el k-espacio vectorial de representacin.

****** Representacin fiel
Se llama representacin *fiel* cuando $\mu$ es inyectiva.

****** Representacin regular
La inclusin en los endomorfismos $A \to \mathrm{End}(A)$ es una *representacin fiel*
que llamamos representacin regular.

***** Mdulos de un lgebra
Dada $A$ lgebra, un A-mdulo por la izquierda es un espacio vectorial $V$
con un producto bilineal $A \times V \to V$ cumpliendo $(ab)v = a(bv)$ y $1v = v$.

****** Submdulos
Llamamos *submdulo a izquierda* a un subconjunto $N$ de un mdulo que 
sea subgrupo aditivo y que cumpla $an \in N$ para $n \in N$. Los submdulos
de un lgebra se llaman *ideales a izquierda*.

****** Retculo de submdulos
Llamamos ${\cal L}(M)$ a la familia de submdulos de $A$. Forman un retculo bajo
la suma y la interseccin.

****** Submdulo generado
El submdulo generado por un conjunto de elementos es el menor submdulo
que los contiene.

***** Equivalencia de mdulos y representaciones
Sean $A$ una k-lgebra y $V$ un k-espacio vectorial. Hay una biyeccin
entre el conjunto de representaciones de $A$ sobre $V$ y los A-mdulos
por la izquierda sobre $V$.

****** Demostracin
Si tenemos una representacin $\mu\colon A \to \mathrm{End}(V)$, definimos el A-mdulo
dado por $av = \mu(a)(v)$. Si tenemos una estructura de A-mdulo podemos
construir la representacin $\mu(a)(v) = av$.

***** Suma directa de mdulos
Llamamos *suma directa* de los mdulos $M_1,\dots,M_n$ al mdulo sobre su
producto cartesiano con las operaciones

 * $(m_1,\dots,m_n) + (m_1',\dots,m_n') = (m_1+m_1',\dots,m_n+m_n')$
 * $a(m_1,\dots,m_n) = (am_1,\dots,am_n)$

***** Teorema de Cayley-Hamilton
Todo endomorfismo de un espacio vectorial de dimensin finita satisface
su ecuacin caracterstica.

****** Demostracin
Sea $T$ un endomorfismo en un espacio $V$ con base $\{v_1,\dots,v_n\}$, definido por
la matriz siguiente

\[C =\begin{pmatrix}
a_{11} & a_{12} & \dots \\
a_{21} & a_{22} & \dots \\
\vdots & \vdots & \ddots \\
\end{pmatrix}.
\]

Si consideramos la matriz $\Delta = (TI_n - C)^t$ en $K[X]$, tenemos que

\[\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
Tv_1 - \sum_{j=1}^n a_{j1}v_j \\
Tv_2 - \sum_{j=1}^n a_{j2}v_j \\
\vdots \\
Tv_n - \sum_{j=1}^n a_{jn}v_j  
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Multiplicando ahora por su matriz adjunta, se tiene que

\[
\widetilde \Delta\Delta\begin{pmatrix}
v_1 \\ v_2 \\ \vdots \\ v_n
\end{pmatrix} = \begin{pmatrix}
\mathrm{det}(\Delta)v_1 \\ \mathrm{det}(\Delta)v_2 \\ \vdots \\ \mathrm{det}(\Delta)v_n
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix}.
\]

Luego, por ser una base, $\mathrm{det}(\Delta)v = 0$ para cualquier $v \in V$. Tenemos
entonces que $T$ satisface la ecuacin polinmica

\[ \mathrm{det}(TI_n - C) = \mathrm{det}(\Delta^t) = \mathrm{det}(\Delta) = 0.
\]

***** Submdulo finitamente generado
Un $A\text{-mdulo}$ $M$ es *finitamente generado* si existe $X \subseteq M$ subconjunto
finito que lo genera, $M = RX$.

****** Submdulo cclico
Un mdulo generado por un elemento se llama *cclico*.

***** Suma de mdulos
Dados submdulos $N_1,\dots,N_m \leq M$, su suma es el menor submdulo que contiene
a todos ellos.

****** Caracterizacin de la suma
Sea $M$ un $A\text{-mdulo}$,

 1. Dados submdulos $N_1,\dots,N_m$ de $M$, tenemos que

    \[
    N_1+\dots+N_m = \left\{ n_1+\dots+n_m \mid n_i \in N_i \right\}.
    \]

 2. Dado $X = \{m_1,\dots,m_n\} \subseteq M$, tenemos que $RX= Rm_1 + \dots + Rm_{n}$.

******* Demostracin
Comprobamos que un mdulo que los contenga debe contener a todos
los elementos de esa forma, adems, forman un mdulo, as que es
el menor.

***** Homomorfismo de mdulos
Un aplicacin entre $A\text{-mdulos}$ $f\colon M \to N$ es *homomorfismo de mdulos*
si $f(am) = af(m)$ para $a \in A, m \in M$.

***** Cociente de mdulos
Sea $L < M$ un submdulo. El cociente $M/L$ tiene estructura de mdulo con

\[a(m+L) = am+L
\]

y la suma inducida en el cociente.

***** Primer teorema de isomorfa para mdulos
Para $f\colon M \to N$ homomorfismo de mdulos, $\mathrm{ker}(f)$ e $\mathrm{im}(f)$ son submdulos
y hay un isomorfismo $\widehat f\colon M/ \mathrm{ker}(f) \to \mathrm{im}(f)$ dado por

\[
\widehat f(m+ \mathrm{ker}(f)) = f(m)
\]

****** Demostracin
Aplicamos primero el primer teorema de isomorfa en grupos. Y comprobamos
que adems $\widehat f$ es $A\text{-lineal}$ por ser $f$ isomorfismo de mdulos.

***** Bases y mdulos libres
Un conjunto de generadores de un $A\text{-mdulo}$ $M$ es *base* si cada $m \in M$
se escribe nicamente como

\[
m = \sum_{i=1}^n a_im_i
\]

****** Mdulo libre
Un mdulo que admite una base se llama *mdulo libre*. Un ejemplo de
mdulo libre es $A^n$.

***** Caracterizacin de bases
Un subconjunto $B \subseteq M$ no vaco finito es base si, y slo si, para 
cualquier aplicacin $f\colon B \to N$ existe un nico homomorfismo de
$R\text{-mdulos}$ $\overline{f} \colon M \to N$ con $\overline{f}_{|B} = f$.

\[\begin{tikzcd}
B \rar[hook]\drar[dashed, swap]{\exists! \overline{f}} & M \dar{f}\\
  & N
\end{tikzcd}\]

****** TODO Demostracin

***** Caracterizacin de finitamente generados
Para $M$ un $A\text{-mdulo}$,

 1. Si $M$ admite un conjunto de generadores $\left\{ m_1,\dots,m_n \right\}$, entonces
    $M \cong A^n/L$ para cierto submdulo $L$.
 2. Si $M$ es libre con base $\left\{ m_1,\dots,m_n \right\}$, entonces $M \cong A^n$.

****** TODO Demostracin

***** Segundo teorema de isomorfa para mdulos
Sean $L,N \in {\cal L}(M)$ submdulos. Existe un isomorfismo

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N}.
\]

****** Demostracin
Aplicamos el primer teorema de isomorfa a la funcin 

\[
f\colon N \to \frac{L+N}{L}
\]

dada por $f(n) = n+L$. Es sobreyectiva y tiene como ncleo a $L \cap N$.

***** Tercer teorema de isomorfa para mdulos
Sean $L \subseteq N \in {\cal L}(M)$. Existe un isomorfismo

\[
\frac{M/L}{N/L}\cong \frac{M}{N}
\]

Adems, hay una biyeccin creciente entre submdulos de $M$ conteniendo
a $L$ y ${\cal L}(M/L)$.

****** Demostracin
Aplicamos priemr teorema de isomorfa a la aplicacin

\[
f \colon M/L \to N/L
\]

dada por $f(m+L) = m+N$.

**** 1.4. Mdulos simples. Teorema de Jordan-Hlder
***** Mdulo simple
Un mdulo $M$ se dice simple si no tiene submdulos propios.

***** Submdulo maximal
Un submdulo propio $N < M$ es *maximal* si lo es en ${\cal L}(M)$.

****** Caracterizacin por simplicidad
Por tercer teorema de isomorfa, esto equivale a que $M/N$ es simple.

***** Serie de composicin
Una cadena de submdulos $0 \subset M_1 \subset M_2 \subset \dots \subset M$ es una *serie de composicin*
de $M$ si cada $M_{i-1}$ es maximal en $M_i$.

***** Teorema de Jordan-Hlder
Sea $M$ un $A$ mdulo de /dimensin finita/ como $K$ espacio vectorial con
dos series de composicin:

\[0 = M_0 \subset M_1 \subset\dots\subset M_n = M\]
\[0 = N_0 \subset N_1 \subset\dots\subset N_m = M\]

Entonces $n=m$ y existe una permutacin con $M_i/M_{i-1} \cong N_{\sigma(i)}/N_{\sigma(i)-1}$.

****** Factores de composicin
Los mdulos $M_i/M_{i-1}$ se llaman *factores de composicin* de $M$ y estn
nicamente determinados salvo isomorfismo y reordenacin.

****** Demostracin
Usaremos induccin sobre $n$. En el caso $n=1$, $M$ es simple y no tiene
submdulos propios, luego todas sus series de composicin son la misma.
En otro caso, no es simple y $n,m>1$.

******* Caso 1
Si $M_{n-1}=N_{n-1}$, aplicamos a ambos la hiptesis de induccin y
ampliamos la permutacin obtenida.

******* Caso 2
Si $M_{n-1} \neq N_{n-1}$, $M_{n-1}+N_{m-1} = M$ por maximalidad, y su interseccin
tiene una serie de composicin

\[
0 \subset L_1 \subset \dots \subset L_{k-1} \subset N_{m-1} \cap M_{n-1}
\]

que adems puede extenderse de dos formas a $M_{n-1}$ y $N_{m-1}$, sabiendo por 
segundo teorema de isomorfa que

\[
\frac{M_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{N_{m-1}}
\quad\text{ y que }\quad
\frac{N_{n-1}}{N_{m-1}\cap M_{n-1}} \cong \frac{M}{M_{m-1}}
\]

son simples. Aplicando la hiptesis de induccin dos veces, tenemos
dos permutaciones que nos dan

\[
L_i/L_{i-1} \cong M_{\tau i}/M_{\tau i - 1}
\quad\text{ y que }\quad
L_i/L_{i-1} \cong N_{\sigma i}/M_{\sigma i - 1}.
\]

Combinndolas tenemos lo pedido.

***** Longitud de un mdulo
El nmero de factores de composicin es la *longitud* del mdulo $\ell(M)$.

***** Longitud y cociente
Si $M$ es de dimensin finita y $N \in {\cal L}(M)$. Entonces $\ell(M)=\ell(N)+\ell(M/N)$.

****** Demostracin
Si tenemos series de composicin

\[
0 \subset N_1 \subset N_2 \subset \dots \subset N
\qquad
\frac{N}{N} \subset \frac{M_1}{N} \subset \dots \subset \frac{M}{N}
\]

podemos aplicar el tercer teorema de isomorfa para tener
$M_j/M_{j-1} \cong \frac{M_j/N}{M_{j-1}/N}$ simple, y por tanto, una serie de composicin

\[
0 \subset N_1 \subset \dots \subset N \subset M_1 \subset \dots \subset M.
\]

Como consecuencia, $\ell(M)=\ell(N)+\ell(M/N)$.

***** Longitud, suma e interseccin
Sea $M$ un mdulo dimensin finita con $N,L \in {\cal L}(M)$. Entonces:

\[\ell(N+L) + \ell(N\cap L) = \ell(N)+\ell(L)\]

****** Demostracin
Aplicamos el [[*Segundo teorema de isomorfa para mdulos][segundo teorema de isomorfa]] y la [[*Longitud y cociente][longitud de un cociente]]
para tener

\[
\frac{L+N}{L} \cong \frac{N}{L \cap N},
\]

y por tanto $\ell(L+N) - \ell(L) = \ell(N) - \ell(L \cap N)$.

**** 1.5. Independencia lineal y sumas directas internas
***** Familia independiente
Una familia $\{N_i \mid i \in I\} \subset {\cal L}(M)$ es *independiente* si se verifica:

\[
N_j \cap \sum_{j\neq i} N_i = \{0\}
\]

***** Suma directa interna
Dada una familia independiente, $\sum_{i\in I} N_i \subset M$ se llama *suma directa interna*.

***** Suma directa externa e interna
Existe un nico homomorfismo de mdulos $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$, tal que
$\theta\iota_i(m) = m$ para cualquier $m \in N_i$.

****** Demostracin
Extendiendo por linealidad la condicin, el nico homomorfismo posible es:

\[
\theta((m_i)_{i \in I}) = \sum_{i \in I} m_i
\]

***** Caracterizacin de familia independiente
Equivalen:

 1. La familia $\{N_i\mid i\in I\}$ es independiente.
 2. Toda subfamilia /finita/ $F \subset \{N_i\mid i\in I\}$ es independiente.
 3. La expresin de cada $m = \sum_{i\in I} m_i$ con $m_i\in N_i$ es nica.
 4. Si $0 = \sum_{i\in I} m_i$, entonces $m_i = 0$.
 5. El homomorfismo cannico $\theta : \bigoplus_{i\in I} N_i \to \sum_{i\in I} N_i$ es inyectivo e isomorfismo.
 6. Para $J_1,J_2 \subset I$ con $J_1\cap J_2 = \varnothing$ se tiene $\sum_{i\in J_1} N_i \cap \sum_{i\in J_2} N_i = \{0\}$.

En este caso, notaremos la suma directa interna tambin por $\bigoplus_{i \in I} N_i$.

****** Demostracin
******* Implicacin 1 a 2
Trivial por definicin de independencia.

******* Implicacin 2 a 3
Esto equivale a que cada $\sum_{i \in I} m_i = 0$ lleva a $m_i = 0$. Pero si hubiera
algn $m_j$ no nulo, sera $m_j = - \sum_{i \in I, i\neq j} m_i$, contraviniendo independencia.

******* Implicacin 3 a 4
Trivial por la unicidad.

******* Implicacin 4 a 5
Desde lo anterior, se tiene que tiene ncleo trivial y por tanto es
inyectivo. Adems, es sobreyectivo porque genera trivialmente todos los
elementos de $\sum N_i$. Es por tanto una biyeccin e isomorfismo.

******* Implicacin 5 a 6
Si no fuera as, existiran subconjuntos $J_1,J_2$ cumpliendo:

\[
\sum_{i \in J_1} m_i = \sum_{i \in J_2} n_i
\]

Ntese que entonces la funcin $\theta$ dara la misma imagen para ambos
subconjuntos, contraviniendo inyectividad.

******* Implicacin 6 a 1
Trivial por el caso de $J_2$ con un elemento.

***** Ampliar familia independiente
Sea $\{N_i \mid i\in I\} \subset {\cal L}(M)$ es familia independiente y tenemos:

\[
N \cap \bigoplus_{i\in I} N_i = \{0\}
\]

Entonces, $\{N_i \mid i \in I\} \cup \{N\}$ es independiente.

****** Demostracin
Si $n + \sum n_i = 0$, tenemos $n \in \bigoplus N_i \cap N$ y, por tanto, $n = 0$. Por 
independencia de la familia $\sum n_i = 0$, se llega a $n_i = 0$.

***** Suma directa en suma de simples
Sea $N \subset \sum_{i\in I} M_i$ suma de submdulos simples. Existe $\{M_i \mid i \in J \subseteq I\} \cup \{N\}$ 
independiente con:

\[
N \oplus \left( 
\bigoplus_{i \in J} M_i
\right) = \sum_{i \in I} M_i
\]

****** Demostracin
Tomamos el conjunto $\Gamma$ de los subconjuntos $J \subseteq I$ tales que $\{M_i \mid i \in J\} \cup \{N\}$
es independiente. Veamos que es no vaco. Si para todo $N \cap M_i \neq 0$, 
debe tenerse por simplicidad $M_i \subset N$ y por tanto $\sum M_i \subset N$. As, debe
existir algn $M_i$ para el que $N \cap M_i = 0$.

Tomamos el maximal $J$. Para cualquier ndice $i \in I -J$, se tiene entonces
por maximalidad que $M_i \cap (N + \bigoplus_{j \in J} M_j) \neq 0$, pero eso implica por simplicidad
que $M_i \subseteq N + \bigoplus_{j\in J} M_j$.

***** Existencia de base para espacio vectorial finitamente generado
Sea $_DV$ espacio vectorial izquierdo sobre el anillo de divisin $D$.
Para todo sistema de generadores no nulos $\{v_i\mid i\in I\}$ de $V$ existe un 
subconjunto tal que $V = \bigoplus_{j\in J} Dv_j$.

Todo espacio vectorial finitamente generado sobre $D$ tiene una base.

****** Demostracin
Un anillo de divisin es simple. Como $Dv_j \cong D$, tenemos que es un 
espacio suma de simples, luego [[*Suma directa en suma de simples][existe un conjunto]] de independientes que
genera el espacio.

**** 1.6. Independencia en familias infinitas
***** Suma directa externa infinita
Se define la *suma directa externa* $\bigoplus_{i\in I} N_i$ como el subconjunto del producto
cartesiano formado por las tuplas con un nmero finito de valores no nulos.

**** 1.7. Clasificacin de las lgebras de divisin reales de dimensin finita
***** Determinante, traza, polinomio caracterstico y mnimo
Dada $a \in D$ en un lgebra de divisin sobre $k$, consideramos su *traza*,
su *determinante*, su *polinomio caracterstico* y su *polinomio mnimo*
como los del endomorfismo lineal multiplicacin, $\lambda_a \colon D \to D$.

***** Lema de clasificacin de lgebras de divisin
Sea $D$ lgebra real de dimensin finita mayor que $1$. Entonces:

\[
V = \{a \in D : a^2 \leq 0\} = \{a\in D\mid tr(a) = 0\}
\]

Luego es un subespacio vectorial con $D = \mathbb{R} \oplus V$. Adems, la dimensin real
de $D$ es par.

****** Demostracin
Llamamos $n = \mathrm{dim}_{\mathbb{R}}(D)$ y dado $a \in D$ consideramos su polinomio 
caracterstico

\[
p(X) = (X-r_1)\dots (X-r_k)q_1(X)\dots q_m(X)
\]

descompuesto en factores lineales y cuadrticos. Por Cayley-Hamilton,
tenemos que $p(a) = 0$, luego debe anularse algn polinomio,

  * si $(a-r_i) = 0$ entonces $a \in \mathbb{R}$, y si $a^2 \leq 0$, nos da $a = 0$.
  * si $a \in D \setminus \mathbb{R}$, tendremos algn $q_j(a) = 0$ como polinomio mnimo de $a$.

Por Ejercicio 18 tenemos $p = q^t$, con $2t=n$ en este caso. Por irreducibilidad
se tiene $q = (X-z)(X-\overline{z})$ para algn complejo, as que

\[\begin{aligned}
q(X) &= X^2 - 2 \mathrm{Re}(z) X + |z|^2 \\
p(X) &= X^{2t} - 2 \mathrm{Re}(z)t X^{2t-1} + \dots \\
p(X) &= X^{2t} - \mathrm{tr}(a) X^{2t-1} + \dots \\
\end{aligned}
\]

desde el desarrollo de $q$ y la definicin de la traza como coeficiente del
polinomio caracterstico.

Sustituyendo en la primera ecuacin desde la ltima tenemos que

\[
a^2 - \frac{\mathrm{tr}(a)}{t}a + |z|^2 = 0,
\]

y que por tanto $a^2 \in \mathbb{R}^-$ si y slo si $\mathrm{tr}(a) = 0$.

***** Teorema de Frobenius
Sea $D$ lgebra de divisin real de dimensin finita. Entonces $D$ es isomorfa
a $\mathbb{R}$, $\mathbb{C}$, o $\mathbb{H}$.

****** Demostracin
Si $D \not\cong \mathbb{R}$, aplicamos el [[*Lema de clasificacin de lgebras de divisin][lema de clasificacin]] para tener $D$ de dimensin
par con $D = \mathbb{R}\oplus V$. Consideramos

\[
B(a,b) = \frac{ab+ba}{2}
= \frac{1}{2}\left( (a+b)^2-a^2-b^2 \right) \in \mathbb{R},
\]

una forma bilineal simtrica definida negativa. Podemos diagonalizarla
para obtener una base donde $B(e_i,e_j) = 0$ si $i\neq j$ y $B(e_i,e_i) = -1$, es decir,
por definicin de $B$,

\[
e_i^2 = -1
\quad\text{ y }\quad
e_ie_j = -e_je_i.
\]

En el caso $t=1$, tenemos $\mathbb{C}$. En el caso $t>1$, tenemos adems la restriccin
de que si tomamos $u = e_1e_2e_j$, se cumple

\[
u^2 = -e_1e_2e_1e_je_2e_j = 1,
\]

luego $0 = (u-1)(u+1)$ en un anillo de divisin nos da $e_j = \pm e_1e_2$, as que
debe tenerse $t=2$, con base $\left\{ 1,e_1,e_2,e_1e_2 \right\}$. En este caso, se comprueba que
hay un isomorfismo $\mathbb{H} \cong D$.

***** Corolario de Frobenius
La nica lgebra de divisin compleja de dimensin finita es $\mathbb{C}$.

****** Demostracin
Ntese que en particular sera un lgebra de divisin real y no podra
ser $\mathbb{H}$ porque no tiene a los complejos como centro.

**** 1.8. Idempotentes y anillos de matrices
***** Idempotente
Un elemento de un lgebra $e \in R$ se llama *idempotente* si $e^2 = e$.
Son idempotentes triviales $0$ y $1$.

***** Conjunto completo de idempotentes ortogonales (CCIO)
Un conjunto de idempotentes no triviales $\{e_1,\dots,e_n\}$ es conjunto completo de
idempotentes ortogonales si:

\[
1 = e_1 + \dots + e_n
\]

Y adems, $e_ie_j = 0$ para $i \neq j$.

***** Descomposicin de un CCIO
Sea $\{e_1,\dots,e_n\}$ un CCIO para $R$. Entonces $R = Re_1 \oplus \dots \oplus Re_n$.

****** Demostracin
Cualquier elemento de $R$ se expresa como:

\[
r = r(e_1+e_2+\dots+e_n)
\]

Y la suma es directa porque si se tiene $x \in Re_j \cap \left(\sum_{i\neq j} Re_i \right)$, entonces:

\[
x = xe_j = \left(\sum_{i\neq j} xe_i\right)e_j = 0
\]

***** Descomposicin en un CCIO
Sea $R = I_1 \oplus \dots \oplus I_n$ descomposicin por ideales a izquierda no triviales.
Entonces, si $1 = e_1 + \dots + e_n$, para $e_i\in I_i$, $\{e_1,\dots,e_n\}$ forman un CCIO 
con $I_i = Re_i$.

****** Demostracin
Si $x \in I_j$, $x = x\sum e_i$ y se tiene,

\[x - xe_j = 
\sum_{i\neq j} xe_i \in I_j \cap \left(\sum_{i\neq j} I_i\right) = 
\{0\}.\]

As, hemos demostrado que

\[
I_j = \{ x \in R \mid xe_j = x\} = Re_i
\]

y que por tanto, $e_i^2 = e_i$. Por eso se tiene $\sum_{i\neq j} e_ie_j = 0$ y por independencia
lineal, se llega a $e_ie_j = 0$.

***** Matrices de descomposicin
Llamamos al conjunto de matrices siguiente,

\[
Mat(e_iRe_j) = \left\{(r_{ij}) \mid r_{ij} \in e_iRe_j\right\}
\]

que es un subespacio vectorial multiplicativamente cerrado de $M_n(R)$. La
matriz diagonal

\[\begin{pmatrix}
e_1 & 0 & \dots & 0\\
0 & e_2 & \dots & 0 \\
\vdots & & & \vdots \\
0 & 0 & \dots & e_n
\end{pmatrix}
\]

es elemento neutro multiplicativo.

****** Demostracin
Se comprueba trivialmente por tenerse:

\[
(e_ire_k)(e_kr'e_j) = e_i(re_kr')e_j \in e_iRe_j
\]

Multiplicando se comprueba adems que la diagonal es la unidad
multiplicativa.

***** Descomposicin en matrices
La aplicacin $\phi \colon R \to Mat(e_iRe_j)$ dada por $\phi(r) = (e_ire_j)_{ij}$ es un isomorfismo
de K-lgebras.

****** Demostracin
******* Es homomorfismo de lgebras
Por definicin es lineal. Si calculamos la componente $(i,j)$ de
$\phi(r)\phi(s)$, tenemos

\[
\sum_k e_ire_ke_kse_j =
\sum_k e_ire_kse_j =
e_ir \left(\sum_k e_k\right) se_j =
e_irse_j
\]

que es la componente $(i,j)$ de $\phi(rs)$. Adems, $\phi(1)$ es claramente la unidad.

******* Es isomorfismo
Supongamos que $\phi(r)=0$, entonces se tiene

\[
r = \left(\sum_i e_i\right)r \left( \sum_{j} e_{j} \right)
= \sum_{i,j} e_{i}re_{j} = 0
\]

y la funcin es inyectiva. Para comprobar que es sobreyectiva, simplemente
tomamos una matriz $(r_{ij})$ de la forma, y comprobamos que por ortogonalidad
e idempotencia se tiene

\[
\phi \left( \sum_{i,j} r_{ij} \right) = (r_{ij})
\]

***** Descomposicin de endomorfismos
Sea $M = M_1 \oplus M_2 \oplus \dots \oplus M_n$ un A-mdulo con $M_i \cong N$. Se tiene

\[
\mathrm{End}(M) = M_n(\mathrm{End}(N)).
\]

****** TODO Demostracin

***** Descomposicin en ideales bilteros
Sea $R = I_1\oplus I_2\oplus \dots \oplus I_n$ descompuesto en ideales bilteros. Sea $\left\{ e_1,\dots,e_n \right\}$
su CCIO asociado. Entonces $e_i \in Z(R)$, idempotente central.

***** Descomposicin en lgebras
Sea $\{e_1,\dots,e_n\}$ un CCIO centrales de $R$. Entonces $Re_i$ es un lgebra con unidad
y tenemos un isomorfismo de lgebras $R \cong Re_1\times Re_2 \times \dots \times Re_n$ definido
por $r \mapsto (re_1,\dots,re_n)$.

***** Idempotente central primitivo
Un idempotente central es *primitivo* si $Re$ no es suma directa de dos ideales
propios de $R$.

***** Descomposin en centrales primitivos
Si $R$ tiene un CCIO centrales primitivos, este conjunto es nico.

****** TODO Demostracin

**** 1.9. El lgebra de enfomorfismos de un mdulo semisimple
***** Complemento
Para $N \subseteq M$ submdulo, un *complemento* de $N$ es un $X$ tal que

\[
M = N \oplus X.
\]

En caso de que tenga complemento lo llamamos *sumando directo*.

***** Mdulos semisimples
Un mdulo de dimensin finita se dice *semisimple* si todo submdulo
es un sumando directo.

***** Caracterizacin de semisimples
Sea $M$ mdulo con dimensin finita como K-espacio vectorial. Equivalen:

  1) $M$ es semisimple.
  2) $M$ es suma directa finita de submdulos simples.
  3) $M$ es suma finita de submdulos simples.

****** Demostracin
******* Primera implicacin
Tomamos una familia maximal de submdulos simples linealmente
independientes. Si el complemento de su suma no fuera nulo, entonces
contendra algn submdulo simple (por finitud) que sera linealmente
independiente, contraviniendo maximalidad.

******* Segunda implicacin
Trivial.

******* Tercera implicacin
Trivial porque podemos tomar [[*Suma directa en suma de simples][suma directa en suma de simples]] para
encontrar el complemento.

***** Lema de Schur
Sean $M,M'$ simples con $f\colon M \to M'$ homomorfismo de mdulos. Se tiene $f=0$
o $f$ isomorfismo.

****** Corolario: anillo de endomorfismos de un mdulo simple
El anillo de los endomorfismos de un mdulo simple es un anillo de
divisin.

****** Demostracin
Si no es nula, el ncleo es un submdulo propio, luego debe ser inyectiva.
La imagen entonces ser un submdulo propio no nulo y ser sobreyectiva.

***** Submdulos y cocientes de semisimples
Si $M$ es un semisimple de dimensin finita, entonces todo submdulo de $M$
y todo cociente de $M$ es semisimple.

****** Demostracin
Si existe un epimorfismo de mdulos $M \to N$, se tiene $N$ semisimple.
Cualquier cociente tendr la proyeccin como epimorfismo hacia l y
cualquier submdulo $N \subseteq M$ ser cociente por su complemento como

\[
\frac{M}{X} =
\frac{N \oplus X}{X} \cong
\frac{N}{N \cap X} \cong N.
\]

******* El epimorfismo da la semisimplicidad
Por [[*Lema de Schur][Lema de Schur]], se tiene que la imagen de un simple ser simple o
nula. As, podemos escribir

\[
N = \sum_{i\in I} f(M_i)
\]

y tendremos que es suma de simples y por [[*Caracterizacin de semisimples][caracterizacin]], semisimple.

***** Unicidad de la descomposicin en simples
Sea $M = M_1\oplus \dots \oplus M_n = N_1 \oplus \dots \oplus N_m$ semisimple descompuesto como suma
directa de simples. Entonces $n=m$ y se tiene $M_i \cong N_{\sigma i}$ para alguna 
permutacin.

****** Demostracin
Tenemos dos series de composicin

\[\begin{aligned}
\left\{ 0 \right\} &= M_0 \subset
M_1 \subset 
M_1 \oplus M_2 \subset 
&\dots& \subset
M_1 \oplus \dots \oplus M_n &= M \\
\left\{ 0 \right\} &= N_0 \subset
N_1 \subset 
N_1 \oplus N_2 \subset 
&\dots& \subset
N_1 \oplus \dots \oplus N_n &= M \\
\end{aligned}\]

en las que los factores son simples, explcitamente por segundo
teorema de isomorfa,

\[
\frac{M_j \oplus \dots \oplus M_0}{M_{j-1}\oplus \dots\oplus M_0} \cong
\frac{M_j}{(M_{j-1} \oplus \dots \oplus M_0) \cap M_j} \cong M_j.
\]

Pero aplicando [[*Teorema de Jordan-Hlder][Jordan-Hlder]], $M_j \cong N_{\sigma j}$.

***** Componentes isotpicas de un mdulo
Sea $M = M_1\oplus \dots \oplus M_n$ descomposicin finita en mdulos simples. Podemos
escoger mdulos simples $\Sigma_1,\dots,\Sigma_t$ y una particin $\{1,\dots,n\} = \Lambda_1 \cup \dots \cup \Lambda_t$
tal que $M_i \cong \Sigma_j$ si y slo si $i \in \Lambda_j$.

Podemos tomar $M_{\Lambda_j} = \bigoplus_{i\in \Lambda_j} M_i$ para descomponer en *componentes isotpicas*

\[
M = M_{\Lambda_1}\oplus \dots \oplus M_{\Lambda_t}
\]

y llamar a $n_j$ la *multiplicidad* $\Sigma_j$ en $M$. Las componentes con su multiplicidad
son invarriantes llamados *estructura del mdulo*.

***** Estructura de los endomorfismos
Sea $M$ con estructura $(\Sigma_1,n_1),\dots,(\Sigma_t,n_t)$ entonces $\Delta_j= \mathrm{End}(\Sigma_j)$ es una
$K\text{-lgebra}$ de dimensin finita y hay un isomorfismo

\[ \mathrm{End}(M) \cong
\mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t)
\]

****** TODO Demostracin
**** 1.10. lgebras semisimples de dimensin finita
***** lgebras semisimples
Un lgebra $A$ de dimensin finita es *semisimple* si todo A-mdulo de
dimensin finita es semisimple.

***** Caracterizacin de lgebras semisimples
Un lgebra de dimensin finita es semisimple si y slo si es semisimple
como A-mdulo.

****** Demostracin
Si $M$ es un mdulo finito-dimensional, es el cociente de un libre $A^n$.
Como $A^n$ es semisimple por serlo $A$, su [[*Submdulos y cocientes de semisimples][cociente]] $M$ es semisimple.

***** Estructura de los mdulos de un lgebra semisimple
Sea $A$ es un lgebra semisimple con estructura $(n_1,\Sigma_1),\dots,(n_t,\Sigma_t)$ como
$A\text{-mdulo}$, entonces todo $A\text{-mdulo}$ finito tiene estructura $(m_1,\Sigma_1),\dots,(m_t,\Sigma_t)$
para algunos $m_1,\dots,m_t$. En particular, todo $A\text{-mdulo}$ simple es isomorfo a 
un $\Sigma_j$.

****** Demostracin
Los mdulos de dimensin finita son cocientes de $A^n$, y la estructura de
$A^n$ es simplemente $(nn_1,\Sigma_1),\dots,(nn_t,\Sigma_t)$, y sabemos que la estructura de los
submdulos y de los cocientes es la misma con coeficientes menores.

***** lgebra de matrices sobre anillo de divisin es semisimple
Dada $\Delta$ lgebra de divisin finito-dimensional, $M_n(\Delta)$ es un lgebra 
semisimple con estructura $(n, \Sigma)$ para $\Delta \cong \mathrm{End}(\Sigma)^{op}$. Adems, $M_n(\Delta)^{op} \cong M_n(\Delta^{op})$.

****** Demostracin
******* El lgebra de matrices es semisimple
Tomamos $A_j$ el ideal izquierda de $M_n(\Delta)$ con base $\left\{ E_{1j},\dots,E_{nj} \right\}$.
Comprobamos que es simple, ya que cualquiera de sus elementos no
nulos genera $M_n(\Delta)E_{jj}$, por ser $\Delta$ anillo de divisin.

As, vemos que $M_n(\Delta)$ es semisimple por ser

\[ M_n(\Delta) = A_1 \oplus \dots \oplus A_n. \]

******* Estructura unimodular
Veamos que existe un isomorfismo de mdulos $A_1 \cong A_j$, explcitamente

\[
f(a_1E_{11}+\dots +a_nE_{n1}) = a_1 E_{1j} + \dots + a_n E_{nj}
\]

es trivialmente isomorfismo de espacios vectoriales y se comprueba que
es homomorfismo de mdulos por tenerse

\[
f\left(\left( \sum_{}  \right)\right)
\]

***** Teorema de Wedderburn
Una $K\text{-lgebra}$ de dimensin finita es semisimple ssi es isomorfa a un
lgebra de la forma

\[ \mathrm{M}_{n_1}(\Delta_1) \times \dots \times \mathrm{M}_{n_t}(\Delta_t).
\]

de forma nica para algunas $\Delta_1,\dots,\Delta_t$ lgebras de divisin de dimensin
finita. Adems, esta factorizacin es esencialmente nica.

****** TODO Demostracin

***** Centro de lgebra semisimple de dimensin finita
Si $A$ es semisimple de dimensin finita, $Z(A)$ es producto finito de cuerpos
extensin finita de $k$. El nmero de factores es el nmero de $A\text{-mdulos}$ simples
no isomorfos en la estructura de $A$.

****** TODO Demostracin
***** Semisimplicidad del lgebra opuesta
Si $A$ es semisimple, entonces $A^{op}$ es semisimple.

****** TODO Demostracin

***** Teorema de Molien
Un lgebra compleja $A$ de dimensin finita es semisimple ssi es
isomorfa a exactamente una de la forma

\[ \mathrm{M}_{n_1}(\mathbb{C}) \times \dots \mathrm{M}_{n_t}(\mathbb{C})
\]

cumpliendo $\mathrm{dim}_{\mathbb{C}}(A) = n_1^2+\dots+n_t^2$.

*** 2. Representaciones de grupos finitos
**** 2.1. Representaciones lineales de grupos finitos y mdulos
***** 2.1. Representacin
Una *representacin* $k\text{-lineal}$ de $G$ es un homomorfismo de grupos

\[\rho \colon G \to \mathrm{GL}(V).\]

****** Espacio de representacin
Llamamos a $V$ /espacio de representacin/ y a su dimensin la
/dimensin de la representacin/. 

****** Dimensin finita
Aqu consideraremos slo representaciones de dimensin finita.

***** lgebra de grupo
Para $G$ grupo finito y $k$ cuerpo, el /lgebra de grupo/ $kG$ se define
como el $k\text{-espacio}$ vectorial libre sobre $G$ con el producto dado por la
extensin bilineal del producto sobre $G$.

***** Relacin entre representacin y mdulo del lgebra de grupo
La aplicacin que asigna cada homomorfismo de lgebras $\Pi\colon kG \to \mathrm{End}_k(V)$
su restriccin $\rho \colon G \to \mathrm{GL}(V)$ es una biyeccin a las representaciones.

Las representaciones $k\text{-lineales}$ de $G$ son las estructuras de $kG\text{-mdulo}$
sobre $V$.

****** Demostracin
Sabemos que cada homomorfismo $G \to \mathrm{GL}(V)$ extiende de manera nica
por ser una base de $kG$ y extiende al producto por estar definido
precisamente por extensin. Cada aplicacin restringe a $GL(V)$ por
ser los elementos de $G$ invertibles en $kG$ y es homomorfismo de
grupos.

***** Subespacio invariante
Un subespacio $W \leq V$ es $\rho\text{-invariante}$ si $\rho(g)(W) \leq W$ para cualquier $g \in G$.

/Equivalentemente, es un $kG\text{-mdulo}$/.

***** Representacin irreducible
Una representacin no nula es irreducible si no tiene espacios invariantes
propios.

/Equivalentemente, el $kG\text{-mdulo}$ es simple/.

**** 2.2. Representaciones completamente reducibles. Teorema de Maschke
***** 2.8. Representacin completamente reducible
Una representacin se llama *completamente reducible* si es nula
o el espacio de representacin es suma directa de espacios irreducibles.

/Equivalentemente, el $kG\text{-mdulo}$ es semisimple/.

***** 2.9. Teorema de Maschke
Sea $G$ grupo finito y $k$ cuerpo con $\mathrm{char}(k) \nmid |G|$. Toda representacin aqu es
completamente reducible.

/Equivalentemente, $kG$ es un lgebra semisimple/.

****** Demostracin
Dada $\varphi \colon V \to U$ $k\text{-lineal}$, definimos

\[
\widetilde \varphi(v) = \frac{1}{|G|}\sum_{g \in G}g \varphi(g^{-1}v),
\]

usando que $\mathrm{char}(k) \nmid |G|$, y es un homomorfismo de $kG\text{-mdulos}$,

\[\begin{aligned}
\widetilde\varphi(hv) = 
\frac{1}{|G|}\sum_{g \in G}hh^{-1}g\varphi(g^{-1}hv) =
h \frac{1}{|G|} \sum_{k \in G} k \varphi(k^{-1}v) = h \widetilde\varphi(v).
\end{aligned}\]

Sea ahora $V$ un $kG\text{-mdulo}$ con $W \leq V$. Consideramos $\pi\colon V \to V/W$, y
usando el complemento como espacio vectorial, creamos $\varphi\colon V/W \to V$
lineal con $\pi\circ\varphi = \mathrm{id}_{V/W}$ y tomamos la $\widetilde \varphi$. Tenemos entonces

\[
\pi(\widetilde\varphi(x)) =
\pi \left( \frac{1}{|G|}\sum_{g \in G}g\varphi(g^{-1}x) \right) =
\frac{1}{|G|} g\pi(\varphi(g^{-1}x)) =
\frac{1}{|G|} \sum_{g \in G} gg^{-1}x = x,
\]

y por tanto $\pi \circ \widetilde\varphi = \mathrm{id}_{V/W}$. Si tomamos $U = \operatorname{Im} \widetilde\varphi$, vemos que $V = W \oplus U$;
luego todo submdulo es un sumando directo.

***** 2.10.a. Representaciones equivalentes
Dos representaciones $k\text{-lineales}$ de $G$ se llaman *equivalentes* si los
$kG\text{-mdulos}$ son isomorfos.

***** 2.10.b. Representacin regular
La representacin regular $\rho_{reg}$ es la asociada al propio $kG$ como $k\text{-mdulo}$.
Cuando $\mathrm{char}(k) \nmid |G|$ es, por [[*Teorema de Maschke][Teorema de Maschke]], suma de irreducibles, que
notaremos como

\[\rho \sim
\rho_1^{n_1}\oplus \dots\oplus \rho_t^{n_t}
\]

para ciertas multiplicidades $n_i$.

***** 2.10.c. Constituyentes
Usando la estructura de las lgebras semisimples, sabemos que cualquier
representacin $k\text{-lineal}$ de $G$ ser de la forma

\[\rho \sim
\rho_1^{m_1}\oplus \dots\oplus \rho_t^{m_t}
\]

para ciertas multiplicidades $m_i$. Llamamos a las $\rho_i$ con multiplicidad positiva
las *constituyentes* de $\rho$.

***** 2.11. Multiplicidades en la representacin regular
Cuando $\mathrm{char}(k) \nmid |G|$, si las representaciones $k\text{-lineales}$ irreducibles de $G$
son $(V_1,\rho_1),\dots,(V_{t},\rho_t)$ y tenemos $n_i$ la multiplicidad de cada una de ellas
en la representacin regular y $d_i = \mathrm{dim}_k(\Delta_i)$ la dimnesin asociada al
lgebra de divisin que da el teorema de Wedderburn; tenemos que
$\mathrm{dim}_k(V_i) = d_in_i$ y $|G| = d_1n_1^2 +\dots + d_tn_t^2$.

****** TODO Demostracin

***** 2.12. Multiplicidades en al representacin regular compleja
Sean $(V_1,\rho_1),\dots,(V_t,\rho_t)$ las representaciones irreducibles complejas de $G$.
Si las multiplicidades en la representacin regular son $(n_1,\dots,n_t)$,
entonces $\mathrm{dim}_{\mathbb{C}} V_i = n_i$ para $i = 1,\dots,t$ y $|G| = n_1^2 + \dots + n_t^2$.

****** TODO Demostracin
***** 2.13. Dimensin del centro del lgebra-grupo
Sean $C_1,\dots,C_r$ las clases de conjugacin de $G$. Entonces $\mathrm{dim}_k Z(kG) = r$.

****** TODO Demostracin

***** 2.14. Nmero de representaciones irreducibles complejas
El nmero de clases de conjugacin de $G$ coincide con el nmero de
representaciones irreducibles complejas de $G$.

****** TODO Demostracin
**** 2.3. Caracteres
***** 2.15. Carcter complejo
Para $(V,\rho)$ representacin compleja de $G$, la aplicacin $\chi_{\rho}\colon G \to \mathbb{C}$ dada
por $\chi_{\rho}(g) = \mathrm{tr}(\rho(g))$, se llama *carcter* complejo de $\rho$.

****** Carcter irreducible
El que procede de una representacin irreducible.

****** Grado de un carcter
Dimensin de $V$ como espacio vectorial complejo.

***** 2.16. Carcter invariante por equivalencia
Dos representaciones complejas equivalentes proporcionan el mismo
carcter.

****** Demostracin
Si $(V,\rho)$ y $(W,\pi)$ son equivalentes por $T \colon V \to W$, para $g \in G$ tenemos
que $T\rho(g) = \pi(g)T$, luego $\rho(g) = T^{-1}\pi(g)T$, y sabemos que la traza se
preserva por semejanza.

***** 2.17.a. Exponente de un grupo
El *exponente* de un grupo $G$ es el mnimo comn mltiplo de los rdenes
de sus elementos.

***** 2.17.b. Diagonalizacin de elementos de la representacin
Sea $G$ con exponente $m$ y $(V,\rho)$ representacin de grado $n$. Existen races
$m\text{-simas}$ de la unidad $\omega_1,\dots,\omega_n$ en las que diagonaliza $\rho(g)$. Se tiene
entonces

\[\chi_{\rho}(g) = \omega_1+\dots + \omega_n \]

y

\[\chi_{\rho}(g^{-1}) = \overline{\chi_{\rho}(g)}.
\]

****** TODO Demostracin

***** 2.18. Cota del carcter
Para $G$ con exponente $m$ y $(V,\rho)$ representacin,

\[|\chi_{\rho}(g)| \leq \operatorname{deg} \chi_{\rho}.
\]

El caso de igualdad se tiene si y slo si $\rho(g) = \omega \mathrm{id}_V$ para alguna raz
$m\text{-sima}$ de la unidad.

****** Caso de la identidad
En particular, $\chi_{\rho}(g) = \operatorname{deg} \chi_{\rho}$ si y slo si $\rho(g) = \mathrm{id}_V$.

***** 2.19. Ncleo de un carcter
Dado $\chi$ carcter complejo, su *ncleo* se define como

\[\ker \chi = \left\{ g \in G \mid \chi(g) = \chi(1) \right\}.
\]

****** TODO El ncleo es un subgrupo normal

***** Extensin de representaciones y caracteres
Dada una representacin $\rho \colon G \to \mathrm{Aut}(V)$, notamos por $\tilde{\rho}(g) \colon \mathbb{C}G \to \mathrm{End}_{\mathbb{C}}(V)$ la
extensin al lgebra-grupo. Dado un carcter $\chi_{\rho} \colon G \to \mathbb{C}$, notamos por 
$\widetilde{\chi_{\rho}} \colon \mathbb{C}G \to \mathbb{C}$ a la extensin al lgebra grupo.

***** Caracteres irreducibles complejos
Los *caracteres irreducibles* complejos de $G$ son los dados por sus
representaciones irreducibles.

****** Dimensin del espacio de representacin
Ntese que para cualquier carcter irreducible se tiene
# Necesitamos que sea irreducible?

\[n_i = \operatorname{dim}_{\mathbb{C}} V_{i} = \chi_i(1).\]

***** Carcter de la suma directa
Si $(W,\pi)$ es una representacin con $W = W_{1} \oplus \dots \oplus W_m$, se tiene que

\[\chi_{\pi} = \chi_{\pi_1} + \dots + \chi_{\pi_m}.
\]

****** TODO Demostracin

***** Carcter regular
El *carcter regular* es el carcter de la representacin regular.
Cumple que

 1) \[\chi_{reg}(g) = \left\{\begin{array}{ll} |G|,  & \mbox{si } g=1 \\0, & \mbox{si }  g \neq 1.
    \end{array} 
    \right.\]
 2) $\chi_{reg} = \chi_1(1)\chi_1 + \dots + \chi_t(1)\chi_t$.

****** TODO Demostracin

**** 2.4. La tabla de caracteres
***** TODO Tabla de caracteres
***** TODO Teorema de Frobenius
**** 2.5. Funciones de clase. Reciprocidad
***** Producto interno
En el espacio vectorial $\mathbb{C}^G$, de dimensin $|G|$, definimos el siguiente
*producto interno*

\[(\varphi,\psi) = \frac{1}{|G|} = \sum_{g \in G}\overline{\varphi(g)}\psi(g).
\]

****** Conjunto ortonormal
Ntese que los $\left\{ \chi_1,\dots,\chi_t \right\}$ forman un /conjunto ortonormal/ de vectores
en $\mathbb{C}^G$.

****** Base ortonormal
Si $G$ es /abeliano/, tiene tantas clases de conjugacin como elementos.
Tenemos $t = |G|$ y los caracteres irreducibles son una base ortonormal
de $\mathbb{C}^G$.

***** Funciones de clase
Una *funcin de clase* de $G$ es una aplicacin $\varphi\colon G \to \mathbb{C}$ constante sobre
cada clase de conjugacin de $G$. Es decir,

\[
\varphi(hgh^{-1}) = h\varphi(g) h^{-1}.
\]

Al subespacio complejo de funciones de clase lo llamamos ${\cal C}(G)$.

***** Base ortonormal de las funciones de clase
Los caracteres irreducibles $\mathrm{Irr}(G) = \left\{ \chi_1,\dots,\chi_t \right\}$ forman una base ortonormal
de ${\cal C}(G)$.

****** TODO Demostracin

***** Equivalencia por caracteres
Dos representaciones complejas de $G$ son equivalentes si, y slo si,
proporcionan el mismo carcter.

****** TODO Demostracin

***** Restriccin e induccin
Fijados $H \leq G$, definimos

 * la *restriccin* $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ de funciones de clase.
 * la *induccin* $(-)^G\colon {\cal C}(H) \to {\cal C}(G)$ de funciones de clase.

La /induccin/ se define como

\[
\varphi^G(g) = \frac{1}{|H|}\sum_{x \in G}\varphi^{\bullet}(x^{-1}gx),
\]

donde $\varphi^{\bullet}(g) = \varphi(g)$ cuando $g \in H$ y $\varphi^{\bullet}(g) = 0$ cuando $g \notin H$.

***** Reciprocidad de Frobenius
Sea $H$ un subgrupo de $G$, $\varphi \in {\cal C}(H)$ y $\psi \in {\cal C}(G)$. Entonces

\[(\psi_H,\varphi) = (\psi,\varphi^G).
\]

****** TODO Demostracin

***** La induccin de un carcter es carcter
Si $\varphi$ es carcter de $H$, entonces $\varphi^G$ es un carcter de $G$.

****** TODO Demostracin

***** TODO Constituyentes

*** Ejercicios de clase
**** Ejercicio 1
#+begin_statement
Comprobar que $K$ es una K-lgebra.
#+end_statement

Tenemos que $K$ es un espacio vectorial sobre s mismo y su propio
producto es una aplicacin bilineal sobre $K$, ya que cumple:

  - $(a+b)c = ac+bc$, por axiomas de anillo.
  - $a(b+c) = ab+ac$, por axiomas de anillo.
  - $a(bc) = (ab)c = b(ac)$, el producto es conmutativo y asociativo.

Adems es un lgebra asociativa y unital.

**** Ejercicio 2
#+begin_statement
Calcular el centro del lgebra de matrices $M_n(K)$.
#+end_statement

Supongamos $A \in Z(M_n(K))$, si tomamos las matrices que slo tienen una 
entrada unidad y el resto ceros $E_{ij} = (\delta_{ij})_{i,j}$. As, tenemos:

\[
E_{ii}A = \begin{pmatrix}
0 & \dots & 0 \\
^{i)} a_{i1} & \dots & a_{in} \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ii} = \begin{pmatrix}
0 & ^{i)}a_{1i} & 0 \\
\vdots & \vdots & \vdots \\
0 & a_{ni} & 0 \\
\end{pmatrix}
\]

Por lo tanto $a_{ij} = 0$ para $i \neq j$. Adems,

\[
E_{ij}A = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)} \dots & a_{ii} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\qquad
AE_{ij} = \begin{pmatrix}
0 & ^{j)}\dots & 0 \\
^{i)}\dots & a_{jj} & \dots \\
0 & \dots & 0 \\
\end{pmatrix}
\]

Por tanto, $A = \lambda I$. Se cumple que $(\lambda I) B = \lambda (I B) = \lambda B = \lambda (B I) = B (\lambda I)$,
y el centro es de la forma

\[
\left\{
\lambda I \mid \lambda \in K
\right\}
\]

**** Ejercicio 3
#+begin_statement
Comprobar que $Im(u) \subseteq Z(A)$, siendo $u : K \longrightarrow A$, $u(\alpha) = \alpha 1_A$.
#+end_statement

Usando la bilinealidad:

\[
u(\alpha) a =
(\alpha 1) a =
\alpha (1a) =
1 (\alpha a) =
(\alpha a) 1 =
a (\alpha 1)
\]

**** Ejercicio 4
#+begin_statement
Supongamos $A$ anillo y $K$ cuerpo. Dado un homomorfismo de anillos $u : K \longrightarrow A$,
demostrar que $A$ es una K-lgebra si defino su estructura de K-espacio 
vectorial como sigue:

\[
\forall\alpha \in K, a \in A:\quad \alpha a = u(\alpha) a
\]

Es decir, podemos definir alternativamente un lgebra sobre $K$ como un
homomorfismo de anillos $u : K \longrightarrow Z(A)$, el *homomorfismo de estructura*.
#+end_statement

Debemos comprobar que la multiplicacin del anillo es bilineal sobre la
estructura de espacio vectorial:

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Por lo que forma un K-lgebra.

**** Ejercicio 5
#+begin_statement
Comprobar que $Z(\mathbb{H}) = \mathbb{R}$.
#+end_statement

Supongamos un elemento en el centro $z = a+bi+cj+dk$, debera conmutar con
$i,j$, as que:

\[
0 = zi-iz = (ai-b-ck+dj) - (ai-b+ck-dj) = 2(dj-ck)
\]
\[
0 = zj-jz = (aj+bk-c-di) - (aj-bk-c+di) = 2(bk-di)
\]

De donde tenemos $b=c=d=0$, y por tanto, el elemento debe estar en $\mathbb{R}$.

**** Ejercicio 6
#+begin_statement
Dados $q,p\in \mathbb{H}$, escritos como suma de vector y escalar, se tiene la frmula:

\[
(a+v)(b+w) = ab + aw + bv - v\cdot w + v \wedge w
\]
#+end_statement

Los tres primeros trminos se tienen porque el producto escalar coincide
con el producto de un real por un cuaternin. Los dos ltimos trminos se
tienen como sigue. Si tomamos $v = xi+yj+zk$, $w = oi+pj+qk$; y los
interpretamos como vectores como $v = (x\ y\ z)$, $w = (o\ p\ q)$:

\[
vw = (-xo-yp-qz) + (pxk-qxj - oyk+qyi + ozj-pzi)
\]

Y comprobamos que:

\[(x\ y\ z)(o\ p\ q) = xo+yp+zq\]

\[\begin{vmatrix}
i&j&k \\
x&y&z \\
o&p&q \\
\end{vmatrix}
=
pxk-qxj - oyk+qyi + ozj-pzi
\]

**** TODO Ejercicio 7
#+begin_statement
Demostrar que un grupo abeliano $(V,+)$ junto a una accin $A\times V \to V$ es
un mdulo ssi verifica las cuatro condiciones siguientes:

  1. $(a+a')v = av + a'v$
  2. $a(v+v') = av+av'$
  3. $a(a'v) = (aa')v$
  4. $1v = v$
#+end_statement
**** Ejercicio 8
#+begin_statement
Definir un submdulo.
#+end_statement

Un submdulo debe tener estructura de mdulo y una inclusin al mdulo
del que es submdulo. Exigimos entonces, para que tenga estructura de mdulo,
que sea cerrado respecto a la suma y al producto por elementos del lgebra.
Ntese que dentro de los elementos del lgebra estn los elementos del 
cuerpo base del lgebra.

**** Ejercicio 9
#+begin_statement
Sea $N_1,\dots,N_m \in {\cal L}(M)$. Demostrar que:

\[
N_1+\dots+N_m
=
\{m_1+\dots+m_n \mid m_i \in N_i \}
\]
#+end_statement

Primero notamos que es un mdulo, ya que:

 - $a(m_1+\dots+m_n) = am_1+\dots+am_n$
 - $(m_1+\dots+m_n)+(m'_1+\dots+m'_n) = (m_1+m'_1) + \dots + (m_n+m'_n)$

Despus notamos que si un mdulo contiene a $N_1,\dots,N_m$ debe contener
todas las sumas de sus elementos por ser cerrado para la suma. As,
este es el mnimo mdulo conteniendo a $N_i$.

**** Ejercicio 10
#+begin_statement
Para qu valores del ngulo el giro en el plano da slo submdulos propios?
Es decir, cundo es $\mathbb{R}^2$ simple como $\mathbb{R}[T]$ mdulo con $T$ giro?
#+end_statement

Sea $M$ un submdulo de $\mathbb{R}^2$ con $v \not\in M$. Si $T(v),v$ son linealmente 
independientes, el espacio $\langle Tv,v \rangle$ ser $\mathbb{R}^2$ y no podr existir un mdulo
propio. En otro caso, $\langle v \rangle$ ser un mdulo propio.

Para tener $Tv,v$ independientes, es necesario tener un giro mltiplo de $\pi$.

**** TODO Ejercicio 11 ()
#+begin_statement
Calcular todos los $\mathbb{R}[X]\text{-mdulos}$ de $\mathbb{P}_n$ para la accin de derivacin.
#+end_statement

**** Ejercicio 12?
#+begin_statement
Sean $M = S_1\oplus \dots \oplus S_t$, $N = T_1\oplus \dots \oplus T_n$ con $S_i,T_i$ simples y cumpliendo
$S_i \not\cong T_j$. Probar que todo homomorfismo de mdulos $f \colon M \to N$ es $0$.
#+end_statement

Similar al [[*Ejercicio 23 ()][ejercicio 23]].

*** Ejercicios de los apuntes
**** Ejercicio 1 (*)
#+begin_statement
Calcular el centro del lgebra de matrices $M_n(K)$.
#+end_statement

**** Ejercicio 2
#+begin_statement
Escribir la demostracin de la Proposicin 1.7.
#+end_statement

***** La imagen es sublgebra
Trivialmente, la imagen es espacio vectorial y $f(a)f(b) = f(ab)$.

***** El ncleo es un ideal
El ncleo es subespacio vectorial y adems,

\[
f(ak) = f(a)f(k) = 0 = f(k)f(b) = f(kb)
\]

para cualquier $f(k) = 0$.

***** Isomorfa
Notamos primero que $\widehat f$ es el mismo que obtendramos aplicando el
primer teorema de Isomorfa entre espacios vectoriales. As, sabemos
que est bien definido y que es una funcin lineal biyectiva.

Comprobaremos simplemente que preserva el producto, probando as que
es un isomorfismo de k-lgebras; pero esto es trivial por la estructura
de lgebra con la que hemos dotado al cociente:

\[
\widehat f((a+I)(b+I)) = 
\widehat f(ab+I) = f(ab) = f(a)f(b) 
= \widehat f(a+I) \widehat f(b+I).
\]

**** Ejercicio 3
#+begin_statement
Supongamos que $K$ es un cuerpo, y $A$ es un anillo (no necesariamente
conmutativo). Sea $u : K \to A$ un homomorfismo de anillos tal que
$Im(u) \subseteq Z(A)$, donde $Z(A)$ denota el centro de $A$, definido de manera
obvia. Comprobar que si definimos la accin de $K$ sobre $A$ dada por
$\alpha a = u(\alpha) a$, para todo $\alpha \in K, a \in A$, entonces $A$ es una k-lgebra.
#+end_statement

Comprobamos primero que $A$ es un k-espacio vectorial. Con su suma es
un grupo abeliano, y por ser el producto sobre ella distributivo y
el homomorfismo de anillos unital y asociativo:

 - $u(\alpha)(a+b) = u(\alpha)a + u(\alpha)b$
 - $u(1)a = 1a = a$
 - $u(\alpha)u(\beta)(a+b) = u(\alpha\beta)(a+b)$
 - $u(\alpha+\beta)a = u(\alpha)a + u(\beta)a$

Ahora comprobaremos simplemente que el producto del anillo es una
operacin bilineal en este espacio vectorial.

  - $(a+b)c = ac+bc$
  - $a(b+c) = ab+ac$
  - $(\alpha a)c = (u(\alpha) a) c = a u(\alpha) c$

Donde hemos usado distributividad del producto y que $u(\alpha) \in Z(A)$.

**** Ejercicio 4
#+begin_statement
Demostrar que, realmente, $End_K(V)$, con las operaciones recin descritas
(suma, producto escalar y composicin), es una K-lgebra.
#+end_statement

La suma se define por $(f+g)(v) = f(v)+g(v)$, lo que da un grupo abeliano
con el neutro $0(v) = 0$; adems, con $(\alpha f)(v) = \alpha f(v)$, nos da un espacio
vectorial.

Comprobamos adems que la composicin es bilineal:

  1. $((f+g)\circ h)(v) = f(h(v)) + g(h(v)) = (f\circ h + g\circ h)(v)$
  2. $(f\circ (g+h))(v) = f(g(v)) + f(h(v)) = (f\circ g + f\circ h)(v)$
  3. $(\alpha f \circ g)(v) = \alpha (f\circ g)(v)) = f(\alpha g(v)) = (f \circ \alpha g)(v)$

Donde en el primer y segundo punto usamos la definicin de suma; y
en el tercer punto usamos la linealidad de la funcin para conmutar
el elemento del cuerpo y la aplicacin de la funcin.

**** Ejercicio 5 (*)
#+begin_statement
Comprobar todas las afirmaciones hechas en el Ejemplo 11.
#+end_statement

***** Estructura del espacio cociente
Sabemos que cada ideal no nulo lo genera un polinomio por ser un
Dominio de Ideales Principales, que adems podemos suponer mnico por ser $K$ 
un cuerpo. Como adems los polinomios forman un dominio eucldeo con el
grado como funcin eucldea, podemos escribir cualquier polinomio $t$ como

\[
t(X) = r(X) + p(X)q(X), \text{ para } \mathrm{deg}(r) < n,
\]

y por tanto, ${\cal B} = \left\{ 1+I, x+I,\dots, x^{n-1}+I \right\}$ es un sistema generador. Sabemos
que es linealmente independiente porque si no lo fuese, tendramos una
relacin lineal que dara lugar a que un polinomio de grado menor que $n$
estuviera en el ideal. As, ${\cal B}$ es base.

***** Matriz compaera
Podemos comprobar que la matriz compaera es la que representa a $\lambda_{x+I}$
por tenerse que $(x+I)(x^{i-1}+I) = (x^{i}+I)$ para $i < n$ y que

\[x^{n}+I = p_0-p_1x-\dots-p_{n-1}x^{n-1} + I\]

Sabemos ahora que $\lambda : A \to \mathrm{End}(A)$ es un homomorfismo inyectivo de lgebras
que lleva $\lambda_{x+I} = \tilde N(p)$ y que por ser inyectivo preserva la independencia
lineal de la base. As, la imagen de los elementos de la base es una base
de la imagen, y tenemos que el lgebra $A$ es isomorfa a la sublgebra de
$M_n(K)$

\[
\left\{ a_0I+a_1\tilde N(p) + \dots + a_{n-1}\tilde N(p)^{n-1} \mid
a_0,a_1,\dots,a_{n-1} \in K \right\} \subseteq M_n(K).
\]

**** Ejercicio 6
#+begin_statement
Expresar el cuerpo $\mathbb{Q}(\sqrt{2})$ como una $\mathbb{Q}$ sublgebra de un lgebra de matrices
sobre $\mathbb{Q}$.
#+end_statement

Empezamos notando que

\[
\mathbb{Q}\left(\sqrt{2}\right) = \frac{\mathbb{Q}}{(X^2-2)},
\]

y que podemos por tanto aplicar el razonamiento del ejemplo 11 para saber
que si la matriz compaera del polinomio $p(x) = x^2-2$ es

\[\tilde N(p) = \begin{pmatrix}
0 & 2 \\
1 & 1
\end{pmatrix},\]

el lgebra ser isomorfa a la sublgebra de $M_2(\mathbb{Q})$ dada por

\[
\left\{ aI + b\tilde N(p) \mid a,b \in \mathbb{Q} \right\}.
\]

**** Ejercicio 7
#+begin_statement
Sea

\[\mathbb{H} = \left\{ \begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} \mid \alpha,\beta \in \mathbb{C} \right\}\]

  1. Demostrar que $\mathbb{H}$ es una sublgebra real de $M_2(\mathbb{C})$ y que $Z(\mathbb{H}) = \mathbb{R}$.
  2. Demostrar que todo elemento no nulo de $\mathbb{H}$ es una unidad.
  3. Demostrar que las matrices

     \[\mathbf{1} = \begin{pmatrix}1 & 0 \\0 & 1\end{pmatrix},\; 
     \mathbf{i} = \begin{pmatrix}0 & -1 \\ 1 & 0\end{pmatrix},\;
     \mathbf{j} = \begin{pmatrix}i & 0 \\ 0 & -i\end{pmatrix},\;
     \mathbf{k} = \begin{pmatrix}0 & i \\ i & 0\end{pmatrix}
     \]

     forman una base de $\mathbb{H}$ como espacio vectorial real.
  4. Comprobar las identidades

     \[
     i^2=j^2=k^2=-1,\; ij=k,\; jk=i,\; ki=j
     \]

El lgebra as construida se llama lgebra de los cuaterniones de Hamilton.
#+end_statement

***** Primer punto
Comprobamos que es cerrada bajo el producto por reales

\[\lambda\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\lambda\overline{\beta} \\
\lambda\beta & \lambda\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\lambda\alpha & -\overline{\lambda\beta} \\
\lambda\beta & \overline{\lambda\alpha}
\end{pmatrix}
\]

y que es cerrada bajo su producto

\[\begin{pmatrix}
\alpha & -\overline{\beta} \\
\beta & \overline{\alpha}
\end{pmatrix}\begin{pmatrix}
\gamma & -\overline{\delta} \\
\delta & \overline{\gamma}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\overline{\delta}\alpha-\overline{\beta}\overline{\gamma} \\
\beta\gamma+\overline{\alpha}\delta & -\overline{\delta}\beta + \overline{\gamma}\overline{\alpha}
\end{pmatrix} = \begin{pmatrix}
\alpha\gamma-\overline{\beta}\delta & -\left(\overline{\beta\gamma+\overline{\alpha}\delta}\right)\\
\beta\gamma+\overline{\alpha}\delta & \overline{\alpha\gamma-\overline{\beta}\delta}
\end{pmatrix}.
\]

Adems, si tomamos una matriz en el centro, debe cumplir

\[\begin{aligned}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix}\begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix} = \begin{pmatrix}
ac-\overline{b}d & -a\overline{d}-\overline{bc} \\
bc+\overline{a}d & \overline{ac} - b\overline{d}
\end{pmatrix} &=\\ =\begin{pmatrix}
ac-b\overline{d} & -\overline{b}c-\overline{da} \\
ad+\overline{c}b & \overline{ac}-\overline{b}d
\end{pmatrix} &= \begin{pmatrix}
c & -\overline{d} \\
d & \overline{c}
\end{pmatrix}\begin{pmatrix}
a & -\overline{b} \\
b & \overline{a}
\end{pmatrix},\end{aligned}
\]

as que $\overline{b}d = b\overline{d}$ y $\overline{a}d+bc = ad + \overline{c}d$. Tomando $c=0$ y $d=1$ llegamos a que
$a,b \in \mathbb{R}$; y tomando $d = i$, que $b=0$. As, las nicas matrices en el centro
sern las que representan a los reales, de la forma

\[\left\{\begin{pmatrix}\lambda & 0 \\ 0 & \lambda
\end{pmatrix}\mid \lambda \in \mathbb{R}\right\}\]

***** Segundo punto
Simplemente comprobar que cada elemento tiene una inversa a derecha

\[\begin{pmatrix}
a & -\overline{b} \\ b & \overline{a}
\end{pmatrix}\begin{pmatrix}
\frac{\overline{a}}{a\overline{a}+b\overline{b}} & 
\frac{\overline{b}}{a\overline{a}+b\overline{b}} \\ 
\frac{-b}{a\overline{a}+b\overline{b}} & 
\frac{a}{a\overline{a}+b\overline{b}}
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}\]

usando que si $a\overline{a}+b\overline{b} = 0$, es porque $a=b=0$ y el elemento es nulo.

***** Tercer punto
Sabiendo que los complejos son un espacio vectorial de dimensin $2$
con base $\{1,i\}$, podemos escribir los elementos de $\mathbb{H}$ como

\[\begin{pmatrix}
a+bi & -c+di \\
c+di & a-bi
\end{pmatrix} = a\begin{pmatrix}
1 & 0 \\ 0 & 1
\end{pmatrix}+
b\begin{pmatrix}
i & 0 \\ 0 & -i
\end{pmatrix}+
c\begin{pmatrix}
0 & 1 \\ -1 & 0
\end{pmatrix}+
d\begin{pmatrix}
0 & i \\ i & 0
\end{pmatrix}\]

que trivialmente es una descomposicin nica por independencia lineal.

***** Cuarto punto
Podemos comprobar trivialmente los clculos.

**** Ejercicio 8
#+begin_statement
Dado un A-mdulo $V$, demostrar que $\mathrm{Ann}_A(V) = \left\{ a \in A \mid av=0\; \forall v\in V \right\}$ es un
ideal de $A$. Dotar a $V$ de estructura de $A/\mathrm{Ann}_{A}(V)\text{-mdulo}$ fiel (es decir,
la representacin correspondiente es fiel).
#+end_statement

Si $a \in \mathrm{Ann}_A(V)$ tenemos que para cualquier $r \in A$ y $v \in V$, $rav = r0 = 0$ y 
$(ar)v = a(rv) = 0$. Podemos dotar a $V$ de estructura de mdulo en el cociente
como

\[
\left( a+ \mathrm{Ann}(V) \right)v = av.
\]

Esta representacin es fiel porque si tenemos $\forall v\in V\colon av = bv$, entonces
se tiene $a-b \in \mathrm{Ann}(V)$.

**** Ejercicio 9
#+begin_statement
Dar una demostracin del Lema 1.25.
#+end_statement

***** Primer punto
Es claro que el menor submdulo que contenga a $N_1 \cup \dots \cup N_m$ debe contener
en particular a todas las sumas y por tanto

\[
\left\{ n_1+\dots+n_m \mid n_i \in N_i \right\} \subseteq N_1 + \dots + N_m.
\]

Si adems probamos que es un submdulo, tendremos que debe ser el menor
conteniendo a la unin. Es cerrado para la suma por tenerse

\[
(n_1+\dots+n_m)+(n'_1+\dots+n'_m) =
(n_1+n'_1)+\dots+(n_m+n_m')
\]

y cerrado para el producto por elementos del anillo por tenerse

\[
a(n_1+\dots+n_m) = an_1+\dots+an_m.
\]

***** Segundo punto
De la misma forma, es claro que el menor submdulo conteniendo a $X$ debe
contener al menor mdulo conteniendo a cada uno de sus elementos, y por
tanto al menor submdulo conteniendo a todos esos submdulos. Sabemos
entonces que

\[
RX \supseteq Rm_1 + \dots + Rm_n.
\]

Pero adems, una suma de mdulos es un submdulo, as que este es el menor
submdulo que contiene a $X$.

**** Ejercicio 10
#+begin_statement
Dados $A\text{-mdulos}$ por la izquierda $M,N$ y una aplicacin $f\colon M \to N$,
demostrar que $f$ es homomorfismo de $A\text{-mdulos}$ si, y slo si,
$f(am+a'm') = af(m) + a'f(m')$ para todo $a,a'\in A;\; m,m'\in M$.
#+end_statement

***** Si es homomorfismo de mdulos cumple la regla
Aplicando primero linealidad y luego dos veces la condicin de homomorfismo
de mdulos tenemos

\[
f(am+a'm') = f(am)+f(a'm') = af(m) + a'f(m').
\]

***** Si cumple la regla, es homomorfismo de mdulos
La linealidad la comprobamos tomando $a=a'=1$, la unidad del lgebra,

\[
f(m+m') = f(1m+1m') = 1f(m) + 1f(m') = f(m) + f(m').
\]

Y la condicin de homomorfismo de mdulos se comprueba tomando $a' = m'=0$,

\[
f(am) = f(am+0) = af(m) + 0f(0) = af(m).
\]

**** Ejercicio 11
#+begin_statement
Demostrar que un conjunto de generadores $\{m_i \mid i \in I\}$ de un mdulo $_RM$ es una
base si, y slo si, la igualdad $\sum_{i\in I}r_im_i = 0$ para $r_i \in R$ implica $r_i = 0$ para
todo $i \in I$.
#+end_statement

***** Si es una base, se tiene la condicin
Si tenemos una base $\{m_i \mid i \in I\}$, en particular el $0$ se escribe de forma 
nica como $0 = \sum_{i\in I} 0m_i$. As, cualquier otra forma de escribir $0 = \sum_{i\in I} r_i m_i$
nos da $r_i = 0$.

***** Si se tiene la condicin, es una base
Si tenemos la condicin y tenemos dos formas distintas de escribir un
elemento, tendramos en particular

\[
\sum_{i\in I} r_im_i = m = \sum_{i\in I}s_im_i
\quad\text{ y }\quad
\sum_{i \in I} (r_i-s_i)m_i = 0.
\]

Lo que nos llevara a $r_i = s_i$ para cumplir la condicin.

**** Ejercicio 12
#+begin_statement
Sea $\theta \in \mathbb{R}$ y $T_\theta : \mathbb{R}^2\to\mathbb{R}^2$ el endomorfismo que gira los vectores un ngulo $\theta$
en sentido contrario de las agujas del reloj. Consideremos la correspondiente
estructura de $\mathbb{R}[X]$ mdulo definida por $T_\theta$ sobre $\mathbb{R}^2$. Discutir para qu valores
de $\theta$ es este mdulo simple.
#+end_statement

Supongamos un $v \in M$, subespacio vectorial. Como $Tv \in M$, tenemos dos casos,

  * si $Tv,v$ son linealmente dependientes, se tiene $Tv = \lambda v$ y por tanto debe
    tenerse $\theta = k\pi$ para algn $k \in \mathbb{Z}$. El mdulo no sera simple, ya que se
    tendra $T^2v = v$.
  * si no son linealmente dependientes, se tiene un espacio de dimensin al
    menos $2$, que debe ser por tanto el total. El mdulo sera simple.

Es decir, salvo en el caso $\theta = k\pi$, el mdulo es simple.

**** Ejercicio 13
#+begin_statement
Sea $M$ un $A\text{-mdulo}$. Demostrar que $M$ es simple si, y slo si, $M = Am$ para
todo $0 \neq m \in M$.
#+end_statement

***** Supongamos M simple
Entonces $Am$ es un submdulo no nulo, que debe ser por tanto $M$.

***** Supongamos la caracterizacin
Sea un submdulo de $M$ que contiene a algn elemento no nulo $m$. Por
las propiedades de submdulo, debe contener tambin a todo $Am = M$.
As, no existen submdulos propios.

**** Ejercicio 14 (*)
#+begin_statement
Consideramos $T\colon \mathbb{R}^3 \to \mathbb{R}^3$ una aplicacin lineal, y la estructura de $\mathbb{R}[X]\text{-mdulo}$
correspondiente sobre $\mathbb{R}^3$. Discutir los posibles valores de la longitud de
$\mathbb{R}^3$ como $\mathbb{R}[X]\text{-mdulo}$. Poner un ejemplo de $T$ para el que se alcance cada longitud.
#+end_statement

La longitud debe ser como mximo $3$, su dimensin como espacio vectorial
sobre $\mathbb{R}$. Estudiaremos los casos posibles.

*Longitud 1.*
Probaremos que no puede tenerse una cadena de longitud $1$; es decir, que
$\mathbb{R}^3$ sea simple. Toda aplicacin lineal $T$ nos da una ecuacin polinmica

\[ | T - \lambda I | = 0
\]

de grado $3$ con coeficientes reales, que debe tener al menos una solucin
en los reales. Esto nos da un vector propio y por tanto un subespacio que
queda fijo por la accin de $T$; es decir, un submdulo.

*Longitud 2.*
Tomamos $T$ la aplicacin que gira un plano mientras deja fija la recta
ortogonal a l; especficamente,

\[T = \begin{pmatrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix}
\]

nos da el subespacio $\left\langle e_3 \right\rangle$ fijo bajo su accin. Por otro lado, el
submdulo $\left\langle e_1,e_2 \right\rangle \cong \mathbb{R}^3/ \left\langle e_3 \right\rangle$ es simple; la rotacin no dejar ninguna
recta fija, no hay vectores propios. As, tenemos una serie de
composicin

\[
0 \subset \left\langle e_1,e_2 \right\rangle \subset \mathbb{R}^3.
\]

*Longitud 3.*
Simplemente tomando la identidad y retirando a cada paso una dimensin
del espacio vectorial

\[
0 \subset \left\langle e_1 \right\rangle
\subset \left\langle e_1,e_2 \right\rangle
\subset \left\langle e_1,e_2,e_3 \right\rangle.
\]

**** Ejercicio 15
#+begin_statement
Sea $\mathbb{P}_{n}$ el espacio vectorial real de las funciones polinmicas en una variable
de grado menor o igual que $n$. Sea $T\colon \mathbb{P}_n \to \mathbb{P}_n$ la aplicacin lineal que asigna
a cada polinomio su derivada. Calcular una serie de composicin de $\mathbb{P}_n$ visto
como $\mathbb{R}[X]\text{-mdulo}$ via $T$.
#+end_statement

Tenemos una base del espacio vectorial dada por $\left\{ 1,x,\dots,x^n \right\}$, podemos generar
una serie de composicin donde vemos que cada uno es un submdulo cerrado para
la derivacin y que cada cociente es simple por ser de dimensin $1$ en los reales
como

\[
0 \subset 
\left\langle 1 \right\rangle \subset
\left\langle 1,x \right\rangle \subset 
\dots \subset
\left\langle 1,x,\dots,x^n \right\rangle.
\]

**** Ejercicio 16 (**)
#+begin_statement
En las condiciones del Ejercicio 15, calcular todos los $\mathbb{R}[X]\text{-submdulos}$ de $\mathbb{P}_n$.
#+end_statement

Probaremos que los nicos submdulos de $\mathbb{P}_n$ son de la forma $\left\langle 1,x,x^2,\dots,x^k \right\rangle$.
Si tomamos un polinomio en un submdulo podemos suponerlo mnico por estar
en un cuerpo; y como adems es de caracterstica $0$, sus derivadas sern cada
una de un grado menor. As, dado $p = x^k+ \dots +a_1x + a_0 \in \mathbb{P}_n$ tendremos

\[\begin{aligned}
p =& x^k+& a_{k-1}x^{k-1} +& \dots &+& a_1x &+& a_0 \\
\partial p =&  &kx^{k-1}+& \dots &+& 2a_2x &+ &a_1 \\
\dots \\
\partial^n p =&  && && && k! \\
\end{aligned}\]

Lo que constituye una base del espacio de polinomios de dimensin $k$ 
equivalente a $\left\langle 1,x,x^2,\dots,x^k \right\rangle$ gracias a que estamos en un cuerpo. As,
cada submdulo ser el submdulo de los polinomios de grado menor o igual
a $k$ para $k$ el grado de su polinomio de mayor grado.

**** Ejercicio 17 (**)
#+begin_statement
Supongamos $T \colon V \to V$ un endomorfismo $K\text{-lineal}$, donde $V$ es un espacio vectorial
de dimensin finita que consideramos, como de costumbre, como $K[X]\text{-mdulo}$.
Supongamos que el polinomio mnimo $m(X)$ de $T$ es irreducible en $K[X]$ (ver
Ejemplo 14 para el concepto de polinomio mnimo). Demostrar que existen 
$K[X]\text{-submdulos}$ simples $V_1,\dots,V_t$ de $V$ tal que $V = V_1\oplus \dots \oplus V_{t}$ como
$K[X]\text{-mdulo}$.
#+end_statement

Como $m(X)$ es irreducible y estamos en un DIP el ideal que genera,
$(m(X))$, es maximal, y por tanto el cociente

\[
k \cong \frac{K[X]}{(m(X))}
\]

es un cuerpo. Y $V$ es un $k\text{-espacio vectorial}$ ya que por el primer teorema de 
isomorfa tenemos que $K[X] \to \mathrm{End}_K(V)$ descompone en una proyeccin y una
inyeccin

\[\begin{tikzcd}
K[X] \rar[two heads] & 
\displaystyle\frac{K[X]}{(m(X))} \rar[hook] &
\mathrm{End}_K(V).
\end{tikzcd}\]

Ahora, si $V$ tiene una base finita como $K\text{-espacio vectorial}$, sabiendo que $K \subseteq k$,
tenemos que $V$ tiene un sistema de generadores finito como $k\text{-espacio vectorial}$.
Por el Corolario 1.45 existe entonces un subconjunto de ese sistema de 
generadores tal que

\[
V = \bigoplus_{j \in J} kv_j = V_1 \oplus \dots \oplus V_t.
\]

Ntese que cada uno de ellos es un submdulo simple por ser isomorfos a $k$.

**** Ejercicio 18 (**)
#+begin_statement
En las condiciones del Ejercicio 17, demostrar que el polinomio caracterstico
de $T$ es $m(X)^t$.
#+end_statement

Por Cayley-Hamilton, sabemos que $T$ cumple su ecuacin caracterstica, y por
tanto, $m(X)$ divide a su polinomio caracterstico. 

Por otro lado, supongamos que tenemos un factor irreducible $p$ del
polinomio caracterstico; este tendr alguna raz $\lambda$ en la clausura
algebraica de $K$. Es decir, tendremos un vector propio con coeficientes
en $\overline{K}$ cumpliendo $Tv = \lambda v$.

Si aplicamos el polinomio mnimo evaluado en $T$ a ese vector tendremos

\[
0 = m(T)v = m(\lambda)v,
\]

as que $\lambda$ es una raz de $m$ en la clausura algebraica. Ahora, como el
polinomio irreducible de $\lambda$ en $K$ sigue siendo $p$, concluimos que $p \mid m$.

En general, hemos demostrado que todo factor irreducible del polinomio
caracterstico divide al polinomio mnimo. Cuando adems el polinomio
mnimo es irreducible, se tiene que el polinomio caracterstico debe
ser de la forma $m(X)^s$.

Ahora comprobaremos que $s=t$. En efecto, tenemos que si $\mathrm{gr}(m) = n$,
entonces, por construccin, $\mathrm{dim}_Kk=n$ y por ser $V_i \cong k$, tenemos
$\mathrm{dim}_{K}(V) = tn$; que debe ser el grado del polinomio caracterstico,
a la vez que debe ser $sn$.

**** Ejercicio 19
#+begin_statement
Demostrar que si $R$ es un dominio de integridad conmutativo, entonces $R$ no
tiene idempotentes no triviales.
#+end_statement

Si $e^2=e$, entonces $e(e-1) = 0$; lo que, en un dominio de integridad implica
que $e = 0$  $e-1 = 0$.

Ntese que no hemos usado la conmutatividad.

**** Ejercicio 20
#+begin_statement
Dar un CCIO para $R = M_n(k)$.
#+end_statement

Sean $E_{ii}$ las matrices nulas excepto por un $1$ en la entrada $i,i$. Se comprueba
trivialmente que $E_{ii}E_{jj} = 0$ para cualesquiera $i \neq j$, y que $E_{ii}^2 = 1$. Forman
adems un conjunto completo por tenerse:

\[
I = E_{11} + E_{22} + \dots + E_{nn}
\]
**** TODO Ejercicio 21
#+begin_statement
Comprobar las afirmaciones realizadas en el Ejemplo 17.
#+end_statement
**** Ejercicio 22
#+begin_statement
Sea $\left\{ e_1,\dots,e_n \right\}$ un ccio para $R$. Demostrar que los idempotentes $e_1,\dots,e_n$ son
centrales si, y slo si, $e_iRe_j = 0$ para todo $i \neq j$.
#+end_statement

***** Si son centrales, cumplen la condicin
Si son centrales, se tiene que, para cualquier $r \in R$,

\[
e_ire_j = re_ie_j = 0
\]

por ortogonalidad.

***** Si cumplen la condicin, son centrales
Sabiendo que cumplen que $e_ire_j = 0$ para cualquier $r \in R$, tenemos

\[
e_ir = e_ir\left(\sum_j e_j\right) = \sum_j e_ire_j = e_ire_i = \sum_j e_jre_i = re_i
\]

por ser completos.

**** Ejercicio 23 (*)
#+begin_statement
Sean $M$ y $N$ mdulos semisimples con descomposiciones como sumas directas
de submdulos simples $M = S_1 \oplus \dots \oplus S_t$ y $N = T_1\oplus \dots \oplus T_s$. Supongamos que
$S_i$ no es isomorfo a $T_j$ para todo $i = 1,\dots,t$, $j = 1,\dots,s$. Demostrar que
todo homomorfismo de mdulos de $M$ a $N$ es cero.
#+end_statement

Desde el ejemplo 17, sabemos que, en los endomorfismos de un mdulo suma
directa, la composicin de inclusin y proyeccin en las distintas componentes
nos da un ccio. Vamos a llamar $q_i \colon M \to M$ al endomorfismo que proyecta e
incluye en la componente $i\text{-sima}$; y vamos a llamar $p_j \colon N\to N$ al que hace
lo mismo en la componente $j\text{-sima}$ de $N$. Sabemos que

\[
q_1 + \dots + q_t = \mathrm{id}
\quad\text{ y que }\quad
p_1 + \dots + p_s = \mathrm{id}.
\]

Ahora, calculamos que

\[\begin{aligned}
f &= (q_1+\dots+q_t) \circ f \circ (p_1+\dots+p_s) \\
  &= \sum_{i=1}^t\sum_{j=1}^s q_i\circ f\circ p_j = 0,
\end{aligned}\]

ya que $q_i\circ f\circ p_j\colon S_i\to T_i$ debe ser nulo o isomorfismo por el Lema de Schur
y hemos supuesto que no es isomorfismo.

# Ntese que no es exactamente esto, sino que hay que partir q en sus
# componentes para igualar a cero.

**** TODO Ejercicio 24
#+begin_statement
Sea $M$ un mdulo semisimple de dimensin finita con estructura
$\left( n_1,\Sigma_1 \right),\dots,(n_t,\Sigma_t)$. Si $N$ es un submdulo de $M$, demostrar que su estructura
es $\left( m_1,\Sigma_1 \right),\dots,(m_t,\Sigma_t)$ para ciertos $m_j \leq n_j$ (admitimos que $m_j=0$ significa
que $\Sigma_j$ no aparece en la estructura de $M$).
#+end_statement
**** TODO Ejercicio 25
#+begin_statement
Establecer un enunciado anlogo al del Ejercicio 24 para cada cociente de $M$.
#+end_statement
**** TODO Ejercicio 26
#+begin_statement
Dada una $K\text{-lgebra}$ $A$, demostrar que la aplicacin $\rho\colon A \to \mathrm{End}(A)^{op}$ definida
por $\rho(a)(a') = a'a$ es un isomorfismo de $K\text{-lgebras}$.
#+end_statement

**** TODO Ejercicio 27 (*)
#+begin_statement
Sea $B$ un lgebra. Demostrar que la aplicacin que asigna a cada matriz
su traspuesta da un isomorfismo de lgebras $M_n(B)^{op} \cong M_n(B^{op})$.
#+end_statement

**** TODO Ejercicio 28
#+begin_statement
Sea $\varphi\colon R \to S$ un isomorfismo de $K\text{-lgebras}$, e $I,J$ ideales por la izquierda
de $R$. Demostrar que $\varphi(I),\varphi(J)$ son ideales por la izquierda de $S$ y que dado
cualquier homomorfismo de $R\text{-mdulos}$ $f \colon I \to J$, la aplicacin $\widehat f\colon \varphi(I) \to \varphi(J)$
definida por $\widehat f(y) = \varphi f \varphi^{-1}(y)$ para $y \in \varphi(I)$ es un homomorfismo de $S\text{-mdulos}$.
#+end_statement

**** TODO Ejercicio 29
#+begin_statement
Sean $R_1,\dots,R_n$ $K\text{-lgebras}$ y $R = R_1\times \dots \times R_n$. Los ideales por la izquierda
de $R$ son de la forma $I_1\times \dots\times I_n$, con $I_i$ ideal por la izquierda de $R_i$ para
$i = 1,\dots,n$. Anloga descripcin tienen los ideales bilteros de $R$.
#+end_statement

**** TODO Ejercicio 30 (*)
#+begin_statement
Sea $A$ un lgebra simple finito-dimensional. Demostrar que $R = \mathrm{M}(A)$ es un
lgebra simple de dimensin finita. Demostrar que asimismo que si $\Sigma$ es un
$A\text{-mdulo}$ simple y $M$ es un $R\text{-mdulo}$ simple, entonces $\mathrm{End}(\Sigma)$ y $\mathrm{End}(M)$
son lgebras isomorfas.
#+end_statement

**** Ejercicio 31 (*)                                             :export:
#+begin_statement
Demostrar que $T_q \in SO(V)$ para todo cuaternio $q$ de norma $1$.
#+end_statement

Sabiendo que los cuaternios se expresan como $\mathbb{H} = \mathbb{R} \oplus V$ escribimos $q = a + bu$, 
donde $u \in V$ y $\|u\| = 1$, lo que nos da $u^2 = -u(-u) = -1$. Como $q$ es de norma $1$ 
debe cumplir

\[
1 = qq^{\ast} = a^2 - ub^2 = a^2 + b^2,
\]

luego puede expresarse como $q = \cos \theta + \sin\theta u$ para algn $\theta \in \mathbb{R}$. Pero entonces
tenemos un cuaternio $w = \cos(\theta/2) + \sin(\theta/2) u$ que al elevarlo al cuadrado
nos da $q$, ya que

\[ w^2 =
\left( \cos \frac{\theta}{2} + \sin \frac{\theta}{2}u \right)^2 =
\cos^2 \frac{\theta}{2} - \sin^2 \frac{\theta}{2} + 
2 \sin \frac{\theta}{2}\cos \frac{\theta}{2}u =
\cos \theta + \sin \theta u = q.
\]

Finalmente, como $T_q = T_w \circ T_w$ siendo isometras, tenemos que
debe cumplirse que $|T_q| = |T_w|^2 = 1$ y por tanto, $T_q \in SO(V)$.

**** Ejercicio 32 (*)                                             :export:
#+begin_statement
Calcular explcitamente una representacin real no trivial de grado $2$ del
grupo de permutaciones $S_3$.
#+end_statement

Partimos de la idea de que $D_6 = S_{3}$, as que cada elemento representar
una simetra del tringulo equiltero con centro en el origen y un
vrtice en $(1\ 0)$.

En $\mathbb{R}^2$, llamamos $r,s,t$ a las rectas de ngulos $0,2\pi/3,4\pi/3$. Consideraremos
las trasposiciones como simetras respecto de estas rectas, y las permutaciones
de tres elementos sern rotaciones compuestas de dos simetras. Explcitamente,
las trasposiciones de dos elementos son

\[
(2\ 3) \mapsto \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix},
\quad
(1\ 2) \mapsto \begin{pmatrix} -1/2 & \sqrt{3}/2 \\ \sqrt{3}/2 & 1/2 \end{pmatrix},
\quad
(1\ 3) \mapsto \begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ -\sqrt{3}/2 & 1/2 \end{pmatrix},
\]

y las rotaciones son

\[
(1\ 2\ 3) \mapsto 
\begin{pmatrix} -1/2 & -\sqrt{3}/2 \\ \sqrt{3}/2 & -1/2 \end{pmatrix},
\quad
(1\ 3\ 2) \mapsto
\begin{pmatrix} -1/2 & \sqrt{3}/2 \\ -\sqrt{3}/2 & -1/2 \end{pmatrix}.
\]

Y podemos comprobar sobre ellas que cumplen la tabla de multiplicacin
del grupo.

**** Ejercicio 33
#+begin_statement
Comprobar que la multiplicacin definida sobre $KG$ es asociativa. Su elemento
neutro es $1e$, donde $e$ es el elemento neutro de $G$.
#+end_statement

Tenemos por bilinealidad

\[
\left( \sum_{g \in G} \lambda_gg \right)
\left( \sum_{h \in G} \mu_hh \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_gg \sum_{j,k \in G} \mu_h\delta_k hk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k g(hk),
\]

mientras que

\[
\left( \sum_{g \in G} \lambda_gg \sum_{h \in G} \mu_hh \right)
\left( \sum_{k \in G} \delta_kk \right) =
\sum_{g \in G} \lambda_g\mu_hgh \sum_{j,k \in G} \delta_kk =
\sum_{g,j,k \in G} \lambda_g\mu_h\delta_k (gh)k,
\]

que son iguales por asociatividad del producto de grupo. Hemos demostrado
en general que cualquier bilineal que extienda un operador binario sobre
los vectores de la base es asociativo.

**** TODO [#A] Ejercicio 34
#+begin_statement
Calcular todos los subespacios invariantes para la representacin de $Q_8$ 
del Ejemplo 20.
#+end_statement

**** TODO [#A] Ejercicio 35
#+begin_statement
Calcular todos los subespacios invariantes para la representacin de $S_3$
del Ejemplo 32.
#+end_statement

**** TODO Ejercicio 36
**** TODO Ejercicio 37
**** TODO Ejercicio 38
**** TODO Ejercicio 39
**** Ejercicio 40 (*)                                             :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres de $Q_8$.
#+end_statement

Puede comprobarse multiplicando que el grupo tiene cinco clases de conjugacin,
con representantes dados por $1,-1,i,j,k$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la nica solucin posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carcter/ ser el dado por la representacin irreducible trivial
   que enva cada elemento del grupo a $1 \in \mathbb{C}$.
 * El /ltimo carcter/, de dimensin $2$ es el dado por la representacin de los
   cuaternios como matrices complejas que conocemos del Ejercicio 7. Es adems
   irreducible por tenerse $(\chi_5,\chi_5) = (2^2+(-2)^2)/8 = 1$.
 * Para cualquiera de $i,j,k$, existe un subgrupo normal de $Q_8$ generado por
   el elemento con $4$ elementos, como por ejemplo $\left\{ 1,-1,i,-i \right\}$. Si llamamos a
   este grupo $A$, se tiene que $Q_8/A \cong \mathbb{Z}_2$, el nico grupo de cardinalidad $2$.
   Este grupo tiene una representacin irreducible en $\mathbb{C}$ como $1,-1$, y por
   el Ejercicio 38, sabemos que la composicin de representacin irreducible
   con una proyeccin a un cociente por un subgrupo normal es una 
   representacin irreducible, as que lo es

   \[
   \rho_{A}\colon Q_8 \overset{\pi}\longrightarrow Q_8 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}.
   \]

   Esta representacin la podemos repetir para los $A$ generados por $i,j,k$,
   dndonos las tres representaciones restantes con caracteres $\chi_2,\chi_3,\chi_4$ 
   respectivamente. Ntese que cada una de ellas
   enva al elemento $1$ a los elementos del grupo y a $-1$ a los elementos fuera
   del grupo.

Tenemos finalmente la tabla de caracteres irreducibles

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
Q_8 & 1 & -1 & i & j & k \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

**** TODO Ejercicio 41 (*)
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihdrico $D_4$.
#+end_statement

Tomamos la presentacin del grupo dihdrico

\[
\left\langle r,s \mid r^4=s^2=e, sr = r^{-1}s \right\rangle
\]

y comprobamos multiplicando que tiene $8$ elementos y $5$ clases de conjugacin
con representantes $e,r,s,r^2,sr$, por lo que tiene cinco representaciones
irreducibles complejas. Sabemos que los cuadrados de las dimensiones de esas 
representaciones deben sumar el orden del grupo, es decir 

\[ 8 = n_1^2 + n_2^2 + n_3^2 + n_4^2 + n_5^2,\]

y como no pueden tenerse dos $n_i > 1$, la nica solucin posible es que tengan
dimensiones $1,1,1,1,2$, determinando el caracter de la identidad en cada una
de las representaciones.

 * El /primer carcter/ ser el dado por la representacin irreducible trivial
   que enva cada elemento del grupo a $1 \in \mathbb{C}$.

 * Tenemos tres subgrupos normales generados por $\left\langle e,r^2,s \right\rangle$, $\left\langle e,r^2,r \right\rangle$ y $\left\langle e,r^2,sr \right\rangle$,
   cada uno de ellos con cuatro elementos. Si llamamos a cualquiera de ellos
   $A$, tenemos la representacin irreducible dada por la composicin de la
   proyeccin al cociente con la representacin irreducible de $\mathbb{Z}_2$ en los
   complejos

   \[
   \rho_{A}\colon D_4 \overset{\pi}\longrightarrow D_4 / A \cong \mathbb{Z}_2 
   \longrightarrow \mathbb{C}
   \]

   que es irreducible en virtud del Ejercicio 38. Esto nos da las
   representaciones con caracteres $\chi_2,\chi_3,\chi_4$ que envan cada elemento del
   grupo $A$ al $1$ y cada elemento fuera del grupo al $-1$.

 * El ltimo carcter proviene de la representacin matricial

   \[
   r \mapsto \begin{pmatrix}
   0 & -1 \\ 1 & 0
   \end{pmatrix} 
   \qquad
   s \mapsto \begin{pmatrix}
   1 & 0 \\ 0 & -1
   \end{pmatrix},
   \]
   
   # la irreducibilidad se debe comprobar (,)=1
   que podemos comprobar que cumple las relaciones de la presentacin.
   Por el caracter que define, que no es suma de otros dos caracteres 
   irreducibles, sabemos que es forzosamente la representacin irreducible
   que nos falta.

Tenemos finalmente la tabla de caracteres irreducibles como

\[\begin{tabular}{c|ccccc}
    & 1 &  1 & 2 & 2 & 2 \\
D_4 & $e$ & $r^2$ & $s$ & $r$ & $sr$ \\
\hline
\chi_1 & 1 &  1 &  1 &  1 &  1 \\
\chi_2 & 1 &  1 & 1  & -1  & -1   \\
\chi_3 & 1 &  1  & -1   & 1   &  -1  \\
\chi_4 & 1 &  1  &  -1  & -1   & 1   \\
\chi_5 & 2 & -2 &  0 &  0 &  0 \\
\end{tabular}\]

Ntese que es la misma tabla de caracteres que $Q_8$.

**** Ejercicio 42 (**)                                            :export:
#+begin_statement
Calcular razonadamente la tabla de caracteres del grupo dihdrico $D_n$, 
para $n \geq 2$.
#+end_statement

Tomamos la presentacin del grupo dihdrico

\[
\left\langle r,s \mid r^n=s^2=e, sr = r^{-1}s \right\rangle,
\]

y sabemos que es un grupo de $2n$ elementos. 

***** Clases de conjugacin del caso impar
Cuando $n$ sea impar, sus clases de conjugacin, que obtenemos
conjugando con los generadores, sern las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$, que se puede comprobar
   que permanecen invariantes por conjugacin de los generadores. Tenemos
   $(n-1)/2$ clases de este tipo, cada una con dos elementos ya que por
   ser $n$ impar, $r^i\neq r^{-i}$.
 * La clase $\left\{ sr^i \mid 0 \leq i < n \right\}$, que se genera desde $s$ usando que $r^isr^{-i} = sr^{-2i}$ 
   y que $n$ es impar. Es una clase de $n$ elementos.

Sumando las cardinalidades de todas ellas, observamos que no hay ms, ya
que

\[
2n = 1 + 2 \frac{n-1}{2} + n.
\]

Tenemos $(n+3)/2$ clases de conjugacin, luego tendremos $(n+3)/2$
representaciones irreducibles complejas.

***** Representaciones en el caso impar
Podemos considerar los caracteres y representaciones siguientes:

 * el caracter trivial dado por la *representacin irreducible trivial*
   que enva cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representacin dada por la proyeccin y la representacin irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * si interpretamos los grupos dihdricos como grupos de simetras de
   los polgonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ngulos $2\pi k/n$ en
   los complejos y $s$ como la simetra, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $k>0$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aqu usamos $n$ impar), pero no son invariantes bajo simetras,
   por lo que no existen subespacios invariantes y la representacin
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Dentro de las ltimas, existirn algunas que sern equivalentes. Notamos
que la caracterstica de $r$ bajo la representacin dada por $k$ es $2\cos(2\pi k/n)$,
por lo que cada $k$ entre $1, \dots, (n-1)/2$ da una caracterstica distinta y por
tanto una representacin no equivalente a las dems. Con estas tenemos en
total $(n+3)/2$ representaciones irreducibles distintas, por lo que el resto
sern equivalentes.

***** Tabla de caracteres del caso impar
Tenemos finalmente la tabla de caracteres irreducibles como

\[
\small
\begin{tabular}{c|cccccc}
    & 1 &  2 & 2 & \dots & 2 & $n$ \\
D_n & $e$ & $r$ & $r^2$ & $\dots$ & $r^{(n-1)/2} & $s$ \\
\hline
\chi_1 & 1 &  1 &  1 &  \dots &  1 & 1 \\
\chi_2 & 1 &  1 & 1  &  \dots  & 1 & -1  \\
\chi_{2+1} &  2 & 2\cos(2\pi 1/n) &  2\cos(2 \pi 2/n)  & \dots   & 2\cos(2 \pi (n-1)/2n)  & 0 \\
\chi_{2+2} &  2 & 2\cos(2\pi 2/n) &  2\cos(2 \pi 4/n)  & \dots   & 2\cos(2 \pi 2(n-1)/2n)  & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots \\
\chi_{2+(n-1)/2} &  2 & 2\cos(2\pi (n-1)/2n) &  2\cos(2 \pi 2(n-1)/2n)  & \dots   & 2\cos(2 \pi (n-1)(n-1)/4n)  & 0 \\
\end{tabular}\]

***** Clases de conjugacin del caso par
Cuando $n$ es par, sus clases de conjugacin, que obtendremos conjugando
con los generadores, sern las siguientes:

 * La clase trivial $\left\{ 1 \right\}$.
 * La clase que forma $\left\{ r^{n/2} \right\}$.
 * Las clases de la forma $\left\{ r^i,r^{-i} \right\}$, donde $0 < i < n$ y adems exigimos que
   $i = n/2$ para evitar el caso $r^i = r^{-i}$. Tenemos $(n-2)/2$ clases de este
   tipo, cada una con $2$ elementos;
 * La clase $\left\{ sr^{2a} \mid 0 \leq a < n/2 \right\}$, que es cerrada para conjugacin
   gracias a la paridad de $n$. Es una clase con $n/2$ elementos.
 * La clase $\left\{ sr^{2a+1} \mid 0 \leq a < n/2 \right\}$, de nuevo con $n/2$ elementos.
 
Sumando las cardinalidades de todas ellas, observamos que no hay ms, ya
que

\[
2n = 1 + 1 + 2\frac{n-2}{2} + \frac{n}{2} + \frac{n}{2}.
\]

Tenemos por tanto $n/2 + 3$ clases de conjugacin y representaciones 
irreducibles complejas distintas.

***** Representaciones en el caso par
Podemos considerar los caracteres y representaciones siguientes

 * el caracter trivial dado por la *representacin irreducible trivial*
   que enva cada elemento del grupo a $1 \in \mathbb{C}$.

 * el grupo generado por $\left\langle r \right\rangle$ es normal y tenemos $D_n/\left\langle r \right\rangle \cong \mathbb{Z}_2$, luego una
   representacin dada por la proyeccin y la representacin irreducible
   de $\mathbb{Z}_2$ en los complejos es irreducible. La llamamos $\chi_2$.

 * el grupo generado por $\left\langle r^2 \right\rangle$ es normal y tenemos $D_n/\left\langle r^2 \right\rangle \cong \mathbb{Z}_2 \times \mathbb{Z}_2$, luego
   podemos buscar las representaciones irreducibles del grupo de Klein. Las
   cuatro representaciones irreducibles unidimensionales de este grupo abeliano
   podemos obtenerlas con la trivial y enviando dos de sus elementos no nulos
   al $-1$. Esto nos da los caracteres $\chi_3,\chi_4$ nuevos adems de los dos anteriores.

 * si interpretamos los grupos dihdricos como grupos de simetras de
   los polgonos, podemos escribir representaciones bidimensionales
   que toman $r$ como cualquiera de las rotaciones de ngulos $2\pi k/n$ en
   los complejos y $s$ como la simetra, es decir,

   \[
   r \mapsto \begin{pmatrix}
   e^{2\pi i k/n} & 0 \\
   0 & e^{-2\pi i k/n} \\
   \end{pmatrix}, \quad
   s \mapsto \begin{pmatrix}
   0 & 1 \\
   1 & 0 \\
   \end{pmatrix}.\]
   
   Comprobaremos que para $0<k<n/2$ todas ellas son irreducibles. Los
   espacios que deja invariantes la primera son claramente $(1\ 0)$ y
   $(0\ 1)$ con dos valores propios $e^{2\pi i k/n} \neq e^{-2\pi i k/n}$
   (aqu usamos $k < n/2$), pero no son invariantes bajo simetras,
   por lo que no existen subespacios invariantes y la representacin
   es irreducible. A sus caracteres los llamamos $\chi_{k+2}$.

Con esto tenemos los $n/2+3$ caracteres irreducibles.

***** Tabla de caracteres del caso par

\[
\small
\begin{tabular}{c|cccccccc}
    & 1  & 1 & 2 & \dots & 2 & $n/2$ & $n/2$ \\
D_n & $e$   & $r^{n/2}$ & $r$ & $\dots$ & $r^{n/2-1} & $s$ & $sr$ \\
\hline
\chi_1 & 1 &1 & 1 & \dots & 1 & 1 & 1 \\
\chi_2 & 1 &1& 1 & \dots & 1 & -1 & -1 \\
\chi_3 & 1 & (-1)^{n/2}& 1 &\dots & (-1)^{n/2-1} & 1 & -1 \\
\chi_4 & 1 & (-1)^{n/2} & 1 &\dots  & (-1)^{n/2-1} & -1 & 1 \\
\chi_{2+1} &  2 & 2\cos(2 \pi 1/2) & 2\cos(2\pi 1/n) & \dots & 2\cos(2 \pi (n/2-1)/n) & 0 & 0\\
\chi_{2+2} &  2 & 2\cos(2 \pi 2/2) & 2\cos(2\pi 2/n) & \dots  & 2\cos(2 \pi 2(n/2-1)/n) & 0 & 0 \\
\dots & \dots & \dots & \dots  & \dots  & \dots & \dots & \dots \\
\end{tabular}\]

**** DONE Ejercicio 43
#+begin_statement
Sea $G$ un grupo abeliano finito, y sea $\widehat G$ el conjunto de los caracteres 
complejos irreducibles de $G$. Demostrar que el producto inducido por el
de nmeros complejos dota a $\widehat G$ de estructura de grupo.
#+end_statement

Todas las representaciones irreducibles de un grupo abeliano son de 
dimensin $1$, luego $\chi_{\rho}(g) = \rho(g)$. La irreducibilidad se tiene por ser
todas de dimensin 1.

**** TODO Ejercicio 44 (**)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $\widehat G$ el grupo definido en el Ejercicio 43.
Demostrar que existe un isomorfismo de grupos $G \cong \widehat G$.
#+end_statement

**** TODO Ejercicio 45
#+begin_statement
Sea $G$ un grupo finito y $g \in G$. Demostrar que $g$ es conjugado con $g^{-1}$ si,
y slo si, $\chi(g) \in \mathbb{R}$ para todo carcter complejo irreducible $\chi$ de $G$.
#+end_statement
**** TODO Ejercicio 46
#+begin_statement
Demostrar que $\varphi^G \in {\cal C}(G)$ para cada $\varphi \in {\cal C}(H)$, y que $\varphi^G(1) = |G:H|\varphi(1)$.
#+end_statement
**** TODO Ejercicio 47 (*)
#+begin_statement
Sea $G$ un grupo abeliano finito, y $H$ un subgrupo de $G$. Demostrar que la
aplicacin $(-)_H\colon {\cal C}(G) \to {\cal C}(H)$ es sobreyectiva. Identificar su ncleo.
#+end_statement
**** Ejercicio 48 (**)                                            :export:
#+begin_statement
Calcular la tabla de caracteres complejos de $A_5$.
#+end_statement

***** Clases de conjugacin
Para determinar las clases de conjugacin usaremos crucialmente
que

\[
\sigma (a\ b\ \dots) \sigma^{-1} = (\sigma(a)\ \sigma(b)\ \dots).
\]

Tenemos las siguientes clases:

 * la clase trivial con el nico elemento $()$.
 * la clase de ciclos de longitud $3$ con todos los elementos de la forma
   $(a\ b\ c)$, que pueden conseguirse desde cualquiera de ellos usando que
   $(a\ d\ e)(a\ b\ c)(d\ a\ e) = (d\ b\ c) = (c\ d\ b)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3/3 = 20$.
 * la clase de pares de trasposiciones disjuntas de la forma $(a\ b)(c\ d)$, 
   que pueden conseguirse desde cualquiera de ellos usando que
   $(e\ b\ a)(a\ b)(c\ d)(e\ a\ b) = (a\ e)(c\ d)$. Esta clase tiene cardinalidad
   $5\cdot 4\cdot 3\cdot 2/4\cdot 2 = 15$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutacin par desde $(1\ 2\ 3\ 4\ 5)$, que son todos aquellos que podemos
   obtener conjugando. Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.
 * la clase de los ciclos de longitud 5 que se obtienen desde una
   permutacin impar desde $(2\ 1\ 3\ 4\ 5)$. Ntese que todos los ciclos de
   longitud 5 deben ser como este o como los anteriores segn cmo
   sea la permutacin que los lleva a $(1\ 2\ 3\ 4\ 5)$ por conjugacin.
   Esta clase tiene cardinalidad $5!/5\cdot 2 = 12$.

Comprobamos que la suma de la cardinalidad de las clases de conjugacin
es la cardinalidad del grupo completo,

\[
60 = 1 + 20 + 15 + 12 + 12.
\]

Y como hay $5$ clases de conjugacin, existirn $5$ representaciones
irreducibles complejas, cuyas dimensiones adems debern sumar la
cardinalidad del grupo, es decir,

\[
60 = n_1^2+n_2^2+n_3^2+n_4^2+n_5^2.
\]

Sabiendo que la primera ser la representacin trivial, podemos
buscar exhaustivamente soluciones a $59 = n_2^2+n_3^2+n_4^2+n_5^2$ y
encontrar que la nica, salvo reordenacin, es $3,3,4,5$. Esas
deben ser las dimensiones de nuestras representaciones.

***** Tabla de caracteres
Calculamos la tabla de caracteres usando que:

 - tenemos claramente la representacin trivial $\chi_1$.
 - desde $S_{5}$ tenemos la representacin $\psi$ dada por permutar
   los vectores de una base de dimensin $5$. Si la restringimos
   tenemos $\psi_{A_5}$. Esta representacin tiene un espacio
   invariante claro en $\left\langle (1,1,1,1,1) \right\rangle$ sobre el que acta trivialmente. 
   Puede descomponerse entonces en la suma de dos representaciones,
   siendo una de ellas la trivial, y sabemos entonces que el caracter
   del otro sumando de la representacin ser $\psi_{A_5} - \chi_1$, por lo que
   nos queda una fila

   \[
   \small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_4     & 5-1=4    & 1-1=0              & 2-1=1           & 0-1=-1                 & 0-1=-1                 \\ 
   \end{tabular}\]

   Comprobamos adems que el caracter $\chi_4$ as obtenido es irreducible, 
   ya que cumple que $(\chi_4,\chi_4) = (4^2+20+12+12)/60 = 1$.

 - podemos obtener la segunda columna aplicando el teorema de ortogonalidad
   consigo misma para obtener $4 = 1^2 + x^2 + y^2 + z^2$ y con la primera
   columna para obtener $0 = 1 + 3x + 3y + 5z$. Si diagonalizamos la 
   representacin de un elemento de esa clase de conjugacin, como tiene
   orden $2$ la diagonal estara formada por $\pm 1$; como adems las dimensiones
   son $5,3,3$, todos impares, nunca podra ser $0$ su traza. As, la nica
   solucin a la primera ecuacin es $x^2 = y^2 = z^2 = 1$ y la solucin a la
   segunda ecuacin es $x=-1, y=-1, z=1$.

 - la ltima fila de la tabla de caracteres la podemos completar usando
   las relaciones de ortogonalidad. Sabemos que

   \[\begin{aligned}
   40 + 20b^2 + 12c^2 + 12d^2 &= 60 \\
   5 +15 + 20b   + 12c   + 12d   &= 0  \\
   20 + 20b   - 12c   - 12d   &= 0  \\
   \end{aligned}\]

   de donde deducimos primero que $c+d=0$, luego $b=-1$ y $c=d=0$.
   Hemos llegado a la conclusin de que

   \[\small
   \begin{tabular}{c|cccccc}
   & 1    & 15             & 20          & 12                & 12                \\
   A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
   \hline
   \chi_5     & 5    & 1              & b=-1           & c=0                 & d=0                 \\ 
   \end{tabular}\]   

 - la tercera columna de la tabla podemos obtenerla de nuevo con relaciones
   de ortogonalidad, tenemos $3 = 1 + u^2 + v^2 + 1 + 1$ y $1 -u-v-1=0$, 
   luego $u = -v$ y $u=v=0$.

 - las dos ltimas entradas estn sujetas a las mismas condiciones, as
   que esperamos obtenerlas como soluciones distintas del mismo sistema
   de ecuaciones de ortogonalidad. Aplicando ortogonalidad tenemos
   $3^2 + 15 + 12p^{2}+ 12q^{2} = 60$ y $3 -15+12p+12q=0$, luego $p=1-q$,
   y como $p^2+(1-p)^2 = 3$, tenemos que las dos soluciones posibles
   sern las de $p^2 - p - 1 = 0$, es decir $p=\pm(1+\sqrt{5})/2$.


As, la tabla de caracteres acaba quedando como

\[\small
\begin{tabular}{c|cccccc}
           & 1    & 15             & 20          & 12                & 12                \\
A_5        & $()$ & $(1\ 2)(3\ 4)$ & $(1\ 2\ 3)$ & $(1\ 2\ 3\ 4\ 5)$ & $(1\ 2\ 3\ 5\ 4)$ \\
\hline
\chi_1     & 1    & 1              & 1           & 1                 & 1                 \\ 
\chi_2     & 3    & -1             & 0           & (1+\sqrt{5})/2    & (1-\sqrt{5})/2    \\ 
\chi_3     & 3    & -1             & 0           & (1-\sqrt{5})/2    & (1+\sqrt{5})/2    \\ 
\chi_4     & 4    & 0              & 1           & -1                & -1                \\ 
\chi_5     & 5    & 1              & -1          & 0                 & 0                 \\ 
\end{tabular}\]
** Inferencia estadstica
# ##
# Estos apuntes se han reescrito desde los apuntes de A. Hermoso Carazo y
# M.D. Ruiz Medina para la asignatura de Inferencia Estadstica del grado
# de matemticas de la Universidad de Granada.
# ##

*** Prerrequisitos
**** Distribuciones
***** Funcin generatriz de momentos
Se define para una variable aleatoria $X$ con funcin de distribucin
$f$ como:

\[
M_X(t) = 
\mathbb{E}(e^{tX}) =
\int_\Omega e^{tx}f(x) \;dx
\]

****** Clculo de momentos
Se cumple que:

\[
\mathbb{E}[X^n] = \frac{\partial^n}{\partial t^n} M_X(0)
\]

***** Funcin caracterstica
Se define para una variable aleatoria $X$ con funcin de distribucin $f$:

\[
\varphi_X(t) = \mathbb{E}[e^{itX}] = \int_\Omega e^{itx}f(x)\;dx
\]

****** Clculo de momentos
Se cumple que:

\[
\varphi_X^{(n)}(0) = i^n\mathbb{E}[X^n]
\]

**** Varianza
***** Varianza
La varianza se define equivalentemente como:

\[Var(X) = E\Big[(X-EX)^2\Big] = E[X^2] - E[X]^2\]

***** Covarianza
La covarianza se define equivalentemente como:

\[cov(X,Y) = E[(X-EX)(Y-EY)] = E[XY] - E[X]E[Y]\]

Ntese que $cov(X,X) = Var(X)$. Ntese adems se comporta como el 
[[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][producto interno]] de un espacio prehilbertiano.

***** Varianza de la suma
La varianza de una suma cumple:

\[
Var(X+Y) = Var(X) + Var(Y) + 2cov(X,Y)
\]

En el caso general:

\[Var\left(\sum X_i\right) = \sum_i\sum_j cov(X_i,X_j)\]

***** Cauchy-Schwarz para la covarianza
Se tiene la desigualdad:

\[cov(X,Y)^2 \leq Var(X)Var(Y)
\]

****** Demostracin
Sabiendo que la varianza es siempre no negativa:

\[
0 \leq Var\left(X - \frac{cov(X,Y)}{Var(Y)} Y\right) =
Var(X) - \frac{\left(cov(X,Y)\right)^2}{Var(Y)}
\]

****** Demostracin por Cauchy-Schwarz
Se comprueba que la covarianza da un producto escalar que genera
un [[https://en.wikipedia.org/wiki/Covariance#Relationship_to_inner_products][espacio cociente]] prehilbertiano. Aplicamos Cauchy-Schwarz.

**** Esperanza condicional
***** Esperanza condicional en caso discreto
Definimos la esperanza condicional de dos variables discretas como:

\[\mathbb{E}[X|Y] = \sum_x xP(X=x\mid Y=y) = \sum_x x\frac{P(X=x, Y=y)}{P(Y=y)}\]

***** Esperanza condicional en el caso continuo
Ms generalmente se define para el caso continuo:

\[
\mathbb{E}[X|Y] = \int_X x f_{X|Y}(x|y) dx = \int_X x \frac{f_{X,Y}(x,y)}{f_Y(y)} dx
\]

***** Ley de esperanza total
La esperanza condicional cumple:

\[\mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]\]

****** Demostracin en el caso discreto
Se tiene:

\[\begin{aligned}
E[E[X|Y]] &= \int_Y f(y)  \left(\int_X x \frac{f(x,y)}{f(y)} dx \right) dy \\
&= \int_X x \int_Y f(x,y) dy dx \\&= \int_X x f(x) dx = E[X]
\end{aligned}\]

Ntese que asumimos una conmutatividad de las integrales discretas.

****** Demostracin en el caso continuo
Puede consultarse la [[https://en.wikipedia.org/wiki/Law_of_total_expectation#Proof_in_the_general_case][Ley de la esperanza total]].

**** Desigualdades
***** Desigualdad de Chebyshev
Para una variable aleatoria $X$ de segundo orden:

\[
P(|X-\mathbb{E}[X]| \geq a) \leq \frac{Var(X)}{a^2}
\]

**** Convergencia
***** Convergencia casi segura
Una sucesin de variables aleatorias converge de forma casi segura a
otra $X_n \overset{c.s.}\longrightarrow X$ cuando el conjunto de sucesos que lo hacen tiene 
probabilidad 1.

\[
P\left(\lim_{n\to\infty} X_n = X\right) = 1
\]

***** Convergencia en probabilidad
Una sucesin de variables aleatorias converge en probabilidad a
otra $X_n \overset{P}\longrightarrow X$ cuando:

\[
\lim_{n\to\infty} P\left(|X_n-X| \geq \varepsilon\right) = 0
\]

para cualquier $\varepsilon$.

****** Equivalentemente
Si consideramos su complemento:

\[
\lim_{n\to\infty} P(|X_n-X| < \varepsilon) = 1
\]

***** Convergencia en distribucin
Una sucesin de variables aleatorias converge en ley o en distribucin 
a otra $X_n \overset{d}\longrightarrow X$, si se tiene que, dadas sus funciones de distribucin,
convergen en los puntos en los que es continua:

\[
\forall x: F \mbox{ continua en } x:
\quad
\lim_{n\to\infty} F_n(x) = F(x)
\]

****** Equivalentemente
Se tiene $X_n\overset{d}\longrightarrow X$ si para cualquier $t$ real:

\[
\lim_{n\to\infty} E\left[ e^{tX_n} \right] = E\left[e^{tX}\right]
\]

***** Implicaciones
La convergencia casi segura implica la convergencia en probabilidad, que
implica a su vez la convergencia en distribucin.

****** TODO Demostracin

***** Ley dbil de los grandes nmeros
Si $X_1,X_2,\dots$ es una sucesin infinita de variables aleatorias 
independientes con la misma esperanza y varianza, entonces:

\[
\overline{X}_n = \frac{1}{n}(X_1+\dots+X_n)
\]

converge en probabilidad a $\mu$:

\[
\lim_{n\to\infty} P(|\overline{X}_n - \mu| \geq \varepsilon) = 0
\]

***** Ley fuerte de los grandes nmeros
Si $X_1,X_2,\dots$ es una sucesin infinita de variables aleatorias 
independientes e idnticamente distribuidas con $E\left[|X_i|\right] < \infty$ y
valor esperado $\mu$, entonces:

\[
P\left(
\lim_{n\to\infty} \overline{X}_n = \mu
\right) = 1
\]

*** Distribuciones discretas
**** 1. Distribucin uniforme
***** Definicin
Se define sobre un conjunto finito de valores $\{x_i\}$ con la misma 
probabilidad como:

\[f(x_i|n) = \frac{1}{n}\]
**** 2. Distribucin binomial
***** Definicin
Determina la probabilidad de $x$ aciertos en $n$ experimentos de Bernoulli.
La funcin de distribucin de $B(x|n,p)$ es:

\[
f(x|n,p) = {n \choose x}p^x (1-p)^{n-x}
\]

****** Esperanza

\[\mathbb{E}[X] = np\]

****** Varianza

\[Var[X] = np(1-p)\]

**** 3. Distribucin multinomial
***** Definicin
Deriva de una binomial con $k$ salidas distintas de probabilidades $p_1,\dots,p_k$
como:

\[
f(X|n,p_1,\dots,p_k) = \frac{n!}{X_1!X_2!\dots X_n!}p^{X_1}p^{X_2}\dots p^{X_k}
\]

**** 4. Distribucin de Poisson
***** Definicin
Definimos la distribucin de Poisson $Poi(\lambda)$ como:

\[
f(n|\lambda) = \frac{e^{-\lambda}\lambda^n}{n!}
\]

****** Es una distribucin
Comprobamos que suma la unidad:

\[
\sum_{n=1}^\infty f(n|\lambda) =
\sum_{n=1}^\infty e^{-\lambda}\frac{\lambda^n}{n!} = 1
\]

***** Funcin generatriz de momentos
La funcin generatriz se calcula como:

\[
M_X(t) = \sum_{n=1}^\infty e^{-\lambda}\frac{(e^t\lambda)^n}{n!}
= e^{\lambda(e^t-1)}
\]

****** Esperanza
Desde la funcin generadora:

\[
\mathbb{E}[X] = \frac{\partial M_X}{\partial t}(0) = \lambda
\]

****** Varianza
Desde la funcin generadora:

\[
Var(X) = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \lambda
\]

***** Suma de Poisson
Para $X \leadsto Poi(\lambda_1)$, $Y \leadsto Poi(\lambda_2)$ independientes, su suma sigue la
distribucin con el parmetro suma.

\[
X + Y \leadsto Poi(\lambda_1+\lambda_2)
\]

*** Distribuciones continuas
**** 1. Distribucin normal
***** Definicin
Definimos la distribucin normal ${\cal N}(\mu,\sigma^2)$ como aquella con funcin de
densidad:

\[f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]

****** Imagen de la distribucin
#+BEGIN_SRC R :file images/normal.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dnorm, seq(-3, 3, 0.1),
                          mean = 0, sd = 1+0.1*i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribucin normal, variando ."))
#+END_SRC

#+RESULTS:
[[file:images/normal.png]]

****** Es una distribucin
Tenemos que comprobar que integra la unidad sobre los reales, y
de hecho, tomando cambio de variable $y = (x-\mu)/\sqrt{2\sigma^2}$ queda:

\[\begin{aligned}
\int^{+\infty}_{-\infty} 
\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\left(\frac{x-\mu}{\sqrt{2\sigma^2}}\right)^2} =
\frac{1}{\sqrt{\pi}}\int^{+\infty}_{-\infty} 
e^{-y^2} = 1
\end{aligned}\]

Que es la [[https://en.wikipedia.org/wiki/Gaussian_integral][integral de Gauss]].

***** Funcin caracterstica
La funcin caracterstica de ${\cal N}(\mu,\sigma^2)$ es:

\[\varphi_X(t) = e^{it\mu - t^2\sigma^2/2}\]

****** TODO Demostracin
Usamos la definicin de funcin caracterstica y completamos
cuadrados para tener:

\[\begin{aligned}
\varphi_X(t) &= 
\mathbb{E}\left[e^{itX}\right] &= 
\int_{-\infty}^{+\infty}
e^{itx}\frac{1}{\sqrt{2\pi\sigma^2}} 
e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx \\&=
\frac{1}{\sqrt{2\pi\sigma^2}} 
\int_{-\infty}^{+\infty}
e^{it\mu}
\end{aligned}\]

***** Suma de normales
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ e $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. Entonces $X+Y\leadsto {\cal N}(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)$.

****** TODO Demostracin

***** Producto por escalar
Si $X \leadsto {\cal N}(\mu,\sigma^2)$, entonces $kX \leadsto {\cal N}(k\mu,k\sigma^2)$.

****** TODO Demostracin
***** Teorema de Cramer
Sean $X,Y$ independientes. Si $X+Y$ es normal, $X$ e $Y$ son normales.

****** TODO Demostracin
**** 2. Distribucin  de Pearson
***** Distribucin chi cuadrado
Es un caso particular de la distribucin gamma, $X \leadsto \chi^2(k) = \Gamma(k/2,1/2)$.
Al parmetro $k$ se le llama *nmero de grados de libertad*.

****** Grfica de la funcin de densidad
#+BEGIN_SRC R :file images/chi.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dchisq, seq(0, 6, 0.1),
                          df = i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribucin (n), variando n."))
#+END_SRC

#+RESULTS:
[[file:images/chi.png]]

****** Funcin de densidad

 \[f(x) = \frac{1}{\Gamma(\frac{k}{2})2^{k/2}} x^{k/2-1}e^{-x/2}\]

******* TODO Demostracin
***** Funcin generatriz de momentos

\[M_X(t) = \frac{1}{(1-2t)^{k/2}}\], para $t < 1/2$.

****** TODO Demostracin
****** Esperanza y varianza

 - $E[X] = k$
 - $Var[X] = 2k$

******* Demostracin
Se calculan desde la funcin generatriz.

***** Propiedad de reproductividad
Si tengo una serie de variables independientes distribuidas 
por $X_i \leadsto \chi^2(k_i)$, entonces:

\[\sum_{i=1}^n X_i \leadsto \chi^2 \left(\sum_{i=1}^n k_i \right)\]

***** Relacin con la normal
Dadas variables independientes $X_i \leadsto {\cal N}(0,1)$,

 \[\sum_{i=1}^n X^2_i \leadsto \chi^2(n)\]

****** TODO Demostracin

***** Teorema central del lmite de Lvy
Para valores pequeos, pueden usarse tablas. Para valores grandes
de $n$, podemos aproximarla mediante el Teorema Central del Lmite
como:

\[ \chi^2(n) \approx {\cal N}(n,2n)\]

****** TODO Demostracin                                         :extra:
**** 3. Distribucin t de Student
***** Definicin 
Dadas dos variables independientes $X \leadsto {\cal N}(0,1)$ e $Y \leadsto \chi^2(n)$,
tenemos:

\[ T = \frac{X}{\sqrt{Y/n}} \leadsto t(n) \]

****** Funcin de densidad

\[ f(t) 
= \frac
{\Gamma\left(\frac{n+1}{2}\right)}
{\Gamma\left(\frac{n}{2}\right) \sqrt{n\pi}} 
\left(
1 + \frac{t^2}{n}
\right)^{-\frac{n+1}{2}}
\], $t \in \mathbb{R}$

******* TODO Demostracin

****** Grfica de la funcin de densidad
#+BEGIN_SRC R :file images/tstudent.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dt, seq(0, 3, 0.1),
                          df=i,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "T de Student, variando n."))
#+END_SRC

#+RESULTS:
[[file:images/tstudent.png]]

***** Momentos
Tenemos que $\exists E[T^k] \iff k < n$. Cuando existen, se tiene

 - $E[T] = 0$
 - $Var[T] = \frac{n}{n-2}$

****** TODO Demostracin

***** Aproximacin por la normal
Tabulada para $n$ pequeos y aproximada por ${\cal N}(0,1)$ para valores
grandes.
**** 4. Distribucin F de Snedecor
***** Definicin
*F de Snedecor*. Dadas dos variables independientes $X \leadsto \chi^2(m)$ e
$Y \leadsto \chi^2(n)$, su cociente nos da:

\[F = \frac{X/m}{Y/n} \leadsto F(m,n)\]

****** Grfica de la funcin de densidad
#+BEGIN_SRC R :file images/fsnedecor.png :results graphics
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(df, seq(0, 2, 0.04),
                          df1=i, df2=i-1,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "F de Snedecor, variando n y m."))
#+END_SRC

#+RESULTS:
[[file:images/fsnedecor.png]]

****** Funcin de densidad

\[g(t)
= \frac
{\Gamma(\frac{m+n}{2})}
{\Gamma(\frac{m}{2})\Gamma(\frac{n}{2})}
\left(\frac{m}{n}\right)^{\frac{m}{2}}
t^{m/2-1}
\left(1+\frac{m}{n}t\right)^{-\frac{m+n}{2}}\], para $t>0$.

******* TODO Demostracin

***** Momentos
Tenemos que $\exists E[T^k] \iff k < n/2$.

 - $n > 2 \Rightarrow \exists E[F] = \frac{n}{n-2}$
 - $n > 4 \Rightarrow \exists Var[F] = \frac{n^2(2m+2n-4)}{m(n-2)^2(n-4)}$

****** TODO Demostracin

***** Propiedades
\[ F \leadsto F(m,n) \iff F^{-1} \leadsto F(n,m)\]
\[T \leadsto t(n) \iff T^2 \leadsto F(1,n)\]

***** Aproximacin
La distribucin est tabulada y las tablas incluyen aproximaciones 
para valores grandes de $n$ y $m$.

**** 5. Distribucin exponencial
***** Distribucin exponencial
Dado un $\lambda>0$, definimos la distribucin exponencial, $\operatorname{Exp}(\lambda)$, como aquella
con funcin de densidad:

\[f(x) = \lambda e^{-\lambda x}\qquad \forall x \in \mathbb{R}^+_0\]

****** Es una distribucin
Trivialmente integrando:

\[
\int_0^\infty \lambda e^{-\lambda x} = 
-\left[ e^{-\lambda x} \right]^\infty_0 = 1
\]

***** Suma de exponenciales
La suma de variables exponenciales es una distribucin Gamma:

***** Caso particular de la distribucin Gamma
La exponencial es un caso particular de la distribucin Gamma:

\[
Exp(\lambda) = \Gamma(1,\lambda)
\]
**** 6. Distribucin de Dirichlet
***** Distribucin de Dirichlet
Dado un vector de reales $\alpha_1,\alpha_2,\dots,\alpha_n$, definimos la distribucin $Dir(\alpha)$ 
como la que tiene funcin de densidad:

\[
f(x) = \frac{1}{B(\alpha)} \prod_{i=1}^K x_i^{\alpha_i-1}
\]

donde,

\[
B(\alpha) =
\frac
{\prod_{i=1}^K \Gamma(\alpha_i)}
{\Gamma\left(\sum_{i=1}^K \alpha_i\right)}
\]

***** Momentos
****** Esperanza

\[
E[X_i] = \frac{\alpha_i}{\sum_k \alpha_k}
\]

****** Varianza

\[
Var[X_i] = \frac{\alpha_i(\alpha_0-\alpha_i)}{\alpha_0^2(\alpha_0+1)}
\]
**** 7. Distribucin Gamma
***** Funcin Gamma
Se define la funcin gamma $\Gamma : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\Gamma(\alpha) = \int^\infty_0 t^{\alpha-1}e^{-t} dt\]

****** La integral est definida
Por un lado, $t^{a-1}e^{-t} < t^{a-1}$, integrable en $[0,b]$. Por otro lado,

\[\lim_{t \to \infty} \frac{t^{\alpha-1}e^{-t}}{e^{-t/2}} = 0\]

Por lo que $t^{\alpha-1}e^{-t} < e^{-t/2}$ integrable, a partir de algn punto.
Partimos la integral como:

\[\int_0^b t^{\alpha-1}e^{-t}dt + \int^{\infty}_b t^{\alpha-1}e^{-t}dt
< \infty\]

***** Propiedades de la funcin Gamma
Sea $\alpha > 0$, se verifica:

  1. $\Gamma(1) = 1$.
  2. $\Gamma(\alpha+1) = \alpha\Gamma(\alpha)$.
  3. $\Gamma(n+1) = n!$ para $n \in \mathbb{N}$.
  4. $\Gamma(\alpha)\Gamma(1-\alpha) = \frac{\pi}{\sin(\alpha\pi)}$ para $0<\alpha<1$.
  5. $\Gamma(1/2) = \sqrt{\pi}$.
  6. $\Gamma(\alpha) = \beta^\alpha \int^\infty_0 t^{\alpha-1}e^{-\beta t} dt$ para $\beta > 0$.

****** Demostracin
******* Punto 1
Trivial.
******* Punto 2
Integral por partes.
******* Punto 3
Induccin sobre los dos primeros apartados.
******* TODO Punto 4
******* Punto 5
Trivial desde el punto anterior.
******* Punto 6
Cambio de variable $\varphi(t) = \beta t$.

***** Distribucin Gamma
Dados $\alpha,\beta > 0$, definimos la distribucin Gamma $\Gamma(\alpha,\beta)$ como aquella con
funcin de densidad:

\[f(x) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}\]

para $x>0$. 

****** Imagen de la distribucin
#+BEGIN_SRC R :results graphics :file images/gamma.png
  library(ggplot2)
  library(ggfortify)
  gg = NULL
  for (i in c(1,2,3,4,5)) {
      gg = ggdistribution(dgamma, seq(0, 4, 0.05),
                          shape = i, rate = 1,
                          colour=topo.colors(5)[i], p=gg)
  }
  print(gg + labs(title = "Distribucin gamma, variando ."))
#+END_SRC

#+RESULTS:
[[file:images/gamma.png]]
***** Propiedades de la distribucin Gamma
La funcin de densidad de una distribucin $\Gamma(\alpha,\beta)$ verifica:

  1. Cuando $0<\alpha<1$, $f$ es decreciente y $\lim_{x\to 0} f(x) = \infty$.
  2. Cuando $\alpha = 1$, $f$ es decreciente y $f(0)=1$.
  3. Cuando $\alpha>1$, $f$ es creciente en $[0,(\alpha-1)/\beta]$ y decreciente 
     en $[(\alpha-1)/\beta,\infty]$.

Y sobre convexidad y concavidad se tiene:

  1. Si $0<\alpha\leq 1$, es convexa.
  2. Si $1 < \alpha \leq 2$, es cncava en $[0,(\alpha-1+\sqrt{\alpha+1})/\beta]$ y convexa
     en $[(\alpha-1+\sqrt{\alpha+1})/\beta,\infty]$.
  3. Si $2 < \alpha$, es cncava en $[(\alpha-1-\sqrt{\alpha+1})/\beta,(\alpha-1+\sqrt{\alpha+1}/\beta)]$ y
     convexa en todo el resto del dominio.

****** TODO Demostracin
***** Suma de Gammas
Para $X \leadsto \Gamma(\alpha_1,\beta)$, $Y \leadsto \Gamma(\alpha_2,\beta)$, independientes:

\[
X+Y \leadsto \Gamma(\alpha_1+\alpha_2,\beta)
\]
**** 8. Distribucin Beta
***** Funcin Beta
Se define la funcin beta $\beta : (0,\infty) \longrightarrow (0,\infty)$ como:

\[\beta(x,y) = \int^1_0 t^{x-1}(1-t)^{y-1}dt\]

****** Est bien definida
Por la [[*Relacin con la funcin Gamma][relacin con la funcin Gamma]] sabemos que debe estar
bien definida.

***** Relacin con la funcin Gamma
Para cada $x,y$ se tiene:

\[\frac{\Gamma(x)\Gamma(y)}{\Gamma(xy)} = \beta(x,y)\]

****** TODO Demostracin

***** Distribucin Beta
Dados $p,q>0$, definimos la distribucin Beta $\beta(p,q)$ como aquella con 
funcin de densidad:

\[f(x) = \frac{1}{\beta(p,q)} x^{p-1}(1-x)^{q-1}\]
*** 1. Introduccin a la inferencia estadstica. Estadsticos muestrales
**** Planteamiento de un problema de inferencia
***** Modelo estadstico
Un modelo estadstico $(X,{\cal P})$ consta de:

  - $X : (\Omega, {\cal A},{\cal P}) \longrightarrow (\mathbb{R},{\cal B},P_X)$ variable aleatoria que describe el 
    objeto de estudio.
  - ${\cal P}$ familia de distribuciones que pueden ser la de $X$.

***** Modelo estadstico paramtrico
Cuando se conoce la forma funcional de $P_X$ y slo desconocemos un 
parmetro tenemos una familia paramtrica de distribuciones $F(x,\theta)$ 
para $\theta$.

***** Modelo estadstico no paramtrico
Cuando la forma funcional de $P_X$ es desconocida.

***** Muestra aleatoria simple
Una muestra aleatoria simple es un vector $(X_1,\dots,X_n)$
de variables independientes idnticamente distribuidas. 

****** Realizacin muestral 
Una realizacin muestral a un valor concreto obtenido al
observar la muestra.

****** Espacio muestral
Conjunto de todas las posibles realizaciones.

**** Funcin de distribucin emprica
***** Funcin de distribucin muestral
La *funcin de distribucin emprica* es una funcin de 
distribucin razonable que podemos obtener desde una 
realizacin muestral.

 \[F^\ast_{X_1,\dots,X_n}(x) = \frac{1}{n} \sum_{i=1}^n \mathbf{1}_{(X_i < x)} \]

***** Propiedades de la funcin de distribucin emprica
Fijado un $x \in \mathbb{R}$, $F^\ast(x)$ es una variable aleatoria siguiendo por 
definicin una binomial:

\[ nF^\ast(x) \leadsto {\cal B}(n, F(x))\]

Calculamos su *esperanza* y *varianza* desde Bernoulli como:

 - Esperanza: $E[F^\ast(x)] = F(x)$
 - Varianza: $Var[F^\ast(x)] = \frac{F(x) (1-F(x))}{n}$

Aplicando entonces el Teorema Central del Lmite:

\[ \frac{F^\ast(x) - F(x)}{\sqrt{\frac{F(x)(1-F(x))}{n}}} \leadsto {\cal N}(0,1) \]

***** Teorema de Glivenko-Cantelli
Las funciones de distribucin muestrales convergen 
casi seguramente uniformemente a la terica.

\[ P\left\{ \lim_{n \rightarrow \infty} 
\sup_{x \in \mathbb{R}} |F^\ast_n(x) - F(x)| = 0\right\} = 1\]

****** Equivalentemente
Con probabilidad 1 se tiene que, al tomar sucesivas observaciones 
independientes y considerar las correspondientes funciones de 
distribucin muestrales:

\[\forall x \in \mathbb{R}: \forall \epsilon>0: \exists n_\epsilon : \forall n \geq n_\epsilon:
\quad F^\ast_n(x) - \epsilon < F_X(x) < F^\ast_n(x) + \epsilon\]

****** Demostracin
[[http://matematicas.unex.es/~nogales/estadisticamatematica/TGC.pdf][Teorema de Glivenko-Cantelli]].

**** Estadsticos muestrales
***** Estadstico muestral
Dada una muestra aleatoria simple, un *estadstico muestral* es una 
funcin sobre ella $T : (\mathbb{R}^n,{\cal B}^n)\longrightarrow (\mathbb{R}^k,{\cal B}^k)$ medible e independiente 
de cualquier parmetro desconocido.

***** Momentos muestrales no centrados
Para cada $k \in \mathbb{N}$:

\[A_k = \frac{1}{n}\sum_{i=1}^n X_i^k\]

***** Momentos muestrales centrados
Para cada $k \in \mathbb{N}$:

\[B_k = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^k\]

***** Media muestral
Caso particular,

\[A_1 = \frac{1}{n}\sum_{i=1}^n X_i = \overline{X}\]

***** Varianza muestral
Caso particular,

\[B_2 = \frac{1}{n}\sum_{i=1}^n(X_i - \overline{X})^2\]

***** Cuasivarianza muestral

\[S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})^2\]

*** 2. Muestreo de poblaciones normales
**** Muestreo de la normal
***** Lema de Fisher
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple con $X \leadsto {\cal N}(\mu,\sigma^2)$.
Los estadsticos $\overline{X}$ y $S^2$ son independientes.

****** TODO Demostracin

***** A1. Inferencia de la media con varianza conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$, y $\overline{X}$ su media muestral:

\[
\frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)
\]

****** Demostracin
Usando las propiedades de la suma de normales y la linealidad de la
esperanza y cuadracidad de la varianza tenemos:

\[
\overline{X} \leadsto {\cal N}(\mu,\sigma^2/n)
\]

Desde donde simplemente normalizamos.

***** A2. Inferencia de la media con varianza desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$ con $\overline{X}$ su media muestral y $S^2$ su cuasivarianza muestral,
entonces:

\[
\frac{\overline{X}-\mu}{S/\sqrt{n}} \leadsto t(n-1)
\]

****** Demostracin
Por la definicin de t de Student, sabiendo:

\[
\frac{\overline{X} - \mu}{S/\sqrt{n}}
=
\frac{\frac{\overline{X} - \mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{(n-1)S^2}{\sigma^2}/n-1}}
\leadsto
t(n-1)
\]

***** B1. Inferencia de la varianza con media conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$, entonces:

\[
\sum_{i=1}^n \left(\frac{X_i-\mu}{\sigma}\right)^2
\leadsto
\chi^2(n)
\]

****** Demostracin
Usando que la suma de cuadrados de normales estndar es una
distribucin chi cuadrado.

***** B2. Inferencia de la varianza con media desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$ con $S^2$ su cuasivarianza muestral, entonces:

\[
\frac{(n-1)S^2}{\sigma^2} \leadsto \chi^2(n-1)
\]

****** Demostracin
Usamos la independencia entre $X_i-\overline{X}$ y $\overline{X}-\mu$ para escribir:

\[
\sum_{i=1}^n (X_i - \mu)^2
=
\sum_{i=1}^n (X_i - \overline{X})^2 +
\sum_{i=1}^n (\overline{X} - \mu)^2
\]

Ahora bien, sabemos que:

\[
\sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma}\right)^2
\leadsto
\chi^2(n)
\]

\[
n\left(\frac{\overline{X} - \mu}{\sigma}\right)^2}
\leadsto
\chi^2(1)
\]

Y desde aqu, por unicidad de las funciones generadoras de momentos
se tiene:

\[
\sum_{i=1}^n \frac{(X_i-\overline{X})^2}{\sigma^2}
\leadsto
\chi^2(n-1)
\]

**** Muestreo de dos normales
***** Extensin del lema de Fisher
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes.
Los vectores $(\overline{X},\overline{Y})$ y $(S^2_1,S^2_2)$ son independientes.

****** TODO Demostracin
***** Inferencia sobre diferencia de medias con varianzas conocidas
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes:

\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
\sqrt{\frac{(n_1-1)S^2_1}{\sigma_1^2} + \frac{(n_2-1)S^2_2}{\sigma_2^2}}
\sqrt{\frac{\sigma_1^2/n_1 + \sigma_2^2/n_2}{n_1+n_2-2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Demostracin
El numerador sigue una distribucin ${\cal N}(0,\sigma^2_1/n_1+\sigma^2_2/n_2)$, as que lo
dividimos para una normal estndar. Cada uno de los sumandos de
la otra raz forma una chi cuadrada, que al sumarse da $\chi(n_1+n_2-2)$.

Usamos entonces la definicin de t de Student.
***** Inferencia sobre diferencia de medias con varianzas iguales
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma^2)$ independientes:

\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
\sqrt{\frac{(n_1-1)S^2_1+ (n_2-1)S^2_2}{n_1+n_2-2}}
\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Demostracin
Desde el caso anterior, tomando las varianzas iguales.

****** Demostracin alternativa
El numerador sigue una ${\cal N}(0,\sigma^2(1/n_1+1/n_2))$. Podemos dividirlo por
la raz de la varianza e incluir otra varianza en la raz de las
cuasivarianzas muestrales para tener una $\chi^2(n_1+n_2-2)$.

Aplicamos definicin de t de Student.
***** Inferencia sobre cociente de varianzas con media conocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes con muestras de
tamaos $n_1$ y $n_2$:

\[
\frac
{\sum_{i=1}^{n_1}(X_i-\mu_1)^2 / n_1\sigma_1^2}
{\sum_{i=1}^{n_2}(X_i-\mu_2)^2 / n_2\sigma_2^2}
\leadsto
F(n_1,n_2)
\]

****** Demostracin
Desde la definicin de la F de Snedecor, sabiendo que cada factor
es una chi cuadrada.

***** Inferencia sobre cociente de varianzas con media desconocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$ y $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$ independientes:

\[
\frac
{S_1^2/\sigma_1^2}
{S_2^2/\sigma_2^2}
\leadsto
F(n-1,m-1)
\]

****** Demostracin
Aplicando la definicin de F de Snedecor y sabiendo que son dos
distribuciones chi cuadrado.

*** 3. Suficiencia y completitud
**** Estadsticos suficientes
***** Estadstico suficiente
Un estadstico $t$ es *suficiente* para un parmetro $\theta$ cuando una vez 
conocido no puede obtenerse ms informacin de sobre $\theta$ de los datos;
esto es:

 \[\Pr(\theta| t,x) = \Pr(\theta|t)\]

****** Definicin equivalente
De forma equivalente, es *suficiente* si la distribucin condicionada 
al estadstico es independiente del parmetro $\theta$:

 \[\Pr(x|t,\theta) = \Pr(x|t)\]

***** Teorema de factorizacin de Fisher-Neyman
$T$ es suficiente para una familia $\theta \in \Theta$ ssi existen funciones no negativas
$g$,$h$ tales que la distribucin $f_\theta$ es:

\[f_\theta(x) = h(x)g_\theta(T(x))\]

Donde $g_\theta$ slo depende de $x$ a travs de $T$ y $h$ no depende de $\theta$.

****** TODO Demostracin
***** Propiedades de los estadsticos suficientes
Los estadsticos suficientes cumplen:

  1. Si $T$ es suficiente para $\{P_\theta \mid \theta \in \Theta\}$, lo es para $\{P_\theta \mid \theta \in \Theta' \subset \Theta\}$.
  2. Si $T$ es suficiente y $T = h'(U)$, $U$ es suficiente.
  3. Toda transformacin biunvoca de suficiente es suficiente.

****** Demostracin
******* Punto 1
Si cumple la factorizacin para un conjunto, lo cumple para tambin
un subconjunto.

******* Punto 2
Por el teorema de factorizacin:

\[f_\theta(x) = h(x)g_\theta(h'(U(x)))\]

******* Punto 3
Trivial desde lo anterior usando la inversa.

**** Estadsticos completos
***** Familia de distribuciones completa
Una familia $\{P_\theta \mid \theta \in \Theta\}$ es completa si dada $X \leadsto P_\theta$ se tiene que
para cada $g$ medible:

\[
E_\theta[g(X)] = 0,\;\forall\theta\in\Theta
\implies
P_\theta(g(X) = 0) = 1,\;\forall\theta\in\Theta
\]

***** Estadstico completo
Un estadstico $T$ es *completo* cuando para cualquier funcin medible $g$,
se tiene:

\[ E_\theta [g(T)] = 0, \; \forall\theta\in\Theta
\implies
P_\theta(g(T) = 0) = 1,\; \forall\theta\in\Theta\]

**** Suficiencia y completitud en familias exponenciales
***** Familia exponencial k-paramtrica
Una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramtrica si:

 1. $\Theta$ es intervalo de $\mathbb{R}^k$.
 2. Los valores de la variable no dependen de $\theta$, esto es:
    $\{{ x \mid f_{\theta}(x) > 0 \} = \{{ x \mid f_{\theta'}(x) > 0 \}$ para cualesquiera $\theta,\theta' \in \Theta$.
 3. La familia es de la forma:

    \[f_\theta(x) = exp\left\{\sum_{h=1}^k {Q_h(\theta) T_h(x) + S(x) + D(\theta)}\right\}\]

***** Teorema de suficiencia y complitud
Si una familia $\{P_\theta : \theta \in \Theta\}$ es exponencial k-paramtrica, cualquier muestra
aleatoria simple tambin lo es:

\[
f^n_\theta(x_1,\dots,x_n) = 
exp\left\{
\sum^k_{h=1} Q_h(\theta) \left(
\sum^n_{i=1} T_h(x_i)
\right) +
\sum^n_{i=1} S(x_i) + nD(\theta)
\right\}
\]

Tenindose adems:

 1. $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ estadstico *suficiente* para $\theta$.
 2. Si $k \leq n$, y $(Q_1(\Theta), \dots Q_k(\Theta))$ contiene un abierto;
    $(\sum_i T_1(X_i), \dots \sum_i T_k(X_i))$ es *completo*.

****** TODO Demostracin

***** Ejemplo: la normal para la media
La familia $\{{\cal N}(\mu,\sigma^2) \mid \mu \in \mathbb{R}\}$ es uniparamtrica escribiendo la funcin
de distribucin como:

\[
f_\theta(x) = 
exp\left\{
log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) -
\left( \frac{x^2}{2\sigma^2} - 2\frac{x\mu}{2\sigma^2} + \frac{\mu^2}{2\sigma^2} \right)
\right\}
\]

De aqu tenemos el $T(x) = x$ suficiente para $\mu$. Y con para una muestra 
tenemos $T(x_1,\dots,x_n) = x_1 + \dots + x_n$.

***** Ejemplo: la normal para la varianza
La familia $\{{\cal N}(\mu,\sigma^2) \mid \sigma\in\mathbb{R}\}$ es uniparamtrica escribiendo la funcin
de distribucin como:

\[
f_\theta(x) = 
exp\left\{
log\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right) -
\frac{1}{2\sigma^2}\left(x^2 - 2x\mu + \mu^2 \right)
\right\}
\]

As $T(x) = \sum_{i=1}^n (x_i - \mu)^2$ es suficiente. Adems es completo porque
tenemos que $Q(\sigma) = -\frac{1}{2\sigma^2}$ tiene en la imagen un intervalo abierto.

***** Ejemplo: distribucin de Poisson
La familia de Poisson $\{Poi(\lambda) \mid \lambda \in \mathbb{R}\}$ tiene como estimador suficiente 
del parmetro a la suma de las muestras. Tenemos:

\[
f_\lambda(x) = \frac{1}{\prod x_i!} e^{-n\lambda} \lambda^{\sum x_i}
\]

Luego por Fisher-Neyman, sabemos que $\sum x_i$ es suficiente.

*** 4. Estimacin puntual
**** Planteamiento del problema de estimacin
***** Estimador puntual
Un estimador puntual de $\theta$ es un estadstico $T$ tomando valores en el 
dominio del parmetro, $\Theta$.

***** Funcin de prdida y de riesgo
La *funcin de prdida*, $L(\theta,t)$, nos dice la prdida asociada a estimar 
un parmetro si su verdadero valor es otro.

\[
L : \Theta \times \Theta \longrightarrow \Theta
\]

***** Funcin de riesgo
La *funcin de riesgo* es la que asocia a cada valor del parmetro la 
prdida media asociada al estimador.

\[ R^L_T(\theta) = E_\theta [L(\theta,T)] \]

***** Estimador ptimo
El *estimador ptimo*, $T$, dada una funcin de prdida, es el que minimiza 
uniformemente la funcin de riesgo:

\[ R^L_T(\theta) \leq R^L_{T''}(\theta),\quad \forall \theta \in \Theta,\; \forall T''\]

***** TODO Ejemplo de estimador ptimo
**** Estimacin de menor error cuadrtico
***** Funcin de prdida cuadrtica
La funcin de prdida cuadrtica, ${\cal L}(\theta, t) = (t - \theta)^2$, hace a la funcin de 
riesgo de un estimador su error cuadrtico medio:

\[R^L_T(\theta) = E_\theta[(T - \theta)^2]\]

Ntese que en el caso de $E[T] = \theta$, se tiene $R^L_T(\theta) = Var_\theta[T]$.

**** Estimacin insesgada de mnima varianza
***** Estimador insesgado
Un estimador $T$ de $g(\theta)$, es *insesgado* o *centrado* si:

 $E_\theta[T] = g(\theta)$

***** UMVUE: Estimador insesgado uniformemente de mnima varianza
Un estimador $T$ insesgado y de segundo orden es *UMVUE* para $g(\theta)$ si para 
cualquier otro estimador insesgado $T'$ se tiene que:

\[ Var_\theta[T] \leq Var_\theta[T']\]

****** De segundo orden
Lo llamamos de segundo orden cuando existe el momento de segundo orden:

\[
\exists \mathbb{E}_\theta[T^2(X_1,\dots,X_n)]
\quad
\forall \theta \in \Theta
\]

***** Propiedades del UMVUE
El estimador UMVUE cumple:

 - Unicidad: El UMVUE de cualquier funcin paramtrica, si existe, es nico.
 - Linealidad: Si $T,Q$ son UMVUE para $g,h$; $aT+bQ$ es UMVUE para $ag+bh$.

****** Unicidad
Si existieran dos UMVUE con $Var(T) = Var(T')$, tendramos:

\[\begin{aligned}
Var\left(\frac{1}{2}(T+T')\right) &= 
\frac{1}{4}
\left(
Var(T) + Var(T') + 2cov(T,T')
\right) \\& \leq
\frac{1}{4}
\left(
Var(T) + Var(T') + 2\sqrt{Var(T)Var(T')}
\right) \\& = Var(T)
\end{aligned}\]

La igualdad se da por ser UMVUE, y entonces, $cov(T,T') = Var(T)$.
De aqu $cov(T-T',T-T') = 0$, haciendo constante la diferencia entre los
dos. La diferencia entre ellos debe ser constantemente $0$ por ser ambos 
insesgados.

****** TODO Linealidad
***** Teorema de Ra-Blackwell
Si $T$ es suficiente para $\theta$ y $S$ es un estimador insesgado de $g(\theta)$ de 
segundo orden:

  - $E[S \mid T]$ es estimador insesgado de $g(\theta)$ de segundo orden.
  - $Var_\theta[E[S \mid T]] \leq Var_\theta[S]$

Es decir, $E[S \mid T]$ ser normalmente mejor estimador y nunca peor que $S$.

****** Demostracin
Sabemos $E[S|T] = E[S] = \theta$ por la [[*Ley de esperanza total][ley de esperanza total]]. La desigualdad
entre varianzas la vemos como:

\[\begin{aligned}
E\Big[(E[S|T] - \theta)^2 \Big] &= 
E\Big[E[S-\theta | T]^2 \Big] \leq
E\Big[E[(S-\theta)^2|T] \Big] = E\Big[(S-\theta)^2\Big]
\end{aligned}\]

Donde volvemos a usar la ley de esperanza total. La desigualdad viene
de que la varianza es positiva, o de la desigualdad de Jensen para el
cuadrado.

***** Teorema de Lehmann-Scheff
Para $T$ suficiente y completo para $\theta$; si $g(\theta)$ admite un estimador insesgado 
de segundo orden $S$, entonces existe el UMVUE de $g(\theta)$ y est dado por:

\[ \mathbb{E} [S \mid T]\]

De otra forma, un estimador insesgado que es funcin de estimador completo
y suficiente es el UMVUE.

****** Demostracin
Por [[*Teorema de Ra-Blackwell][Ra-Blackwell]], sabemos que es un estimador insesgado; y que, dado
cualquier otro estimador insesgado $Q$, tenemos que:

\[ Var[E[Q|T]] \leq Var[Q]\]

Ahora bien, dado otro, tendramos:

\[
E\Big[ E[S|T] - E[Q|T] \Big] = 0
\]

Y como $T$ es completo y ambos son dependientes de $T$, eso implica que:

\[P\Big(
E[S|T] - E[Q|T] = 0
\Big) = 1\]

Por lo tanto, ambos son el UMVUE.

***** Clculo del UMVUE
Dado $T$ suficiente y completo. Para calcular el UMVUE de $g(\theta)$ podemos:

  1. Buscar un estimador insesgado y de segundo orden cualquiera de $g(\theta)$.
     Entonces $\mathbb{E}[S|T]$ ser el UMVUE.
  2. Buscar $h(T)$ tal que $\mathbb{E}_\theta[h(T)] = g(\theta)$, un estimador insesgado que es
     slo funcin de $T$. Se cumplir $\mathbb{E}[h(T)|T] = h(T)$.

**** Estimacin eficiente
***** Condiciones de regularidad de Frchet-Cramer-Rao
Una familia $\{P_\theta \mid \theta\in\Theta\}$ es *regular* en el sentido de Frchet-Cramer-Rao
si cumple que:

  1. $\Theta$ es intervalo abierto de $\mathbb{R}$.
  2. $\forall \theta,\theta'\in\Theta : \{x \mid f_\theta(x) > 0\} = \{x \mid f_{\theta'}(x) > 0\} = \chi$
  3. Tenemos $f_\theta(x)$ derivable respecto a $\theta$ para todo $x \in \chi$ con:

     \[ \int_\chi \frac{d f_\theta(x)}{d\theta} dx = 
     \frac{d}{d\theta} \int_\chi f_\theta(x) dx = 
     0, \quad \forall \theta\in\Theta\]
   
     O, cuando la distribucin es discreta:
   
     \[\sum_\chi \frac{d f_\theta(x)}{d\theta}
     = 
     \frac{d}{d\theta}\sum_\chi f_\theta(x)
     = 
     0\]

***** Funcin de informacin de Fisher
Si $\{P_\theta : \theta \in \Theta\}$ es regular, definimos la *funcin de informacin* asociada
a $X$ como:

\[I_X(\theta) = E_\theta\left[\left( \frac{d}{d\theta} \ln(f_\theta(X))
\right)^2\right]\]

Y la funcin de informacin asociada a una muestra como:

\[
\[I_{X_1,\dots,X_n}(\theta) = 
E_\theta\left[\left( \frac{d}{d\theta}\ln(f_\theta(X_1,\dots,X_n))
\right)^2\right]\]

***** Propiedades de la funcin de informacin
La funcin de informacin tiene como propiedades:

  1. $I_X(\theta) \geq 0$.

  2. En el caso $I_X(\theta) = 0$, $f_\theta(X)$ no depende de $\theta$.

  3. \[E_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = 0\].

  4. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X) \right] = I_X(\theta) \].

  5. \[E_\theta \left[\frac{d}{d\theta} \ln f_\theta(X_1,\dots,X_n) \right] = 0\].

  6. \[ Var_\theta \left[\frac{d}{d\theta} \ln f_\theta(X_1,\dots,X_n) \right] = I_{X_1,\dots,X_n}(\theta) \].

  7. Aditividad, $I_{X_1,\dots,X_n}(\theta) = nI_X(\theta)$.
 
****** Demostracin
******* Punto 3
Derivando y asumiendo las condiciones de regularidad:

\[
\mathbb{E}_\theta\left[\frac{\partial}{\partial\theta} \ln f_\theta(x)\right]
=
\int_\chi \left(\frac{\partial}{\partial\theta} \ln f_\theta(x)\right) f_\theta(x)\; dx
=
\int_\chi \frac{\partial}{\partial\theta} f_\theta(x)\;dx
= 0
\]

***** Funcin de informacin bajo Cramer-Ra
Bajo las hiptesis de regularidad fuertes de Frchet-Cramer-Ra:

\[
I(\theta) = E_{\theta}\left[
-\frac{\partial^2}{\partial\theta^2} \log f_\theta(X)
\right]
\]

Es decir, debemos exigir que:

\[
\int_X \frac{\partial^2}{\partial\theta^2} f_\theta(x) dx =
\frac{\partial^2}{\partial\theta^2} \int_X  f_\theta(x) dx
\]

****** Demostracin
Notando primero la siguiente igualdad:

\[
\frac{\partial^2}{\partial\theta^2}\log f_\theta(x) =
\frac{1}{f_\theta(x)}\frac{\partial^2}{\partial\theta^2}f_\theta(x) -
\left(\frac{\partial}{\partial\theta}\log f_\theta(x)\right)^2
\]

Y simplemente tomamos esperanzas, sabiendo que por las condiciones de
regularidad:

\[
\mathbb{E}\left[
\frac{1}{f_\theta(x)}
\frac{\partial^2}{\partial\theta^2} f_\theta(x)
\right]
=
\frac{\partial^2}{\partial\theta^2}
\int_X f_\theta(x)\;dx 
= 
\frac{\partial^2}{\partial\theta^2}
1
=
0
\]

***** Estadstico regular
Un estadstico $T$ es regular en el sentido de Frchet-Cramer-Ra, si
siendo una distribucin discreta:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\sum_{x \in \chi^n} T(x)f_\theta(x) \\&= 
\sum_{x \in \chi^n} T(x) \frac{d}{d\theta} f_\theta(x)
\end{aligned}\]

O, siendo una distribucin continua:

\[\begin{aligned}
\frac{d}{d\theta}
E_\theta[T] &=
\frac{d}{d\theta} 
\int_{x \in \chi^n} T(x)f_\theta(x) \;dx \\&= 
\int_{x \in \chi^n} T(x) \frac{d}{d\theta} f_\theta(x) \;dx
\end{aligned}\]

***** Cota de Frchet-Cramer-Ra
Si $\{P_\theta \mid \theta \in \Theta\}$ es regular, la funcin de informacin se acota
$0 < I_X(\theta) < \infty$, y $T$ es un estadstico regular, de segundo orden e
insesgado en una funcin derivable $g(\theta)$, se tiene:

  1. \[Var_\theta[T] \geq \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]

  2. Para todo $\theta \in \Theta$ tal que $g'(\theta) \neq 0$:

     \[Var_\theta[T] = \frac{g'(\theta)^2}{I_{X_1,\dots,X_n}(\theta)}\]
     
     ssi existe $a(\theta) \neq 0$ tal que:

     \[P_\theta\left(
     \frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = 
     a(\theta)[T(X_1,\dots,X_n) - g(\theta)]
     \right) = 1\]

****** Demostracin
******* Primer punto
Llamamos primero:

\[V_\theta = \frac{\partial}{\partial\theta} \ln f_\theta(x_1,\dots,x_n)\]

Tenemos que:

  - $Var_\theta(V_\theta) = I_{X_1,\dots,X_n}(\theta)$
  - $\mathbb{E}(V_\theta) = 0$
  - $Cov(T,V_\theta) = \mathbb{E}[TV_\theta] - \mathbb{E}[T]\mathbb{E}[V]$

Calculando:

\[\begin{aligned}
Cov(T,V_\theta) 
&=
\int_{\chi^n} 
T(x_1,\dots,x_n)
\left(\frac{\partial}{\partial\theta} \ln f_\theta(x_1,\dots,x_n)\right)
f_\theta(x_1,\dots,x_n)\;dx 
\\&=
\int_{\chi^n} 
T(x_1,\dots,x_n)
\left(\frac{\partial}{\partial\theta} f_\theta(x_1,\dots,x_n)\right)\;dx 
\\&=
\frac{\partial}{\partial\theta} \int_{\chi^n} 
T(x_1,\dots,x_n)
\left(f_\theta(x_1,\dots,x_n)\right)\;dx 
\\&=
\frac{\partial}{\partial\theta} g(\theta)
\end{aligned}\]

Y finalmente aplicamos la desigualdad de Cauchy-Schwartz a la 
covarianza entre $T,V_\theta$ para tener:

\[
Cov(T,V_\theta) \leq Var[T]Var[V_\theta]
\]
    
***** Estimador eficiente
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con la funcin de informacin acotada 
$0 < I_X(\theta) < \infty$ y $g(\theta)$ funcin paramtrica derivable. Un estimador $T$ de $g(\theta)$ 
es *eficiente* si es insesgado, regular, y su varianza alcanza la
cota de Frchet-Cramer-Ra en todo punto:

\[Var_\theta[T] = \frac{(g'(\theta))^2}{I_{X_1,\dots,X_n}(\theta)},
\qquad \forall\theta \in \Theta\]

***** Caracterizacin de estimadores eficientes
Sea $\{P_\theta \mid \theta \in \Theta\}$ regular, con $0 < I_X(\theta) < \infty$ y $g(\theta)$ funcin paramtrica
derivable y *no constante*. Un estimador $T$ es eficiente ssi existe un $a(\theta)$
cumpliendo:

  1. \[P_\theta\left(\frac{d}{d\theta} \ln f^n_\theta(X_1,\dots,X_n) = a(\theta)[T(X_1,\dots,X_n) - g(\theta)]\right) = 1\]

  2. \[I_{X_1,\dots,X_n}(\theta) = a(\theta)g'(\theta)\]

****** Demostracin
******* Primera implicacin
Si tenemos un $T$ eficiente, tomamos el $T$ de la cota y $g'(\theta)\neq 0$,
de ah tenemos la primera igualdad.

***** Ejemplo: distribucin binomial
Dada la familia de distribuciones $\{B(k_0,p) \mid p \in (0,1)\}$, veremos que es
regular.

****** Es regular
El intervalo $p \in (0,1)$ es abierto y $\chi = (0,\dots,k_0)$.

Si la expresamos exponencialmente es ms fcil calcular su derivada
y relacionarla con una esperanza:

\[
f_p(x)
= 
\exp\left\{\log{k_0\choose x} + x \log p + (k_0-x)\log (1-p)\right\}
\]

Tenemos:

\[
\sum_\chi \frac{\partial f_p(x)}{\partial p}
=
\sum_\chi \frac{x-pk_0}{p(1-p)} f_p(x)
=
\mathbb{E}\left[\frac{X-pk_0}{p(1-p)} \right] = 0
\]

****** Funcin de informacin
Desde la derivada podemos calcular la funcin de informacin:

\[
I_{X_1,\dots,X_n}(p) = \frac{nk_0}{p(1-p)}
\]

****** Caracterizacin del estimador eficiente
Calcularemos para usar la caracterizacin:

\[
\frac{\partial}{\partial p} \ln f_p(x_1,\dots,x_n)
=
\sum \frac{\partial}{\partial p} f_p(x_i)
=
n\frac{\overline{x}-pk_0}{p(1-p)}
\]

As, para cumplir la caracterizacin, tiene sentido tomar:

  - $g(p) = pk_0$
  - $T(X_1,\dots,X_n) = \overline{X}$
  - $a(p) = \frac{n}{p(1-p)}$

**** Estimacin de mxima verosimilitud
***** Funcin de verosimilitud
Para cada realizacin muestral se define la funcin de verosimilitud
de la realizacin, $L_{x_1,\dots,x_n} : \Theta \longrightarrow \mathbb{R}^+_0$, como:

\[L(\theta) = f_\theta(x_1,\dots,x_n)\]

***** Estimador de mxima verosimilitud
Tenemos $\hat\theta$ estimador de mxima verosimilitud de $\theta$ cuando la estimacin
asociada a cada realizacin muestral maximiza la verosimilitud:

\[L_{x_1,\dots,x_n}\left(\hat\theta(x_1,\dots,x_n)\right)
= \max_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)\]

***** Ecuacin de mxima verosimilitud
El procedimiento habitual para hallar el estimador de mxima 
verosimilitud es derivar e igualar:

\[
\frac{\partial}{\partial\theta_j} \ln L_{X_1,\dots,X_n}(\theta_1,\dots,\theta_k)
= 0
\]

Ntese que esto slo nos da un punto crtico.

****** Demostracin
Usando simplemente que el logaritmo es creciente y la caracterizacin
de los mximos.

***** Propiedades del estimador de mxima verosimilitud
Un estimador de mxima verosimilitud $\hat\theta$ de $\theta$ cumple:

  1. Consistencia:

     \[\lim_{n \to \infty}\hat\theta(x_1,\dots,x_n) = \theta\]

  2. Normalidad asinttica. Para $n$ suficientemente grande, sus errores
     pueden aproximarse por una normal:

     \[\sqrt{n}(\hat\theta(x_1,\dots,x_n) - \theta) \leadsto {\cal N}(0,1/I_X(\theta))\]

****** TODO Demostracin

***** Relacin con estadsticos suficientes
Si $\{P_\theta \mid \theta \in \Theta\}$ admite estadstico suficiente $T$, entonces $\hat\theta$ es funcin
de $T$.

****** Demostracin
Por Teorema de factorizacin de Fisher-Neyman, tenemos que la
funcin de distribucin se escribir como:

\[
f_\theta(x) = h(x)g_\theta(T)
\]

Entonces para maximizarla habr que maximizar $g_\theta(T)$.

***** Relacin con estimadores eficientes
Si $T$ es estimador eficiente de $\theta$, entonces $T$ es el nico estimador 
mximo verosmil de $\theta$.

****** TODO Demostracin

***** Funcin de verosimilitud de una funcin paramtrica
Se define la funcin de verosimilitud de $g : \Theta \longrightarrow \Lambda$ asociada a
una realizacin, $M_{x_1,\dots,x_n} : \Lambda \longrightarrow \mathbb{R}^+_0$, como:

\[M_{x_1,\dots,x_n}(\lambda)
= \sup_{\theta \in g^{-1}(\lambda)} L_{x_1,\dots,x_n}(\theta) \]

***** Estimador de mxima verosimilitud de una funcin paramtrica
Ser $\hat\lambda$ estimador mximo verosmil de $\lambda$ cuando:

\[M_{x_1,\dots,x_n}(\hat\lambda(x_1,\dots,x_n)) 
= \max_{\lambda \in \Lambda} M_{x_1,\dots,x_n}(\lambda) \]

***** Teorema de invarianza de Zenha
Si $\hat\theta$ es estimador mximo verosmil de $\theta$, entonces $g(\hat\theta)$ es estimador
mximo verosmil de $g(\theta)$.

****** TODO Demostracin
Se cumple:

\[
M(\lambda') = sup_{\theta \in g^{-1}(\lambda')} L(\theta)
\leq
sup_{\theta \in \Theta} L(\theta)
=
L(\hat\theta)
=
M(g(\hat\theta))
\]

**** Mtodo de los momentos
***** Descripcin
El estimador de una funcin dependiente en los momentos
poblacionales es el mismo dependiendo en los momentos muestrales.

\[g(\theta) = h(m_{\theta,1},\dots,m_{\theta,k}) 
\quad\Rightarrow\quad
\widehat{g(\theta)}(X_1,\dots,X_n) = h(A_1,\dots,A_k)\]

****** Momentos poblacionales
Definimos los momentos poblacionales como:

\[m_{\theta,j} = E_\theta[X^j]\]

****** Momentos muestrales
Definimos los momentos muestrales como:

\[A_j = \frac{1}{n}\sum_{i=1}^n X^j_i\]

**** Mtodo de mnimos cuadrados
***** Descripcin
Si $X_i$ son las observaciones aleatorias de una magnitud $\varphi(t,\theta)$ con
errores $\varepsilon_i$; es decir:

\[X_i = \varphi(t_i,\theta) + \varepsilon_i\]

Entonces el estimador de mnimos cuadrados de $\theta$ es el que minimice
la suma de cuadrados de los errores:

\[\sum^n_{i=1}(X_i - \varphi(t_i,\theta))^2\]

*** 5. Estimacin por intervalos de confianza
**** Definiciones y mtodos de construccin
***** Intervalo de confianza
Para $X \leadsto P_\theta$, un intervalo de confianza $\alpha$ para $\theta$ es un intervalo 
aleatorio $(I_1,I_2)$ tal que para cualquier $\theta \in \Theta$:

\[P_\theta\left(
I_1(X_1,\dots,X_n) \leq \theta \leq I_2(X_1,\dots,X_n)
\right)
\geq 1 - \alpha\]

***** Intervalo de confianza de menor longitud esperada uniformemente
Un interavlo $(I_1,I_2)$ es el de menor longitud esperada uniformemente 
si para cualquier otro $(I_1',I_2')$ al mismo nivel, se tiene:

\[
E_\theta[I_2(X_1,\dots,X_n) - I_1(X_1,\dots,X_n)]
\leq
E_\theta[I_2'(X_1,\dots,X_n) - I_1'(X_1,\dots,X_n)]
\]

***** Intervalos mediante desigualdad de Chevychev
Si $T$ es estimador insesgado de $\theta$ con varianza uniformemente acotada:

  - $E_\theta[T(X_1,\dots,X_n)] = \theta$
  - $Var_\theta[T(X_1,\dots,X_n)] \leq c$

Por lo que por Chevychev tenemos, dado $k>0$, un intervalo de confianza
para $\theta$ al nivel de confianza $1 - c/k^2$:

\[P\left(T - k \leq \theta \leq  T + k \right) \geq 1 - c/k^2\]

****** TODO Demostracin

***** Pivote para un parmetro
Un pivote es una funcin $T(X_1,\dots,X_n,\theta)$ tal que fijado cualquier $\theta$,
$T(X_1,\dots,X_n,\theta)$ es una variable con distribucin independiente de $\theta$.

***** Intervalos obtenidos mediante el mtodo pivotal
Dado un pivote $T$ estrictamente montono respecto a $\theta$, y dos valores
$\lambda_1,\lambda_2$, tales que:

\[P_\theta(\lambda_1 < T < \lambda_2) \geq 1 - \alpha\]

Tomamos las soluciones $\hat\theta_1, \hat\theta_2$, cumpliendo $T(X_1,\dots,\hat\theta_1) = \lambda_1$ y
$T(X_1,\dots,\hat\theta_2) = \lambda_2$; y ellas forman un intervalo de confianza:

  - $P_\theta(\hat\theta_1 < \theta < \hat\theta_2) \geq 1 - \alpha$, para $T$ creciente.
  - $P_\theta(\hat\theta_2 < \theta < \hat\theta_1) \geq 1 - \alpha$, para $T$ decreciente.

****** TODO Demostracin

***** Un pivote en distribuciones continuas
Si $X$ es continua con $F_\theta$ funcin de distribucin, un pivote es:

\[ T(X_1,\dots,X_n,\theta) = -2 \sum_{i=1}^n \ln F_\theta(X_i) \leadsto \chi^2(2n)\]

****** TODO Demostracin
***** Un pivote dado un estadstico
Sea $S$ un estadstico de distribucin continua con $F^S_\theta$ funcin de 
distribucin. Un pivote es:

\[T(X_1,\dots,X_n,\theta) = F^S_\theta(S(X_1,\dots,X_n)) \leadsto U(0,1)\]

****** TODO Demostracin
**** Ejemplos de intervalos de confianza
***** A1. Intervalo para la media de una normal con varianza conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2_0)$. El intervalo para $\mu$ de menor longitud
media uniforme a nivel de confianza $1-\alpha$ ser:

\[\left(
\overline{X}-z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}},
\overline{X}+z_{\alpha/2}\frac{\sigma_0}{\sqrt{n}}
\right)\]

donde $z_{\alpha/2}$ cumple que \[P\left(Z > z_{\alpha/2}\right) = \alpha/2\] con $Z \leadsto {\cal N}(0,1)$.

****** Pivote
Usamos como pivote a la normalizada:

\[T(X_1,\dots,X_n,\mu) = \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \leadsto {\cal N}(0,1)\]

****** Intervalos candidatos
Usando el pivote, tenemos el siguiente candidato a intervalo de
confianza:

\[
1 - \alpha > 
P_\mu\left(
\lambda_1 < 
\frac{\overline{X} - \mu}{\sigma_0 / \sqrt{n}} <
\lambda_2
\right)
=
P_\mu\left(
\overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} <
\mu <
\overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}}
\right)
\]

Debiendo tenerse que, si $\Phi$ es la funcin de distribucin de la
normal $\Phi(\lambda_2)-\Phi(\lambda_1) = 1 - \alpha$.

****** Longitud media
Buscamos el que minimice la longitud media:

\[E_\mu \left[
\left( \overline{X} - \lambda_1\frac{\sigma_0}{\sqrt{n}} \right) -
\left( \overline{X} - \lambda_2\frac{\sigma_0}{\sqrt{n}} \right)
\right] 
= (\lambda_2-\lambda_1)\frac{\sigma_0}{\sqrt{n}}\]

Por lo que tratamos de minimizar $(\lambda_2-\lambda_1)$.

****** Minimizacin
Usamos multiplicadores de Lagrange para definir:

\[F(\lambda_1,\lambda_2) = \lambda_2-\lambda_1 + \lambda(\Phi(\lambda_2) - \Phi(\lambda_1) - (1-\alpha))\]

Calculando las derivadas parciales tenemos:

\[\begin{aligned}
-1-\lambda\Phi'(\lambda_1) &= 0\\
1 + \lambda\Phi'(\lambda_2) &= 0
\end{aligned}
\]

Luego debe tenerse $\Phi'(\lambda_1) = \Phi'(\lambda_2)$. Sabiendo que $\Phi'$ es la funcin
de distribucin de la normal, tenemos $\lambda_1 = \pm \lambda_2$. Como deben ser
distintos para cumplir la restriccin, tenemos $\lambda_1 = -\lambda_2$.

****** Conclusin
La restriccin nos fuerza a $\Phi(\lambda_2) - \Phi(-\lambda_2) = 1 - \alpha$, luego estamos
buscando el $z_{\alpha/2}$ que cumple, para una normalizada $Z$, $P(Z > z_{\alpha/2}) = \alpha/2$.

***** A2. Intervalo para la media de una normal con varianza desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\mu$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ ser:

\[
\left(
\overline{X} - t_{n-1;\alpha/2}\frac{S}{\sqrt{n}},\,
\overline{X} + t_{n-1;\alpha/2}\frac{S}{\sqrt{n}}
\right)
\]

donde $t_{n-1;\alpha/2}$ cumple que $P(Z \leq t_{n-1;\alpha/2}) = \alpha/2$ con $Z \leadsto T(n-1)$.

****** Pivote
Usaremos como pivote la t de Student:

\[
T = \frac{\overline{X}-\mu}{S/\sqrt{n}} \leadsto t(n-1)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1 - \alpha =
P_\mu\left(
\lambda_1 < 
\frac{\overline{X} - \mu}{S / \sqrt{n}} <
\lambda_2
\right)
=
P_\mu\left(
\overline{X} - \lambda_2\frac{S}{\sqrt{n}} <
\mu <
\overline{X} - \lambda_1\frac{S}{\sqrt{n}}
\right)
\]

Donde, si $\Phi$ es la funcin de distribucin de $t(n-1)$, tenemos
que $1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$.

****** Longitud media
Queremos minimizar la longitud esperada del intervalo:

\[
\mathbb{E}\left[
\left(\overline{X}-\lambda_1\frac{S}{\sqrt{n}}\right) - 
\left(\overline{X}-\lambda_2\frac{S}{\sqrt{n}}\right)
\right]
=
(\lambda_2-\lambda_1)\mathbb{E}\left[
\frac{S}{\sqrt{n}}
\right]
\]

Buscamos por tanto minimizar $\lambda_2-\lambda_1$.

****** Minimizacin
Usamos multiplicadores de Lagrange para definir:

\[F(\lambda_1,\lambda_2) = \lambda_2-\lambda_1 + \lambda(\Phi(\lambda_2) - \Phi(\lambda_1) - (1-\alpha))\]

De donde deducimos $\Phi'(\lambda_1) = \Phi'(\lambda_2)$. Como la t de Student es simtrica
y montona en cada mitad, tenemos $\lambda_1 = -\lambda_2$.

****** Conclusin
Buscamos entonces el $t_{\alpha/2}$ que cumple $P(Z > t_{\alpha/2}) = \alpha/2$.

***** B1. Intervalo para la varianza de una normal con media conocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\sigma^2$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ es:

\[
\left(
\frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{n;\alpha/2}}
,\quad
\frac{\sum_{i=1}^n(X_i-\mu)^2}{\chi^2_{n;1-\alpha/2}}
\right)
\]

Donde $\chi^2_{n;\alpha/2}$ cumple que $P(Z > \chi^2_{n;\alpha/2}) = \alpha/2$ para $Z \leadsto \chi^2(n)$.

****** Pivote
Tomamos como pivote a la funcin:

\[
\sum_{i=1}^n \left(\frac{X_i - \mu}{\sigma}\right)^2
\leadsto
\chi(n)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1-\alpha = P\left(
\frac{\sum_{i=1}^n (X_i-\mu)^2}{\lambda_2}
\leq
\sigma^2
\leq
\frac{\sum_{i=1}^n (X_i-\mu)^2}{\lambda_1}
\right)
\]

Donde, si $\Phi$ es la funcin de distribucin de $\chi(n)$, tenemos que
$1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$. Buscamos minimizar $1/\lambda_1-1/\lambda_2$.

****** Minimizacin
Usamos minimizadores de Lagrange. Definimos:

\[
F(\lambda_1,\lambda_2) = 
\frac{1}{\lambda_2}-\frac{1}{\lambda_1} + 
\lambda(\Phi(\lambda_2)-\Phi(\lambda_1) - (1-\alpha))
\]

Calculando las derivadas parciales tenemos:

\[
\lambda\Phi'(\lambda_2) - \frac{1}{\lambda_2^2} = 0
\]
\[
\lambda\Phi'(\lambda_1) - \frac{1}{\lambda_1^2} = 0
\]

Y por tanto se minimiza cuando $\Phi(\lambda_1)/\Phi(\lambda_2) = \lambda_2^2/\lambda_1^2$. En la prctica
se usa el intervalo de colas iguales.

****** Conclusin
El intervalo de colas iguales nos da $\lambda_1 = \chi^2_{n;1-\alpha/2}$ y $\lambda_2 = \chi^2_{n;\alpha/2}$.

***** B2. Intervalo para la varianza de una normal con media desconocida
Sea $X \leadsto {\cal N}(\mu,\sigma^2)$. El intervalo para $\sigma^2$ de menor longitud media uniforme
a nivel de confianza $1-\alpha$ es:

\[
\left(
\frac{(n-1)S^2}{\chi^2_{n-1;\alpha/2}}
,\quad
\frac{(n-1)S^2}{\chi^2_{n-1;1-\alpha/2}}
\right)
\]

Donde $\chi^2_{n-1;\alpha/2}$ cumple que $P(Z > \chi^2_{n-1;\alpha/2}) = \alpha/2$ para $Z \leadsto \chi^2(n-1)$.

****** Pivote
Tomamos como pivote:

\[
\frac{(n-1)S^2}{\sigma^2} \leadsto \chi^2(n-1)
\]

***** C1. Intervalo para la diferencia de medias de normales de varianza dada
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\mu_1-\mu_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - 
z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}
,\quad
\overline{X}-\overline{Y} +
z_{\alpha/2}\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}
\right)
\]

Donde $z_{\alpha/2}$ cumple que $P(Z>z_{\alpha/2}) = \alpha/2$ para $Z\leadsto {\cal N}(0,1)$.

****** Pivote
Usamos como pivote:

\[
\frac
{\overline{X}-\overline{Y}-(\mu_1-\mu_2)}
{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}}
\leadsto
{\cal N}(0,1)
\]

***** C2. Intervalo para la diferencia de medias de normales de varianza igual
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2)$, $Y \leadsto {\cal N}(\mu_2, \sigma^2)$. El intervalo para $\mu_1-\mu_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
,\quad
\overline{X}-\overline{Y} + t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

donde,

\[
S_p = \sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S^2_2}{n_1+n_2-2}}
\]

y donde $t_{n_1+n_2-2;\alpha/2}$ cumple que $P(Z > t_{\alpha/2}) = \alpha/2$ con $Z \leadsto t(n_1+n_2-2)$.

****** Pivote
Tomamos como pivote a la funcin:


\[
\frac{(\overline{X}-\overline{Y}) - (\mu_1-\mu_2)}
{
S_p
\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
}
\leadsto
t(n_1+n_2-2)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente invervalo de confianza:

\[
1-\alpha = P\left(
\overline{X}-\overline{Y} - \lambda_1S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\leq
\mu_1-\mu_2
\leq
\overline{X}-\overline{Y} + \lambda_2S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

Donde, si $\Phi$ es la funcin de distribucin de $t(n_1+n_2-2)$, tenemos
que $1-\alpha = \Phi(\lambda_2) - \Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimizacin
Usaremos minimizadores de Lagrange para deducir de nuevo que
$\Phi'(\lambda_1) = \Phi'(\lambda_2)$, por monotona y simetricidad, $\lambda_1=\lambda_2$.

****** Conclusin
Buscamos entonces el $t_{\alpha/2}$ que cumple $P(Z > t_{\alpha/2}) = \alpha/2$.

***** D1. Intervalo para el cociente de varianzas de normales de media dada
Sean $X \leadsto {\cal N}(\mu_1,\sigma_1^2)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\sigma_1^2/\sigma_2^2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
F_{n_2,n_1;1-\alpha/2}
\frac{\sum_{i=1}^{n_1} (X_i-\mu_1)^2/n_1}{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2/n_2}
,
F_{n_2,n_1;\alpha/2}
\frac{\sum_{i=1}^{n_1} (X_i-\mu_1)^2/n_1}{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2/n_2}
\right)
\]

donde, $F_{n_2,n_1;\alpha/2}$ cumple que $P(Z > F_{\alpha/2}) = \alpha/2$ con $Z \leadsto F(n_2,n_1)$.

****** Pivote
Tomamos como pivote a la funcin:

\[
\frac
{\sum_{i=1}^{n_2} (Y_i-\mu_2)^2 / n_2\sigma_2^2}
{\sum_{i=1}^{n_2} (X_i-\mu_1)^2 / n_1\sigma_1^2}
\leadsto
F(n_2,n_1)
\]

****** Intervalos candidatos
Usando el pivote tenemos el siguiente intervalo de confianza:

\[
1 - \alpha = P
\left(
\lambda_1\frac
{\frac{1}{n_1}\sum_{i=1}^{n_1} (X_i-\mu_1)^2}
{\frac{1}{n_2}\sum_{i=1}^{n_2} (Y_i-\mu_2)^2}
\leq
\frac{\sigma^2_1}{\sigma^2_2}
\leq
\lambda_2\frac
{\frac{1}{n_1}\sum_{i=1}^{n_1} (X_i-\mu_1)^2}
{\frac{1}{n_2}\sum_{i=1}^{n_2} (Y_i-\mu_2)^2}
\right)
\]

Donde, si $\Phi$ es la funcin de distribucin de $F(n_1,n_2)$, tenemos que
$1-\alpha = \Phi(\lambda_2)-\Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimizacin
Por el mismo razonamiento con multiplicadores de Lagrange, llegamos
a $\Phi'(\lambda_2) = \Phi'(\lambda_1)$. Ntese que en este caso la distribucin no es
simtrica.

****** Conclusin
Buscamos entonces:

  - el $F_{n_2,n_1;1-\alpha/2}$ que cumple $P(Z > F) = 1-\alpha/2$.
  - el $F_{n_2,n_1;\alpha/2}$ que cumple $P(Z>F) = \alpha/2$.

***** D2. Intervalo para el cociente de varianzas de normales de media desconocida
Sean $X \leadsto {\cal N}(\mu_1,\sigma^2_1)$, $Y \leadsto {\cal N}(\mu_2,\sigma_2^2)$. El intervalo para $\sigma^2_1/\sigma^2_2$ de menor
longitud media uniforme a nivel de confianza $1-\alpha$ es:

\[
\left(
F_{n_2-1,n_1-1; 1-\alpha/2}\frac{S_1^2}{S_2^2}
,
F_{n_2-1,n_1-1; \alpha/2}\frac{S_1^2}{S_2^2}
\right)
\]

donde, $F_{n_2-1,n_1-1; 1-\alpha/2}$ cumple que $P(Z > F_{\alpha/2}) = \alpha/2$ con $Z \leadsto F(n_2-1,n_1-1)$.

****** Pivote
Tomamos como pivote a la funcin:

\[
\frac{S_2^2/\sigma_2^2}{S_1^2/\sigma_1^2}
\leadsto
F(n_2-1,n_1-1)
\]

****** Intervalos candidatos
Usando el pivote llegamos al siguiente intervalo de confianza:

\[
1-\alpha = P
\left(
\frac{\sigma_1^2}{\sigma_2^2}\lambda_1
\leq
\frac{S_2^2}{S_1^2}
\leq
\frac{\sigma_1^2}{\sigma_2^2}\lambda_2
\right)
\]

Donde, si $\Phi$ es la funcin de distribucin de $F(n_2-1,n_1-1)$, tenemos
que $1-\alpha = \Phi(\lambda_2) - \Phi(\lambda_1)$. Buscamos minimizar $\lambda_2-\lambda_1$.

****** Minimizacin
Por el mismo razonamiento con multiplicadores de Lagrange, llegamos
a $\Phi'(\lambda_2) = \Phi'(\lambda_1)$. Ntese que en este caso la distribucin no es
simtrica.

****** Conclusin
Buscamos entonces:

  - el $F_{n_2-1,n_1-1;1-\alpha/2}$ que cumple $P(Z > F) = 1-\alpha/2$.
  - el $F_{n_2-1,n_1-1;\alpha/2}$ que cumple $P(Z>F) = \alpha/2$.

**** TODO Intervalos unilaterales
*** 6. Contraste de hiptesis
**** Planteamiento del problema
***** Problema de contraste de hiptesis
Dada $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto P_\theta$, para
$\theta \in \Theta_0 \cup \Theta_1$, llamamos:

 - *Hiptesis nula*: $H_0 : \theta \in \Theta_0$
 - *Hiptesis alternativa*: $H_1 : \theta \in \Theta_1$

a dos hiptesis posibles.

***** Test de hiptesis
El *test de hiptesis* es un estadstico $\varphi$ tomando valores en $[0,1]$, que 
da la posibilidad de rechazar $H_0$ dada una realizacin muestral. Se 
llama:

  - *Test no aleatorizado*, si toma valores $0,1$.
  - *Test aleatorizado*, si toma valor distinto de $0,1$.

***** Tipos de errores de un test de hiptesis
Hay dos tipos de erorres:

  - *Error de tipo 1*: Rechazar $H_0$ siendo cierta. Falso negativo.
  - *Error de tipo 2*: Aceptar $H_0$ siendo falsa. Falso positivo.

***** Funcin de potencia de un test
Dado un test $\varphi$, su funcin de potencia $\beta_\varphi : \Theta \longrightarrow [0,1]$ se define:

\[\beta_\varphi(\theta) = E_\theta[\varphi(X_1,\dots,X_n)]\]

Que es la probabilidad media de rechazar $H_0$ bajo $P_\theta$.

***** Tamao del test
El tamao del test es $\sup_{\theta \in \Theta_0} \beta_\varphi(\theta)$, la mxima probabilidad media de
cometer un error de tipo 1.

***** Nivel de significacin de un test
Un test $\varphi$ tiene nivel de significacin $\alpha$ si su tamao es menor o igual
que $\alpha$. Es decir,

\[
\forall \theta \in \Theta_0, \quad
\beta_\varphi(\theta) =
E_\theta[\varphi(X_1,\dots,X_n)] \leq
\alpha
\]

***** Test uniformemente ms potente
Un test con nivel de significacin $\alpha$ es uniformemente ms potente a 
dicho nivel si para cualquier otro test $\varphi'$ con nivel de significacin
$\alpha$, se tiene:

\[\beta_{\varphi'}(\theta) \leq \beta_\varphi(\theta)
\quad \forall \theta \in \Theta_1\]

**** Lema de Neyman-Pearson
***** El problema de contraste
Fijado un nivel de significacin, encontrar el test uniformemente ms
potente a dicho nivel.

***** Lema de Neyman-Pearson
Sea $X \longrightarrow \{P_{\theta_0}, P_{\theta_1}\}$ y $(X_1,\dots,X_n)$ una muestra aleatoria simple
con funciones de densidad $f_0,f_1$. Consideramos el problema de contraste 
con $H_0 : \theta = \theta_0$ y $H_1 : \theta = \theta_1$.

  1. Cualquier test de la forma:

     \[
     \varphi(\tilde X) = 
     \threepartdef
     {1}{f_1(\tilde X) > kf_0(\tilde X)}
     {\gamma(\tilde X)}{f_1(\tilde X) = kf_0(\tilde X)}
     {0}{f_1(\tilde X) < kf_0(\tilde X)}
     \]
     
     con $k \in \mathbb{R}^+_0$ y $\gamma(X_1,\dots,X_n) \in [0,1]$, es de mxima potencia entre todos
     los de nivel de significacin $\alpha = E_{\theta_0}[\varphi]$, su tamao.
     
  2. Para todo $\alpha \in (0,1]$ existe un test de la forma anterior con
     $\gamma(X_1,\dots,X_n) = \gamma$ constante y tamao $\alpha$.

  3. Si $\varphi'$ es de mxima potencia al nivel de significacin $\alpha = E_{\theta_0}[\varphi']$, 
     entonces $\varphi'$ es de la forma anterior con probabilidad 1 bajo $P_{\theta_0}$ y $P_{\theta_1}$.

  4. El test de mxima potencia entre todos los de nivel de significacin
     0 es:
     
     \[
     \varphi_0(\tilde X) = \twopartdef
     {1}{f_0(\tilde X) = 0}
     {0}{f_0(\tilde X) > 0}
     \]

****** Demostracin
******* Punto 1
Dado otro test $\varphi'$, como toma valores en $[0,1]$ tenemos que:

\[
(\varphi-\varphi')(f_1-kf_0) \geq 0
\]

Podemos entonces integrar para tener:

\[
\int (\varphi(x)-\varphi'(x))(f_1(x)-kf_0(x)) \;dx \geq 0
\]

Conociendo las funciones de potencia $\int \varphi f_i = \beta_\varphi(\theta_i)$ y $\int \varphi' f_i = \beta_{\varphi'}(\theta_i)$ , 
tenemos:

\[
\beta_{\varphi}(\theta_1) - \beta_{\varphi'}(\theta_1) +
k(\beta_{\varphi'}(\theta_0) - \beta_{\varphi}(\theta_0))
\geq 0\]

Usando ahora que $\beta_{\varphi'}(\theta_0) \leq \beta_\varphi(\theta_0) = \alpha$, tenemos que $\beta_\varphi(\theta_1) \geq \beta_{\varphi'}(\theta_1)$.
As, nuestro test es el ms potente uniformemente.

******* Punto 3
Cuando es de mxima potencia, se da el caso de igualdad en la ltima
ecuacin, que lleva el caso de igualdad a la integral. Como es una
integral de trminos positivos, debe ser distinta de cero slo en
un conjunto de medida nula.

**** TODO Descripcin mediante p-valores
**** Test de la razn de verosimilitudes
***** Test de la razn de verosimilitudes
Sea $(X_1,\dots,X_n) \in \chi^n$ una muestra aleatoria simple de $X \leadsto \{P_\theta \mid \theta \in \Theta_0 \cup \Theta_1\}$.
El test de razn de verosimilitudes para el problema de contraste con
$H_0 : \theta \in \Theta_0$ y $H_1 : \theta \in \Theta_1$; se define como:

\[
\varphi(X_1,\dots,X_n) = \twopartdef
{1}{\lambda(X_1,\dots,X_n) < c}
{0}{\lambda(X_1,\dots,X_n) \geq c}
\]

donde se define:

\[\lambda(x_1,\dots,x_n) = \frac
{\sup_{\theta \in \Theta_0} L_{x_1,\dots,x_n}(\theta)}
{\sup_{\theta \in \Theta} L_{x_1,\dots,x_n}(\theta)}
\]

siendo $L$ la funcin de verosimilitud y $c \in (0,1]$ una constante que se 
determina imponiendo el tamao o nivel de significacin requerido.

**** Dualidad entre tests de hiptesis y regiones de confianza
***** Dualidad
Sea $X \leadsto \{P_\theta \mid \theta \in \Theta\}$. Para cada $\theta_0 \in \Theta$ consideramos un conjunto $A(\theta_0) \subseteq \chi^n$
y para cada relizacin se define:

\[
\varphi_{\theta_0}(x_1,\dots,x_n) =
\left\{\begin{array}{ll} 
1 & \mbox{if } (x_1,\dots,x_n) \notin A(\theta_0) \\
0 & \mbox{if } (x_1,\dots,x_n) \in A(\theta_0) \\
\end{array} 
\right.
\]

Y con esto se define:

\[
S(x_1,\dots,x_n) = \{\theta\in \Theta \mid (x_1,\dots,x_n) \in A(\theta)\}
\]

Cada uno de los tests $\varphi_{\theta_0}$ tiene nivel de significacin $\alpha$ ssi $S$ es una
regin de confianza para $\theta$ a nivel de confianza $1-\alpha$.

**** Ejemplos
***** Contrastes sobre la media de una normal con varianza conocida
****** Hiptesis: valor de la media
Si tomamos $H_0:\mu=\mu_0$ y $H_1:\mu\neq\mu_0$, podemos crear un [[*Test de la razn de verosimilitudes][TRV]] como:

\[
\varphi(X_1,\dots,X_n) =
\left\{\begin{array}{ll} 
1 & \mbox{if } \left| \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \right| > z_{\alpha/2} \\
0 & \mbox{if } \left| \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \right| \leq z_{\alpha/2} \\
\end{array} 
\right.
\]

******* Clculo
Sabiendo que la funcin de verosimilitud es:

\[
L_{x_1,\dots,x_n}(\mu) = 
\frac{1}{(\sigma_0^2)^{n/2}(2\pi)^{n/2}}
e^{-\sum_{i=1}^n (x_i-\mu)^2/2\sigma_0^2}
\]

Calculamos el test:

\[
\lambda = 
\frac{\sup_{\mu = \mu_0} L(\mu)}{\sup_{\mu\in\mathbb{R}} L(\mu)} = 
\frac{L(\mu_0)}{L(\overline{x})} =
\exp\left\{\frac{-n(\overline{x}-\mu_0)^2}{2\sigma^2_0}\right\}
\]

Y podemos tomar races para tener otro test equivalente que, al
seguir una distribucin normal, podemos ajustar para tener el
parmetro $\alpha$ pedido.

****** Hiptesis: media menor que un valor
Si tomamos $H_0 : \mu \leq \mu_0$ y $H_1 : \mu > \mu_0$, podemos crear un TRV como:

\[
\varphi(X_1,\dots,X_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if  } \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} > z_\alpha \\
0 & \mbox{if  } \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} \leq z_\alpha \\
\end{array} 
\right.
\]

******* Clculo
Si en este caso calculamos la $\lambda$ tenemos que:

\[
\lambda(x_1,\dots,x_n) = 
\frac{\sup_{\mu\leq\mu_0} L(\mu)}{L(\overline{x})} =
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \leq 0 \\
\frac{L(\mu_0)}{L(\overline{x})} 
& \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq 0 \\
\end{array} 
\right.
\]

****** Hiptesis: media mayor que un valor
Si tomamos $H_0 : \mu \geq \mu_0$ y $H_1 : \mu < \mu_0$, podemos crear un TRV como:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} < z_{1-\alpha} \\
0 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq z_{1-\alpha}
\end{array} 
\right.
\]

******* Clculo
Si en este caso calculamos la $\lambda$ tenemos que:

\[
\lambda(x_1,\dots,x_n) 
=
\frac{\sup_{\mu\geq\mu_0} L(\mu)}{L(\overline{x})}
=
\left\{\begin{array}{ll} 
1& \mbox{if } \overline{x} \geq \mu_0 \\
\frac{L(\mu_0)}{L(\overline{x})}& \mbox{if } \overline{x} \leq \mu_0
\end{array} 
\right.
\]

Dndonos un test:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \lambda(x_1,\dots,x_n) < c \\
0 & \mbox{if } \lambda(x_1,\dots,x_n) \geq c
\end{array} 
\right.
=
\left\{\begin{array}{ll} 
0 & \mbox{if } \overline{x} \geq \mu_0 \\
1 & \mbox{if } \frac{L(\mu_0)}{L(\overline x)} < c \\
0 & \mbox{if } \frac{L(\mu_0)}{L(\overline x)} \geq c
\end{array} 
\right.
\]

Las dos primeras condiciones colapsan cuando tomamos la raz y
comparamos con ella:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} < c \\
0 & \mbox{if } \frac{\overline{x}-\mu_0}{\sigma_0/\sqrt{n}} \geq \min(0,c)
\end{array} 
\right.
\]

Ahora ajustamos la $c$ para que nos d la significancia $\alpha$:

\[
\alpha = 
\sup_{\mu \geq \mu_0} 
P\left( \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} < c' \right)
=
\sup_{\mu \geq \mu_0}
P\left( \frac{\overline{X}-\mu}{\sigma_0/\sqrt{n}} < \frac{\mu_0-\mu}{\sigma_0/\sqrt{n}} + c' \right)
\]

Tomamos entonces como $c' = z_{1 - \alpha}$. Ntese que es negativo.

***** Contrastes sobre la varianza de una normal con media conocida
****** Hiptesis: valor de la varianza
Si tomamos $H_0 : \sigma^2 = \sigma_0^2$ y $H_1 : \sigma^2 \neq \sigma_0^2$, creamos un TRV como:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1& \mbox{if } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} < \chi^2_{n;1-\alpha/2} 
   \mbox{  } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} > \chi^2_{n;\alpha/2} \\
0& \mbox{if } \chi^2_{n;1-\alpha/2} \leq \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} \leq \chi^2_{n;\alpha/2}
\end{array} 
\right.
\]

******* Clculo
Sabiendo que la funcin de verosimilitud es:

\[
L_{x_1,\dots,x_n}(\sigma) = 
\frac{1}{(\sigma^2)^{n/2}(2\pi)^{n/2}}
e^{-\sum_{i=1}^n (x_i-\mu)^2/2\sigma^2}
\]

Usamos que el estimador mximo verosmil de $\sigma^2$ es:

\[
\widehat\sigma^2 = \frac{\sum_{i=1}^n (x_i-\mu_0)^2}{n}
\]

Calculamos el test:

\[
\lambda = 
\frac{\sup_{\sigma = \sigma_0} L(\sigma)}{\sup_{\sigma\in\mathbb{R}} L(\sigma)} = 
\frac{L(\sigma_0)}{L(\widehat\sigma)} =
\left(\frac{\widehat\sigma^2}{\sigma_0^2}\right)^{n/2}
\exp\left\{
\frac{-n\widehat\sigma_0^2}{2\sigma_0^2}+\frac{n}{2}
\right\}
\]

La funcin $xe^{-x}$ tiene un mximo antes de ir hacia $-\infty$ por ambos
lados. As, podemos escribir:

\[
\varphi(x_1,\dots,x_n) = 
\left\{\begin{array}{ll} 
1& \mbox{if } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} < c_1 
   \mbox{  } \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} > c_2 \\
0& \mbox{if } c_1 \leq \frac{\sum^n_{i=1} (x_i-\mu_0)^2}{\sigma_0^2} \leq c_2
\end{array} 
\right.
\]

Ntese que sigue una distribucin $\chi^2(n)$ como suma de $n$ normales.

***** Contrastes sobre la varianza de una normal con media desconocida
Se tendr como estimador mximo verosmil a:

\[
\widehat\sigma^2 = \frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}
\]

*** 7. Teora general de modelos lineales
**** Modelo lineal general y modelo de Gauss Markov
***** Modelo lineal general
El modelo general lineal queda descrito por:

\[\mathbf{Y = X\beta + \varepsilon}\]

****** Vector observable
$Y = (Y_1,\dots,Y_n)$ es un vector aleatorio observable.

****** Matriz de diseo
Una matriz conocida $X$ de dimensin $n \times k$, cuyo rango determina el 
rango del modelo.

****** Vector de efectos
Un vector desconocido $\beta = (\beta_1,\dots,\beta_k)$.

****** Vector de errores
Un vector aleatorio no observable $\varepsilon = (\varepsilon_1,\dots,\varepsilon_n)$ representando el 
error entre $Y$ y $X\beta$.

***** Modelo de Gauss-Markov
Modelo lineal donde las componentes del vector de errores son variables
aleatorias de segundo orden, centradas, homocedsticas (igual varianza)
e incorreladas:

  - $E[\varepsilon_i] = 0$
  - $E[\varepsilon_i^2] = \sigma^2$
  - $E[\varepsilon_i\varepsilon_j] = 0$

****** Enunciado vectorial
Las condiciones sobre el vector de errores equivalen a exigir:

  - $E[\varepsilon] = 0$
  - $E[\varepsilon\varepsilon^T] = \sigma^2 I_{n \times n}$

****** Objetivo del modelo
Inferir $\beta$ y $\sigma^2$ a partir de observaciones del vector $Y$.

**** Estimacin de mnimos cuadrados del vector de efectos
***** Modelo
En el modelo de Gauss-Markov queremos minimizar la suma de
cuadrados de los errores:

\[S^2(\beta) = 
\sum^n_{i=1} \varepsilon^2_i =
\|Y - X\beta\|^2\]

****** Minimizacin
Para minimizarlo, calculamos la derivada:

\[\frac{\partial}{\partial \beta_h} S^2(\beta) = 
-2 x_{ih} \sum^n_{i=1} \left(
Y_i - \sum^k_{j=1} x_{ij}\beta_j
\right) = 0
\]

Y obtenemos las ecuaciones normales siguientes:

\[
\sum^n_{i=1} Y_i x_{ih} = \sum^n_{i=1}\sum^k_{j=1} x_{ij}x_{ih}\beta_j
\]

Que pueden expresarse matricialmente como:

\[X^TY = (X^TX)\beta\]

***** Estimador de mnimos cuadrados de beta
Llamamos $\widehat\beta$ al estimador de mnimos cuadrados de $\beta$.

  - Existencia: existe al menos un estimador de mnimos cuadrados de $\beta$.
  - Unicidad: garantizada cuando el modelo es de rango mximo por tenerse
    la solucin \[\widehat\beta(Y) = (X^TX)^{-1}X^TY\].

**** Funciones estimables
***** Funcin lineal estimable
Una $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable si admite un estimador insesgado,
lineal en las componentes de $Y$. Es decir:

\[\exists \widehat\psi(Y) = c_1Y_1 + \dots + c_nY_n\]

tal que $E[\widehat\psi(Y)] = \psi(\beta)$.

***** Teorema de Gauss-Markov
Si $\psi(\beta) = a_1\beta_1 + \dots + a_k\beta_k$ es estimable, admite un nico UMVUE. 
Dicho estimador es:

\[\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y) \]

Donde $\widehat{\beta}(Y)$ es un estimador de mnimos cuadrados de $\beta$.

****** TODO Demostracin

***** Propiedades del estimador de mnimos cuadrados en modelos de rango mximo
Sea $\widehat\beta(Y) = (X^TX)^{-1}X^TY$ el estimador de mnimos cuadrados en un modelo 
de rango mximo.

  1. $\widehat\beta_j(Y)$ es el estimador lineal insesgado de mnima varianza de $\beta_j$.
  2. Las varianzas y covarianzas vienen dadas: $Cov(\widehat\beta(Y)) = \sigma^2(X^TX)^{-1}$.
  3. Toda funcin lineal de las componentes de $\beta$ es estimable con 
     estimador lineal insesgado de mnima varianza
     $\widehat\psi(Y) = a_1\widehat\beta_1(Y) + \dots + a_k\widehat\beta_k(Y)$.

****** TODO Demostracin

**** Modelo estimado
***** Modelo estimado
Siendo $\widehat\beta$ el estimador de mnimos cuadrados, llamamos:

  - Modelo estimado: $\widehat Y = X\widehat\beta$
  - Residuos mnimo-cuadrticos: $R = Y - X\widehat\beta$

***** Propiedades del modelo estimado
El modelo estimado cumple:

  1. $\widehat Y_i$ es el estimador lineal insesgado de mnima varianza de $E[Y_i]$.
  2. Los residuos son centrados $E[R_i] = 0$.
  3. El vector de residuos es ortogonal al vector estimado:

     \[X^TR = 0,\quad \widehat{Y}^TR = 0\]

***** Varianza residual
Siendo $r$ el rango de $X$, la *varianza residual* es un estimador
insesgado de $\sigma^2$:

\[
S^2_R = \frac{1}{n-r}\sum_{i=1}^n R_i^2 = \frac{1}{n-r}\|Y-X\widehat\beta\|^2
\]

**** Inferencia bajo hiptesis de normalidad
***** Hiptesis de normalidad
La hiptesis de normalidad asume que los errores se distribuyen
bajo una distribucin normal:

\[
Y_i = \sum_{j=1}^k x_{ij}\beta_j + \varepsilon_i 
\leadsto 
{\cal N}\left(\sum_{j=1}^k x_{ij}\beta_j, \sigma^2 \right)
\]

Para $Y_1,\dots,Y_n$ independientes.

****** Equivalentemente
Podemos expresar los errores como:

\[\varepsilon \leadsto {\cal N}(0,\sigma^2)\]

***** Funcin de mxima verosimilitud
La funcin de mxima verosimilitud bajo la hiptesis de normalidad queda
como:

\[
L_y(\beta,\sigma^2) = 
\frac{1}{(2\pi)^{n/2}\sigma^n}
\exp\left\{
-\frac{\sum_{i=1}^n(y_i - \sum_{j=1}^k x_{ij}\beta_j)^2}{2\sigma^2}
\right\}
\]

***** Estimadores mximo verosmiles de efectos
Los estimadores mximo verosmiles de $\beta$ son $\widehat\beta$, estimadores de mnimos
cuadrados.

****** TODO Demostracin

***** Estimador mximo verosmil de la varianza
El estimador mximo verosmil de la varianza es:

\[
\widehat\sigma^2 = \frac{1}{n}\sum_{i=1}^n R_i^2 = \frac{n-r}{n}S^2_R
\]

*** 8. Inferencia Bayesiana
# ##
# Este captulo se ha escrito siguiendo los apuntes de estadstica
# de Andrs Herrera, Nuria Rodrguez, Javier Poyatos, Mara del Mar Ruiz y 
# Juan Luis Surez.
#
# Pueden consultarse los apuntes originales en:
#   https://github.com/andreshp/math-notes/tree/master/StatisticalInference
# ##

**** 8.1. Introduccin
***** Ley de la probabilidad total
La ley de la probabilidad total establece, para $A_i$ una particin del
espacio de sucesos:

\[
P(B) = \sum_{i=1}^n P(B|A_i)P(A_i)
\]

***** Teorema de Bayes
Para un espacio de probabilidad $(\Omega,{\cal A},P)$, si tenemos una particin dada
por $A_1,\dots,A_n$ con probabilidad no nula:

\[P(A_i|B) 
=
\frac{P(A_i \cap B)}{P(B)} 
= 
\frac{P(B|A_i)P(A_i)}{P(B)}
\]

***** Distribucin a priori
Sea $X$ variable aleatoria con distribucin $f(x|\theta)$, con $\theta \in \Theta$. A una 
distribucin $\pi(\theta)$ establecida con informacin previa sobre $\theta$ se le
llama *distribucin a priori*.

***** Distribucin condicionada
Dada una muestra $\tilde{X} = (X_1,\dots,X_n)$ y una distribucin a priori $\pi(\theta)$,
tenemos una distribucin conjunta con funcin de densidad:

\[
f(\tilde x,\theta) = f(\tilde x|\theta)\pi(\theta)
\]

***** Distribucin marginal
La distribucin marginal de $\tilde X$ la definimos como:

\[
m(\tilde x) 
= 
\int_{\Omega} f(\tilde x,\theta) d\theta
=
\int_{\Omega} f(\tilde x|\theta) \pi(\theta) d\theta
\]

***** Distribucin a posteriori
Dada una realizacin de la muestra y una distribucin a priori, definimos
una distribucin a posteriori como:

\[
\pi(\theta|\tilde x) = 
\frac{f(\tilde x|\theta)\pi(\theta)}{m(\tilde x)} =
\frac{f(\tilde x|\theta)\pi(\theta)}{\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta}
\]

**** 8.2. Estadstica clsica
Se destacan las siguientes diferencias con la estadstica clsica.
En la estadstica clsica:

  1. La probabilidad se limita a sucesos con frecuencias relativas.
  2. El parmetro $\theta$ es fijo, completamente desconocido.
  3. Se usan estimadores de mxima verosimilitud o insesgados.
  4. Los tests de hiptesis se construyen fijando un tamao $\alpha$.

Mientras que en la estadstica bayesiana:
  
  1. La probabilidad se puede establecer previa a cualquier suceso.
  2. El parmetro $\theta$ es una variable aleatoria.
  3. El mtodo de muestreo es irrelevante.
  4. Podemos calcular la probabilidad de que una hiptesis sea cierta.

**** 8.3. Familias conjugadas
***** Familia conjugada
Sea ${\cal F} = \{\pi_i(\theta) \mid i \in I\}$ una familia de distribuciones a priori. Se llama
*conjugada* respecto a una familia de densidades $P = \{f(x|\theta) \mid \theta \in \Theta\}$ si
para cada $\pi(\theta) \in {\cal F}$ y $f(x\mid \theta) \in P$, se tiene que $\pi(\theta\mid \tilde x) \in {\cal F}$.

***** Lema de caracterizacin de familias conjugadas
Para $\pi(\theta),\Pi(\theta) \in {\cal F}$, equivalen:

  1. $f(\tilde x|\theta)\pi(\theta) \propto \Pi(\theta)$
  2. $\pi(\theta|\tilde x) = \Pi(\theta)$

****** Demostracin
******* Primera implicacin
Por definicin:

\[
\pi(\theta|\tilde x) 
=
\frac{f(\tilde x|\theta)\pi(\theta)}{\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta}
=
\frac{M\Pi(\theta)}{M \int_\Omega \Pi(\theta) d\theta}
=
\Pi(\theta)
\]

Usando que $\int_\Omega \Pi = 1$ por ser distribucin.

******* Segunda implicacin
Por definicin:

\[
f(\tilde x|\theta)\pi(\theta) = \Pi(\theta)\int_\Omega f(\tilde x|\theta)\pi(\theta) d\theta
\]

***** Caracterizacin de familias conjugadas
Una familia de distribuciones a priori ${\cal F}$ es conjugada respecto a ${\cal P}$ ssi
el producto de cualesquiera dos distribuciones de ambas familias vuelve
a ser una distribucin de la familia de distribuciones a priori, salvo
alguna constante.

\[\forall f \in {\cal P}, \pi \in{\cal F}: \exists k:\quad 
kf(x|\theta)\pi(\theta) \in {\cal F}\]

***** Ejemplos de familias conjugadas
****** Beta para Bernoulli
La familia de distribuciones Beta es una familia conjugada para:

  - distribuciones de Bernoulli.
  - distribuciones binomiales.
  - distribuciones binomiales negativas.

Se tiene:

  - $X \leadsto B(n,\theta)$
  - $\theta \leadsto \beta(p,q)$
  - $\theta|x \leadsto \beta(x+p,n-x+q)$

****** Gamma para Poisson
La familia de distribuciones Gamma es una familia conjugada para
distribuciones de Poisson.

Se tiene:

  - $X\leadsto Poi(\theta)$
  - $\theta \leadsto \Gamma(\alpha,\beta)$
  - $\theta|\tilde x \leadsto \Gamma(\sum x_i + \alpha, n + \beta)$

****** Normales para normales con varianza conocida
La familia de distribuciones normales es conjugada para las 
distribuciones normales de varianza conocida.

Se tiene:

  - $X \leadsto {\cal N}(\mu,\sigma^2)$
  - $\mu \leadsto {\cal N}(\eta,\tau)$
  - $\mu|\tilde x \leadsto {\cal N}\left(\frac{n\overline{x}\tau^2+\sigma^2\eta}{n\tau^2+\sigma^2}, \frac{\sigma^2\tau^2}{n\tau^2+\sigma^2}\right)$

****** Dirichlet para multinomiales
La familia de distribuciones de Dirichlet es conjugada para la
familia de distribuciones multinomiales.

Se tiene:

  - $X_1,\dots,X_n \leadsto Multi(\theta_1,\dots,\theta_k)$
  - $\theta_1,\dots,\theta_k \leadsto Dir(\alpha_1,\dots,\alpha_k)$
  - $\theta_1,\dots,\theta_n|x_1,\dots,x_n \leadsto Dir(x_1+\alpha_1,\dots,x_k+\alpha_k)$

**** 8.4. Distribuciones objetivas
***** Distribucin de Jeffreys
Para una familia $\{f(x|\theta) \mid \theta\in\Theta\}$, la distribucin de Jeffreys se define 
como:

\[\pi^J(\theta) \propto \sqrt{{\cal I}_X(\theta)}\]

para la informacin de Fisher.

**** 8.5. Convergencia de distribuciones a posteriori
***** Convergencia en un espacio paramtrico discreto
Sea $\Theta = \{\theta_1,\dots,\theta_k\}$, cuando el tamao de la muestra diverge, la distribucin
a posteriori degenera en $\theta_0$, el valor verdadero del parmetro.

\[
\pi(\theta\mid X_1,\dots,X_n) 
\overset{P_{\theta_0}}{\underset{n \to \infty}\longrightarrow} \theta_0
\]

Ntese que los $\theta_i$ deben generar distribuciones distintas para aplicar
este resultado.

****** Demostracin
Dada una distribucin a priori $\pi$, llamamos $\pi(\theta_j) = p_j \in [0,1]$. Llamamos
$\theta_t$ al verdadero parmetro, y tomamos $X_1,\dots,X_n$ con la distribucin
dada por $f(x|\theta_t)$.

\[
\pi(\theta_i|X_1,\dots,X_n)
=
\frac
{\displaystyle p_i\prod_{j=1}^n f(X_j|\theta_i)}
{\displaystyle \sum_{r=1}^k\left(\prod_{j=1}^n f(X_j|\theta_r) \right) p_r}
\]

Si multiplicamos por $\prod_{j=1}^n f(X_j|\theta_t)$ tenemos:

\[
\pi(\theta_i|X_1,\dots,X_n)
=
\frac
{\displaystyle p_i\prod_{j=1}^n \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}}
{\displaystyle \sum_{r=1}^k\left(
\prod_{j=1}^n \frac{f(X_j|\theta_r)}{f(X_j|\theta_t)}
\right) p_r}
\]

Tomando logaritmos estudiamos las variables aleatorias $Z_j = \log\frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}$,
que son i.i.d. y por la Ley fuerte de los grandes nmeros, tenemos que
converge casi seguramente respecto a la probabilidad que define $\theta_t$:

\[
\frac{1}{n}\sum_{j=1}^n \log\frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}
\longrightarrow
\mathbb{E}\left[\log \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)} \right]
\]

Que adems sabemos (no trivialmente) que es negativo. Tenemos entonces
por continuidad del logaritmo que:

\[
\prod_{j=1}^n \frac{f(X_j|\theta_i)}{f(X_j|\theta_t)}
\longrightarrow
0
\]

Aplicando esto a la probabilidad a posteriori tenemos que slo converge
a uno en el valor $\theta_t$ y converge a cero en todos los dems.

***** Nota: Influencia de la distribucin a priori
Ntese que la distribucin a priori ha sido independiente de la 
convergencia a la distribucin a posteriori degenerada.

***** Nota: Estimadores bayesianos
Los modelos bayesianos asignan probabilidad 1 a la hiptesis correcta
cuando el tamao de la muestra diverge.

**** 8.6. Test de hipesis bayesianos
***** Probabilidad a posteriori de un modelo
Dados dos modelos $M_1 : \{f_{\theta_1}(x), \pi(\theta_1|M_1), \pi(M_1)\}$ y $M_2 : \{f_{\theta_2}(x), \pi(\theta_2|M_2), \pi(M_2)\}$,
la probabilidad de que se cumpla el primero condicionada a una muestra es:

\[
\pi(M_1|x) = \frac{\pi(M_1)m(x|M_1)}{\pi(M_1)m(x|M_1) + \pi(M_2)m(x|M_2)}
\]

****** Modelos
Cada modelo $M : \{f(x|\theta,M), \pi(\theta|M), \pi(M)\}$ viene dado por:

  1. Una funcin de distribucin condicionada a cada parmetro $\theta$.
  2. Una probabilidad para cada parmetro, condicionada al modelo.
  3. Probabilidad de que se cumpla el modelo.

Necesitamos $\pi(M_1)+\pi(M_2) = 1$ en el caso de comparar esos dos modelos.

***** Factor de Bayes
Dados dos modelos $M_1 : \{f_{\theta_1}(x), \pi(\theta_1|M_1), \pi(M_1)\}$ y $M_2 : \{f_{\theta_2}(x), \pi(\theta_2|M_2), \pi(M_2)\}$,
Definimos el factor de Bayes como:

\[
B_{21}(x) = \frac{m(x|M_2)}{m(x|M_1)}
\]

cociente entre distribuciones marginales.

Cuanto ms alto es, ms baja es la probabilidad a posteriori del modelo $M_1$.

***** Mtodo de Leamer: motivacin
Si usamos distribuciones impropias para realizar tests de hiptesis y
las multiplicamos por coeficientes para que sean integrables, el factor
de Bayes se vera afectado arbitrariamente por estos coeficientes.

***** Mtodo de Leamer: muestras de entrenamiento
Una *muestra de entrenamiento* $\tilde x_1 \subset \tilde x$ es una sublista de la muestra original.
Se llama *propia* si $0 < m(\tilde x_1 | M) < \infty$. Se llama *minimal* si es propia y
ninguna sublista suya lo es.

***** Mtodo de Leamer
Dada una muestra de entrenamiento, sabemos que $\pi(\theta|M)f(\tilde x_1|\theta,M)$
integrar y podremos usarlo como distribucin a priori.

Interesa utilizar una muestra minimal para que se pierdan el menor
nmero de elementos en la muestra para el test de hiptesis.

**** TODO 8.7. Probabilidades subjetivas
*** Ejercicios
**** Tema 1. Introduccin a la inferencia estadstica
***** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. 
Dar el espacio muestral y calcular la funcin masa de probabilidad 
de $(X_1,\dots,X_n)$ en cada uno de los siguientes casos:

  1. $X \longrightarrow \{{\cal B}(k_0,p); p \in (0,1)\}$ binomial
  2. $X \longrightarrow \{{\cal P}(\lambda); \lambda\in\mathbb{R}^+\}$ Poisson
#+end_statement

****** Punto 1
El espacio muestral es $\{0,1,\dots,k_0\}^n$, una palabra $k_0\text{-aria}$ de $n$ letras. 
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) 
= \prod_{i=1}^n \left({k_0 \choose x_i} p^{x_i}(1-p)^{k_0-x_i} \right)\]
****** Punto 2
El espacio muestral es $\mathbb{N}^n$, palabras en los naturales.
Usando independencia:

\[P(x_1,\dots,x_n) = \prod P(x_i) = \prod_{i=0}^n e^{-\lambda}\frac{\lambda^{x_i}}{x_i!}\]

***** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X$. Dar el espacio
muestral y calcular la funcin masa de probabilidad de $(X_1,\dots,X_n)$ en cada uno de
los siguientes casos:

  1. $X \longrightarrow \{U(a,b); a,b\in\mathbb{R}; a < b\}$ uniforme
  2. $X\longrightarrow \{{\cal N}(\mu,\sigma^2)\}$ normal
#+end_statement
****** Punto 1
El espacio muestral aqu es $[a,b]^n$, donde por independencia tengo como funcin
de densidad:

\[f(x_1,\dots,x_n) = \prod f(x_i) = \left(\frac{1}{b-a}\right)^n\]

****** Punto 2
El espacio muestral es $\mathbb{R}^n$, siendo la funcin de densidad:

\[f(x_1,\dots,x_n) = 
\prod_{i=0}^n \frac{1}{\sigma\sqrt{2\pi}} 
e^{-\frac{1}{2}\left(\frac{x_i-\mu}{\sigma}\right)^2}\]

***** Ejercicio 4
#+begin_statement
Se dispone de una muestra aleatoria simple de tamao 40 de una
distribucin exponencial de media 3, cul es la probabilidad de que
los valores de la funcin de distribucin muestral y la terica, en
$x=1$, difieran menos de 0.01?  Aproximadamente, cul debe ser el
tamao muestral para que dicha probabilidad sea como mnimo 0.98?
#+end_statement

****** Probabilidad de que difieran
Tenemos que $nF^\ast_X(1) \leadsto {\cal B}(n,F(1))$, luego podemos calcular la probabilidad
como:

\[\begin{aligned}
P\Big( F(1) - 0.01 < F^\ast(1) < F(1) + 0.01 \Big) = \\
P\Big( 10.93 < 40F^\ast(1) < 11.73 \Big) = \\
P\Big(10 < 40F^\ast(1) < 12) =\\
P\Big(11 = 40F^\ast(1)) =\\
{40 \choose 11} F(1)^{11}(1-F(1))^{40-11} \approx\\
0.1318
\end{aligned}\]

Sabiendo que $F(1) = 1 - e^{-1/3} \approx 0.283$ y que $F^\ast$ es variable discreta.

******* Clculos
#+BEGIN_SRC R :results output
f1 = 1-exp(-1/3)
f1
n = 40
n*(f1 + 0.01)
n*(f1 - 0.01)
dbinom(11,n,0.3)
#+END_SRC

#+RESULTS:
: [1] 0.2834687
: [1] 11.73875
: [1] 10.93875
: [1] 0.1318644

****** TODO Tamao muestral
Llamamos $\sqrt{\frac{1}{n}F(1)(1-F(1))} = \sigma_n$, y esta vez aplicamos el Teorema 
Central del Lmite para tener que:

\[\frac{F^\ast(1) - F(1)}{\sigma_n} \leadsto {\cal N}(0,1)\]

Lo que buscamos es que:

\[\begin{aligned}
P\Big( -0.01 < F^\ast(1)-F(1) < 0.01 \Big) > 0.98 \\
P\Big( \frac{-0.01}{\sigma_n} < \frac{F^\ast(1)-F(1)}{\sigma_n} < \frac{0.01}{\sigma_n} \Big) > 0.98 \\
\end{aligned}\]

Dada $\Phi$ funcin de distribucin de la normal tipificada, 
tenemos que:

\[\begin{aligned}
\Phi\left(\frac{0.01}{\sigma_n}\right) -
\Phi\left(\frac{-0.01}{\sigma_n}\right) > 0.98 \\
2\Phi\left(\frac{0.01}{\sigma_n}\right) > 0.98 +1 \\
1 -\Phi\left(\frac{0.01}{\sigma_n}\right) < 0.01
\end{aligned}\]

Usando la tabla de la normal, tenemos:

\[\frac{0.01}{\sigma_n} \geq 2.33\]

Desde donde calculamos:

\[n = 10978\]

# Esto debe estar mal

******* Clculos
#+BEGIN_SRC R :results output
# Lookup on the normal distribution table
qnorm(1-0.01)
#+END_SRC

#+RESULTS:
: [1] 2.326348

***** Ejercicio 7
#+begin_statement
Dada una muestra aleatoria simple $(X_1,\dots,X_n)$ de una variable $X$, obtener
la distribucin en el muestreo de $\overline{X}$ en los casos:

  1. $X \leadsto B(1,p)$
  2. $X\leadsto P(\lambda)$
  3. $X \leadsto exp(\lambda)$
#+end_statement

****** Punto 1
Por independencia y suma de binomiales:

\[
\overline{X} \leadsto \frac{1}{n}B(n,p)
\]

Ntese que deja de ser una binomial.

****** Punto 2
Por independencia y suma de Poisson:

\[
\overline{X} \leadsto \frac{1}{n}Poi(n\lambda)
\]

****** Punto 3
Por independencia y suma de Gammas:

\[
\overline{X} = \frac{1}{n}\Gamma(n,\lambda)
\]

***** Ejercicio 10
Desde la distribucin de la estimacin de la normal.

**** Tema 2. Distribuciones en el muestreo de poblaciones normales
***** Ejercicio 1
#+begin_statement
Se toma una muestra aleatoria simple de tamao $5$ de una variable aleatoria
con distribucin ${\cal N}(2.5, 36)$. Calcular:

  1. Probabilidad de que la cuasivarianza muestral est comprendida entre
     $1.863$ y $2.674$.
  2. Probabilidad de que la media muestral est comprendida entre $1.3$ y $3.5$,
     supuesto que la cuasivarianza muestral est entre $30$ y $40$.
#+end_statement

****** Probabilidad de la Cuasivarianza
Buscamos:

\[\begin{aligned}
P\Big(1.863 \leq S^2 \leq 2.674 \Big) &\leq 
P\Big(\frac{n-1}{\sigma^2}1.863 \leq \frac{n-1}{\sigma^2}S^2 \leq \frac{n-1}{\sigma^2}2.674 \Big)
\end{aligned}\]

Y sabiendo que $\frac{n-1}{\sigma^2}S^2 \leadsto \chi^2(n-1)$, sea $\phi$ la funcin de distribucin para
tener que la probabilidad ser:

\[\phi\left(\frac{n-1}{\sigma^2}2.674\right) - 
\phi\left(\frac{n-1}{\sigma^2}1.863\right) =
0.010 - 0.005 = 0.005
\]

Consultando la tabla de Poisson.

******* Clculos
#+BEGIN_SRC R
n = 5
s2 = 36
pchisq((n-1)/s2 * 2.674, df=n-1) - pchisq((n-1)/s2 * 1.863, df=n-1)
#+END_SRC

#+RESULTS:
: 0.00499959549303851

****** Probabilidad de la Media Muestral
La suposicin de que la cuasivarianza muestral est entre 30 y 40 no
aporta nada porque la media y ella son estadsticos independientes por
el Lema de Fisher.

Buscamos:

\[P\Big(  
1.3 \leq \overline{X} \leq 1.5
\Big) = 
P\Big(  
\frac{1.3 - \mu}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq 
\frac{1.5 - \mu}{\sigma/\sqrt{n}}
\Big)
\]

Y como $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, siendo $\phi$ la distribucin de la normal, calculamos
la probabilidad usando las tablas de la normal.

\[
\phi(-0.3726) - \phi(-0.4472) = 0.3557 - 0.3300 = 0.0257
\]

******* Clculos
#+BEGIN_SRC R
n = 5
m = 2.5
s2 = 36
s = sqrt(36)
pnorm((1.5-m)/(s/sqrt(n))) - pnorm((1.3-m)/(s/sqrt(n)))
#+END_SRC

#+RESULTS:
: 0.0273336344978247

***** Ejercicio 3
#+begin_statement 
De qu tamao mnimo habra que seleccionar una muestra de una variable
con distribucin normal ${\cal N}(\mu,4)$ para poder afirmar, con probabilidad mayor
que $0.9$, que la media muestral diferir de la poblacional menos de $0.1$?
#+end_statement

Buscamos:

\[P\Big(
\frac{-0.1}{\sigma/\sqrt{n}} \leq 
\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leq
\frac{0.1}{\sigma/\sqrt{n}}
\Big)\]

Sabiendo que $\frac{\overline{X} - \mu}{\sigma/\sqrt{n}} \leadsto {\cal N}(0,1)$, calculamos:

\[\begin{aligned}
1 - 2\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\geq 0.9 \\
\phi\left(\frac{-0.1}{\sigma/\sqrt{n}}\right) &\leq 0.05 \\
\end{aligned}\]

Usando la tabla de la distribucin, tenemos que:

\[\frac{0.1}{2/\sqrt{n}} = 1.65\]

Desde donde: $n = 1089$.

****** Clculos
#+BEGIN_SRC R
s2 = 4
s = sqrt(s2)
q = qnorm(1-0.05)
((s*q)/0.1)^2
#+END_SRC

#+RESULTS:
: 1082.21738163816

***** Ejercicio 7
Comprobando sumas se llega a que siguen una Poisson.

**** Tema 3. Suficiencia y complitud
***** Ejercicio 1
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable $X \leadsto B(k,p)$
y sea $T(X_1,\dots,X_n) = \sum^n_{i=1} X_i$. Probar, usando la definicin y aplicando el
teorema de factorizacin, que $T$ es suficiente para $p$.
#+end_statement

****** Usando la definicin
Llamamos $S = \sum^n_{i=1} X_i$. Veremos que $P(x_1,\dots,x_n\mid S)$ no depende de $p$.
En el caso $x_1+\dots+x_n \neq S$, la probabilidad es $0$ y claramente 
independiente de $p$. En el otro caso, tenemos:

\[\begin{aligned}
P(x_1,\dots,x_n\mid S) = 
\frac{P(x_1,\dots,x_n)}{P(S)} =
\frac
{\prod {k \choose x_i} p^{x_i}(1-p)^{k-x_i}}
{{nk \choose S} p^{S}(1-p)^{nk-S}} =
\frac
{\prod {k \choose x_i}}
{{nk \choose S}}
\end{aligned}\]

Que no depende de $p$. Hemos usado que $S = \sum_{i=1}^n X_i \leadsto {\cal B}(nk,p)$ para 
calcular la probabilidad de que valga un valor concreto.

****** Usando el teorema de factorizacin
Factorizamos la funcin de densidad como:

\[
f(x_1,\dots,x_n) =
\prod_{i=1}^n {k \choose x_i} p^{x_i}(1-p)^{k-x_i} =
\left(p^{\sum x_i}(1-p)^{nk - \sum x_i}\right)
\left(\prod^{k}_{i=1} {k\choose x_i}\right)
\]

El primer factor slo depende de los datos a travs de la suma y el
segundo factor no depende de la probabilidad.

***** Ejercicio 3
#+begin_statement
Sea $(X_1,X_2,X_3)$ una muestra aleatoria simple de una variable $X \leadsto B(1,p)$.
Probar que el estadstico $X_1+2X_2+3X_3$ no es suficiente.
#+end_statement

Llamamos $S=X_1+2X_2+3X_3$. Vamos a calcular $P(1,1,0\mid S=3)$ y 
comprobaremos que depende de $p$. Ntese que puede llegarse a $S=3$ de dos
formas, como $1+2+0$ y como $0+0+3$.

\[
P(1,1,0\mid S=3) =
\frac{P(1,1,0)}{P(S=3)} =
\frac{p^2(1-p)}{p^2(1-p)+p(1-p)^2}=
p
\]

**** Tema 4. Estimacin puntual. Mtodos de estimacin
***** Ejercicio 2
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de $X \leadsto B(1,p)$ y sea 
$T = \sum_{i=1}^n X_i$.

  1. Probar que si $k \in \mathbb{N}$ y $k\leq n$ el estadstico

     \[\frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

     es un estimador insesgado de $p^k$. Es este estimador el UMVUE?
  2. Probar que si $k>n$, no existe ningn estimador insesgado para $p^k$.
  3. Puede afirmarse que $\frac{T}{n}\left(1-\frac{T}{n}\right)^2$ es insesgado para $p(1-p)^2$?
#+end_statement

****** Punto 1. Es insesgado.
Llamamos $M = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}$. Comprobamos que es insesgado calculando 
la esperanza. Dividimos entre los casos $i\leq k$ que son nulos y los dems.
Usamos $P(T = i) = {n \choose i}p^i(1-p)^{n-i}$.

\[\begin{aligned}
\mathbb{E}[M] &=
\sum_{i=1}^n {n \choose i} p^i (1-p)^{n-i}
\frac{i(i-1)\dots(i-k+1)}{n(n-1)\dots(n-k+1)} \\&=
\sum_{i=1}^n p^i (1-p)^{n-i}
\frac{(n-k)!}{(i-k)!((n-k)-(i-k))!} \\&=
p^k \sum_{i=1}^n p^{i-k} (1-p)^{(n-k)-(i-k)}
{n-k \choose i-k} \\&= p^k
\end{aligned}\]

Usando binomio de Newton en el ltimo paso.

****** Punto 1. Es el UMVUE.
Usaremos el teorema de Lehmann-Scheff, sabiendo que $M$ es un estimador
insesgado de $p^k$; y que $T$ es suficiente y completo para $p$.

Para ver que $T$ es completo, calculamos:

\[\begin{aligned}
\mathbb{E}[g(T)] 
&= \sum_{t=0}^n g(t) {n \choose t} p^t(1-p)^{n-t} \\
&= (1-p)^n \sum_{t=0}^n g(t) {n \choose t} \left(\frac{p}{1-p}\right)^t \\
\end{aligned}\]

Para que se anule siempre, debe anularse el polinomio
$\sum g(t) {n \choose t}r^t$ para $r \in \mathbb{R}^+$, lo que implica $g(t) = 0$.

Pero ahora, por Lehmann-Scheff, tenemos que el UMVUE ser:

\[\mathbb{E}[M\mid T] = \frac{T(T-1)\dots(T-k+1)}{n(n-1)\dots(n-k+1)}\]

Que es un UMVUE.

****** Punto 2.
Supongamos un estimador $Q$ que fuera insesgado para $p^q$. Tendramos:

\[\mathbb{E}[Q(X)] = p^q\]

Es decir, llamando $R(T) = \sum_{\sum x_i = T} Q(X)$,

\[
\sum^n {n \choose k} R(t) p^t(1-p)^{n-t} = p^q
\]

Pero esto nos dara un polinomio de grado $q$ sobre $p$, que no puede ser 
nulo.

****** TODO Punto 3.
No. Si calculamos la esperanza usando linealidad obtenemos algo distinto.

#+BEGIN_SRC sage
n,p = var('n p')
m1 = n*p
m2 = m1*(1-p+m1)
m3 = m1*(1-3*p+3*m1+2*p^2 - 3*n*p^2 + n^2*p^2)
(p - 2*m2/n^2 + m3/n^3).normalize()
#+END_SRC

#+RESULTS:
: (n^2*p^3 - 2*n^2*p^2 - 3*n*p^3 + n^2*p + 5*n*p^2 + 2*p^3 - 2*n*p - 3*p^2 + p)/n^2

***** Ejercicio 3
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable
$X \leadsto \{{\cal P}(\lambda)\mid \lambda > 0\}$. Encontrar, si existe, el UMVUE para $\lambda^s$, siendo
$s \in \mathbb{N}$ arbitrario.
#+end_statement

Por familia uniparamtrica demostramos $T = \sum X_i$ suficiente y completo.
Probando llegamos a que $\frac{1}{n^s}T(T-1)\dots(T-s)$ es insesgado.

***** Ejercicio 7
****** Punto 1
Se comprueba que es familia exponencial uniparamtrica. Con
$T(X) = X$ y por tanto con $\sum_i T(X_i)$ como estadstico suficiente.
Adems, es completo porque $Q(\Theta)$ tiene un abierto en su imagen.

****** DONE Punto 2

***** Ejercicio 8
****** DONE Punto 1

**** Tema 5. Intervalos de confianza
***** Ejercicio 1
El mnimo es $n=44$.
***** Ejercicio 2
****** Primer punto
Intervalo de $(170.75, 179.75)$.

****** Segundo punto
Da un $n \geq 865$.
***** Ejercicio 5
Se llega a $t = 2.1788$.

***** Ejercicio 7
****** Primer punto
Calculamos:

  - $\overline{X} = 37.2$
  - $\overline{Y} = 16.88$
  - $S_X^2 = 482.137$
  - $S_Y^2 = 208.517$
  - $n_1 = 6$
  - $n_2 = 5$

Y tenemos un intervalo de confianza para el cociente de varianzas.
Calculando primero desde las tablas (?), con $\alpha = 0.95$:

  - $F_{1-\alpha/2} =$
  - $F_{\alpha/2} =$
***** Ejercicio 9
Tomamos el estimador:

\[
T = \frac{1}{n}\sum_{i=1}^n X_i
\]

Si partimos de la desigualdad de Chebyshev con la cota $c = 1/n$ a la
varianza, llegamos a $k = 1/\sqrt{n\alpha}$, que nos da el intervalo:

\[
\left(
\frac{1}{n} \sum X_i + \frac{1}{\sqrt{n\alpha}}
,\quad
\frac{1}{n} \sum X_i - \frac{1}{\sqrt{n\alpha}}
\right)
\]

Con la confianza $\alpha$.
**** Tema 6. Contraste de hipotsis
**** Ejercicio 1
#+begin_statement
Se toma una observacin de una variable con distribucin de Poisson para
contrastar que la media vale 1 frente a que vale 2.

  1. Construir un test no aleatorizado con nivel de significacin 0.05 
     para el contraste planteado. Calcular las probabilidades de cometer
     error de tipo 1 y de tipo 2, el tamao y la potencia del test frente
     a la hiptesis alternativa.
  2. Cmo debe aleatorizarse el test para alcanzar el tamao 0.05?Cul
     es la potencia de este test?
#+end_statement

Usaremos el lema de Neyman-Pearson para crear un test donde el problema
de contraste es: $H_0 : \lambda = 2$, $H_1 : \lambda = 1$, para una distribucin $Poi(\lambda)$.

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } f_1(X) \geq kf_0(X) \\
0 & \mbox{if } f_1(X) < kf_0(X)
\end{array} 
\right.
\]

Sabemos que este test tendr tamao $\mathbb{E}_{\lambda=2}[\varphi]$, calculamos:

\[f_1(x) = \frac{1}{ex!}\]

\[
f_0(x) = \frac{2^x}{e^2x!}
\]

La condicin $f_1(X) \geq kf_0(X)$ equivale a:

\[
x \leq \log_2 \frac{e}{k}
\]

Siendo $\Phi$ la funcin de distribucin de una Poisson $Poi(2)$, que es la 
distribucin que sigue aqu $x$, tenemos, consultando las tablas:

\[
\mathbb{E}_{\lambda=2}[\varphi] = 
\Phi\left(\log_2\frac{e}{k}\right) = 
0.05
\]

# Tenemos que resolver esto y no parece que en las tablas se d nada
# sensato. Repasar el ejercicio.
**** Ejercicio 2
#+begin_statement
Una urna contiene 10 bolas, blancas y negras. Para contrastar que el 
nmero de bolas blancas es 5 frente a que dicho nmero es 6  7, se
extraen tres bolas con reemplazamiento y se rechaza $H_0$ slo si se 
obtienen 2  3 bolas blancas. Calcular el tamao de este test y la
potencia frente a alternativas.
#+end_statement

***** Tamao del test
Llamamos $X$ a la variable dada por cada extraccin, siendo 1 si es blanca
y 0 si es negra. Vemos que $X \leadsto B(1,\theta/10)$. Tenemos como hiptesis la
hiptesis nula $H_0 : \theta = 5$ y la alternativa $H_1 : \theta \in \{6,7\}$. Nuestro test est
definido por:

\[
\varphi(X_1,X_2,X_3) = 
\left\{\begin{array}{ll} 
1 & \mbox{if } \sum X_i = 2,3 \\
0 & \mbox{if } \sum X_i = 0,1
\end{array} 
\right.
\]

Calculamos el tamao sabiendo que $Z = \sum X_i \leadsto B(3,\theta/10)$:

\[
\sup_{\theta = 5} \beta_\varphi(\theta) = E_{\theta=5}[\varphi]
=
P(Z = 2) + P(Z=3) = \frac{1}{2}
\]

***** Potencia frente alternativas
Calculamos:

\[\beta_\varphi(6)\]
\[\beta_\varphi(7)\]

**** Ejercicio 3
#+begin_statement
Sea $(X_1,\dots,X_n)$ una muestra aleatoria simple de una variable aleatoria
con distribucin de Poisson de parmetro $\lambda$. Encontrar el test ms potente
de tamao $\alpha$ para resolver el problema de contraste:

\[
H_0 : \lambda = \lambda_0
\]
\[
H_1 : \lambda = \lambda_1
\]

Aplicacin: En una centralita telegnica el nmero de llamadas por minuto
sigue una distribucin de Poisson. Si en cinco minutos se han recibido 12
llamadas, puede aceptarse que el nmero medio de llamadas por minuto es
1.5, frente a que dicho nmero es 2, al nivel de significacin 0.05?
Calcular la potencia del test obtenido.
#+end_statement

***** Desarrollo terico
Por Neyman-Pearson, el test ms potente de tamao $\alpha$ ser de la forma:

\[
\varphi(x_1,\dots,x_n) = \left\{\begin{array}{ll} 
1 & \mbox{if } f_1(x_1,\dots,x_n) > kf_0(x_1,\dots,x_n) \\
\gamma & \mbox{if } f_1(x_1,\dots,x_n) = kf_0(x_1,\dots,x_n) \\
0 & \mbox{if } f_1(x_1,\dots,x_n) < kf_0(x_1,\dots,x_n)
\end{array} 
\right.
\]

La desigualdad es equivalente a:

\[
\frac{e^{-n\lambda_1}\lambda_1^{\sum x_i}}{\prod x_i!} 
> 
k \frac{e^{-n\lambda_0}\lambda_0^{\sum x_i}}{\prod x_i!} 
\]

\[
k = \frac
{n(\lambda_0-\lambda_1)-c}
{\log\left(\lambda_0/\lambda_1\right)}
> \sum x_i
\leadsto
Poi(n\lambda_0)
\]

Por tanto podemos tomar una distribucin de Poisson siendo $\rho_\alpha$ el valor
que da $\alpha$ en la funcin de distribucin y tener:

\[
c = n(\lambda_0-\lambda_1) + \rho_\alpha\log(\lambda_0/\lambda_1)
\]

Tenemos por tanto un test de la forma:

\[
\varphi(x_1,\dots,x_n) = \left\{\begin{array}{ll} 
1 & \mbox{if } \sum x_i < \rho_\alpha \\
0 & \mbox{if } \sum x_i \geq \rho_\alpha
\end{array} 
\right.
\]

El tamao del test entonces ser $\alpha$.

***** Aplicacin
En este caso tenemos $\sum x_i = 12$, para $n=5$. Para nivel de significacin
$\alpha = 0.05$, tenemos $P(Poi(10) > \rho_{0.05}) = 0.05$.

Tenemos:

\[
P(Poi(10) > 14) = 0.05
\]

Y como $12 < 14$, se el test da la hiptesis alternativa.
# Esto hay que comprobarlo, que lo he hecho muy rpido y creo que le
# dado la vuelta.

**** Ejercicio 4
#+begin_statement
Sea $(X_1,\dots,X_n)$ muestra aleatoria simple de una variable con distribucin
${\cal N}(\mu,\sigma^2_0)$. Deducir el test ms potente de tamao arbitrario para contrastar
hiptesis simples sobre $\mu$.
#+end_statement

Aplicaremos Neyman-Pearson para crear un test con dos hiptesis,
$H_0 : \mu =\mu_0$, $H_1:\mu =\mu_1$, de la forma:

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } f_1(X) > kf_0(X) \\
\gamma(X) & \mbox{if } f_1(X) = kf_0(X)\\
0& \mbox{if } f_1(X) < kf_0(X)
\end{array} 
\right.
\]

Que ser el de mayor potencia con nivel de significacin $E_{\mu_0}[\varphi]$.
Calculamos la significacin sabiendo que la condicin $f_1 > kf_0$ nos
da:

\[
f_1(X) = \frac{1}{(2\pi\sigma)^{n/2}} e^{-\sum \frac{(x_i-\mu_1)^2}{2\sigma^2}}
\]

\[
f_0(X) = \frac{1}{(2\pi\sigma)^{n/2}} e^{-\sum \frac{(x_i-\mu_0)^2}{2\sigma^2}}
\]

Simplificando la condicin:

\[
\sum x_i > \frac{\log k - (\mu_0^2-\mu_1^2)}{2(\mu_1-\mu_0)} = k'
\]

Y usamos la normal con $P(Z \geq z_\alpha) = \alpha$ para obtener el valor necesario para
$k'$ si queremos un test de tamao $\alpha$:

\[
k' = z_\alpha\sigma/\sqtr{n} + \mu_0
\]

El test ms potente de tamao $\alpha$ es entonces:

\[
\varphi(X) =
\left\{\begin{array}{ll} 
1 & \mbox{if } \sum x_i > k' \\
0& \mbox{if } \sum x_i \leq k'
\end{array} 
\right.
\]

**** DONE Ejercicio 5
#+begin_statement
Deducir el test ms potente de tamao $\alpha$ para contrastar $H_0:\theta=\theta_0$
frente a $H_1:\theta=\theta_1$ y calcular su potencia. Cul es el test ptimo fijado
un nivel de significacin arbitrario?
#+end_statement

**** Ejercicio 6
#+begin_statement
Deducir el test ms potente de tamao arbitrario para contrastar $H_0 : \theta = \theta_0$
frente a $H_1 : \theta = \theta_1$, basndose en una muestra de tamao $n$ de una variable
aleatoria con funcin de densidad


\[
f_\theta(x) = \frac{\theta}{x^2}, \quad x > \theta
\]

Deducir el test ptimo para un nivel de significacin arbitrario.
#+end_statement


**** Ejercicio 8
Minimizando y calculando se llega a:

\[
\lambda(X) =
\frac{1}{\theta_0^n} e^{(1-1/\theta_0)\sum x_i}
\]

**** Ejercicio 9
#+begin_statement
En base a una observacin $X \leadsto B(n,p)$, deducir el test de razn de 
verosimilitudes para contrastar la hiptesis de que el parmetro $p$ no
supera un determinado valor, $p_0$.
#+end_statement

**** Ejercicio 10
#+begin_statement
Sea $X$ variable con funcin de densidad

\[
f_\theta(x) = \theta x^{\theta-1},\quad 0<x<1
\]

Basndose en una observacin de $X$, deducir el test de razn de 
verosimilitudes de tamao arbitrario para contrastar:

\[
H_0 : \theta \leq \theta_0
\]
\[
H_1 : \theta > \theta_0
\]
#+end_statement

**** Ejercicio 13
#+begin_statement
Un profesor asegura que tiene un nuevo mtodo de enseanza mejor que el
usado tradicionalmente. Para comprobar si tiene razn se selecciona de
forma aleatoria e independiente dos grupos de alumnos, A y B, utilizndose
el nuevo mtodo en el grupo A y el tradicional con el B. A final de curso
se hace un examen a los alumnos, obtenindose las siguientes puntuaciones.

  - Grupo A: 6, 5, 4, 7, 3, 5.5, 6, 7, 6
  - Grupo B: 5, 4, 5, 6, 4, 6, 5, 3, 7

Supuesto que las puntuaciones de cada grupo siguen una distribucin normal,
proporcionan estos datos evidencia para rechazar el nuevo mtodo, con
un nivel de significacin 0.05?
#+end_statement

Usaremos la dualidad entre intervalos de confianza y tests de hiptesis
para buscar si el 0 est en un intervalo de confianza 0.95 de la diferencia
de ambas medias. Las varianzas son desconocidas pero las suponemos iguales.

El intervalo para $\mu_1-\mu_2$ de menor longitud media uniforme a nivel de
confianza $1-\alpha$ es:

\[
\left(
\overline{X}-\overline{Y} - t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
,\quad
\overline{X}-\overline{Y} + t_{n_1+n_2-2;\alpha/2}S_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
\right)
\]

Y simplemente calculamos.
** Informtica grfica

 - curena@ugr.es
 - [[http://lsi.ugr.es/curena]]
 - [[http://lsi.ugr.es/doce/ig/17-18]]

1 punto por trabajo aparte.
Defensa de prcticas con 1 semana antelacin.

*** Tema 1. Introduccin
**** 1. Introduccin
**** 2. Proceso de visualizacin
**** 3. Librera OpenGL
**** 4. Programacin del cauce grfico
***** 4.1. Cauce programable
En la GPU se ejecutan dos etapas y entre ambas la rasterizacin y
recortado de polgonos.

 * *Transformacin* de coordenadas de vrtice a ventana; realizado por
   el /vertex shader/ que se ejecuta al llamar a =glVertex=.
 * *Sombreado*, clculo del color de pixel; realizado por el
   /fragment shader/.

Hay dos opciones para seleccionar shaders

 * *cauce de funcionalidad fija*, predefinidos hasta OpenGL 3.0;
 * *cauce programable*, escrito en GLSL, ms flexible y eficiente,
   compilado en tiempo de ejecucin.

El cauce grfico fluye entonces como:

 1) CPU, aplicacin.
 2) Implementacin de OpenGL.
 3) Vertex shader para cada vrtice.
 4) Rasterizacin.
 5) Fragment shader para cada pixel.
 6) Framebuffer.

***** 4.2. Shaders bsicos
Un *program* es un /vertex shader/ con un /fragment shader/. Se
almacenan en =char*=, se compilan con OpenGL y se enlazan.

****** TODO Programar un vertex shader
****** TODO Programar un fragment shader
***** 4.3. Creacin y ejecucin de programas
Un *program* tiene un =GLuint= identificador.

 * =glCreateShader=
 * =glShaderSource=
 * =glCompileShader=
 * =glCreateProgram=
 * =glAttachShader=
 * =glLinkProgram=
 * =glUseProgram=

***** 4.4. Funciones auxiliares
**** 5. Apndice: puntos, vectores y marcos
*** Tema 2. Modelado de objetos
**** 2.1. Modelos geomtricos
***** 2.1.1. Introduccin
El modelo geomtrico ms general son los conjuntos pero no permiten
una representacin computacional clara. Se usan

 * *voxels*, cuadrculas de volmenes,
 * *fronteras*, polgonos planos.

**** 2.2. Modelos de fronteras
***** 2.2.1. Elementos y adyacencia
Los modelos de fronteras usan mallas de polgonos, normalmente
mallas de tringulos. Se consideran adyacencias entre vrtices,
aristas y caras bajo un *marco de referencia local de la malla*.

La malla tiene como atributos

 * normales de las caras,
 * normales de los vrtices,
 * colores de caras, 
 * colores de vrtices, que luego interpolarn las caras;
 * coordenadas de textura,
 * vectores bitangentes.

***** 2.2.2. Lista de tringulos
La estructura ms simple es la *lista de tringulos aislados*, una
entrada para cada tres vrtices, $9n$ floats; consume mucha memoria
innecesaria. =Objeto3D=, =MallaTA=

****** Visualizacin
Puede hacerse

 * con =glBegin/glEnd= llamando a =glVertex3fv=,
 * con =glDrawArrays=, usando $3n$ tuplas de coordenadas.

***** 2.2.3. Mallas como tiras de tringulos
Cada tringulo es adyacente al anterior y tenemos $3(n+2)$ floats.
En algunos casos hay que usar varias o repetir vrtices. La complejidad
de representarlas luego es mayor. =MallaTT=

***** 2.2.4. Mallas indexadas
Usar dos tablas

 * *tabla vrtices*, con entrada por vrtice,
 * *tabla tringulos*, llamando a tabla vrtices.

Mucho ms efiicente =MallaInd=, $3n$.

***** 2.2.5. Representacin con aristas aladas
Las aristas tienen dos caras adyacentes, hay una tabla de vrtices y
otrade aristas, donde la segunda guarda

 * vrtice inicial,
 * vrtice final,
 * tringulo a la izquierda,
 * tringulo a la derecha,
 * arista anterior en el tringulo izquierda,
 * arista siguiente en el tringulo izquierda,
 * arista anterior en el tringulo derecha,
 * arista siguiente en el tringulo derecha.

Podemos as resolver adyacencias, pueden usarse tambin

 * tabla de aristas de vrtice,
 * tabla de aristas de tringulo.

***** 2.2.6. Representacin con atributos
A los vrtices se les puede asignar

 * colores,
 * normales,
 * coordenadas de textura,
 * otros atributos.

Pueden asociarse con =glVertex= o usando =glDrawArrays= con
=glDrawElements=. A las caras no se pueden asignar atributos
directamente, pero se pueden cambiar al enviar la cara.

***** 2.2.7. Visualizacin de mallas en modo diferido
Se enva todo una sla vez a la GPU. Puede hacerse con

 * display lists (obsoletas),
 * vertex buffer objects (VBO).

El VBO se crea tomando un identificador, generando luego el VBO,
asignndolo al dentificador y haciendo la transferencia a GPU,
puede desactivarse luego.

#+BEGIN_SRC c++
GLuint id_vbo;
glGenBuffers(1, &id_vbo);
glBindBuffer(tipo, id_vbo);
glBufferData(tipo, tamanio, puntero, GL_STATIC_DRAW);
glBindBuffer(tipo, 0);
#+END_SRC

La malla se puede visualizar muchas veces entonces sin enviar datos a
GPU usando =glBindBuffer= y =glDrawElements=. Colores y normales se
pueden almacenar en los mismos VBOs.

**** 2.3. Transformaciones geomtricas
***** 2.3.1. Transformacin geomtrica
Todas las mallas deben acabar apareciendo en *coordenadas del mundo*.
Se usan transformaciones geomtricas matriciales para mostrar los
objetos.

Se consideran matrices 4x4 donde el ltimo vector indica si es un punto
y las coordenadas de ese punto. Se transforma sobre un marco de coordenadas
$R$ desde $p = R(x,y,z,w)^t$ a $p' = R(x',y',z',w')^t$; viene as determinada
por tres funciones lineales

\[\begin{aligned}
x' &= f_x(x,y,z,w) \\
y' &= f_y(x,y,z,w) \\
z' &= f_z(x,y,z,w) \\
w' &= w
\end{aligned}\]

que dependen del marco de referencia.

***** 2.3.2. Transformaciones usuales en IG
Todas ellas son afines y coherentes, $T(p-q) = Tp - Tq$.

****** Traslacin
Para puntos $\mathrm{Tra}[d](p) = p + d$ y para vectores $\mathrm{Tra}[d](v) = v$.
Queda como

\[\begin{aligned}
x' &= f_x(x,y,z,w) &= x + d_xw \\
y' &= f_y(x,y,z,w) &= y + d_yw \\
z' &= f_z(x,y,z,w) &= z + d_zw \\
w' &= w
\end{aligned}\]

y puede escribirse como =MAT_Traslacion(dx,dy,dz)=.

****** Escalado

****** Cizalla

****** Rotacin

****** Composicin

****** Representacin matricial
***** 2.3.3. Matrices y marcos de coordenadas
Si las coordenadas del marco $B$ en $A$ vienen dadas por $a,b,c,d$,
la matriz de cambio de $B$ a $A$ viene dada por

\[M_{A,B} = \begin{pmatrix}
a_x & b_x & c_x & d_x \\
a_y & b_y & c_y & d_y \\
a_z & b_z & c_z & d_z \\
0 & 0 & 0 & 1 \\
\end{pmatrix}\]

y se calculan las coordenadas como $Mc_{A} = c_B$.

***** 2.3.4. Representacin de matrices en memoria
Se usa el tipo =Matriz4f=.

***** 2.3.5. Transformaciones en OpenGL
OpenGL almacena

 * *matriz de modelado* (N), pasa de coordenadas de objeto a coordenadas
   del mundo; posiciona un objeto en la escena;

 * *matriz de vista* (V), pasa de coordenadas del mundo a coordenadas de
   ojo, relativas a la cmara;

 * *modelview* (M), compone modelado y vista $M = VN$.

La modelview puede especificarse por composicin

#+BEGIN_SRC c++
glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(..);     // Vista
glMultMatrix(..);  // Modelado
#+END_SRC

La gestin directa de matrices es obsoleta a partir de OpenGL3.1.

***** 2.3.6. Gestin de matriz de modelado en GLSL
**** 2.4. Modelos jerrquicos, representacin y visualizacin
*** Tema 3. Visualizacin
**** 3.1. Cauce grfico y definicin de la cmara
***** 3.1.1. El cauce grfico del algoritmo Z-buffer
El algoritmo Z-buffer elimina partes ocultas (EPO) en 3D y se
implementa en hardware. Tiene 4 pasos.

 * Transformacin de coordenadas de vrtices, proyeccin a la
   pantalla.
 * Recortado de polgonos fuera de zona visible.
 * Rasterizacin y EPO, clculo de pxeles donde proyectar.
 * Iluminacin y texturacin.

****** Sistemas de coordenadas

 * (OC) Coordenadas de *objeto*, propias de cada objeto fuera de escena.
 * (WC) Coordenadas de *mundo*, colocando los objetos en la escena.
 * (EC) Coordenadas de *cmara* u *ojo*, relativas a la cmara virtual.
 * (CC) Coordenadas de *recortado*, distancias normalizadas relativas al
   rectngulo de la pantalla.
 * (NDC) Coordenadas *normalizadas de dispositivo*, de recortado dentro de
   la zona visible.
 * (DC) Coordenadas de *dispositivo*, en pixels.

****** Cambios de coordenadas

 * (N) La matriz de *modelado* pasa objeto a mundo.
 * (V) La matriz de *vista* pasa mundo a cmara.
 * (P) La matriz de *proyeccin* pasa de cmara a recortado.
 * (D) La matriz de *viewport* pasa normalizadas (NDC) a dispositivo (DC).

***** 3.1.2. Transformacin de vista
La matriz de vista se define con

 * $o_c$, posicin de observador (PRP),
 * $n$, normal al plano de proyeccin (VPN),
 * $a$, punto de atencin (VRP), alternativa a especificar $n$,
 * $u$, direccin que seala el "arriba" de la imagen (VUP).

****** Construir del marco de referencia
A partir de los parmetros se pueden construir tres vectores
perpendiculares formando el *marco del observador*,

\[\begin{aligned}
n &= o - a \\
z_c &= \frac{n}{\|n\|} \\
x_c &= \frac{n \times u}{\|n \times u\|} \\
y_c &= z_c \times u_c
\end{aligned}\]

y este marco se representa en coordenadas de mundo $W$. =gluLookAt=
toma $o,a,u$ como parmetros.

****** Clculo de matriz de vista dado un marco
Dado $p$ en coordenadas del mundo podemos tomar los productos escalares
de $p-o_c$ con los ejes $x_c,y_c,z_c$. La matriz de vista ser entonces

\[V = \begin{pmatrix}
a_x & a_y & a_z & 0 \\
b_x & b_y & b_z & 0 \\
c_x & c_y & c_z & 0 \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\begin{pmatrix}
1 & 0 & 0 & -o_{x} \\
0 & 1 & 0 & -o_{y} \\
0 & 0 & 1 & -o_{z} \\
0 & 0 & 0 & 1 \\
\end{pmatrix}\]

donde $a = x_c, b = y_c, c = z_c$ son los tres ejes.

****** Clculo de matriz de vista con ngulos de Euler
Los ngulos de Euler pueden construirse a partir de las coordenadas
del marco

\[
V = \mathrm{Rot}[\gamma,z] \cdot \mathrm{Rot}[\beta,y] \cdot \mathrm{Rot}[\alpha,x] \cdot \mathrm{Tra}[-o_c]
\]

***** 3.1.3. Transformacin de proyeccin
Se proyecta sobre un *viewplane* de dos formas

 * *perspectiva*, con lneas proyectoras hacia un foco; hay un factor de
   escala que decrece afnmente con la distancia $s = 1/(ad_z + b)$;
 * *ortogrfica*, con lneas proyectoras paralelos, es una proyecci
   afn simple.

****** El view-frustum
Regin de la escena visible en el viewport. La transformacin de
proyeccin debe transformarlo en un cubo de lado 2 centrado en el
origen, esta no es lineal pero puede serlo en cuatro dimensiones.

 * Es un ortoedro en proyeccin ortogrfica.
 * Es una pirmide truncada en proyeccin perspectiva.

****** Parmetros del view-frustum
Se interpretan en coordenadas de vista, y se usan para transformar
de vista a recortado (matriz P)

 * $n,f$, near y far, son los lmites en Z del view-frustum, se exigen
   positivos, determinan planos de recorte trasero y delantero;

 * $l,r,b,t$, bottom y top, lmites en X e Y, que se transformarn en
   [-1,1];

 * $(r-l)/(t-b)$ debe ser la relacin de aspecto del viewport.

****** TODO Matriz de proyeccin perspectiva
****** TODO Matriz de proyeccin ortogrfica
****** Matrices en OpenGL
#+BEGIN_SRC c++
glFrustum(l,r,b,t,n,f); // perspectiva
glOrtho(l,r,b,t,n,f);   // ortogrfica

gluPerspective(fovy,a,n,f) // perspectiva (alternativa)
#+END_SRC

donde para =gluPerspective= se asume $r = -l$ y $t = -b$ y se tiene

 * =fovy= es la apertura del campo de visin, grados de 0 a 180;
 * =a= es la relacin de aspecto $r/b$;
 * =n,f= son near y far.

**** 3.2. Modelos de iluminacin
***** 3.2.1. Radiacin visible
La *radiancia* $L(\lambda,p,v)$ determina el tono y brillo de un punto. 
Los colores pueden medirse en RGB usando mezcla aditiva, la
traduccin depender del dispositivo.

***** 3.2.2. Emisin y reflexin de la radiacin
La radiancia es suma de emitida y reflejada, para cada radiancia
incidente desde cada punto, se refleja una fraccin en cada direccin
$v$,

\[
L(\lambda, p,v) = L_{em}(\lambda, p,v) + \sum_i L_{in}(\lambda,p,u_i)f_r(\lambda,p,v,u_i)
\]

***** 3.2.3. Simplificaciones en modelos computacionales
Se asume para calcular

 * fuentes puntuales no extensas,
 * la nica iluminacin indirecta es constante,
 * objetos opacos,
 * no hay sombras arrojadas,
 * no hay dispersin,
 * slo funciona en RGB.

**** 3.3. Modelo de iluminacin local (MIL) bsico
***** 3.3.1. Elementos del modelo: normales y colores
La iluminacin depende de la orientacin caracterizada por el *vector
normal*.

***** 3.3.2. Fuentes de luz, materiales y reflexin
 * Posicionales, con vector unitario

   \[
   l_i = \frac{q_i-p}{\|q_i-p\|}
   \]

 * Direccionales, a distancia infinita, direccin constante.

***** 3.3.3. Componentes del modelo
 * Radiancia emitida $L_{em}(p)$, emisividad del material.

 * Reflectividad difusa $f_{ra}(p,v,l_i) = M_A(p)$.

 * Componente difusa dependiendo de la posicin, independiente de la
   direccin; $f_{rd}(p,v,l_i) = M_D(p) \max(0,n_p \cdot l_i)$.

 * Material difuso $M_A(p)$.

 * Componente pseudo-especular, el reflejo de la luz en objetos
   brillantes. *Modelo de Phong*,

   \[
   f_{rs}(p,v,l_i) = M_S(p) d_i [\max(0,r_i \cdot v)]^{e}
   \]

   con $r_i$ reflejado, $e$ exponente de brillo, $d_i$ midiendo si
   est de cara a la superficie.

***** 3.3.4. Modelo completo
\[
L(p,v) = M_E(p) + A_G(p) + \sum_{i=0}^{n-1}S_iC_i
\]

donde

\[
C_i = M_A(p) + M_D(p) \max(0,n\cdot l_i) + M_S(p) d_i (\max(0,r_i \cdot v))^e
\]

**** 3.4. Iluminacin en OpenGL
***** 3.4.1. Iluminacin vs asignacin de colores
Obsoleta y eliminada a partir de OpenGL3.1. Cuando est activada se
usa el MIL para calcular el color.

#+BEGIN_SRC c++
glEnable(GL_LIGHTING);
glDisable(GL_LIGHTING);
#+END_SRC

Los parmetros del MIL son

 * $M_E$, emisividad,
 * $M_A,M_{D},M_S$, reflexividad difusa, ambiente y pseudoespecular,
 * $A_G$, luz ambiente,
 * $e$, exponente,
 * $S_{iA},S_{iD},S_{iS}$, luminosidad de cada fuente de luz,
 * $q_i,l_i$, posicin y direccin de cada fuente de luz.

El modelo de funcionalidad fija es parecido al MIL visto.

***** 3.4.2. Definicin de fuentes de luz
Hay luces =GL_LIGHTi= para =i = 0..8=. Pueden especificarse en varios
marcos de coordenadas con transformaciones.

#+BEGIN_SRC c++
// Activacin
glEnable(GL_LIGHTi);
glDisable(GL_LIGHTi);

// Configuracin de colores
glLightfv(GL_LIGHTi, GL_AMBIENT, caf);
glLightfv(GL_LIGHTi, GL_DIFFUSE, caf);
glLightfv(GL_LIGHTi, GL_SPECULAR, caf);

// Posicin/direccin
glLightfv(GL_LIGHTi, GL_POSITION, tupla);
glLightfv(GL_LIGHTi, GL_DIRECTION, dirf);
#+END_SRC

***** 3.4.3. Representacin de fuentes de luz
Clase =FuenteLuz=, se guardan en =ColeccionFL=.

***** 3.4.4. Vector hacia observador
El observador puede ser local o en el infinito.

#+BEGIN_SRC c++
glLightModeli(GL_LIGHT_MODEL_LOCAL_VIEWER, GL_FALSE); // Ortogonal
glLightModeli(GL_LIGHT_MODEL_LOCAL_VIEWER, GL_TRUE); // Perspectiva
#+END_SRC

***** 3.4.5. Normales de vrtices
Se pueden especificar con =glNormal= y normalizarse con
=glEnable(GL_NORMALIZE)=.

***** 3.4.6. Atributos materiales
El trmino ambiente, emisividad y colores se controlan.

#+BEGIN_SRC c++
glLightModelf(GL_LIGHT_MODEL_AMBIENT, color);
glMaterialf(GL_FRONT_AND_BACK, GL_EMISSION, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_AMBIENT, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_DIFFUSE, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_SPECULAR, color);
glMaterialfv(GL_FRONT_AND_BACK, GL_SHININESS, color);
#+END_SRC

***** 3.4.7. Representacin de materiales
Clase =Material=.

**** 3.5. Mtodos de sombreado para Z-Buffer
***** 3.5.1. Evaluacin del MIL con Z-Buffer
El MIL puede evaluarse

 * *sombreado plano* (flat shading): una vez por polgono.
 * *sombreado de vrtices* (smooth shading, Gouround): una vez por vrtice.
 * *sombreado de pixel* (pixel shading): una vez por pixel.

***** 3.5.2. Sombreado plano
Eficiente, discontinuidades y poco realista. Crea bandas Mach

***** 3.5.3. Sombreado en vrtices
Eficiente pero ms realista, puede tener bandas Mach. Puede perder
zonas brillantes.

***** 3.5.4. Sombreado en pixeles
Costoso, ms calidad y realismo.

***** 3.5.5. OpenGL: mtodo de sombreado
Slo plano y vrtices

#+BEGIN_SRC c++
glShadeModel(GL_FLAT);
glShadeModel(GL_SMOOTH);
#+END_SRC

**** 3.6. Visualizacin de texturas
***** 3.6.1. Detalles a pequea escala
Rugosidades variando la normal y la reflectividad. Pueden usarse
polgonos de detalle, pero las *texturas* son ms eficientes, llevan
texels a un cuadrado del espacio. Pueden ser procedurales.

***** 3.6.2. Coordenadas de textura
Aplican la textura al objeto.

***** 3.6.3. Asignacin explcita de coordenadas de textura
Se asignan al modelar el objeto en escena.

***** 3.6.4. Asignacin procedural de coordenadas de textura
Un subprograma =CoordText(p)= que las calcula en cada punto.

 * Asignacin a vrtices, interpolando luego.
 * Asignacin a puntos.

Se suelen usar:

 * funciones lineales,
 * coordenadas paramtricas,
 * coordenadas polares,
 * coordenadas cilndricas.

En los casos de una superficie paramtrica, podemos usar las coordenadas
como coordenadas de textura. Las esfricas y cilndricas pueden proporcionar
mejores resultados en algunos casos.

***** 3.6.5. Consulta de texels
El texel (i,j) tiene centro en un punto $(c_i,d_j)$ y puede
consultarse

 * el texel ms cercano a ese punto,
 * una interpolacin bilineal entre los cuatro texels.

La interpolacin es ms suave.

**** 3.7. Texturas en OpenGL
***** 3.7.1. Activacin y desactivacin
#+BEGIN_SRC c++
glEnable(GL_TEXTURE_2D);
glDisable(GL_TEXTURE_2D);
#+END_SRC

Cuando se activan, el color de textura sustituye a reflexividades del
material y al color.

***** 3.7.2. Carga de texturas
OpenGL gestiona varias texturas por identificadores, en cada momento
habr una sola activa. Las texturas se guardan en RAM.

#+BEGIN_SRC c++
// Genera
GLuint idTex;
glGenTextures(1, &idTex);

// Asocia, con potencias o mipmaps
glTexImage2D(GL_TEXTURE_2D, 0,GL_RGB,ancho,alto,borde = 0, GL_RGB,GL_UNSIGNED_BYTE, texels);
gluBuild2DMipmaps(GL_TEXTURE_2D, GL_RGB, ancho,alto, GL_RGB, GL_UNSIGNED_BYTE, texels);

// Activa
glBindTexture(GL_TEXTURE_2D, idTex);
#+END_SRC

***** 3.7.3. Configuracin de texturas
Determinan la apariencia de textura

 * color de texels,
 * seleccin de texels (cercano o interpolacin),
 * seleccin fuera de rango (replicado o truncamiento),
 * coordenadas explcitas o procedurales.

****** Texturas, reflectividades e iluminacin
#+BEGIN_SRC c++
glLightModeli(GL_LIGHT_MODEL_COLOR_CONTROL, GL_SINGLE_COLOR); // Color en lugar de reflectividades
glLightModeli(GL_LIGHT_MODEL_COLOR_CONTROL, GL_SEPARATE_SPECULAR_COLOR); // Especular aparte
#+END_SRC

****** Seleccin de texels
#+BEGIN_SRC c++
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST); // Ms cercano
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);  // Interpolacin
#+END_SRC

****** Tipo de generacin procedural
Dos tipos de generacin,

#+BEGIN_SRC c++
glTexGeni(GL_S, GL_TEXTURE_GEN_MODE, GL_OBJECT_LINEAR); // Coordenadas de objeto
glTexGeni(GL_T, GL_TEXTURE_GEN_MODE, GL_OBJECT_LINEAR); // Coordenadas de ojo
#+END_SRC

****** Especificacin de coeficientes de generacin procedural
Los coeficientes de las funciones lineales de generacin

#+BEGIN_SRC c++
glTexGenfv(GL_S, GL_OBJECT_PLANE, coefsS);
glTexGenfv(GL_T, GL_OBJECT_PLANE, coefsT);
#+END_SRC

***** 3.7.4. Asignacin explcita de texturas y VBOs
Puede hacerse con =glBegin/glEnd= usando =glTexCoord2f=. Pueden
crearse VBOs con coordenadas de textura.

***** 3.7.5. Representacin de texturas
Clase =Textura=.

**** 3.8. Materiales en grafo de escena
***** 3.8.1. Modelo de aspecto
Los materiales dan un modelo de aspecto que puede insertarse en el
grafo de escena afectando a todas las entradas por debajo. Para esto
es cmodo tener una =PilaMateriales=.

***** 3.8.2. Implementacin de materiales en el grafo
Aadimos materiales a =EntradaNGE= y visualizamos con =visualizarGL=.

**** 3.9. Visualizacin con cauce grfico programable
***** 3.9.1. Introduccin
La nica forma de evaluar el MIL es usar vertex+fragment shader en el
cauce grfico con GLSL.

****** Parmetros del vertex shader
Hay parmetros de entrada al vertex shader, que se enviarn con
=glVertexAttrib= y =glVertexAttribPointer=

 * *uniform*, mismo valor para todos los vrtices,
 * *vrtice*, potencialmente distintos para cada vrtice.

Los parmetros de salida se entregan interpolados al fragment shader.
Pueden declararse explcitamente y estn predefinidos algunos.

***** 3.9.2. Sombreado de pixeles (fragment shader)
El shader tiene

 * parmetros *uniform*, iguales en todos los pixeles =glUniform=,
 * parmetros *in*, interpolados a partir de los *out* del vertexShader.

El factor geomtrico de la pseudo-especular puede calcularse usando
Blinn-Phong y puede escribirse una completa evaluacin del MIL.

***** 3.9.3. Atributos vrtice genricos
Es necesario usar atributos de vrtice para los parmetros de entrada.
Tienen,

 * localizacin, identificador en la aplicacin,
 * nombre, identificador en el fuente del vertexshader.

Se puede asociar localizacin a los nombres con =glBindAttribLocation=
y se pueden enviar tablas de atributos genricos.

*** Tema 4. Interaccin y animacin
**** 4.1. Introduccin
Buscamos un sistema grfico interactivo que responda al usuario
interactivamente. Habr retroalimentacin, tcnicas y funciones de
entrada que lean de dispositivos lgicos, cambiando su estado y
generando eventos.

***** Leer de dispositivos
Existen tres modos

 - modo de muestreo :: variables con el estado actual, la CPU debe
      muestrear a frecuencia suficiente.
 - modo de peticin :: se hace una peticin y se espera a que ocurra
      el evento determinado, pueden perderse eventos y tiempo
      esperando.
 - modo cola de eventos :: se aade a una cola FIFO cada evento y se
      va procesando luego.

**** 4.2. Eventos en GLUT
GLUT gestiona los eventos con cola de eventos; cada evento va asociado
a un *callback*, una funcin que lo trata y toma parmetros de l.

***** Funciones de registro de callback
#+BEGIN_SRC c++
glutDisplayFunc(); // es necesario redibujar la imagen.
glutMouseFunc(); // pulsar/levantar de botones del ratn.
glutMotionFunc(); // movimiento del ratn con un botn pulsado.
glutPassiveMotionFunc(); // movimiento del ratn sin botn pulsado.
glutReshapeFunc(); // cambio de tamao de la ventana.
glutKeyFunc(); // pulsar o levantar de tecla.
glutIdleFunc(); // ausencia de eventos externos.
glutTimerFunc(); // ha transcurrido un intervalo de tiempo.
#+END_SRC

***** Eventos de botones de ratn
Declaramos un callback 

#+BEGIN_SRC c++
void FGE_BotonRaton(GLint boton, GLint estado, GLint x, GLint y);
#+END_SRC

donde =boton= toma tres constantes (=GLUT_LEFT_BUTTON=,
=GLUT_RIGHT_BUTTON=, =GLUT_MIDDLE_BUTTON=) segn el botn pulsado y
dos estados (=GLUT_UP=, =GLUT_DOWN=) segn se haya pulsado o levantado
la =x,y= indica la posicin del ratn en cada momento.

****** Ejemplo de callback de botones de ratn
#+BEGIN_SRC c++
int xClickIzq, yClickIzq; // posicin del ltimo click del botn izquierdo
[...]

void FGE_BotonRaton(int boton,int estado,int x,int y) {
  if (boton == GLUT_LEFT_BUTTON && estado == GLUT_DOWN) { 
    xClickIzq = x; 
    yClickIzq = y; 
  }
  else if
  [...]
}
#+END_SRC
***** Eventos de movimiento de ratn
****** Ejemplo de callback de movimiento de ratn
**** 4.3. Posicionamiento
La posicin que introduce un usuario est en /coordenadas de dispositivo/
y es necesario pasarla a coordenadas de mundo.

***** Posicionamiento 2D
Las coordenadas de dispositivo $x,y$ se convierten a mundo $x',y'$ con una
transformacin inversa

\[\begin{aligned}
x' &= X_{min} + x (X_{max} + X_{min}) / \mathrm{ancho}; \\
y' &= Y_{max} - y (Y_{max} + Y_{min}) / \mathrm{alto}; \\
\end{aligned}\]

donde los parmetros son los que determinan el ancho y alto del
dispositivo y mnimos y mximos del mundo.

#+BEGIN_SRC c++
glOrtho(Xmin,Xmax, Ymin,Ymax, Zmin,Zmax);
glViewport(x0, y0, ancho, alto);
#+END_SRC

***** Posicionamiento 3D
Se restringe a un plano no perpendicular al de proyeccin y se traza
una recta desde el centro de proyeccin por el punto introducido, que
cortar al plano dado.

**** 4.4. Control de cmaras
Dos usos de la cmara

 - visualizacin de objetos en modo *orbital* centrando el objeto;
 - exploracin de escenario en *primera persona*, desplazando VRP y
   rotando VPN y VUP en torno al marco de coordenadas de la cmara.

El *marco de coordenadas de vista* est determinado por tres versores
ortonormales $x_c, y_c, z_c$ y un origen $o_c$. La *matriz de vista* se obtiene
directamente desde ellas

\[V = \begin{pmatrix}
x_c(0) & y_c(0) & z_c(0) & -o_c \cdot x_c \\
x_c(1) & y_c(1) & z_c(1) & -o_c \cdot y_c \\
x_c(2) & y_c(2) & z_c(2) & -o_c \cdot z_c \\
0 & 0 & 0 & 1 \\
\end{pmatrix}
\]

y transforma coordenadas de mundo en coordenadas de cmara.

***** 4.4.1. Cmaras en modo primera persona

 * *Rotaciones*: se rotan VPN y VUP en torno a PRP (origen). VPN rota
   en horizontal o vertical y VUP permite rotar en torno a un centro.
   La rotacin se hace con los ejes del marco.

 * *Traslaciones*: se desplaza PRP en la direccin de traslacin.
   La traslacin se hace con los ejes del marco.

***** 4.4.2. Cmaras orbitales
Las coordenadas esfricas, el punto de atencin y la distancia a l
fijan la cmara. El marco de vista puede obtenerse desde estos
parmetros.

**** 4.5. Seleccin
Se pueden dar identificadores de seleccin a

 * tringulos,
 * mallas,
 * grupos de objetos,
 * nodos del grafo de escena.

Puede seleccionarse pixel en pantalla y buscar identificadores
proyectados en ese pixel. La bsqueda puede hacerse por

 * *ray-casting*, por interseccin de rectas,
 * *clipping*, recortando dentro de un view-frustum pequeo,
 * *rasterizacin*, visualiza con identificadores.

En OpenGL hay un modo seleccin y puede usarse un framebuffer distinto
para rasterizar con identificadores.

***** 4.5.1. Seleccin de OpenGL [Obsoleto]
#+BEGIN_SRC c++
glRenderMode(GL_SELECT);
glRenderMode(GL_RENDER);
#+END_SRC

Hay una pila de nombres que se almacenan en un buffer de
seleccin. Durante la rasterizacin, OpenGL registra nombres.

***** 4.5.2. Seleccin con frame-buffer invisible
Se puede usar de dos formas, la segunda ms simple

 * crear un *frame-buffer object* (FBO);
 * *doble buffer* un back buffer y un front buffer.

****** Visualizacin con identificadores
Codificamos los identificadores como colores en lugar de usar los
colores de los objetos. Cambiamos el color actual de OpenGL y desactivamos
la iluminacin, las texturas, usar sombreado plano y tringulos planos.

Este es el *modo identificadores* de visualizacin.

****** Transformacin de identificadores a colores
Los identificadores deben ser =unsigned char= con una variante de
=glColor= que los acepta en lugar de valores flotantes. Puede
reconstruirse el unsigned de nuevo desde los tres colores.

**** 4.6. Animacin
#+BEGIN_SRC c++
glutPostRedisplay(); // Regenera la imagen
glutSwapBuffers();   // Intercambia buffer dibujado
glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA | GLUT_DEPTH); // Activacin de buffer
#+END_SRC

La modificacin en escena se puede hacer con

 * *keyframes*, configuraciones sobre las que se interpola,
 * *simulacin fsica*, usando mecnica clsica,
 * *esqueletos*, que simplifican la animacin,
 * *animacin procedural*, objetos descritos por procedimientos.

*** Tema 5. Realismo en rasterizacin, ray-tracing
**** 5.1. Tcnicas realistas de rasterizacin
***** 5.1.1. Mipmaps
La resolucin de las texturas debe adaptarse a la imagen. Puede
solucionarse con *antialiasing* o con *mipmaps*, una serie de texturas
$\left\{ M_i \right\}$ donde cada una se obtiene promediando grupos de
$4$ pixels de la anterior, con resoluciones $2^{n-i} \times 2^{n-i}$.

El $i$ de textura que se usa crece con el logaritmo de la distancia.

***** 5.1.2. Perturbacin de la normal
Las rugosidades a pequea escala causaran un rendering muy lento; se
usa una textura que modifica la normal a pequea escala (*bump-maps*).

 * La textura la da un campo de alturas, que puede ser generado
   procedural o dado como tonos de gris.

 * Sobre ese campo de alturas se calculan derivadas parciales o
   diferencias finitas $d_u,d_{v}$.

 * A las derivadas en un punto se les llama tangente y bitangente y
   definen un plano tangente perpendicular a la normal. Pueden
   obtenerse interpolando en algunos casos.

***** 5.1.3. Sombras arrojadas
Las sombras arrojadas plantean un problema similar a visibilidad. 

 * Lo soluciona el Algoritmo de Weiler-Atherton-Greenberg, para
   eliminacin de partes ocultas.

 * Ms eficiente es usar Z-buffer.

***** 5.1.4. Superficies transparentes
La refraccin la calcula la ley de Snell, $n_i\sin(\theta_i) = n_j\sin(\theta_j)$.

 * El Z-buffer slo puede tener en cuenta los rayos que van hacia el
   observador, pero puede adaptarse a superficies transparentes cuando
   no hay refraccin. Los colores en superficies transparentes dependen
   del orden de los polgonos.

 * La reflexin especular no puede reproducirse con los mtodos
   vistos.  Pueden usarse mapas de entorno tipo caja; y en espejos
   planos puede sintetizarse directamente una cmara simtrica.

**** 5.2. Ray-tracing
***** 5.2.1. El algoritmo de Ray-tracing
Ray-tracing rene todos los efectos anteriores y es ms sencillo y realista
que el Z-buffer. Cada pixel crea un rayo primario.

***** 5.2.2. Evaluacin del MIL

 * Las sombras se calculan siguiendo el rayo hasta la fuente.
 * Las superficies especulares o con refraccin crean rayos
   secundarios.

***** 5.2.3. Esquema del algoritmo
La funcin es recursiva, devuelve un color y tendr algn parmetro
para evitar la recursividad infinita.

*** Ejercicios
**** Ejercicio 12
***** apartado a
4by

vrtices = (n+1)*(m+1) = nm + n + m + 1
caras = 2nm

floats = 3*vertices = 3nm + 3n + 3m + 3
ints = 3*caras = 6nm

tamao = 4*ints + 4*floats = 24nm + 12nm + 12n + 12m + 12 = 36nm + 12n + 12m + 12

***** apartado b
592908

***** apartado c
1/2

**** Ejercicio 13
verticestira = 2n+2
totalvert = verticestira * m
tamao = 4*totalvert = 3*4m(2n+2) = 24nm + 24m
**** Ejercicio 39
La matriz de vista simplemente centrara en la cmara

\[
\mathrm{gluLookAt}((c_x,c_y,c_z), (c_x,c_y,c_z-1), (0,1,0))
\]

mientras que la de proyeccin describe el cuadro ortogonal

\[
\mathrm{glOrtho}\left(-\frac{s}{2},\frac{s}{2},-\frac{s}{2},\frac{s}{2},-\frac{s}{2},\frac{s}{2}\right).
\]
**** TODO Ejercicio 40
**** TODO Ejercicio 41
**** TODO Ejercicio 42
**** TODO Ejercicio 43
**** Ejercicio 46
# Tabla de coordenadas de textura
** Ingeniera, empresa y sociedad
#
# Estos apuntes de empresa han sido escritos por Mario Romn, tomando
# como base la docencia de Matilde Ruiz Arroyo para la asignatura de
# Ingeniera, Empresa y Sociedad.
#
# Pueden copiarse y distribuirse bajo la siguiente licencia respetando
# la nota de autora original:
#
#  Creative Commons Attribution-NonCommercial-ShareAlike 4.0 
#  International Public License
# 

*** Detalles de la asignatura
Profesora Matilde Ruiz, departamento de Organizacin de Empresas. 
(matilderuiz@ugr.es)

*Evaluacin:*

- 70% Pruebas objetivas: la prueba final de junio y los exmenes parciales.
- 30% Actividades prcticas: participacin, ejercicios y asistencia.

*Bibliografa:*

 - Fuentes Fuentes M. et al. /"Fundamentos de direccin y administracin de empresas"/

*** 1. La empresa y direccin de empresas
**** 1.0. Introduccin
***** Economa
La *economa* se define como la ciencia que estudia la administracin
eficiente de la escasez de recursos. Tambin como ciencia que
estudia la eleccin.

Este concepto proviene de las ideas de *Malthus*. La escasez justifica
la necesidad de reparto y la pobreza.

***** Administracin de empresas
La *administracin de empresas* estudia la economa en el contexto de
una empresa, as como la gestin de proyectos, la planificacin y el
liderazgo. Es una disciplina cientfica multidisciplinar y contempla
aspectos psicosociales.

**** 1.1. Concepto de empresa y de organizacin
***** Organizacin
Una *organizacin* es una unidad social deliberadamente destinada a un
objetivo especfico. Requiere constar de una estructura interna
deliberada y fijar el objetivo comn.

****** Definicin de Gibson
La *organizacin* es una unidad coordinada /deliberada/ formada por
ms de una persona que trabaja para alcanzar un /objetivo comn/.

****** Definicin de Etzioni
Unidades sociales deliberadamente constituidas para promover objetivos
especficos.

****** Clasificacin de organizaciones
Una clasificacin genrica sencilla las separa segn tengan o no
*nimo de lucro*.

******* Ejemplo: Inditex
Industria de diseo textil INDITEX S.A. es una empresa multinacional
que tiene como objetivo maximizar el beneficio. Segn la empresa,
su objetivo es "/escuchar a los clientes para ofrecerles las propuestas/
/de moda que desean/".

******* Ejemplo: Amigos del museo del Prado
En sus estatutos aclara que su fin primario es cultural. Puede
obtener beneficios econmicos, pero sern un fin secundario, slo
un medio para su fin primario cultural:

"/tiene por fin particular todo lo relacionado con la promocin,/
/estmulo, apoyo y desarrollo de cuantas acciones culturales,/
/educativas y de otra ndole tengan relacin con el Museo/"

***** Definicin de empresa
La *empresa* es una organizacin que /transforma/ un conjunto de recursos
fsicos, monetarios y cognitivos en bienes y/o servicios, con el objetivo
principal de /obtener beneficios/.

****** Autores
Otras definiciones de empresa.

 - Unidad tcnico-econmica que combina elementos humanos y financieros.
 - Una organizacin con nimo de lucro.
 - Unidad de decisin.
 - Sistema en el que se coordinan factores de produccin.
 - Conjunto de factores de produccin.

***** Es el beneficio el nico objetivo?
Hay posiciones distintas.

****** Friedman
S, hay que maximizarlo teniendo como nicas restricciones

 * las leyes,
 * las normas de la economa capitalista, y
 * evitar engaos y fraudes.

****** Freeman
No, no slo hay que maximizar el beneficio, tambin hay que satisfacer
a los *stakeholders*, que son todas las personas que tienen intereses en
la compaa.

***** Stakeholder
Los *stakeholders* son todas las partes interesadas en una empresa. Pueden
ser

 * *internas*, como los empleados, gerentes y propietarios.
 * *externas*, como los proveedores, clientes y la sociedad.

Originalmente, los stakeholders se definieron como los miembros de los grupos
sin cuyo apoyo la empresa dejara de existir.

***** La empresa social
Las *empresas sociales* nacen con el objetivo de resolver problemas
sociales. No tienen nimo de lucro, sino que buscan un objetivo
social.

Organizaciones con nimo de lucro y sin nimo de lucro pueden tener un
fin fundamental con beneficio social, medioambiental o poltico. Pero
a las empresas sociales se les exige que sean rentables por s mismas.

En su filosofa se incluye que no reemplaza a la empresa tradicional,
sino que que quiere coexistir con ella. Como ejemplos:

 - plataformas sociales, como /Ashoka/ y /SocialEmprende/.
 - /DBS/.

***** Tipos de responsabilidad jurdica
Existen varias formas de responsabilidad, que indican cmo responder la
empresa ante las posibles prdidas. La responsabilidad puede ser limitada
o ilimitada y solidaria o mancomunada.

****** Responsabilidad ilimitada
Se llama *responsabilidad ilimitada* cuando el propietario responde
con todo el patrimonio ante las posibles prdidas de la
empresa. Existe cuando ste realiza la actividad con su propia persona
como personalidad jurdica.

****** Responsabilidad limitada
Se llama *responsabilidad limitada* a aquella que no obliga a responder
con el patrimonio a los socios ante posibles prdidas. La responsabilidad
de cada socio est limitada por sus aportaciones.

****** Responsabilidad solidaria
La *responsabilidad solidaria* se reparte entre los socios equitativamente.

****** Responsabilidad mancomunada
La *responsabilidad mancomunada* hace que cada socio responda por su parte.

***** Clasificacin de empresas segn forma jurdica (individuales)
Constituidas por una persona fsica, que sigue usando su NIF y tributando
mediante el IRPF.

****** Empresario individual
Cuando el *empresario individual* responde por la empresa de manera
ilimitada. Se constituye como una mera persona fsica, que responde
con su patrimonio, utiliza su NIF como persona jurdica y paga el IRPF.

****** Emprendedor de responsabilidad limitada
El *emprendedor de responsabilidad limitada* es una forma jurdica
permitida segn ciertos criterios. La nica diferencia es que la
responsabilidad del empresario individual pasa a limitarse. 

Aun as, sigue siendo un empresario individual. No tiene CIF y paga el
IRPF.

***** Clasificacin de empresas segn forma jurdica (societarias)
En una *forma societaria*, varias personas aportan capital o trabajo
bajo un contrato de asociacin que da lugar a una personalidad jurdica
nueva.

****** Sociedad colectiva
En una *sociedad colectiva* la responsabilidad es /ilimitada y
mancomunada/ entre los socios, pero slo participan del beneficio por
la parte que han aportado de capital y trabajo.

****** Sociedad comanditaria
En una *socidedad comanditaria* existen dos tipos de socios

 - *socios colectivos*, similares a los de las sociedades colectivas,
   aportando trabajo y capital y con responsabilidad ilimitada.
 - *socios comanditarios*, slo aportan capital y no trabajan en la
   empresa. Su responsabilidad se limita a su capital y sus beneficios
   son proporcionales a su aportacin.

****** Sociedad limitada (SL)
En una *sociedad limitada* el capital se divide en *participaciones 
sociales*. Estas se diferencian de las /acciones/ en que existen obstculos
legales a su transmisin directa; slo pueden ser transmitidas si da el
visto bueno una /junta de socios/ o la transmisin se hace a familiares o a
otros socios.

Tiene trmites ms costosos y lentos que otras formas societarias de
responsabilidad ilimitada. El capital social en ellas no puede ser inferior
a los 3000 mnimos iniciales.

****** Sociedad de responsabilidad limitada unitaria (SLU)
Hay una *sociedad de responsabilidad limitada unitaria* cuando existe un
socio nico, que debe cumplir con una declaracin de unipersonalidad y que
puede tomar decisiones unilateralmente.

****** Sociedad de responsabilidad limitada nueva empresa (SLNE)
La *sociedad limitada nueva empresa* es una especializacin de la
sociedad limitada que facilita su crecin. Se da de alta en un
procedimiento telemtico de 48 horas y se utilizan modelos genricos
para constituirla.

****** Sociedad annima (SA)
En una *sociedad annima*, el capital se divide en partes iguales
(alcuotas) llamadas *acciones*. Las acciones se transmiten libremente
en el mercado financiero a terceros, suelen representar un voto y la
responsabilidad de los socios o /accionistas/ se limita a su
aportacin. Es el nico tipo de sociedad que puede cotizar en Bolsa.

Necesita 60000 como capital mnimo inicial.

****** Empresas de economa social
Las *empresas de economa social* suelen constituirse para solventar
crisis de las empresas. Suelen ser democrticas.

******* Sociedades cooperativas (SC)
Las *sociedades cooperativas* no tienen nimo de lucro. Cada socio
aporta capital y trabajo; responde slo con el capital aportado y
tiene un voto independientemente del capital. Es /limitada/ y 
/solidaria/.

Estas uniones de trabajo asociado suelen darse cuando los trabajadores
tienen un objetivo comn fuerte. Tienen regulacin estatal y
autonmica y en ocasiones exenciones fiscales (las andaluzas se llaman
SCA).

El beneficio se llama /retorno/. Las reservas (la parte del beneficio
que no se distribuye entre los socios), suelen ser ms grandes. Suelen
tener una reserva obligatoria para invertir en la formacin de los
socios.

/Ejemplo: cooperativa Mondragn/

******* Sociedades laborales
Las *sociedades laborales* son sociedades annimas o de responsabilidad
limitada donde los trabajadores poseen al menos el 51% del capital.

Suelen ser intentos de los trabajadores de evitar la quiebra de la
empresa.

***** Clasificacin de empresas segn tamao
La clasificacin segn tamao se realiza en base a varios criterios, tales
como

 * *nmero de trabajadores* contratados en la empresa.

 * *volumen de negocio anual*, el total de ingresos por ventas
   contabilizadas. Equivale al valor total de los bienes y servicios
   vendidos en un ao.

 * *balance general anual (activo)*, bienes y derechos de la empresa, sin
   contar las obligaciones de pago, que perteneceran al /pasivo/.

Por ellos se dividen en: grandes, medianas, pequeas y
microempresas. El 99.9% de empresas en Espaa son PYMEs (pequeas y
medianas empresas).

****** Empresas autnomas o asociadas
En el caso de que la empresa tenga relacin con otras, sus datos
debern incluirse al calcular su tamao. Una empresa se clasifica
segn su relacin con otras en

  * *autnoma* si es totalmente independiente y no tiene participacin en
    otras empresas, ni otras empresas en ella.
  * *asociada* si hay terceros con ms del 25% de la empresa o tiene
    participacin de ms del 25% en otra empresa.

Aun as existen empresas que se consideran autnomas a pesar de esto.
Adems, dos empresas estn *vinculadas* cuando una puede ejercer
influencia dominante sobre la otra, ya sea nombrando miembros del
consejo de administracin, mediante clusulas estatutarias o contratos.

**** 1.2. Enfoque sistmico de la empresa
***** Definicin de sistema
Un *sistema* es un conjunto de elementos relacionados dinmicamente que
realizan una actividad para alcanzar un objetivo; operando con entradas
y proveyendo salidas.

***** Condiciones para la existencia de un sistema
Para considerar algo un sistema se le exigen

 * un *conjunto de elementos*, los factores productivos.
 * una *estructura de sistema*, jerarqua de la empresa.
 * un *plan comn*, la misin de la empresa.
 * unas *funciones caractersticas*, las funciones tcnicas y
   administrativas que desarrollan la actividad.
 * un *conjunto de estados*, el balance de la empresa.

La empresa transforma materias primas (proceso tcnico), transforma
ahorro en capital (proceso financiero) y procesa informacin (proceso
mental).

***** Clasificacin de sistemas
Se clasifican en

 * *abiertos* si se relacionan con el entorno.
 * *cerrados* si no interaccionan con el entorno.
 * *naturales* si no influye el ser humano en su creacin.
 * *artificiales* si se crean por voluntad humana.

La empresa se considera un sistema abierto artificial.

***** Retroalimentacin o feedback
La empresa se considera *autorregulada* porque cuando se desva de los
objetivos, el proceso de *retroalimentacin o feedback* permite
conocer a la empresa que se han producido estas desviaciones y
corregirlas. Puede as adaptarse al entorno.

La *homeostasis* es la capacidad de la empresa de mantener esa
estabilidad.

**** 1.3. Subsistemas funcionales de la empresa
***** Principio de jerarqua
El *principio de jerarqua* permite descomponer un sistema en
subsistemas y estudiarlos concretamente.

***** Subsistemas segn criterio funcional
El *criterio funcional* de jerarquizacin divide a la empresa en tantos
subsistemas como actividades desarrolle. Estos son

 * *subsistema de aprovisionamiento*, que adquiere los insumos.
 * *subsistema de produccin*, transforma insumos en productos.
 * *subsistema de comercializacin*, decide precio, promocin y
   distribucin.
 * *subsistema de recursos humanos*, selecciona y orienta
   trabajadores.
 * *subsistema financiero*, decide los fondos y aplica inversiones.
 * *subsistema de direccin*, estrategia y gestin de la empresa.

***** Sinergia
La *sinergia* es el aumento de productividad de varios sistemas cuando
interactan entre ellos frente a cuando trabajan de manera aislada.

**** 1.4. La direccin de empresas
***** Eficiencia y eficacia
La *eficacia* mide el nivel de cumplimiento de los objetivos. La *eficiencia*
mide el uso de la cantidad adecuada de recursos para lograr sus objetivos.

Una empresa bien dirigida debe ser eficaz y eficiente.

***** Funciones de los administradores
La gestin empresarial define las siguientes *funciones del directivo*, que
son propias del subsistema de management o direccin.

 * La *planificacin* define la estrategia de la empresa y los planes para
   conseguir los objetivos.
 * La *organizacin* disea la estructura para realizar las tareas,
   asignando personal y decidiendo cmo se tomarn decisiones.
 * La *direccin* coordina a la organizacin, motivando, comunicando y
   resolviendo potenciales conflictos.
 * El *control* vigila el desempeo de la organizacin, lo compara con
   los objetivos y lo corrige en caso de que sea necesario.

*** 2. Teoras de la empresa y del empresario
**** 2.1. Teoras de la empresa
# Nada

**** 2.2. Teoras del empresario
***** Evolucin histrica del empresario
Se consideran figuras distintas segn la poca, en

 * *capitalismo mercantilista* (S. XVI-XVIII), existe un estado que es el
   agente econmico predominante y mercaderes, que simplemente comercian.
 * *revolucin industrial* (S. XVIII-XIX), se desarrolla el pensamiento
   clsico capitalista del empresario *Adam Smith* habla de la regulacin
   del mercado por la mano invisible. En el siglo XIX, *Karl Marx* explica
   el beneficio como la extraccin de la plusvala de los trabajadores
   mediante la propiedad privada de los medios de produccin.
 * *aportaciones posteriores*, Cantillon define en el S. XVIII el
   /entrepreneur/ y habla del talento del empresario. Say aporta la
   funcin directiva en el S. XIX.

***** Teora del empresario riesgo. Knight (1921)
*Knight* desarrolla la figura del empresario como persona que asegura las
rentas de los factores productivos, adelantando el pago. El riesgo que
asume al aportar el dinero es lo que justifica el beneficio empresarial.

Los riesgos sern

  - *tcnicos*, como cumplir con la produccin esperada.
  - *financieros*, al aportar el capital inicial.

***** Teora del innovador de Schumpeter (1912)
*Schumpeter* diferencia en /Teora del desenvolvimiento econmico/
entre capitalista y empresario. El empresario ser el que aplica una
tecnologa existente a un problema real, el capitalista pone el dinero.

Se justifica el beneficio porque se dice que esa innovacin es la que
desencadena el desarrollo econmico y social.  As, el empresario que
innova es el motor del progreso econmico y social.

El cambio tecnolgico se desarrolla en un ciclo entre un *monopolio*
*temporal* del empresario sobre la innovacin y lo pierde luego a una
*situacin de equilibrio*.

# **** Autnomos
# Nos dicen que hay menos autnomos en Espaa que en Europa por
# culpa de las cuotas de autnomo. Aqu artculos en contra:
#
# - [[http://www.ticbeat.com/empresa-b2b/desmontando-el-mito-de-la-cuota-de-autonomos-en-espana-y-europa/][Desmontando el mito de la cuota de autnomos en Espaa]]
# - [[http://www.elderecho.com/actualidad/Espana-quinto-Europa-autonomos-ATA_0_457500143.html][Espaa, quinto pas de Europa que ms autnomos crea con 46.000 nuevas altas]]
#
# Pero hay miles a favor tambin. Ojal manejramos datos.

****** Proceso de cambio tecnolgico
Se definen tres fases

 - *invencin*, generacin de nuevas ideas, ajena a la actividad empresarial.
 - *innovacin*, aplicacin de la invencin a un producto.
 - *imitacin*, difusin de la innovacin.

***** Tecnoestructura de Galbraith (1950s)
*Galbraith* supera la concepcin de empresario como persona y deja que
delegue en la /tecnoestructura/, un grupo de personas, un rgano
colegiado, que dirige la empresa.

Separa propietario (capital de la empresa) y gestor (administracin).

**** 2.3. Propiedad, direccin y gobierno de la empresa
***** Definicin de directivo
El *directivo* supervisa la combinacin de los recursos productivos. Sus
funciones son

 * fijar objetivos y toma decisiones.
 * coordinar la empresa.
 * coordinar relacin de la empresa con el entorno.

Los directivos suelen ser los mismos propietarios, pero pueden ser gestores
contratados u otras personas al nombre del propietario.

***** Definicin de capitalista
El *capitalista* es el propietario del capital de la empresa.

***** Empresario
El *empresario* es un directivo capitalista. 

/Ejemplos: Amancio, Florentino./

****** Emprendedor
Llamamos *emprendedor* al empresario que es a su vez el creador de la
idea del negocio o del cambio y se implica a nivel gestor y
capitalista.

****** Empresario individual propietario
Segn Cuervo (1997), es el empresario clsico en el que convergen 
capitalista y directivo; sigue las nociones de [[*Teora del empresario riesgo. Knight (1921)][empresario riesgo]] y
[[*Teora del innovador de Schumpeter (1912)][empresario innovador]].

****** Empresario corporativo
Controla la empresa sin participar significativamente en el capital.
Es parte slo de la tecnoestructura.

***** Estructura de la propiedad de la empresa
La *estructura de la propiedad* de una empresa es el modo en el que se
distribuye la propiedad del capital de la empresa entre sus
propietarios legales. Todo partcipe en el capital de la empresa tiene
la consideracin legal de *propietario*; es decir, los propietarios
son las personas (fsicas y jurdicas) que aportan el dinero y los
bienes necesarios para la actividad productiva.

Los propietarios pueden haber accedido a la titularidad

  * crendola.
  * heredndola.
  * comprndola.

****** Grupos de propiedad
Se consideran los siguientes grupos de propiedad en la empresa

 * sector pblico.
 * particulares y familias.
 * empresas industriales y servicios (capital empresarial).
 * entidades financieras (capital bancario).

La estructura de la propiedad refleja la importancia relativa de los
grupos. Vara segn sectores y pases y condiciona los objetivos que
persigue la empresa.

***** Estructura accionarial
La /estructura de la propiedad/ en sociedades annimas se distribuye
entre los *accionistas*. Los hay de dos tipos

 * *accionistas de control*, si son activos en las decisiones de la
   empresa.
 * *accionistas pasivos*, si son simples inversores financieros.

La estructura accionarial completa se divide en

 * *Autocartera*, las acciones propias que la sociedad mantiene entre
   sus activos.
 * *Accionistas mayoritarios y de control*, que tienen control de la
   empresa.
 * *Pequeos accionistas*, capital flotante en compraventa libre en el
   mercado financiero. Son propietarios sin poder en la empresa, para
   controlarla necesitan asociarse.
 * *Inversores institucionales*, sociedades de inversin, fondos de
   pensiones o compaas de seguros que buscan la rentabilidad.

***** Gobierno corporativo
El *gobierno corporativo* es la estructura que concreta las relaciones
entre todos los /stakeholders/ para establecer los objetivos de la empresa
y los medios para controlarla.

****** Motivacin
Cuando las empresas son pequeas, suele coincidir la propiedad y la
gestin. Conforme crecen, deben dotarse de estructuras que limiten
conflictos y aseguren que los directores no toman decisiones
contrarias a los propietarios.

Se intenta paliar un problema que surge en un contexto de informacin
asimtrica; donde las partes interesadas pueden tener intereses
contrarios a la empresa.

****** Responsabilidad social corporativa
Los criterios de *responsabilidad social corporativa* (RSC) son cdigos
de buen gobierno que buscan asegurar
 
 * la confianza y la transparencia.
 * el adecuado funcionamiento de los rganos y la separacin entre ellos.
 * el control interno y la responsabilidad.

En particular, las empresas que cotizan en la comisin del mercado de
valores deben seguir un cdigo de gobierno especfico.

***** Mecanismos de control
Los *mecanismos de control* delimitan el modelo de gobierno corporativo que
sigue la empresa.

***** Mecanismos internos de control
Los *mecanismos internos* son los diseados por la propia organizacin.

****** Junta general de socios accionistas
En una /sociedad annima/, la *Junta General de Socios* es una reunin
de accionistas que toma acuerdos por mayora. 

Sus competencias son:

 * nombrar al consejo de administracin.
 * nombrar y destituir administradores.
 * disolver la sociedad.
 * elegir consejero ejecutivo.
 * adquirir de determinados bienes y tomar otras decisiones.

Es obligatoria y debe reunirse anualmente. Ntese que no puede
administrar, tomar acuerdos contrarios a los estatutos o representar a
la sociedad; slo puede nombrar a los /administradores/.

****** Consejo de administracin
En /sociedades de capital/ (limitadas, annimas y comandatarias), el
*consejo de administracin* est formado por personas elegidas por los
propietarios que administran y representan a la empresa.

Est compuesto por:

 * *Consejeros internos o ejecutivos.* Delegados de la
   empresa. /Ejemplo: Jobs, Zuckerberg./
 * *Consejeros externos dominicales.* Significativos. Representan
   empresas con capital en la sociedad.
 * *Consejeros externos independientes.* Expertos en gestin que son
   independientes. /Ejemplo: Felipe Gonzlez, Jos Mara Aznar./

****** Caso de las empresas pequeas
Normalmente coinciden. Slo a partir de cierto tamao tienen que
nombrar administradores.

***** Mecanismos externos de control
Los *mecanismos externos* son los que se derivan de la estructura de la
economa de mercado.

****** Oferta Pblica de Adquisicin de Valores (OPA)
Intenta comprar parte de una empresa para controlar sus cambios de
direccin. Puede intentarse por alterar su estructura financiera o
para construir imperios empresariales.

****** Mercados financieros
Con los fondos se determinar el valor de la empresa y la posibilidad
de ser controlada desde el exterior.

****** Mercado laboral de consejeros y directivos
La alta competencia del mercado laboral de consejeros y directivos hace
que funcionen correctamente. Se compra su reputacin positiva, que deben
haber ganado en otras empresas previamente.

**** 2.4. La direccin: funciones y niveles
La *direccin* consiste en la integracin de las distintas partes de la
empresa entre s. Se divide en varios niveles de jerarquizacin de las 
decisiones.

***** Alta direccin
La *alta direccin* est formada por personas con responsabilidad
sobre toda la empresa que fijan los grandes objetivos.  Lo forma el
/comit ejecutivo/ de la empresa con el /director ejecutivo/ (tambin
consejero delegado o CEO) y las personas que considere para participar
de los anlisis gestores de la empresa. 

/CEOs, Comit Ejecutivo, Presidente Ejecutivo, Consejero Delegado./

***** Direccin media
La *direccin media* la forman los directivos que actan como enlace
jerrquico entre la alta direccin y la direccin de primera lnea.
Marcan objetivos a medio y corto plazo, que deben estar alineados con
los grandes objetivos.

/Directores departamentales, director financiero, director comercial./

***** Direccin de primera lnea
La *direccin de primera lnea* la constituyen supervisores y directivos
que toman decisiones en problemas diarios y rutinarios para la empresa.

/Jefes de equipo, capataces, jefe de planta./

*** 3. Entorno de la empresa
**** Objetivos
Conocer:

 - Anlisis de entorno. PEST.
 - Comprender su utilidad en la direccin estratgica.

En conjunto forma el anlisis DAFO.

***** Anlisis externo: amenazas y oportunidades
Provenientes del entorno.

 * *Amenaza*, aspecto negativo del entorno.
 * *Oportunidad*, aspecto positivo del entorno.

***** Anlisis interno: debilidades y fortalezas
Provenientes de la propia empresa.

 * *Debilidad*, aspecto negativo interno.
 * *Fortaleza*, aspecto positivo interno.

**** 3.1. Definicin de entorno
Entendiendo la empresa como un sistema abierto que se relaciona con el
exterior, tiene sentido estudiar el entorno como el conjunto de
fuerzas externas con las que se relaciona. 

***** Definicin de entorno
El *entorno* es el conjunto de factores que, siendo /externos/ a la
empresa, tienen o pueden tener incidencia en sus actuaciones y
resultados. La viabilidad depende de la empresa depende de ellos.

*(!) Nada que sea parte de la empresa es entorno de la empresa.*

****** Definicin de Downey y Slocum
El *entorno* es un conjunto de personas y grupos con las que la
organizacin tiene relaciones de intercambio y de las que depende su
viabilidad.

****** Definicin de Mintzberg
El *entorno* es todo aquello ajeno a la empresa como organizacin.

***** Relacin con el entorno
Segn sus decisiones cambia su relacin con el entorno. La empresa
puede influir, pero no controlar el entorno.

****** Factores estratgicos
El entorno est formado por los *factores estratgicos*, que son todos
los factores que pueden incidir en las actuaciones de la empresa son
los factores estratgicos, tanto en el presente como en el futuro. Son
*amenazas* y *oportunidades*.

****** Entorno relevante
La influencia del entorno puede ser diferente segn tiempo y
organizacin. Los factores estratgicos son los ms influyentes y
sobre los que centra la atencin el anlisis de entorno; aquellos
que afectan a la empresa son parte de su entornro relevante.

****** Anlisis del entorno
Debe sistematizarse el anlisis de los factores estratgicos para 
tratar de estar preparado y anticiparse a los cambios.

***** Lmites del entorno
Los lmites del entorno varan segn la relacin con el exterior.
Los proveedores pueden considerarse internos a la empresa. Son los
llamados *lmites difusos*.

***** Niveles del entorno
Segn /Bueno (2002)/, se establecen varios niveles del entorno segn
el mbito geogrfico.

 * Entorno *global*, a nivel mundial.
 * Entorno *internacional*, a nivel de una regin internacional.
 * Entorno *nacional o domstico*, a nivel del pas.
 * Entorno *regional*, dentro de un pas o varios pases.
 * Entorno *local*, a nivel de un ncleo urbano.
 
La mayora de las empresas en la actualidad funcionan a niveles globales,
debido a la /globalizacin/ de la actividad econmica.

**** 3.2. Caractersticas del entorno
Las *caractersticas del entorno* son los atributos a los que se enfrenta
una organizacin. 

Identifica /caractersticas o atributos/ que definen unos entornos
frente a otros.

***** Entorno como fuente de recursos
La idea del entorno como *fuente de recursos* aparece en las teoras de
Aldrich, Pfeffer y Salancik. Estas fuentes de recursos se caracterizan por

 * si los recursos son *abundantes*.
 * si los recursos son *variados*.
 * si estn *concentrados*.
 * si otras empresas *compiten* por ellos.

En base a estas caractersticas se consideran distintos tipos de entorno.

****** Estable-Aleatorio
En un entorno *estable-aleatorio*, no hay competencia por los recursos,
estn distribuidos y son abundantes.

/Ultramarinos de un pueblo. No hay competencia pero hay demanda estable./

****** Plcido-Integrado
En un entorno *plcido-integrado*, los recursos son estables pero estn
concentrados; haciendo algunas posiciones en el entorno ms ventajosas
que otras.

/Silicon Valley aprovecha recursos tecnolgicos de la zona./

****** Inestable-Reactivo
En un entorno *inestable-reactivo* los cambios son pocos pero
existen varias empresas con las mismas necesidades de recursos. Todos
los movimientos por los recursos sern respondidos por los
competidores.

/Empresas de software intentando captar empleados./

****** Turbulento
En un entorno *turbulento* existe competencia entre las empresas y
adems las condiciones y los recursos estn en continuo cambio.

/Empresas en zonas de inestabilidad poltica./

***** Entorno como fuente de incertidumbre
La idea del entorno como *fuente de incertidumbre* aparece en las
teoras de Duncan, Lawrence y Lorsch. Se considera el entorno como una
fuente de informacin sobre la que la empresa toma decisiones. Estas
fuentes de informacin se caracterizan por

 * la *predecibilidad e incertidumbre*, que viene dada por la cantidad
   de informacin a la que se puede acceder en el entorno.

Se establecen cuatro dimensiones para medirlo.

****** Dinmico/Estable
Un entorno es *dinmico* si hay variaciones numerosas e impredecibles;
y es *estable* si no hay cambios o son muy predecibles.

****** Complejo/Sencillo
Un entorno es *complejo* cuando se necesitan muchos conocimientos
especficos para entenderlo; y *sencillo* cuando el conocimento es
comprensible.

****** Diverso/Integrado
Un entorno es *diverso* cuando hay un gran nmero de clientes
distintos a los que abastecer; e *integrado* cuando son todos
similares y se concentran en reas prximas.

****** Hostil/Munificiente
Un entorno es *hostil* cuando existe mucha competencia por los
recursos; y *munificiente* cuando la competencia es pequea.

***** Entorno general
El *entorno general* est integrado por un conjunto de factores que
ejercen influencia sobre todas las empresas dentro de un sistema
socioeconmico.

****** Definicin de Cuervo (2001)
El *entorno genrico* agrupo los elementos que afectan de manera
similar a todas las empresas en un espacio dado independientemente
de su sector.

***** Entorno general: Anlisis PESTEL
El *anlisis PESTEL* tiene como objetivo diagnosticar el entorno
general valorando el impacto que varias variables tienen en la
actuacin de la empresa. Identifica las principales oportunidades y
amenazas.

****** Variables
El anlisis *PESTEL* analiza las dimensiones

 * *poltica*, dada por la estabilidad, proteccionismo e
   intervencionismo del estado. Nivel de corrupcin de un pas.

 * *econmica*, dada por factores econmicos como

   - la /inflacin/, maracada por el IPC y los precios al
     consumo. Hay inflacin y deflacin segn suban o bajen.
   - la /tasa de desempleo/.
   - el /tipo de cambio/ frente al dlar como base.
   - la /renta disponible/ de las familias, corregida por inflacin.
   - los /tipos de inters/.

 * *social*, dada por preferencias como valores, creencias,
   desigualdad, religin, feminismo, tradicin, cultura.

 * *tecnolgica*, dada por el grado de infraestructuras del
   pas. Gasto en I+D. Inversin pblica del gobierno y
   patentes. Leyes de proyeccin del conocimiento.

 * *ecolgica*, dada por la poltica medioambiental y el consumo de
   energa.

 * *legal*, dada por la legislacin laboral, la normativa de fusiones
   y adquisiciones y las restricciones a la libre competencia.

****** Etapas del anlisis
El anlisis PEST se divide en varias etapas

 * en el *Paso 1*, se delimitan los factores estratgicos y se estudia
   qu variables pueden tener ms incidencia sobre la empresa. Se
   estudian /variables y factores clave/.

 * en el *Paso 2*, se describe la evolucin esperada de los factores
   estratgicos del entorno.

 * en el *Paso 3*, se valoran y jerarquizan las oportunidades y
   amenazas.

****** Realizacin de la tabla y perfil estratgico del entorno
Todo el anlisis puede representarse en una tabla plantilla que
considera los factores principales del entorno. Pueden colocarse
tambin en un perfil estratgico del entorno.

****** Consideraciones sobre el anlisis PEST
El anlisis PEST proporciona una herramienta fcil de usar e
interpretar, pero tiene el problema de que

 * es un anlisis muy subjetivo y cualitativo. 
 * este anlisis debe entrar en detalles y por tanto debe tratar los
   factores ms relevantes.
 * no todas las variables estarn en un anlisis PEST. Hay que ser
   selectivos y slo considerar los factores estratgicos.
 * el impacto de un mismo entorno puede variar entre distintas
   industrias y entre empresas de una misma industria.

En ocasiones se utiliza el anlisis PESTEL como una ampliacin del
anlisis PEST.

***** Entorno general: Diamante de Porter
***** Entorno especfico
El *entorno especfico o competitivo* lo forma el conjunto de empresas
que se dedican a la misma actividad econmica que la empresa que se
est analizando y que conforman su /sector/. El entorno especfico
marca las reglas de competencia.

****** Componentes de Hall (1996)
Segn Hall, el entorno especfico est formado por

 * *proovedores* de los recursos necesarios.
 * *clientes*, que consumen los productos.
 * *competidores*, que compiten por los recursos y clientes.
 * *reguladores* que controlan y fiscalizan a las organizaciones.

***** Entorno especfico: Modelo de Porter (2009)
El *modelo de las cinco fuerzas competitivas de Porter*, desarrollado
en el 2009 mide el /grado de atractivo/ de una industria por cinco
fuerzas competitivas bsicas, que definen la posibilidad de obtener
rentas superiores en la industria. A ms rivalidad, menos posibilidad
de obtener rentas superiores.

Tambin se llama *modelo de rivalidad ampliada*.

****** 1. Competidores actuales
Grado de rivalidad con los competidores del sector. La amenaza que
representan depende de varios factores.

******* Nmero y equilibrio entre competidores
En las *industrias concentradas* hay pocos competidores y estn muy
desequilibrados formando oligopolios; no hay competencia. En las
*industrias fragmentadas* hay muchos competidores y estn equilibrados,
por lo que la competencia es mayor.

/Un ejemplo de industria concentrada es la farmacutica./
/Un ejemplo de industria fragmentada son los bares./

******* Ritmo de crecimiento del sector
El ritmo de crecimiento determina la competencia. Cuanto ms reciente
es el sector, menos competencia hay. Segn el ritmo de crecimiento una
industria se consideran las fases de

 * *introduccin*, donde la industria se est creando. Un ejemplo
   son los coches autnomos.

 * *crecimiento*, donde hay oportunidades y /menos competencia/. Un 
   ejemplo son los drones.

 * *madurez*, donde la industria se estabiliza. Un ejemplo son los
   electrodomsticos.
   
 * *declive*, donde las ventas se reparten y hay /ms competencia/.
   Un ejemplo son los SMS.

Y la posibilidad de incrementar las ventas es ms difcil
despus. La intensidad de la competencia es mayor conforme
avanza.

******* Barreras de movilidad
Las *barreras de movilidad* son las que se encuentran las empresas
para ampliar su lnea de productos a otros segmentos. Si hay muchas
barreras, las empresas se quedarn donde estn y la competencia del
sector ser menor.

******** Ejemplo: banca privada
Es muy difcil iniciarse en la banca privada. Hay unas barreras muy
grandes entre servicios usuales y los servicios privados. Los
contratos suelen estar blindados y los canales de distribucin suelen
trabajar con las marcas que ya conocen.

******** Ejemplo: automocin
Slo unas pocas fabrican coches y camiones. Es difcil saltar del
diseo de unos al diseo de otros; se necesita tecnologa, cadenas
y materiales diferentes.

******* Barreras de salida
Las *barreras de salida* son el equivalente a la movilidad a nivel
del sector. Cuanto ms difcil sea salir del sector, ms se intentar
sobrevivir y mayor ser la competencia.

******** Ejemplo: activos especializados
Si hay activos especializados que no se amortizan, y que por ser tan
especficos, es muy difcil vender.

******** Ejemplo: costes fijos de salida
Para cerrar, hay que hacer frente a costes como los costes de
despidos. Las empresas que no quieren pagarlos, se mantienen en el
sector.

******** Ejemplo: imagen de marca
En ocasiones se mantiene un sector slo para mantener el prestigio de
la imagen de marca. El dao a la imagen es un coste de salida.

******** Ejemplo: empresas familiares
La barrera emocional de seguir negocio familiar tradicional constituye
una barrera de salida. Estn dispuestas a continuar a pesar de las
prdidas.

El ejemplo usual es la /almazara/.

******** Ejemplo: presiones externas
Fbricas que emplean a mucha gente en una regin tienen la presin
externa para seguir empleando a la gente.

******* Estructura de costes de las empresas
Un mayor peso de los costes fijos en la *estructura de costes* lleva
a operar a plena capacidad y por tanto a incrementar la intensidad
competitiva.

******** Estructura de costes
La *estructura de costes* es la proporcin entre costes fijos y
costes variables que cumplen $CT = CF + CV$ siendo
 
 * CF: los *costes fijos*. Hay que pagarlos siempre.
 * CV: los *costes variables*. Se pagan segn cunto produzcas.
 * CT: los *costes totales*.

******** Margen de beneficio
El margen de beneficio es la diferencia del precio y el coste de
produccin unitario $\mathrm{margen_{unitario}} = p - c_v$. El margen bruto es el
margen unitario por nmero de unidades

\[\mathrm{margen} = u(p - c_v).
\]

Ntese que es distinto del beneficio (!), que tiene en cuenta tambin
los costes fijos. El beneficio es $B = \mathrm{Ingresos} - CT$.

As, cuando los costes fijos son muy grandes, es muy difcil entrar
en la competencia, as que la competencia ser menor. El *punto muerto*
es el punto a partir del cual se van a obtener beneficios.

******* Grado de diferenciacin de los productos/servicios
La *diferenciacin* de productos disminuye la intensidad de la
competencia. Cada uno vende cosas distintas y tiene una cartera de
clientes fieles que es difcil que cambien de proveedor.

/Ejemplo: compaas telefnicas tienen poca diferenciacin./
/Ejemplo: las bebidas son diferentes./

******* Costes de cambio
Los *costes de cambio* son los que debe asumir un cliente para cambiar
de proveedor. Cuantos ms altos, ms difcil es que cambie un cliente
y menor es la competencia. Pueden ser tcnicos, de formacin o
financieros.

/Ejemplo: es difcil el cambio de compaa telefnica por permanencias./

******* Capacidad productiva instalada
Cuando ms *capacidad productiva* instalada, hay ms necesidad de
vender los productos, y ms alta es la competencia.

/Un planta produciendo 1000 unidades/da debe producir a ese volumen./ 

******* Diversidad de competidores
Si los competidores difieren en estrategias, puede aumentar la
competitividad.

******* Intereses estratgicos
Cuando todas las empresas estn interesadas en el sector, mayor ser
la competencia.

****** 2. Competidores potenciales
Los *competidores potenciales* son las empresas potencialmente
interesadas en entrar en el sector. La amenaza depende de dos
factores.

******* Barreras de entrada
Las *barreras de entrada* son los obstculos que enfrentan las
empresas para entrar al sector. Se resumen en

 1. la *economa de escala*. Las empresas que entran al sector deben
    hacerlo a gran escala para beneficiarse de las reducciones de
    costes que da el incremento de volumen productivo; esto supone
    una barrera para los nuevos. Al caso contrario se le llama una
    /deseconoma de escala/. La sinergia es una causa de la economa
    de escala.

 2. la *diferenciacin de productos*. Cuando todos tienen
    diferenciados sus productos, para entrar al sector habr que
    ofrecer algo diferente para poder competir al mismo nivel.

 3. las *necesidades de capital*. Un sector que necesita una inversin
    muy grande tiene una barrera de entrada muy grande.

 4. los *costes de cambio*. Si los clientes estn fidelizados, el que
    entre nuevo en el sector va a tener que saltar la barrera de los
    costes de cambio.

 5. el *acceso a canales de distribucin*, que normalmente estarn en
    manos de las empresas del sector.

 6. las desventajas en *costes de desarrollo*. Hay que pagar patentes
    o desarrollar tecnologas alternativas. Hay que encontrar buenas
    localizaciones, que las tienen las empresas del sector. La
    experiencia del sector la tienen las empresas.

 7. la *poltica gubernamental*. Pueden existir restricciones que
    limitan la entrada al sector. Normas reguladoras de la competencia
    que impiden la libre competencia en el mercado.

******* Represalias esperadas
Represalias de los competidores que estn ya en el sector contra
los nuevos competidores. Las represalias son mayores cuanto ms
recursos de defensa pueden invertir en la represalia.

/Empresas como las teleoperadoras pueden ejercerlos contra nuevas
empresas./

****** 3. Productos sustitutivos
Los *productos sustitutivos* son aquellos que cubren las mismas
funciones desde el punto de vista de los clientes usando otra tecnologa
u otras materias primas.

Si hay muchos productos sustitutivos, ser menos atractivo el sector;
depender adems de

  * el grado de *sustitucin*.
  * los *precios relativos* al sustitutivo.
  * *obsolescencia* que causan los sustitutivos.
  * *costes de cambio* al sustitutivo.

Pueden no tener siquiera el mismo CNAE, y no los consideramos dentro
del mismo sector, pero hay competencia entre ellos.

/Ejemplo: azcar y sacarina./

/Ejemplo: aceite oliva y el girasol./

****** 4. Proveedores
A mayor poder de *negociacin de los proveedores*, ms podrn influir en
el coste o los plazos de entrega de las empresas del sector. Cuanto
ms concentrados estn y menos sustitutos haya para los proveedores,
ms poder de negociacin tendrn.

******* Integracin vertical
La *integracin vertical* es el proceso por el cual un proveedor o
un cliente pasa a integrar otra parte de la cadena de produccin.

El poder de negociacin del proveedor aumenta cuanto ms informado
est el proveedor y ms fcil sea que entre en el sector por
integracin vertical.

/Ejemplo: Inditex realiza integracin hacia atrs al producir tela./

/Ejemplo: Apple realiza integracin hacia alante al crear tiendas./
******* Nmero de proveedores y grado de concentracin
******* Grado de diferenciacin de los proveedores
******* Existencia de productos sustitutos al del proveedor
******* Importancia de nuestra empresa para el proveedor
******* Nivel y calidad de la informacin
****** 5. Clientes
A mayor poder de *negociacin de los clientes*, ms podrn influir en
lo que debe producir la empresa.

******* Nmero de clientes y grado de concentracin
******* Grado de diferenciacin de los productos
******* Existencia de sustitutos al producto
******* Amenaza de integracin vertical
******* Informacin de la que dispone el cliente
***** Entorno especfico: limitaciones y extensiones del modelo
Al modelo de las 5 fuerzas de Porter se le plantean las siguientes
crticas y limitaciones

 * tiene un *carcter esttico*, requiere de una actualizacin del
   anlisis siempre que se pueda.
 * no tiene en cuenta *industrias auxiliares* y complementarias; no
   considera relaciones de colaboracin.
 * la realidad es *heterognea*, no todas las fuerzas ni todos los
   factores tienen la misma influencia.
 * no todos los *competidores* se encuentran afectados de la misma
   manera por las fuerzas del sistema. (Se intenta salvar esto
   mediante el anlisis de los sectores estratgicos, que aplica un
   anlisis particular en los distintos grupos estratgicos; es
   distinta la competencia de Inditex y la de una pequea textil)

*** 4. La direccin estratgica
**** 4.1. Concepto de direccin estratgica
La *direccin de empresa* es la gestin diaria de la misma para lograr
eficacia y eficiencia. Este concepto contrastar con la idea de
direccin estratgica.

***** Concepto de estrategia
La *direccin estratgica* es el proceso de diseo e implantacin de
una estrategia con la que responder al entorno. 

La idea de la direccin estratgica surge porque la empresa debe
responder a un entorno que es turbulento y que presenta debilidades y
amenazas.

****** Estrategia
Del griego /stratos/ (ejrcito), /ego/ (lder, gua); se entiende
como la gua que marca el camino de la empresa hacia unos objetivos.

****** Definicin de estrategia (Johnson)
La *estrategia* es la direccin en el sentido de orientacin a largo
plazo para lograr ventajas en un entorno cambiante para conseguir
los beneficios de los stakeholders.

****** Definicin de estrategia (Porter)
La *estrategia* es una accin ofensiva o defensiva para obtener una
posicin competitiva en un sector; afrontar las cinco fuerzas
competitivas y conseguir un mayor rendimiento sobre la inversin de la
empresa.

****** Definicin de estrategia (Grant)
La *estrategia* define cmo desplegar la empresa sus recursos en el
entorno para satisfacer los objetivos a largo plazo. La estrategia
aporta coherencia y cohesin, dando sentido a toda la organizacin.

****** Definicin de estrategia (Guerras y Navas)
La *estrategia* es la respuesta que se disea para sobrevivir o para
responder al entorno.

***** Ideas bsicas del concepto
El concepto de estrategia se basa
 
 * en la *respuesta* de la empresa su entorno. El entorno
   es cambiante y por tanto la estrategia tambin lo ser.

 * Tiene el objetivo ltimo de posicionar y mejorar la empresa frente
   a competidores. Busca la *ventaja competitiva*.

 * en conseguir los objetivos a largo plazo de los *stakeholders*.
   Refleja dnde quiere llegar la empresa.

 * en la *toma de decisiones* como proceso que la genera. Se evalan
   distintas opciones segn su ajuste a la empresa y al entorno.

 * en definir los *cursos de accin*. En la estrategia se *definen las
   decisiones* que se toman en toda la organizacin. El resto de
   decisiones se supeditan a ella.

***** Componentes de la estrategia: campo de actividad
El *campo de actividad* es el conjunto de productos y mercados que
componen la actividad econmica de la empresa. La estrategia define
/el campo de actividad/.

Puede estar integrado por distintas *Unidades Estratgicas de Negocio*
*(UEN)*, conjuntos homogneos para los que se puede definir una
estrategia especfica para ellos y diferente a las dems.

****** Empresa diversificada
Las *empresas diversificadas* son aquellas que tienen varias Unidades
Estratgicas de Negocio, actuando en varios sectores distintos. Las
estrategias en cada uno de ellos sern distintos.

Existen dos tipos de diversificacin

 * se considera *diversificacin relacionada* si se pueden compartir
   proveedores, canales de distribucin o partes del proceso de
   produccin entre varias UEN.

 * se considera *diversificacin no relacionada* si no se comparten
   partes del proceso de produccin entre UEN.

/Ejemplo: Danone hace diversificacin relacionada/

/Ejemplo: Virgin hace diversificacin no relacionada./

****** Estrategias distintas
Cada UEN tiene una estrategia competitiva distinta porque

 * se desarrolla en un *entorno* distinto.
 * tiene *competidores* distintos.
 * tiene *oportunidades* distintas.
 * las *competencias* y capacidades requeridas son diferentes.

******** Ejemplo: grupo PRISA
Tiene varias unidades distintas de educacin, noticias, audiovisual...

******** Ejemplo: Danone
Productos lcteos, agua, nutricin mdica y nutricin infantil. Aunque
sean grupos similares, las estrategias sern distintas en cada uno de
ellos.

***** Componentes de la estrategia: capacidades distintivas
Las *capacidades distintivas* son el conjunto de recursos y capacidades
que permiten a la empresa realizar determinados procesos mejor que sus
competidores. Constituyen la base de la /ventaja competitiva/.

/Ejemplo: la capacidad de innovacin./

***** Componentes de la estrategia: ventaja competitiva
La *ventaja competitiva* es el conjunto de caractersticas por las que
se tiene una mejor posicin competitiva respecto a los competidores.

No debe confundirse con las /bases de la ventaja competitiva/, que son
todos aquellos factores que provocan la ventaja competitiva. La ventaja
competitiva es el resultado final de la formulacin e implantacin de
la estrategia de la empresa.

***** Componentes de la estrategia: sinergia
La *sinergia* es el efecto que hace que los recursos y capacidades
integrados ofrezcan un rendimiento mayor al que ofreceran de forma
aislada. La integracin y la conexin entre campos de actividad debe
formar parte de la estrategia.

En las empresas diversificadas las sinergias pueden conseguirse fcilmente
si la diversificacin es relacionada.

***** Niveles de la estrategia
La estrategia se aborda a distintos *niveles* relacionados entre s.
Las estrategias de cada nivel deben estar integradas y ser coherentes
entre s. Derivan de una estrategia corporativa global.

****** Nivel de estrategia corporativa
La *estrategia corporativa* responde a la pregunta de /dnde competir?/.  
Es la estrategia global de la empresa, la que define el campo de actividad.

****** Nivel de estrategia competitiva o negocio
La *estrategia competitiva* responde a la pregunta de /cmo competir?/. 
Persigue alcanzar una /ventaja competitiva/ en costes o en diferenciacin.

****** Nivel funcional
La *estrategia funcional* determina las decisiones a tomar en cada
rea funcional de la empresa teniendo en cuenta los recursos y
capacidades distintivas de la misma.

Implica tomar decisiones sobre

 * direccin comercial o de mrketing.
 * direccin de la produccin.
 * direccin financiera.
 * direccin de recursos humanos.

****** Resumen
La estrategia corporativa decide los campos de actividad, dnde va a
diversificar la empresa. La estrategia de negocio se formula para cada
UEN distinto; y por ltimo, la estrategia funcional decide cmo vamos
a aplicar los recursos dentro de cada rea funcional.

|-------------+----------------------------------+------------------------|
| Corporativa | Campo de actividad de la empresa | Direccin general      |
| De negocio  | UENs                             | Jefes de divisin      |
| Funcionales | reas funcionales                | Directores sectoriales |
|-------------+----------------------------------+------------------------|

**** 4.2. Proceso de direccin estratgica
Anlisis del entorno e interno. En base a l formulamos las direcciones
para los objetivos, decidiremos cul es la ms adecuada y lo implementaremos.

Se divide en varias etapas.

***** Etapa de anlisis estratgico
En la fase de *anlisis estratgico* debe realizarse un diagnstico de
la situacin de la empresa, partiendo del objetivo a largo plazo, la
misin, valores y objetivos.

Partiendo del objetivo a largo plazo, se hace un anlisis DAFO, con un
anlisis tanto externo como interno.

****** Anlisis DAFO
El anlisis DAFO puede usarse en esta fase para analizar la situacin
externa e interna de la empresa. Recoge debilidades y fortalezas,
amenazas y oportunidades.

***** Etapa de formulacin de estrategias
En la fase de *formulacin de estrategias* se disean, evalan y
seleccionan las estrategias que vamos a implementar, a niveles
coorporativo y competitivo.

***** Etapa de implantacin
En la fase de *implantacin de la estrategia* se pone en prctica la
estrategia seleccionada. Suele elaborarse un /plan estratgico/ que
recoja las decisiones tomadas. Puede suponer cambios de direccin, de
equipamiento tcnico, de compromiso, de recursos y de control; y debe
adecuarse a la cultura organizativa de la empresa.

**** 4.3. Opciones estratgicas bsicas
***** Opciones a nivel de estrategia corporativa
Las opciones a nivel de *estrategia corporativa* decidirn la estrategia
global de la empresa; /dnde competir/, qu actividades vamos a
desarrollar y en qu mercados vamos a tener presencia.

****** Estrategias de crecimiento
Las *estrategias de crecimiento* deben responder hacia dnde se quiere
crecer y cmo se quiere crecer. Para ello, nos valemos de la matriz de
Ansoff, que clasifica las estrategias de crecimiento.

|---------------------+------------------------+----------------------|
|                     | Productos Existentes   | Productos nuevos     |
|---------------------+------------------------+----------------------|
| Mercados Existentes | Penetracin de mercado | Desarrollo productos |
| Mercados Nuevos     | Desarrollo de mercados | *Diversificacin*    |
|---------------------+------------------------+----------------------|

Dentro de estas estrategias se consideran tres *estrategias de expansin*, 
que implican crecimiento sin variar el campo de actividad 
considerablemente. Son

 * *estrategia de penetracin en el mercado*, cuando se siguen explotando
   los mismos productos en los mismos mercados. Se busca incrementar
   la cuota de mercado. Se siguen estrategias de mrketing.

 * *estrategia de desarrollo de productos*, cuando se desarrollan nuevas
   variedades de productos para los mercados habituales; o se migra
   hacia modelos superiores.

 * *estrategia de desarrollo de mercados*, cuando se introducen los
   mismos productos en nuevos mercados. Incluye la
   /internacionalizacin/.

Adems, se considera una estrategia que s supone un cambio sustancial,
la

 * *estrategia de diversificacin*, busca explotar productos nuevos
   en mercados desconocidos. Incluye la /integracin vertical/.

****** Formas de crecimiento
La empresa crece con distintos mtodos

 * *crecimiento interno u orgnico* cuando invierte en s misma para
   incrementar su valor econmico y su capacidad productiva.

 * *crecimiento externo* cuando lleva a cabo adquisiciones o fusiones
   con otras empresas; o toma control sobre las decisiones de otra
   empresa. No implica crecimiento real de la economa.

 * *crecimiento hbrido* cuando existen acuerdos temporales entre
   empresas que no varan su identidad jurdica. Ejemplos son 
   la /franquicia/, las /subcontratas/ o los /UTE/.

****** Estrategia de reestructuracin
La *estrategia de reestructuracin* es aquella que emprende cambios en
el *campo de actividad*, reduciendo la importancia de algunos negocios
y abandonando la explotacin de unidades estratgicas. Al abandonar
negocios estamos cambiando nuestro campo de actividad.

***** Opciones a nivel de estrategia competitiva
Las opciones a nivel de *estrategia competitiva* decidirn la estrategia
particular de cada UEN; /cmo competir/, y qu guas deber seguir la
empresa para obtener y mantener la ventaja competitiva.

|-----------+---------------------+----------------------------|
|           | Costes              | Diferenciacin             |
|-----------+---------------------+----------------------------|
| Industria | Liderazgo en costes | Diferenciacin de producto |
| Segmento  | Segmentacin        | Segmentacin               |
|-----------+---------------------+----------------------------|

****** Liderazgo en costes
La estrategia de *liderazgo en costes* persigue producir con costes
inferiores a los de los competidores. Sabiendo que los costes son

\[m = p - c\]

donde

 * $m$ es el margen de beneficio,
 * $p$ el precio unitario del producto, y
 * $c$ el coste unitario.

Puede explotarse la bajada del coste unitario manteniendo el
precio e incrementando su rentabilidad, o disminuyendo el precio
y esperando un aumento de ventas frente a los competidores.

****** Diferenciacin
La estrategia de *diferenciacin* busca que el producto sea percibido
como diferente o superior por los clientes. Por calidad, atencin o
por ser diferente.

Puede explotarse la diferenciacin aumentando el precio unitario y 
manteniendo los clientes gracias a esta diferenciacin.

****** Segmentacin
La estrategia de *segmentacin* se centra en un segmento de los
clientes o se enfoca en slo una parte de la poblacin. Normalmente el
enfoque va acompaado de una estrategia de costes o diferenciacin.

****** Problema: stuck in the middle
Cuando se persiguen los objetivos de coste y diferenciacin a la vez,
se corre el riesgo de no conseguir ninguno. A esto se le llama
quedarse /atrapado en el medio/.

***** Opciones a nivel funcional
Las *opciones estratgicas* a nivel funcional son especficas y
variadas para cada rea funcional. Se consideran compuestas de todas las
decisiones estratgicas derivadas de las decisiones de los niveles
superiores y se clasifican por reas.

****** Produccin
Se toman decisiones como

 * nivel de integracin vertical.
 * nivel de capacidad mxima por unidad productiva.
 * gestin de la produccin.
 * localizacin de la produccin.

****** Mrketing
Se toman decisiones como

 * eleccin del producto.
 * poltica de precios.
 * canales de distribucin.

****** Recursos humanos
Se toman decisiones como

 * incentivos y promocin interna.
 * criterios de seleccin de personal.
 * remuneracin.

****** Financiero
Se toman decisiones como

 * poltica de dividendos.
 * seleccin de inversores.
 * gestin del riesgo.

**** Sobre misin y visin
En el proceso de direccin estratgica, hay una parte de anlisis
externo, anlisis DAFO y anlisis interno. En la formulacin de
estrategias. Pero todo ello depende en primera instancia de la
visin y misin de las empresas.

/Ntese que algunas empresas mezclan misin y visin./

***** La misin
La *misin* es el motivo de la empresa. Responde a la pregunta
de /qu/ hace la empresa. Es la expresin de la identidad de la
empresa y declaracin de propsito general.

****** Diferenciacin
Dos empresas competidoras en el mismo sector tendrn normalmente
misiones distintas. Harn nfasis en cosas distintas.

****** Empresas diversificadas
En empresas diversificadas, la misin es el hilo conductor; pero
pueden enunciarse misiones distintas para las distintas unidades
en casos de diversificacin extrema no relacionada.

***** La visin
Enuncia la *visin* ideal futura de la empresa. Se expresa en trminos
de ideales, procurando que no slo haga referencia a los stakeholders.

***** El eslogan
Ntese que no se relacionan con el eslogan, que es slo un
reconocimiento a nivel publicitario y comercial.

**** Modelos de negocio
La lgica de la estrategia competitiva es crear valor. Los modelos de
negocio estudian cmo construir la ventaja competitiva. El modelo de
negocio se suele plasmar en un lienzo de 9 bloques creado por
Osterwalder (el /Business Model Canvas/).

Dos empresas que satisfacen la misma necesidad a los clientes pueden
tener dos modelos de negocio diferentes.

***** Business model canvas
Debemos entender el problema del cliente y ofrecerle soluciones.
Osterwalder considera que el verdadero producto que ofrece una empresa
es su modelo de negocio.

***** Elementos del modelo de negocio
El orden y tamao de los bloques en el canvas es semntico. La parte
izquierda es el backend mientras que la derecha es el frontend. Abajo
queda la parte financiera.

 * Propuesta de valor.
 * Segmentos de clientes.
 * Canales de comunicacin con el cliente.
 * Relacin con el cliente.
 * Fuentes de ingresos.
 * Asociaciones clave: competidores, proovedores.
 * Canales.
 * Recursos clave.
 * Actividades clave: verbos, acciones esenciales para construir y
   crear la propuesta de valor.
 * Fuentes de ingresos y de gastos.

*** Ejercicios
**** Ejercicio 1
#+begin_statement
En el modelo de las 5 fuerzas competitivas de Porter, qu
representara el nuevo servicio de llamadas de Whatsapp para las
empresas de telecomunicacin en 2015?Crees que supona en aquel
entonces una amenaza relevante?
#+end_statement

El servicio de llamadas de Whatsapp cubre la misma necesidad que
cubran las llamadas tradicionales usando una tecnologa distinta, la
VoIP. Es por tanto un *producto sustitutivo* de las llamadas
tradicionales segn el modelo de Porter.

En el 2015 pareca suponer una amenaza relevante porque era un
sustitutivo accesible a la mayora de consumidores (700 millones de
personas usaban Whatsapp) y existan previsiones de que superara a
las llamadas en 2018. Adems, los SMS eran un precedente de cmo un
proceso similar haba sido una amenaza para las telefnicas.

**** Ejercicio 2
#+begin_statement
Ante el lanzamiento en 2015 del nuevo servicio de llamadas de Whatsapp,
qu reacciones se esperaban por parte de las compaas de telefona mvil?
#+end_statement

Segn Csar Crcoles y otros profesores de la UOC, las estrategias
podran ser

 * *reducir el costo* de las llamadas, ofreciendo ms minutos de voz en
   las tarifas. Estn bajando los precios relativos al sustitutivo.
 * *incluir la VoIP* en sus servicios y promocionarla para vender ms en
   las tarifas de internet.
 * *rebajar la calidad del servicio de VoIP* en detrimento del servicio
   de Whatsapp y otras aplicaciones similares. Ira contra sus propios
   usuarios y el principio de neutralidad de la red. Sera una represalia
   contra un potencial competidor.

**** Ejercicio 3
#+begin_statement
Segn el informe de Cisco Systems citado en el artculo, "se prev que
en 2018 los minutos de llamadas por Wifi superen los minutos de
llamads por la red telefnica convencional". Ante la cercana del
momento pronosticado, crees que se han cumplido las previsiones?Cmo
calificaras, segn los parmetros estudiados en clase, la amenaza de
este servicio para las operadoras de telefona tradicionales?
#+end_statement

Las previsiones parecen no haberse cumplido y parece que todava las
llamadas sobre WiFi no superaran a las llamadas tradicionales, aunque
seguramente la existencia de servicios de mensajera y mensajes de voz
haya hecho caer ambas.

Como amenaza, debemos tener en cuenta parmetros como

 * el *coste de cambio* al VoIP es muy bajo. La mayora de usuarios ya 
   lo tienen instalado.
 * el *acceso a canales de distribucin* lo tienen ya las empresas de
   VoIP, que tienen clientes obtenidos gracias a ofrecer servicios de
   mensajera.
 * el *grado de sustitucin*. Aunque la VoIP sustituye las llamadas en
   la mayora de los casos, si se quieren llamadas de alta calidad y sin
   cortes, podra necesitarse volver a las llamadas tradicionales.
 * los *precios relativos al sustitutivo* son mucho ms bajos para las
   llamadas por VoIP en general debido a que aprovechan la red Wifi que
   se est usando.
 * la *obsolescencia* no es en este caso un problema para las llamadas
   tradicionales, que siguen teniendo normalmente mayor calidad que las
   llamadas VoIP.

**** Ejercicio 4
#+begin_statement
Cul era la estrategia inicial pensada por Zuckerberg para poder
ofrecer servicios "efmeros" de realidad aumentada e intercambio de
archivos para usuarios de smartphones?
#+end_statement

La estrategia pretenda eliminar o integrar en s toda la competencia.
Estrategia de adquisicin por va de crecimiento externo.

Especficamente, comprar la principal empresa de la competencia, como
intent en 2013, y crear una plataforma de realidad aumentada, con la
que el resto de potenciales competidores se veran obligados a
integrarse.

**** Ejercicio 5
#+begin_statement
Tras la marcha de los acontecimientos, cmo podemos clasificar a
Facebook Stories en el marco del modelo de rivalidad ampliada de
Porter, respecto de Snapchat (suponiendo que la industria de
referencia es la que ofrece el tipo de servicios descritos en el punto
1)?
#+end_statement

Acta como un competidor actual. Especficamente sabemos que no es un
producto sustitutivo porque est usando exactamente las mismas
tecnologas, que, de hecho, ha imitado directamente en lugar de
innovar.

Adems, quiere realizar integracin vertical para crear una plataforma
de realidad aumentada y convertirse en proveedor del resto de plataformas
que pudieran existir en el sector.

** Teora de Nmeros y Criptografa
*** Factorizacin
**** Mtodos bsicos de factorizacin
***** Fuerza bruta
Probando a dividir cada nmero hasta $\sqrt{n}$.

***** Mtodo de Fermat
Escribimos un nmero como diferencia de cuadrados para factorizarlo como
$n = t^2 - s^2 = (t+s)(t-s)$.

****** Soluciones en congruencias no triviales
Si $(t,s)$ es una solucin no trivial de $x^2 \equiv y^2$, entonces $gcd(n,t+s)\neq 1$
y $gcd(n,t-s) \neq 1$.

**** Mtodo de factor base
Una *base* es un conjunto $B = \{p_0 = -1,p_1,\dots,p_h\}$ donde $p_0,p_1,\dots,p_n$
son enteros primos.

***** Conjunto de candidatos B-nmeros
Un conjunto de candidatos B-nmeros es $\mathbb{Z}_n$ escribiendo la
mitad de nmeros ms grandes dentro de la base, como:

\[
\mathbb{Z}_n =
\{0,1\dots,-2,-1\}
\]

Llamamos $\operatorname{abmod}$ a la clase de equivalencia del nmero en el conjunto 
de candidatos.

***** B-nmero
Un nmero $b$ es B-nmero respecto de $n$ si $\operatorname{abmod}(b^2,n)$ factoriza por los 
elementos de la base $B$.

***** Alfa-vectores
Dado $b$ un B-nmero, con:

\[
\operatorname{abmod}(b^2,n) = p_0^{e_0}\dots p_h^{e_h}
\]

definimos el *-vector* como $\alpha vect(b) = (e_0,e_1,\dots,e_h)$.

***** TODO Idea del algoritmo
Sea $S_0 = \{\alpha_0,\dots,\alpha_r\}$ un -vector del conjunto de B-nmeros.

**** Mtodos de eleccin de la base B y los B-nmeros
***** Algoritmo: voy a tener suerte
Se eligen los $h \in \mathbb{N}$ primeros nmeros primos. Escogemos dos ndices
$k_{max} \leq i_{max}$ y calculamos:

  - $\lfloor \sqrt{n}\rfloor, \lfloor \sqrt{2n}\rfloor, \dots, \lfloor \sqrt{k_{max}n}\rfloor$
  - $\lfloor \sqrt{n}\rfloor+1, \lfloor \sqrt{2n}\rfloor+1, \dots, \lfloor \sqrt{k_{max}n}\rfloor+1$
  - $\dots$
  - $\lfloor \sqrt{n}\rfloor + i_{max}, \lfloor \sqrt{2n}\rfloor+i_{max}, \dots, \lfloor \sqrt{k_{max}n}\rfloor+i_{max}$

Entre estos, buscamos B-nmeros y calculamos los -vectores 
correspondientes.

***** Algoritmo: voy a forzar la suerte
**** Fracciones continuas
***** Fraccin continua
Notamos una fraccin continua como:

\[
[a_0,a_1,a_2,\dots] =
a_0 + \frac{1}{a_1+\frac{1}{a_2+\dots}}
\]

***** Propiedades de las fracciones continuas
Las fracciones continuas cumplen:

  1. Todo racional se expresa como fraccin continua finita.
  2. Todo real se expresa como fraccin continua.
  3. Se cumple la frmula:

     \[\frac{a+\sqrt{d}}{b} = [a_0,[a_1,\dots,a_r]]\]

     Si notamos $[a_0,[a_1,\dots,a_r]] = [a_0,a_1,\dots,a_r,a_1,\dots,a_r,\dots]$.

***** Clculo de la fraccin continua de un real
Sea $x \in \mathbb{R}$, tomamos $a_0 = \lfloor x \rfloor$ y podemos escribir recursivamente la 
fraccin continua como:

\[
x = a_0 + \frac{1}{x_1^{-1}}
\]
** Taller de Geometra y Topologa
*** 1. Construcciones con regla y comps
**** 1.1. Construcciones posibles
***** 1.1.0. Construcciones elementales
Axiomticamente consideramos realizables las siguientes construcciones
elementales:

  1. Dados dos puntos, puede construirse un *segmento* entre ellos.
  2. Todo segmento puede extenderse.
  3. Dados dos puntos, puede construirse un *crculo* con centro y radio.
  4. Dadas dos rectas secantes, puede construirse su *punto* de corte.
  5. Dados crculo y rectas, puede construirse su *punto* de corte.
  6. Dados crculos tangentes, pueden construirse *puntos* de corte.

****** Equivalencia de compases                                  :extra:
Asumimos un comps colapsable, pero podramos usar uno no colapsable
con el mismo efecto, por la [[https://en.wikipedia.org/wiki/Compass_equivalence_theorem][equivalencia de compases]].

***** 1.1.1. Construcciones bsicas
****** 1. Tringulo equiltero sobre un segmento
****** 2. Copiar un segmento
****** 3. Cortar segmento de otro dado
****** 4. Bisecar ngulo
****** 5. Mediatriz de un segmento
****** 6. Perpendicular a travs de un punto en una recta
****** 7. Perpendicular a travs de un punto fuera de una recta
****** 8. Tringulo con longitudes de lados dada
****** 9. Copiar un segmento a un segmento dado
****** 10. Copiar un ngulo a un rayo
****** 14. Paralela a una recta a travs de un punto exterior
***** 1.1.2. Construcciones involucrando razones geomtricas
****** 15. Cortar un segmento en n partes iguales
****** 16. Cortar un segmento en un racional
****** 17. Media geomtrica de dos segmentos
***** 1.1.3. Construcciones involucrando reas
****** 19. Paralelogramo con igual rea que un tringulo dado
***** 1.1.4. Circunferencias destacadas
****** 24. Centro de una circunferencia
****** 25. Circunferencia inscrita a un tringulo
Usando bisectrices.
****** 26. Circunferencia circunscrita a un tringulo
**** 1.2. Construcciones imposibles
***** 1.2.1. Elementos constructibles o realizables
Un real $x$ es constructible cuando podemos construir puntos $C,D$ tales que
$\overline{CD} = x$.

****** Subcuerpo de nmeros constructibles
Los nmeros constructibles forman un subcuerpo de $\mathbb{R}$. Llamamos $\mathfrak{C}$ al
cuerpo de los constructibles.

******* TODO Demostracin
****** Los racionales son constructibles
Todo subcuerpo de $\mathbb{R}$ debe contener a los racionales.

****** Las races de constructible son constructibles
Si $x \in\mathfrak{C}$, entonces $\sqrt{|x|} \in \mathfrak{C}$.

***** 1.2.1. Extensin cuadrtica
Dado $\mathbb{K}$ subcuerpo de $\mathbb{R}$ llamamos a:

\[
\mathbb{K}(\sqrt{e}) = \{ a+ b\sqrt{e} \mid a,b\in\mathbb{K}\}
\]

una extensin cuadrtica de $\mathbb{K}$.

***** 1.2.1. Teorema de Descartes
Un nmero real es constructible ssi est en alguna extensin cuadrtica
iterada de $\mathbb{Q}$.

****** TODO Demostracin

*** 2. Geometra no eucldea
**** El Quinto Postulado de Euclides
***** Quinto postulado de Euclides
El Quinto Postulado de Euclides afirma que, dadas $r,s,t$ rectas
cortando $r$ a $t,s$ con ngulos $\alpha,\beta$; si $\alpha+\beta < \pi$, entonces $s \cap t \neq \varnothing$.

***** Teorema de Legendre
El Quinto Postulado equivale a que la suma de los ngulos de un
tringulo es exactamente $\pi$. Si la suma de los ngulos de un tringulo
es $\pi$, se cumple el Quinto Postulado.

***** Cuadrilteros de Saccheri
Un cuadriltero $ABCD$ es *de Saccheri* cuando $\widehat{A},\widehat{B}$ son rectos y 
adems $\overline{AD}=\overline{BC}$.

***** Cuadriltero de Lambert
Un cuadriltero es *de Lambert* si tiene tres ngulos rectos.

***** Independencia del Quinto Postulado
Los siguientes resultados son independientes del Quinto Postulado

 * la suma de los ngulos de un tringulo es menor o igual que $\pi$.
 * los dos ngulos no rectos de un cuadriltero de Saccheri son
   iguales y menores o iguales que $\pi/2$.
 * el lado superior de un cuadriltero de Saccheri es menor que 
   el lado inferior.

***** Implicacin al Quinto Postulado
Los siguientes resultados equivalen al Quinto Postulado

 * los ngulos de un tringulo suman $\pi$.
 * los ngulos de todos los tringulos suman $\pi$.
 * un cuadriltero de Saccheri tiene todos los ngulos rectos.

**** Geometra hiperblica
***** Axioma de Lobachevsky
Dada una recta $r$ y un punto $a \notin r$, existen al menos dos rectas $s_1,s_2$
distintas con $a \in s_1\cap s_2$, pero $s_1\cap r = s_2\cap r = \varnothing$.

***** Infinitas rectas
Dada una recta $r$ y un punto $a \notin r$, existen infinitas rectas que pasan
por $a$ y no contienen a $r$.

**** Paralelas en geometra hiperblica
***** Existencia de rectas dado un ngulo
Dada una recta $r$ y un punto $a \notin r$, dado cualquier ngulo $\alpha \in (0,\pi)$ y
siendo $a \in t_a \perp r$, existen dos rectas $l_1,l_2$ formando un ngulo $\alpha$ con
$t_a$.

***** Existencia de paralelas
Dada una recta $r$ y un punto $a \notin r$, tomamos $t_{a}$ la perpendicular por $a$
y $l_{\alpha}$ la dada con ngulo $\alpha$ por el teorema anterior. Existe un nico
$\beta \in (0,\pi/2)$ tal que

  * $l_{\beta}\cap r = \varnothing$,
  * $\forall a \in (0,\beta): l_{\alpha}\cap r \neq \varnothing$.
 
En este caso, la recta $l_{\beta}$ es *paralela*.

***** El paralelismo es independiente del punto elegido
Si una recta es paralela a otra por un punto, lo es por todos sus
puntos.

***** El ngulo de paralelismo slo depende de la distancia
El ngulo de paralelismo de una recta por un punto slo depende de
la distancia de la recta al punto.

***** Existen exactamente dos paralelas
Dada una recta y un punto exterior, existen exactamente dos paralelas
distintas que pasan por el punto.

***** Simetra del paralelismo
Si $r$ es paralela a $s$, $s$ es paralela a $r$.

***** Ultraparalelas
Dos rectas se dicen ultraparalelas si no son secantes ni paralelas.

***** Caracterizacin de ultraparalelas
Dos rectas son ultraparalelas si y slo si admiten una perpendicular
comn.

**** Defecto de tringulos
***** Defecto de un tringulo
El *defecto* de un tringulo $ABC$ es

\[ \mathrm{def}(ABC) =
\pi - {\widehat A} - \widehat B - \widehat C > 0.
\]

***** Los defectos de tringulos son aditivos
Dado un $D \in AB$ y $ABC$ un tringulo, se tiene

\[ \mathrm{def}(ABC) = \mathrm{def}(ACD) + \mathrm{def}(BCD).
\]

***** Dos tringulos son congruentes si tienen los mismos ngulos
Dos tringulos con los mismos ngulos en geometra hiperblica
deben ser congruentes.

***** Paralela a una y perpendicular a otra
Dadas dos semirectas formando un ngulo agudo, existe una nica
perpendicular a una y paralela a la otra.

***** El defecto es el rea
El defecto es igual al rea del tringulo.

**** Semiplano de Poincar
***** Definicin
Llamamos $\mathbb{H}^2 = \left\{ (x,y) \in \mathbb{R}^2\mid y>0
\right\}$ y $\forall p = (x,y) \in \mathbb{H}^2$ y sobre l tomamos 
la mtrica $g_p = \frac{1}{y^{2}}\left\langle \cdot,\cdot \right\rangle$.

*** Ejercicios
**** Formas del universo
***** Ejercicio 1
#+begin_statement
Como seres de dimensin 3 en un mundo de tres dimensiones es fcil
dibujar y entender posibles formas de Planilandia pero no de nuestro
propio Universo. Imaginar la forma de nuestro Universo en alguna de
las siguientes situaciones:

 * Hacemos una expedicin a una galaxia remota. Al llegar a ella
   descubrimos estar de vuelta en la tierra.

 * Un astrnomo acaba de descubrir que los mismos objetos se
   encuentran en posiciones distintas del Universo.

 * Buscando ondas de radio que detecten seales extraterrestres,
   detectamos una sexal que procede de una galaxia lejana.
   Investigamos y vemos que se trata de la seal de un programa de TV
   emitido hace 50 aos.

A las posibles formas de nuestro Universo les llamaremos
variedades de dimensin 3 y su estudio constituye la Topologa
3-dimensional.
#+end_statement

En cualquiera de esos casos podramos estar ante un toro tridimensional.
Los objetos se repetiran en el espacio una y otra vez, y todo el espacio
se repetira con ellos. Podramos interpretar que vivimos en un cubo en el
que estn identificadas cada una de las caras con la opuesta. Ntese que
segura siendo un universo orientable.

En un segundo ejemplo, podra ocurrir que tuviramos un universo similar
al anterior pero en el que una de las paredes del cubo cambiara la 
orientacin. Al pasar por ella volveramos al mismo punto pero habramos
intercambiado derecha e izquierda.

En un tercer ejemplo, podra ocurrir que el universo fuera infinito en
una dimensin pero en las otras dos se comportara como un toro plano.
Dependiendo de la direccin que tomramos, volveramos o no al punto
de partida.

***** Ejercicio 2
#+begin_statement
1. Cules de las siguientes superficies tienen la misma topologa?
   
   [[./img/formasuniverso1.png]]

2. En Planilandia CP descubri que dos caminos cerrados partiendo del mismo
   punto en direcciones opuestas no tienen por qu volver a cruzarse en un
   punto diferente. Es esta propiedad geomtrica o topolgica?
3. Describir superficies con la misma topologa pero diferente geometra.
#+end_statement

1) Tienen la misma topologa:
   * la esfera y el objeto justo debajo.
   * el toro y la taza.
   * el resto de objetos.
2) Esta es una propiedad topolgica. El hecho seguir siendo cierto al
   aplicar deformaciones continuas al espacio.
3) Por ejemplo de un ejercicio anterior tomamos el toro y la taza, que
   tenan la misma topologa pero se puede observar que al hacer la
   deformacin del toro en la taza han cambiado propiedades como rea
   que es diferente para ambas figuras.

***** Ejercicio 3
#+begin_statement
Distingue segn su topologa intrnseca y extrnseca.

[[./img/formasuniverso2.png]]

 * Puedes forrar un cilidro con parte de una hoja de papel sin deformarla?,
   y un cono?, y un trozo de esfera?
 * Coo pueden los planilandeses que vivan en mundos como los de la figura
   conocer que sus geometras intrnsecas son diferentes? Qu pueden decir
   acerca de sus topologas extrnsecas e intrnsecas?

   [[./img/formasuniverso3.png]]

$\quad$
#+end_statement

Todas las figuras tienen misma topologa intrnseca. En el caso de la
topologa extrnseca podemos distinguir tres grupos:

 * las figuras azules junto a la morada adyacente a estas.
 * las figuras amarillas.
 * la morada que nos queda.

Podemos forrar el cilindro y el cono, por el contrario se crearan
pliegues en el papel al intentar cubrir el trozo de esfera.

En el trozo de esfera al medir los ngulos de un tringulo el
resultado sera mayor que PI, en el hiperboloide sera menor que PI, y
en el plano sera igual a PI.

***** Ejercicio 4
#+begin_statement
  * Justifica que el toro llano y la superficie de un donut son
    topolgicamente equivalentes.

  * Consigue en la siguiente figura un de un toro llano tres =X=
    en lnea.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso4.png]]

  * Cules de las posiciones siguientes seran equivalentes al jugar
    unas "tres en lnea" sobre un toro llano.

    [[./img/formasuniverso5.png]]

  * En el siguiente tablero de ajedrez sobre un toro llano, qu figuras
    estn amenazadas por el caballo blanco?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso6.png]]

  * Qu figuras estn amenazadas por el caballo y la reina blancos?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso7.png]]

  * Las siguientes figuras muestran un toro llano de tres dimensiones.
    Explica cmo se construye e imagina qu veras al mirar en una direccin
    concreta.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso8.png]]

$\quad$
#+end_statement

 * Triangulando el toro llano y el donut llegamos fcilmente a la misma
   triangulacin.
 * Escribimos X en la casilla inferior central.
 * Todos los celestes por un lado; todos los amarillos excepto los de la
   primera columna y el ltimo de la tercera columna, y todos los dems.
 * Rey, afil, y dos caballos negros.
 * Todas.
 * Identificando las caras, veramos nuestra espalda delante, nuestros pies
   hacia arriba y nuestra cabeza hacia abajo.

***** Ejercicio 5
#+begin_statement
Jugando en la botella de Klein:

  * Cules de las siguientes posiciones ganan en el juego del tres en
    raya dentro de una botella de Klein?

    [[./img/formasuniverso10.png]]

  * Analiza cmo hacer tres en lnea en la siguiente figura.

    [[./img/formasuniverso11.png]]
#+end_statement

De las tres posiciones del tres en raya

 * la primera gana.
 * la segunda gana.
 * la tercera gana.

Si escribimos coordenadas del tres en raya como

| 0,0 | 0,1 | 0,2 |
| 1,0 | 1,1 | 1,2 |
| 2,0 | 2,1 | 2,2 |

se ganan las partidas con la posicin

 * primera: (2,2)
 * segunda: (0,0)
 * tercera: (0,2)
 * cuarta: (2,2)
 * quinta: (1,1)

***** Ejercicio 6
#+begin_statement
Actividades:

 * Si un planilands viviendo en un plano proyectivo cruza el ecuador,
   vuelve como su imagen especular?
 * Una familia de planilandeses vive en un plano proyectivo. Planean
   edificar dos gasolineras separadas cuanto ms mejor. Dnde deberan
   construirlas?
 * CP conoce que vive en una esfera o en un plano proyectivo. Cmo
   podra saber cul de los dos es su mundo?
 * Un segundo planilands sabe que su Universo es un plano proyectivo o
   una botella de Klein, qu podra hacer para conocer de cul de los dos
   se trata?

$\quad$
#+end_statement

 1) S, el plano no es orientable.
 2) Una en el centro y otra en el ecuador.
 3) Cruzando la frontera y al volver, comparando su orientacin.
 4) Ampliar primero una zona segura en la que pudiera volver a cada punto
    sin haber cambiado la orientacin y luego comprobar si el resto del
    universo ha quedado dividido en dos (suma de planos) o en uno (plano).

***** Ejercicio 7
#+begin_statement
Haciendo sumas conexas:

 * Deducir que si a una cinta de Mbius le pagamos un disco por el borde,
   obtenemos un plano proyectivo.
 * Corrobora las palabras de Klein: "La cinta de Mbius es divina, si pegas
   dos por su borde obtienes mi botella".
 * Construye usando papel la suma conexa de una cinta de Mbius a un toro
   y a una botella de Klein.
 * Muestra que la suma conexa de un toro con un plano proyectivo es 
   topolgicamente equivalente a la suma conexa de una botella de Klein con
   un plano proyectivo.
 * Establece una correspondencia por equivalencia topolgica entre las
   superficies de los conjuntos A y B:

   \[
   A = \{
   \mathbb{T}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2,
   \mathbb{S}^2\#\mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{T}^2,
   \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2
   \}
   \]

   \[
   B = \{
   \mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2\#\mathbb{P}^2,
   \mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2,
   \mathbb{T}^2,
   \mathbb{T}^2\#\mathbb{P}^2
   \}
   \]
#+end_statement

1) Un plano proyectivo menos un disco es una banda de Mbius porque
   podemos dibujar el plano proyectivo en un disco y quitarle un disco
   que corte la frontera del disco.
2) Ntese que si partimos la botella de Klein por la mitad, lo que queda
   en cada una de las mitades es una banda de Mbius.
3) Seran al final 5 planos proyectivos.
4) Usando la clasificacin de superficies compactas sabemos que no
   necesitamos mezclar asas con gorros cruzados $\times \circ = \times^3$.
5) Usaremos clasificacin de superficies compacatas para escribir cada
   una como suma de planos proyectivos o toros. La $\mathbb{S}^2$ es neutra bajo la
   suma conexa.

   Nos quedan

   * $\mathbb{B}^2 \cong \mathbb{P}\#\mathbb{P}$,
   * $\mathbb{B}^2 \#\mathbb{P}^2 \cong \mathbb{P}^2 \# \mathbb{P}^2 \# \mathbb{P}^2$,
   * $\mathbb{S}^2\# \mathbb{S}^2 \cong \mathbb{S}^2 \# \mathbb{S}^2 \# \mathbb{S}^2$,
   * $\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2 \cong \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2$,
   * $\mathbb{T}^2 \cong \mathbb{T}^2\#\mathbb{S}^2$,
   * $\mathbb{T}^2\#\mathbb{P}^2 \cong \mathbb{P}^2\#\mathbb{T}^2$.


Las geodsicas del modelo vienen dadas por intersecciones del hiperboloide
con subespacios lineales bidimensionales, que nunca sern vacos
** Desarrollo y sistemas de informacin
*** 1. Sistemas de informacin
**** Definicin
***** Sistema
Conjunto de elementos ordenadamente relacionados contribuyendo a
una determinada funcin

***** Datos
Representacin simblica de variables cuantitativas o cualitativas.

***** Informacin
Conjunto organizado de datos procesados, formando un mensaje que
cambia el estado de conocimiento del sistema que lo procesa.

***** Sistema de informacin
Un sistema de informacin es

 * un sistema automatizado o manual para recopilar, procesar y
   transmitir datos representando informacin.

 * la infraestructura para la recopilacin, procesamiento y transmisin
   de informacin.

**** Sistemas de informacin empresarial: gestin de recursos
La *gestin de recursos* de una empresa es una utilidad de sistemas de
informacin. Sirven para

 * *comunicacin*
   * intranets/extranets
   * value added networks (VANs)

 * *resolucin de problemas*
   * decision support systems (DSSs)
   * knowledge-based systems (KBSs)

debido a la complejidad de los sistemas actuales y al ahorro econmico
que proporcionan.

Gestionan recursos fsicos y conceptuales.

**** Sistemas de informacin empresarial: funciones de un gerente
Las funciones de un gerente son

 - funciones de Fayol :: planificar, organizar, apoyar, dirigir y
      controlar.
 - papeles de Mintzberg :: interpersonales, informacin y toma de
      decisiones.

a distintos niveles gerenciales

 - planificacin estratgica :: ejecutivos,
 - control gerencial :: directores de producto, jefes de seccin,
 - control operativo :: jefes de proyecto, jefes de departamento,

a distintos niveles vara el origen y nivel de detalle de la informacin
requerida.

**** TODO Sistemas de informacin empresarial: CBIS

*** 2. Diseo conceptual de sistemas de informacin
**** Modelo Entidad-Relacin
El *modelo entidad-relacin* es el ms extendido para el diseo
conceptual; debe reflejar fielmente las necesidades de informacin y
ofrecer un diseo independiente. Representa y manipula informacin
de forma general y sistemtica.

 - Datos :: tratamiento de un recurso conceptual.
 - Convenciones :: actuacin sistemtica y rigurosa.
 - Redundancia mnima :: modelado nico de cualquier objeto.

**** Elementos del modelo
# Pasar a folio los diagramas
Los elementos del modelo son

 - entidades :: objetos delimitados y distinguibles de los dems;
 - conjuntos de entidades :: grupo de entidades con las mismas
      cualidades; tambin llamados *tipos*;
 - atributos :: propiedades caracterizando un conjunto de entidades.

***** Atributos
Sobre los atributos, se consideran 

 - dominio :: valores permitidos para un atributo,
 - identificadores :: atributos que identifican unvocamente a
      una entidad (se sealan rellenando el crculo),
 - atributo compuesto :: formado por varios (se seala como un
      crculo con atributos a su vez).

***** Entidades fuertes y dbiles
Decimos que B *depende existencialmente* de A si cada B tiene
un A asociado y es imposible identificar a un b sin identificar
su a. La B es una entidad dbil respecto de A.

# TODO: Cardinalidad en entidades dbiles!

***** Asociaciones
Relaciones semnticas entre dos o ms conjuntos de entidades.
Pueden tener *cardinalidad*

 * n:m - muchos a muchos
 * m:1 - uno a muchos
 * 1:m - muchos a uno
 * 1:1 - uno a uno,

y *participacin*

 * 0 si es parcial u opcional,
 * 1 si es total.

Se leen fijando un objeto de la relacin. Las relaciones pueden
tener atributos en algunos casos.

***** Especializacin
A es una especializacin de B si est completamente includo en l.
Todo a es un b.

 * *(p) Obligatoriedad parcial:* si hay entidades que no pertenezcan a
   ninguna especialidad.
 * *(t) Obligatoriedad total:* si toda entidad tiene que pertenecer a
   algn conjunto especializado.
 * *(e) Exclusividad*: si slo se pertenece a una especializacin.
 * *(s) Solapada*: si puede pertenecerse a varias especializaciones.

***** Agregacin
Entidad genrica de la que no se especifica estructura interna.

**** Heursticas de modelado

 1. El grado de las relaciones suele ser binario. La cardinalidad
    n-aria hay que analizarla por partes.

 2. La aparicin de ciclos es normal, pero pueden estar dando lugar
    a informacin redundante.

 3. No se debe abusar de las agregaciones. Quiz un conjunto nuevo
    solucione la agregacin.

**** Refinamiento
El refinamiento transforma diagramas E/R.

***** TODO Primitivas descendentes
Parten de versin general y llegan a versin especfica. No todos
los esquemas son producibles descendentemente, slo los basados en
conexiones en serie y paralelo.

# TODO: Tipos de primitivas
***** TODO Primitivas ascendentes
Van de una visin especfica a la versin conectada. Todos los
esquemas son producibles ascendentemente.

# TODO: Tipos de primitivas
***** TODO Diseo centrfugo
Vara el orden de aplicacin en los refinamientos.

***** Diseo mixto
Se produce un armazn y se modela cada parte con primitivas descendentes,
luego se conecta con primitivas ascendentes. Permite ms flexibilidad.

*** Seminario 4: Modelado de datos
**** Esquemas de navegacin

 - I :: insercin,
 - D :: borrado,
 - U :: actualizacin,
 - R :: consulta.

Las flechas marcan los atributos de entrada. Los atributos que aparecen
sin flecha son de salida. El sentido en el que se obtienen lo marcan las
flechas.

***** Errores
Un esquema de navegacin slo puede tener una consulta de insercin,
borrado o actualizacin; la nica excepcin son las entidades dbiles.

*** 4. Normalizacin
**** Algoritmos
***** Simplificacin de conjunto de dependencias funcionales
Dado un conjunto de dependencias funcionales, lo simplifica a uno
equivalente. Usos:

 * facilitar la normalizacin posterior,
 * facilitar el clculo de claves candidatas.

****** Algoritmo
1. Simplificar partes *derechas* ABC como AB y AC.
2. Simplificar partes izquierdas eliminando *atributos raros*, esto
   es, si ABC y AB, tenemos directamente AC.
3. *Eliminar* las dependencias que se deducen de otras.

***** Clculo de claves candidatas
Obtener las claves candidatas de una relacin. Se resume en tener cuidado
con independientes y equivalentes y luego simplemente formar claves con la
izquierda y con ambas.

****** Algoritmo
Clasificamos en

 * atributos independientes de las relaciones,
 * parejas de atributos equivalentes
 * atributos solo a izquierda,
 * atributos en ambos lados,
 * atributos solo a derecha.

Y ejecutamos

1. Elimina atributos *independientes* del algoritmo, formarn
   siempre parte de la clave.
2. Elimina *equivalencias*, puede considerar uno y olvidar el otro,
   podra formar parte de la clave cualquiera de los dos.
3. Comprueba si con los de izquierda se forma clave.
4. Comprueba en caso de que no haya funcionado aadiendo atributos
   de ambos lados.
5. Incorpora independientes.
6. Incorpora equivalentes.

**** Repaso de formas normales
Se definen

 * 1NF: los dominios de atributo tienen valores indivisibles.
 * 2NF: todo atributo no-primo depende completamente de cualquier
   clave candidata.
 * 3NF: todo atributo no-primo depende de forma no transitiva de cada
   clave candidata de R.
 * BCNF: cada dependencia no trivial (subconjunto) tiene a la derecha
   una clave candidata.

Se resuelven

 * 1NF: partiendo los atributos.
 * 2NF: partiendo en dos tablas distintas.
 * 3NF: partiendo en dos tablas distintas por la transitividad.
 * BCNF: rediseando en tablas distintas.

***** Pledge
Every [non-key](FNBC) attribute must provide a fact about the key (1NF), the
whole key (2NF) and nothing but the key (3NF). For each candidate key.

***** Non-solvable problems
Beeri and Bernstein showed in 1979 that, for example, a set of
functional dependencies {AB  C, C  B} cannot be represented by a
BCNF schema.

**** 4.1. Normalizacin
***** Dependencias
****** Dependencia funcional
Sean relaciones R(A,A  A),   R,   R entre atributos.
Decimos que    ssi  t,s  r: t[] = s[]  t[] = s[].

Los valores para el subconjunto  determinan de forma nica
los valores para el subconjunto .

****** Dependencia funcional completa
Una dependencia funcional es completa,    cuando se tiene
que ningn subconjunto de atributos    tiene una dependencia
  . Este  es minimal en ese sentido.

****** Atributo primo
Forma parte de una clave candidata

***** Axiomas de Armstrong sobre dependencias
1. Reflexividad.    nos da   .
2. Ampliacin.    nos da   .
3. Transitividad.    y    nos dan   .
4. Unin.    y    nos dan   .
5. Descomposicin.    nos da    y   .
6. Pseudotransitividad.    y    nos dan   .

****** Cierre de un conjunto de dependencias
F+ se obtiene como clausura de las dependencias de F aplicando
axiomas de Armstrong. Llamamos + a todos los atributos que se
obtienen como dependencias desde .

****** Recubrimiento minimal o cannico
Es el mnimo F' tal que (F')+ = F+.

***** Obtencin del recubrimiento minimal

1. *Partimos con la regla de descomposicin* todas las partes derechas
   compuestas: ABC parte en AB y AC.

2. *Simplificamos los atributos raros* de la izquierda, aquellos que
   dependen de los que le acompaan: si AB  C y sabemos A  B,
   podemos dejar A  C.

3. *Eliminamos dependencias redundantes* que puedan obtenerse de
   otras.

La ventaja de trabajar con recubrimiento minimal es que, al no
tener dependencias redundantes, podemos comprobar directamente si
cualquiera de ellas se ha perdido al aplicar Teorema de Heath.

***** 1FN
El dominio de cada atributo es atmico y cada valor del atributo
slo contiene un valor para ese dominio.

***** 2FN
La 2FN es

 * estar en 1FN,
 * todos los atributos no primos dependen de forma completa de las
   claves candidatas.


****** Descomposicin sin prdidas
Una relacin (R,r) se descompone *sin prdidas* en (R1,r1) y (R2,r2)
cuando R1  R2 = R y adems (r1 join r2) = r.

****** Teorema de Heath
Si tenemos grupos , ,  con   , podemos separar la relacin
sin prdidas en

 * R1(,)
 * R2(,)

***** 3FN
La 3FN es

 * estar en 2FN,
 * no tener dependencias transitivas problemticas, a travs de
   atributos no primos.

****** Dependencia transitiva
CK  , para  formado por algn atributo no primo, es transitiva
cuando   R, (  R)  F+, tal que

(CK  )  F;  y adems,  (  )  F

***** FNBC
La definicin original de 3FN tiene deficiencias si hay varias claves
candidatas. La FNBC considera estos casos, es

 * estar en 3FN,
 *    F se cumple que
   *  es clave candidata y , o
   *   .

Es decir, todo determinante es una clave candidata.

***** Clculo de llaves candidatas
1. Eliminacin de atributos independientes: de ellos no se deduce
   ningn otro, tendrn que estar en la clave candidata en cualquier
   caso.

2. Construccin de atributos equivalentes: para cada pareja de
   equivalentes se usa slo uno de ellos.

3. Clave sin determinantes determinados: se selecciona un candidato a
   clave candidata sin determinantes no determinados.

4. Si hay ms claves sin determinantes determinados se necesitar
   cubrir todas las claves posibles, aadiendo a cada paso n nuevo
   determinante que sea determinado.

5. Aadimos atributos independientes a las claves obtenidas

6. Replicamos las claves con las equivalencias del paso 2.

***** Proceso de normalizacin
1) Localizar las claves candidatas.

   1) Descomponer dependencias a la derecha.
   2) Eliminar atributos raros a la izquierda.
   3) Eliminar dependencias redundantes.
   4) Localizar claves candidatas

2) Comprobar 2FN, usar Teorema de Heath.

3) Comprobar 3FN, eliminar transitividades problemticas.

**** 4.2. Diseo fsico
**** Ejercicios
***** Soluciones normalizacin
****** Ejercicio 1
Simplificando dependencias queda

| Tabla        | ABCDE        |
| Claves       | AD, DBC, DBE |
|--------------+--------------|
| Dependencias | A  B        |
|              | A  C        |
|              | BC  A       |
|              | BCD  E      |
|              | E  C        |

No existiendo atributos primos, est en 3FN. Normalizamos
a FNBC como

| Tabla        | ABC    | BDE     | EC    |
| Claves       | A, BC  | BDE     | E     |
|--------------+--------+---------+-------|
| Dependencias | A  B  |         | E  C |
|              | A  C  |         |       |
|              | BC  A |         |       |

se ha perdido la dependencia BCDE.

****** Ejercicio 2
Simplificando dependencias queda

| Tabla        | ABCD   |
| Claves       | AB, AC |
|--------------+--------|
| Dependencias | C  D  |
|              | AB  C |
|              | C  B  |

La tabla no est en 2FN por CD. Partimos como sigue para llegar a 3FN

| Tabla        | ABC    | CD    |
| Claves       | AB, AC | C     |
|--------------+--------+-------|
| Dependencias | C  B  | C  D |
|              | AB  C |       |


Y partimos de nuevo para llegar a FNBC

| Tabla        | AC | CB    | CD    |
| Claves       | AC |       | C     |
|--------------+----+-------+-------|
| Dependencias |    | C  B | C  D |
|              |    |       |       |
|              |    |       |       |

Hemos perdido la dependencia ABC.

****** Ejercicio 3
Simplificando dependencias queda

| Tabla        | AOIVND |
| Claves       | VI     |
|--------------+--------|
| Dependencias | V  D  |
|              | I  A  |
|              | IV  N |
|              | A  O  |

No estamos en 2FN por VD y IA, partimos en

| Tabla        | IVN    | IA    | AO    | VD    |
| Claves       | VI     | I     | A     | V     |
|--------------+--------+-------+-------+-------|
| Dependencias | IV  N | I  A | A  O | V  D |

Que est en FNBC.

****** Ejercicio 5
Simplificando dependencias queda

| Tabla        | SIDBQO |
| Claves       | S      |
|--------------+--------|
| Dependencias | S  I  |
|              | S  D  |
|              | I  B  |
|              | S  Q  |
|              | B  O  |

Estamos en 2FN porque todas dependen completamente por transitividad
de S, pero no estamos en 3FN. Corregimos partiendo en

| Tabla        | SIDQ  | IB    | BO    |
| Claves       | S     | I     | B     |
|--------------+-------+-------+-------|
| Dependencias | S  I | I  B | B  O |
|              | S  D |       |       |
|              | S  Q |       |       |

Que estn en FNBC.

****** Ejercicio 6
Simplificando dependencias queda

| Tabla        | ABCDE  |
| Claves       | BE     |
|--------------+--------|
| Dependencias | A  C  |
|              | B  C  |
|              | C  D  |
|              | DE  C |
|              | CE  A |

No est en 2FN porque BC, por ejemplo. Vamos a partir la tabla para
llegar a 3FN sin prdidas. A cada paso, partiremos de forma que los
atributos compartidos entre las dos partes sean una clave en alguna de
ellas.

| Tabla        | BE | BC    | ECD    | ECA    |
| Claves       | BE | B     | EC, ED | EC, EA |
|--------------+----+-------+--------+--------|
| Dependencias |    | B  C | DE  C | CE  A |
|              |    |       | C  D  | A  C  |

Esta separacin no est en FNBC por C  D y A  C, partimos de nuevo
para llegar a FBNC,
 
| Tabla        | BE | BC    | EC | CD    | EA | AC    |
| Claves       | BE | B     | EC | C     | EA | A     |
|--------------+----+-------+----+-------+----+-------|
| Dependencias |    | B  C |    | C  D |    | A  C |

hemos perdido DE  C y CE  A como dependencias.

****** Ejercicio 7
Simplificando dependencias

| Tabla        | ABCDE  |
| Claves       | AB     |
|--------------+--------|
| Dependencias | AB  C |
|              | C  E  |
|              | E  C  |
|              | C  D  |

Estamos en 2FN porque todos dependen de AB de forma completa; pero no
estamos en 3FN. Partimos para llegar a 3FN.

| Tabla        | ABC    | CE    | CD    |
| Claves       | AB     | C, E  | C     |
|--------------+--------+-------+-------|
| Dependencias | AB  C | E  C | C  D |
|              |        | C  E |       |

Que estn en FNBC.

***** Ejercicio 1
#+begin_statement
Normalizar,

A  BC,  BC  A, BCD  E, E  C.
#+end_statement

Las dependencias estn ya descompuestas a la derecha.

Eliminamos atributos raros a izquierda, BC  E no tiene
atributos raros; para BCD  E podemos comprobar que ni
BC genera D, ni BD genera C ni CD genera B.

Eliminamos dependencias redundantes, la A  BC no lo es
porque no se sigue de las dems ninguna dependencia de A.
La BC  A tampoco lo es, as como la BCD  E ni E  C.
***** Ejercicio 2
#+begin_statement
Normalizar R(A,B,C,D) con

AB  D,  C  D,  AB  C,  C  B.
#+end_statement

****** Recubrimiento minimal
Descomponemos a derecha, ya hecho. simplificamos atributos
raros, ya hecho. Eliminamos dependencias redundantes, como
la AB  D; nos queda

C  D,  AB  C,  C  B.

****** Clave candidata
Localizamos claves candidatas

| Izquierda | Ambos | Derecha |
|-----------+-------+---------|
| A         | BC    | D       |

tenemos A+={A}, luego aadimos otra, AB+={ABCD} es clave
candidata.

****** 2FN
Los atributos C, D deberan depender de forma completa.
Tenemos que no dependen de A sola ni de B sola, luego lo
hacen de forma completa.

****** 3FN
Tenemos una transitividad AB  C y C  D. Queremos que todo
determinante sea una clave candidata, as que partimos

R1(_A,B_,C) y R2(_C_,D)

donde R1 tiene AB  C y C  B; mientras que R2 tiene C  D.

****** FNBC
Tenemos un determinante en R1 que no es clave candidata.
Solucionamos partiendo

R2(_C_,D),
R3(_A,C_),
R4(_C_,B),

el problema aqu es que se pierde el hecho de que AB  C.

***** Ejercicio 3
#+begin_statement
Normalizar R(A,O,I,V,N,D) con,

V  D,  I  A,  IV  N,  A  O.
#+end_statement

****** Clave candidata
Las dependencias estn descompuestas a la derecha.
Eliminamos atributos raros a izquierda, ntese que en IV  N, tenemos
I={IAO} y V={VD}, luego no hay atributos raros.
No hay ninguna dependencia redundante, ya que cada
dependencia genera un atributo distinto.

Localizamos claves candidatas,

| Izquierda | Ambos | Derecha |
|-----------+-------+---------|
| VI        | A     | NDO     |

Tenemos que VI forman parte de cualquier clave candidata.
VI={VIANDO}, luego es clave candidata.

****** Segunda forma normal
Comprobamos ahora que est en segunda forma normal.

 * Los atributos AOD no primo no dependen de forma completa de las
   claves candidatas. Descomponemos

   R(V,I,N)
   R(I,A,O)
   R(V,D)

   tal que cada una est en forma normal. 

****** Tercera forma normal
La nica transitividad est en I  A y A  O. Descomponemos
como

 R($V,$I,N)
 R($V,D)
 R($I,A)
 R($A,O)

y todas estas tablas estn en FNBC; ya que slo la primera tiene
una clave candidata compuesta y el nico atributo depende de la
clave de forma completa.
***** Ejercicio 4 (es el 2!?)
#+begin_statement
Normalizar R(A,B,C,D)

AB  C,  AB  D,  C  D,  C  B.
#+end_statement

****** Recubrimiento minimal
Partimos a la derecha, ya hecho. Simplificamos atributos raros

***** Ejercicio 5
#+begin_statement
Normalizar

S  ID,  I  B,  IS  Q,  B  O
#+end_statement

****** Recubrimiento minimal
Partimos a la derecha S  I, S  D. Simplificamos atributos raros, con
S  Q, nos queda

 SI, SD, IB, SQ, BO.

****** Clave candidata

| Izq | Amb | Der |
|-----+-----+-----|
| S   | IB  | DQO |

Y tenemos que S+={SIDBQO}, luego es clave candidata.

****** 2FN
Deberan depender todos de forma completa de S y lo hacen
porque est formada por un slo atributo.

****** 3FN
Tenemos una transitividad SI, IB, BO; la quitamos como

R1(_S_,I,D,Q)
R2(_I_,B)
R3(_B_,O)

****** FNBC
Todas las relaciones con una nica llave candidata en 3FN estn en
FNBC.  Todo determinante es clave candidata.

***** Ejercicio 6
Sea el esquema R(A,B,C,D,E) con dependencias

 AC, BC, CD, DEC, CEA.

****** Recubrimiento minimal
Empezamos trabajando con un recubrimiento minimal de las
dependencias, simplificamos a derecha y eliminamos atributos
raros. Eliminamos dependencias redundantes. Ya hecho.

****** Clave candidata

| Izq   | Ambos | Der |
|-------+-------+-----|
| BE    | ACD   |     |

Tenemos {BE}+={BECAD}, luego es clave candidata.

R(_B,E_,A,C,D)

****** 2FN
Todos deberan depender de forma completa de BE, pero no lo hacen;
tenemos BC, BD, luego partimos

R1(_B,E_,A)
R2(_B_,C,D)

****** 3FN
No queremos ahora dependencias transitivas completas, luego

R1(_B,E_,A)
R2(_B_,C)
R3(_C_,D)

hemos perdido que CEA (??).

****** FNBC
???

***** Ejercicio 7
#+begin_statement
Sea el esquema R(A,B,C,D,E) con dependencias

AB  C,  C  E,  E  C,  C  D,  AB  E.
#+end_statement

****** Recubrimiento minimal
Descomponemos a derecha, quitamos atributos raros y eliminamos
redundancia.

Quitamos AB  E.

****** Clave candidata
Quitamos independientes, que no hay. Reducimos equivalentes,
donde tenemos CE y EC. Nos queda

ABC, CD

| Izq | Amb | Der |
|-----+-----+-----|
| AB  | C   | D   |

Como {AB}+={ABCDE}, ya tenemos clave candidata nica.

****** 2FN
Dependencia completa se tiene siempre.

****** 3FN
Transitividades que se pueden quitar estn CE y CD

R1(_A,B_,C)
R2(_C_,D,*E*)

Perdemos que EC.

****** FNBC
En R2 tenemos dos llaves candidatas, queremos que todo determinante
sea clave candidata.

R1(A,B,C) con clave A,B
R2(C,D,E) con clave C o con clave E.

***** Ejercicio 8
#+begin_statement
Dado

AB, AC, AB, BC, BA, BD, DC
#+end_statement

****** Claves candidatas

| Izq | Med | Der |
|-----+-----+-----|
|     | ABD | C   |

A+={A,B,C,D}
B+={B,A,C,D}
D+={C}

La A y la B son claves candidatas. Hay dependencias transitivas
pasando por la D.

****** 3FN
No queremos transitividad a travs de no primos, as que

R(A,B) candidatas A y B
R(A,D) clave A
R(D,C) clave D

****** FNBC
Todo determinante debe ser clave candidata. Lo es.
** Apuntes de lgebra homolgica de Pascual Jara
*** Homologa de Hochschild
**** R;R mdulos
***** R;R mdulo
Sea $R$ una $K\text{-lgebra}$; un $(R;R)$ *mdulo* es un $R$ mdulo a
izquierda y derecha verificando la *relacin de compatibilidad*:

\[r_1(mr_2) = (r_1m)r_2\]

En particular, se tiene,

\[km = mk \quad \forall k \in K\]

Un *homomorfismo de R;R-mdulos* es un homomorfismo de R-mdulos a izquierda y
R-mdulos a derecha. Forman la categora $(R;R)\mathtt{-Mod}$.

***** lgebra envolvente
Sea $R$ una $K\text{-lgebra}$, llamamos *lgebra envolvente* a $R^e = R \otimes R^{op}$.
Con el producto:

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1)\]

***** Caracterizacin de R;R-mdulos
Para cada $K\text{-lgebra}$, $R$, las categoras siguientes son isomorfas:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$

****** Demostracin
Ntese primero que a $R^e$ le damos estructura de lgebra con el
producto:

\[
(r_1\otimes s_1)(r_2\otimes s_2) = (r_1r_2\otimes s_2s_1)
\]

******* Primera implicacin
Si tenemos $M$ un $(R;R)$ mdulo, podemos darle estructura de $R^e$ mdulo
con: $(r\otimes s)m = rms$. Que esta estructura es compatible con el producto
se comprueba trivialmente con:

\[
(a\otimes b)(c \otimes d)m = acmdb = (ac \otimes bd)m
\]

******* Segunda implicacin
Si tenemos $M$ un $R^e$ mdulo, podemos darle estructura de $R;R$ mdulo
tomando: $rms = (r\otimes s) m$. La relacin de compatibilidad se tiene por
el mismo proceso anterior.

**** Cohomologa de Hochschild
***** Definicin
Sea $R$ una $K\text{-lgebra}$ y $M$ un $(R;R)\text{-mdulo}$, llamamos:

  - *Cohomologa de Hochschild* de $R$ en $M$ a $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - *Homologa de Hochschild* de $R$ en $M$ a $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.

***** Notas
1. [[https://sbseminar.wordpress.com/2007/07/22/hochschild-homology/][Hochschild homology | Secret Blogging Seminar]]

***** Resolucin estndar
Para cada k-lgebra $R$ se tiene $(P_{\bullet},d_{\bullet})$ resolucin proyectiva de $R$ en 
$(R;R)\mathrm{-mod}$. Se llama *resolucin estndar* de $R$, definiendo

 - $P = R \otimes (R^{\otimes n}) \otimes R$
 - $d_{n} = \sum_{i=0}^n (-1)^id^i_n$

donde tomamos

\[
d_n^i(a_0 \otimes \dots \otimes a_{n+1}) =
a_0 \otimes \dots \otimes a_ia_{i+1}\otimes \dots \otimes a_{n+1}.
\]

***** Complejo de cocadenas
Para el clculo de la cohomologa tenemos un complejo de cocadenas

\[
\mathrm{Hom}_K(K,M) \overset{b^0} \longrightarrow
\mathrm{Hom}_K(R,M) \overset{b^1} \longrightarrow
\mathrm{Hom}_K(R^{\otimes 2},M) \overset{b^2} \longrightarrow
\dots.
\]

Donde estn definidas las $b^{n}$ como

 - $b^0(m)(a) = am-ma$
 - $b^n = \sum^{n+1}_{i=0}(-1)^ib_i^n$

para unas aplicaciones auxiliares $b_i^n$ definidas como

\[
b^n_i(f)(a_1\otimes \dots \otimes a_{n+1}) =
\left\{\begin{array}{ll} 
a_1f(a_2\otimes\dots\otimes a_{n+1})& \mbox{if } i=0  \\
f(a_1\otimes\dots\otimes a_ia_{i+1}\otimes\dots\otimes a_{n+1}}& \mbox{if } i=1,\dots,n \\
f(a_1\otimes\dots\otimes a_n)a_{n+1}& \mbox{if } i=n+1
\end{array} 
\right.
\]

**** Desde Weibel
***** Identidades simpliciales
Las identidades simpliciales son las relaciones entre morfismos cara y
morfismos degenerados en un objeto simplicial.

****** Objeto simplicial
Un conjunto simplicial con morfismos:

 - *Morfismos cara*, $\partial_i : S_n \to S_{n-1}$, que eliminan el vrtice $i$.
 - *Morfismos degenerados*, $\sigma_i : S_n \to S_{n+1}$, que duplican el vrtice $i$.

****** Identidades simpliciales
Se cumplen:

 1. $\partial_i\circ\partial_j = \partial_{j-1}\partial_i$ cuando $i<j$
 2. $\sigma_i\comp\sigma_j = \sigma_j\circ\sigma_{i-1}$ cuando $i > j$
 3. Se componen como:

    \[
    \partial_i\circ s_j = \left\{\begin{array}{ll} 
    s_{j-1}\circ\partial_i & \mbox{if } i<j \\
    id & \mbox{if } i=j \mbox{ or } i=j+1 \\
    s_j\circ \partial_{i-1}& \mbox{if } i>j+1
    \end{array} 
    \right.
    \]

****** Diferencial alternado
Definimos el morfismo cara alternado como la suma alternada de morfismos
cara:

\[
\partial(x) =
\sum_{k=0}^n (-1)^k \partial_k(x)
\]

Esto nos da un operador de frontera cumpliendo $\partial\circ\partial=0$.

******* Demostracin
Usando distributividad de la composicin y la primera identidad 
simplicial:

\[\begin{aligned}
\partial\circ\partial
&=
\left(
\sum (-1)^k \partial_k
\right)
\left(
\sum (-1)^t \partial_t
\right)
\\&= 
\sum_{k,t} (-1)^{k+t} \partial_k\partial_t
\\&=
\sum_{k<t} 
\left(
(-1)^{k+t} \partial_k\partial_t +
(-1)^{k+t-1} \partial_{t-1}\partial_k
\right)
\\&= 0
\end{aligned}
\]
***** Mdulo simplicial sobre R;R mdulo
Sea $R$ una k-lgebra y $M$ un $R;R$ mdulo. Tenemos un k-mdulo simplicial
en $M\otimes R^{\otimes\ast}$, dado por:

\[
\dots \longrightarrow
M\otimes R\otimes R \longrightarrow
M\otimes R \longrightarrow
M \longrightarrow 
0
\]

Con fronteras:

\[
\partial_i(m\otimes r_1 \otimes \dots \otimes r_n) =
\left\{\begin{array}{ll} 
mr_1 \otimes r_2 \otimes \dots \otimes r_n& \mbox{if } i = 0 \\
m \otimes r_1 \otimes r_2 \otimes \dots \otimes r_ir_{i+1} \otimes \dots \otimes r_n& \mbox{if } 0 < i < n \\
r_nm \otimes r_1 \otimes r_2 \otimes \dots \otimes r_{n-1} & \mbox{if } i = n
\end{array}.
\right.
\]

Y con degeneracin

\[
\sigma_i(m \otimes r_1 \otimes \dots \otimes r_n) =
m \otimes \dots \otimes r_i \otimes 1 \otimes r_{i+1} \otimes \dots \otimes r_n.
\]

***** Homologa de Hochschild
La homologa de Hochschild se define como la de los k-mdulos:

\[
HH_n(R,M) = H_nC(M\otimes R^{\otimes\ast})
\]

**** Ejemplos de clculo de cohomologa de Hoschild
***** TODO Derivaciones y derivaciones externas
*** lgebras separables
**** lgebras separables
***** Dimensin de Hochschild
Definimos $\mathrm{Hdim}(R)$ como el menor $n$ tal que $HH^{n+1}(R,M) = 0$ para cualquier
mdulo $M$. Si no existe, decimos que hay dimensin de Hochschild infinita.

***** lgebras separables
Las lgebras de dimensin de Hochschild $0$ se llaman *separables*. Se
tiene $R$ un $R^e-\mathrm{mod}$ izquierda proyectivo.

***** Caracterizacin de lgebras separables
Para una k-lgebra R equivalen:

  1) Existen $a_i,b_i \in R$ con $\sum_{i=1}^na_ib_i=1$ y $\sum_{i=1}^n ra_i\otimes b_i = \sum_{i=1}^n a_i \otimes b_ir$.
  2) Dimensin de Hochschild de $R$ cero.
  3) $\mathrm{Der(R,M)} = \mathrm{Der}_{int}(R,M)$ para cada $M$ y $n \geq 1$.

Llamamos $e = \sum_{i=1}^n a_i\otimes b_i \in R^e$ *idempotente de separabilidad*.

***** Teorema de Zelinsky
Toda k-lgebra separable es un k-espacio vectorial de dimensin finita.

**** lgebras semisimples
***** lgebra semisimple
Una k-lgebra es semisimple si cada mdulo a la izquierda suyo es proyectivo.

***** Separable es semisimple
Toda k-lgebra separable es semisimple.

****** TODO Demostracin

***** lgebras separables sobre cuerpos algebraicamente cerrados
Una k-lgebra separable en un cuerpo de caracterstica cero es de la forma:

\[
R \cong
M_{n_1}(K) \times \dots \times M_{n_t}(K)
\]

***** Traza
Llamamos *traza* de $\varphi \in \mathrm{End}(R)$ a la suma de su diagonal. Tenemos

 - una aplicacin $\tau(r) = \mathrm{Tr}(\lambda(r))$ k-lineal.
 - una aplicacin $\sigma(r,s) = \tau(rs)$ k-bilineal simtrica.

Cuando $R$ es k-lgebra separable, $\sigma$ es no degenerada.

***** Caracterizacin de lgebras separables
Para una k-lgebra $R$ equivalen

 1) $R$ una k-lgebra separable.
 2) $\mathrm{dim}_{k}(R) < \infty$ y $\sigma$ es forma bilineal simtrica no degenerada.
 3) Existe un nico idempotente de separabilidad simtrico.

**** lgebras formalmente lisas
***** Extensiones de Hochschild
Para $\pi : S \longrightarrow R$ homomorfismo sobreyectivo con $\ker(\pi)^2=0$,

\[
0 \longrightarrow 
\mathsf{a}= \mathrm{ker}(\pi) \longrightarrow
S \longrightarrow
R \longrightarrow
0
\]

es una *extensin de Hochschild* de $R$ por $\mathsf{a}$.

***** Estructura de R;R-mdulo de la extensin
Si $0 \longrightarrow \mathsf{a} \overset{\pi}\longrightarrow S \longrightarrow R \longrightarrow 0$ es una extensin de Hochschild, entonces
$\mathsf{a}$ es un R;R-mdulo.

****** Demostracin
Consideramos una inversa del homomorfismo sobreyectivo $\pi \circ \psi = id$.
Definimos el producto como

 - $ax = \psi(a)x$
 - $xa = x\psi(a)$

y comprobamos que $a(bx) = (ab)x$. Se tiene en efecto que

\[
\psi(a)\psi(b) - \psi(ab) \in \mathrm{ker}(\pi) = \mathsf{a}
\]

***** Extensiones equivalentes
Dos extensiones de Hochschild son equivalentes si existe un diagrama
conmutativo

\[\begin{tikzcd}
0 \rar & M \arrow[d,equal] \rar & S_1\dar{\varphi}\rar{\pi_{1}} & R \rar\dar[equal] & 0 \\
0 \rar & M \rar & S_2\rar{\pi_{2}} & R \rar & 0
\end{tikzcd}\]

para $\varphi$ un homomorfismo de k-lgebras.

***** lgebra formalmente lisa
Un lgebra $R$ es formalmente lisa si su dimensin de Hochschild es menor o
igual que 1. Equivalentemente, $HH^2(R,M) = 0$ para cualquier $M$. Como
consecuencia, toda extensin de Hochschild es trivial.

***** Producto de separable y formalmente lisa
Si $S$ es separable y $R$ es formalmente lisa, $R \otimes S$ es formalmente lisa.

*** Anillos graduados
**** lgebra aumentada
Una $K\text{-lgebra}$ $R$ es *aumentada* si existe un $R\text{-mdulo}$ $M$ con un 
epimorfismo $\varepsilon\colon R \to M$.

***** lgebra aumentada tensor
Si $\varepsilon\colon R \to M$ es un lgebra aumentada, $\varepsilon\otimes S\colon R\otimes_K S \longrightarrow M \otimes_K S$ es
un lgebra aumentada.

**** Mdulos y lgebras graduadas
***** Mdulo graduado
Un $K\text{-mdulo}$ graduado es aquel que se escribe como suma directa,

\[
M = \bigoplus_{n \in \mathbb{N}} M_n.
\]

****** Elemento homogneo
Un elemento es homogneo de grado $n$ si pertenece a $M_n$.

****** Homomorfismo graduado
Un homomorfismo $f\colon M \to N$ tal que $f(M_n) \subseteq f(N_n)$.

****** lgebra graduada
Un $K\text{-mdulo}$ graduado $R = \bigoplus R_i$ cumpliendo

\[
R_rR_t \subseteq R_{r+t}.
\]

***** Ejemplos de lgebras graduadas
****** Graduacin trivial
****** Graduacin del anillo de polinomios
****** Graduacin del anillo de endomorfismos
***** Homomorfismos graduados
Un homomorfismo graduado de grado $t \in \mathbb{N}$ es aquel homomorfismo $f\colon M \to N$
cumpliendo $f(M_r) \subseteq f(M_{r+t})$.

*** Mdulos diferenciales
**** Diferencial
Un homomorfismo graduado de grado uno, $\delta\colon M \to M$ se llama *diferencial*
si $\delta\circ\delta = 0$.

**** DG-mdulo
Un par $(M,\delta)$ formado por un $K\text{-mdulo}$ graduado $M$ y un diferencial $\delta$.

***** Homomorfismo de DG-mdulos
Un homomorfismo de DG-mdulos $f \colon (M,\delta_1) \to (N,\delta_2)$ es un homomorfismo
de mdulos graduados cumpliendo

\[
f\delta_1 = \delta_2 f.
\]

**** lgebra graduada diferencial
Una $K\text{-lgebra}$ graduada $R$ con un diferencial $\delta\colon R\to R$ que verifica:

  * $(R,\delta)$ es un DG-mdulo.
  * $\delta(ab) = \delta(a)b + (-1)^{|b|}a\delta(b)$.

Es lo que conocemos como *lgebra graduada diferencial*, o DG-lgebra.

***** Aritmtica en lgebras graduadas I
Dada una DG-lgebra $(R,\delta)$,

 1) Para elementos homogneos $h_1,\dots,h_n$ se verifica

    \[ \delta(h_1\dots h_n) =
    \sum_{i=1}^t (-1)^{|h_1|+\dots+|h_{i-1}|}h_1\dots \delta(h_i)\dots h_t.
    \]

 2) Para elementos $a_0,\dots,a_n \in R_0$ se verifica

    \[\delta(a_0 \delta(a_1)\dots \delta(a_n)) =
    \delta(a_0)\delta(a_1)\dots\delta(a_n).
    \]

***** TODO Aritmtica en lgebras graduadas II

**** Complejo de Hochschild
Definimos el *complejo de Hochschild* como

\[
C_{\bullet}(R,M)\colon \dots 
\longrightarrow M \otimes R^{\otimes n}
\overset{d}\longrightarrow M \otimes R^{\otimes n-1}
\overset{d}\longrightarrow \cdots
\]

donde las diferenciales se definen como $d = \sum (-1)^id_i$ para

\[\begin{aligned}
d_0(m\otimes a_1\otimes\dots\otimes a_n) &= (ma_1)\otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= m \otimes a_1\otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_n \\
d_i(m\otimes a_1\otimes\dots\otimes a_n) &= a_nm \otimes a_1\otimes \dots \otimes \dots \otimes a_{n-1} \\
\end{aligned}
\]

***** Es un diferencial
Se tiene que $d\circ d = 0$.

***** Complejo bar
En el caso particular de $R=M$ tenemos

\[C_{\bullet}(R) = C_{\bullet}(R,R) = 
(\cdots \to R^{\otimes n+1} \to \cdots \to R)\]

Llamamos *complejo bar* a

\[ C^{bar}_{\ast}(R) = (\cdots \to R^{\otimes n} \to \cdots \to R^{\otimes 2}).
\]

***** Complejo bar normalizado
Llamamos $D_n$ al generado por elementos $m\otimes a_1\otimes \dots\otimes a_n$ donde algn $a_i = 1$.
Podemos crear el complejo bar normalizado con mdulos de la forma

\[\frac{M\otimes R^{\otimes n}}{D_n} \cong M \otimes \overline{R}^{\otimes n}.
\]

Lo representamos por $\overline{C}(R,M)$.

*** La DG-lgebra Omega
**** DG-lgebra omega
Definimos

\[
\Omega_S^nR = 
R \otimes_S \overline{R}^{\otimes n}
\quad\text{ y, en total, }\quad
\Omega_SR = \bigoplus_{n\in \mathbb{N}} \Omega_S^n R.
\]

La diferencial la definimos mediante

\[
\delta(a_0\oplus \overline{a_1} \oplus\dots\oplus \overline{a_r})
=
1 \oplus \overline{a_0} \oplus \dots \oplus \overline{a_r}.
\]

** lgebra conmutativa de Carlos Ivorra
*** I. Funtores Derivados
**** 1.1. Haces
***** Prehaces
Un *prehaz* sobre un espacio topolgico $X$ es un par $({\cal F},\rho)$, donde cada abierto $U$
tiene un grupo asociado ${\cal F}(U)$ y cada inclusin $U \subset V$ tiene asociado un homomorfismo
llamado *restriccin*, $\rho_U^V : {\cal F}(V) \longrightarrow {\cal F}(U)$ cumpliendo:

  - ${\cal F}(\varnothing) = 0$
  - $\rho_U^U$ es la identidad
  - Si $U\subset V\subset W$, entonces $\rho_V^W \circ \rho_U^V = \rho_U^W$

Cuando los grupos ${\cal F}(U)$ son anillos o mdulos tenemos un *prehaz de anillos* o un
*prehax de mdulos*.

# Categricamente, un funtor contravariante desde los conjuntos del espacio
# topolgico con la inclusin a los grupos, o mdulos, o lgebras...

***** Notacin de restriccin
Normalmente escribiremos $f|_{U}$ para llamar a la restriccin de $f$ a $U$, esto 
es $\rho_U^V(f)$.

***** Haces
Un *haz* es un prehaz tal que si $U = \bigcup U_i$ es el recubrimiento de un abierto:

  - Si $f|_{U_i} = 0$ para todos los $i$, entonces $f = 0$.
  - Para una familia de elementos $f_i \in {\cal F}(U_i)$ cumpliendo que 
    $f_i|_{U_i \cap U_j} = f_j|_{U_i \cap U_j}$, se tiene que hay un $f \in {\cal F}(U)$ tal que $f|_{U_i} = f_i$.

***** Grupo de grmenes o grupo local
Dado un prehaz ${\cal F}$ sobre $X$, con $P \in X$, llamamos *grupo de grmenes* en $P$ al grupo
${\cal F}_P$, formado por las clases de equivalencia de pares $(U,f)$ con $P\in U$, $f \in {\cal F}(U)$;
respecto de la relacin dada por $(U,f) \sim (V,g)$ ssi hay un abierto $W \subset U \cap V$
tal que $P \in W$ y adems $f|_W = g|_W$. Teniendo como operacin de grupo a:

\[ [(U,f)]+[(V,g)] = [(U\cap V, f|_{U\cap V} + g|_{U\cap V})] \]

***** Homomorfismo de prehaces
Un *homomorfismo de prehaces* $\alpha : {\cal F} \longrightarrow {\cal G}$, asigna a cada abierto $U$ un homomorfismo
de grupos $\alpha_U : {\cal F}(U) \longrightarrow {\cal G}(U)$, tal que:

\[ \begin{tikzcd}
{\cal F}(V) \rar{\alpha_V} \dar[swap]{\rho_U^V} & {\cal G}(V) \dar{\rho_U^V} \\
{\cal F}(U) \rar{\alpha_U} & {\cal G}(U)
\end{tikzcd} \]

# Categricamente son transformaciones naturales.

** Koszul pairs
# Parte de la memoria de beca de colaboracin con Pascual Jara.
*** Introduction
*Koszul algebras* have numerous applications in diverse fields of
Mathematics such as Algebraic Topology, Combinatorics, Representation
Theory or Algebraic Geometry, as it is showed in cite:polishchuk05,
and many of its fundamental properties still hold in *Koszul rings*,
a particular case of graded rings.

*Almost-Koszul pairs* are a tool for the study of Koszul rings; to
every strongly graded ring corresponds a canonical almost-Koszul pair.
Every almost-Koszul pair has three associate chain complexes and three
cochain complexes. If any of this six complexes is exact, all the others
are exact too; in this case, we call the pair a *Koszul pair*.

*** Area of interest
In order to define Koszul pairs, we need to introduce some homological
algebra prerequsites. We will define abelian categories in general,
even if we are going to use later only the particular case of module
categories, where we will define projective, injective and flat
modules.

In particular, we will need to define *Hoschschild comohology*.

**** Abelian categories
The theory of abelian categories was introduced by Buchsbaum and Grothendieck
in cite:grothendieck57 to unify the multiple cohomology theories at the time.

***** Additive category
The original motivation for additive categories is the category of abelian
groups, and, more generally, the category of momdules over a fixed ring $R$.
In these categories, morphisms between two objects form an abelian group;
and we can define functors preserving this group structure.

#+begin_definition
${\cal C}$ is an *additive category* if:

 - $\mathrm{Hom}(A,B)$ is an /abelian group/.
 - /Distributivity/ holds: $b \circ (f+g) = b\circ f + b \circ g$ and $(f+g)\circ a = f\circ a + g\circ a$.
 - Has a /zero object/.
 - Has finite /products/ and /coproducts/.

A functor $T$ between two additive categories is and *additive functor* 
if $T(f+g) = Tf+Tg$. cite:rotman08_setting
#+end_definition

***** Abelian category
Our interest is specifically on abelian categories. We will need to
assume that every morphism has a kernel and a cokernel in order to
prove results on homological algebra.

#+begin_definition
An *abelian category* is an /additive category/ such that

  * every morphism has a kernel and cokernel.
  * every monomorphism is a kernel.
  * every epimorphism is a cokernel.
#+end_definition

The category of $R\text{-modules}$ is an abelian category, but also
the category of chain complexes of an arbitrary abelian category,
$\mathtt{Ch}({\cal A})$, is an abelian category.

**** Chain complexes and homology
/Homology/ was originally defined in algebraic topology as a rigorous
method allowing the topological distinction of manifolds with arbitrary
dimensional holes. The same construction can be translated into multiple
different homology theories.

$\quad$

In abelian categories, the homology provides a formal description of
the failure of a functor to be exact.

***** Chain complexes
/Chain complexes/ were initially a representation the relationships
between cycles and boundaries on a topological space; we will study
chain complexes in the abstract setting of module categories, devoided
of any explicit relation to its motivating example.

#+begin_definition
A *chain complex* is a family of $R\text{-modules}$ $\left\{ C_n \right\}$ and homomorphisms
$d_n \colon C_n \to C_{n-1}$ called /differentials/, such that each composite of
consecutive differentials is zero, i.e. $d_{n-1} \circ d_n = 0$.
#+end_definition

#+begin_theorem
Given an abelian category ${\cal A}$, the category $\mathtt{Ch}({\cal A})$ is an abelian category.
cite:weibel94_introd
#+end_theorem

***** Exact sequences
/Exact sequences/ provide a convenient framework for homological questions
such as the completion of the middle term of a particular sequence in such
a way that the homology groups are exactly zero. This kind of problems, in
particular in the category of groups, have been proven to be useful to the
resolution of problems such as the classification of finite simple groups.

#+begin_definition
A pair of composable morphisms is *exact* in the object where they can be
composed when $\mathrm{img}(f) = \mathrm{ker}(g)$. Equivalently, when $\mathrm{coker}(f) = \mathrm{coimg}(g)$.
#+end_definition

#+begin_definition
A *short exact sequence* is a diagram

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

exact on $a$,$b$ and $c$.
#+end_definition

#+begin_definition
A *morphism of short exact sequences* is defined by three morphisms
$f,g,h$ making the following diagram commute

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

The short exact sequences of an abelian category $A$ define a category with
these morphisms called $\mathtt{Ses}(A)$, which is preadditive with the component by 
component sum.
#+end_definition

***** Snake lemma
The /snake lemma/ will provide us with a tool to construct long exact sequences,
which will be used in the definition of derived functors. This is a first result
on algebraic homology theory.

#+begin_theorem
Given a morphism of short exact sequences $f,g,h$; there exists a morphism
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ such that the following sequence is exact

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
In this extended diagram

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

we can first define the morphism $\delta$ using the properties of abelian categories
to prove that it exists and then prove that it is exact using again the
properties of monomorphisms and epimorphisms.
#+end_proof

***** Homology
The definition of /homology/ tries to capture the failure of the complex to be
exact as the quotient of the kernel and the image of the sucessive differential
maps.

#+begin_definition
Given a chain complex $\left\{ C_n \right\}$ with differentials $d_n$, we define the nth
homology group as

\[ H_n(C) \cong \mathrm{ker}(d_n) / \mathrm{im}(d_{n+1}).
\]
#+end_definition

It is important to notice that a sequence will be exact if and only if
all their homology groups are zero.

**** Projective, injective and flat resolutions
Resolutions of injective modules are needed to define Hochschild
homology.

***** Definitions
#+begin_definition
An R-module $D$ is:

 1. *Projective* if $\mathrm{Hom}(D, -)$ is exact.
 2. *Injective* if $\mathrm{Hom}(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.
#+end_definition

We know that $\mathrm{Hom}(D,-)$ and $\mathrm{Hom}(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ epimorphism induces
   $\mathrm{Hom}(D,B) \longrightarrow \mathrm{Hom}(D,C)$ epimorphism.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ epimorphism induces
   $\mathrm{Hom}(B,D) \longrightarrow \mathrm{Hom}(A,D)$ epimorphism.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ monomorphism induces 
   $D\otimes A \longrightarrow D \otimes B$ monomorphism.

***** Resolutions
#+begin_definition
A *projective resolution* is a resolution

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where every $P_i$ is projective.
#+end_definition

#+begin_definition
An *injective resolution* is a resolution

\[0 \longrightarrow M \longrightarrow E^0\longrightarrow E^1
\longrightarrow E^2 \longrightarrow \dots\]

where every $E^i$ is injective.
#+end_definition

#+begin_definition
A *flat resolution* is a resolution

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.
#+end_definition

****** Explicit construction
Notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

***** Derived functors
/Derived functors/ provide a canonical way to extend the image of an
exact sequence by a non two-sided exact functor.  We need an abelian
category $A$ with enough injectives to construct left-derived
functors; and we need enough projectives to construct right-derived
functors.

****** Construction of the right derived functor
Let $F$ be additive, covariant and left-exact. Let $0 \longrightarrow M \longrightarrow E^\bullet$ be an 
injective resolution with $M$ deleted; then $F(E^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E^i) \longrightarrow F(E^{i+1})\}}
{\im\{ F(E^{i-1}) \longrightarrow F(E^i)\}}\]

That is, if we take the /injective resolution/

\[ 0 \longrightarrow M \longrightarrow E^0 \longrightarrow E^1 
\longrightarrow \dots\]

we can delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology

\[ 0 \longrightarrow F(E^0) \longrightarrow F(E^1)
\longrightarrow F(E^2) \longrightarrow \dots.\]

****** Construction of the left derived functor
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the /projective resolution/

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

**** Hochschild homology
***** Preliminaries
Our main interest will be on a particular kind of homology and comology called
/Hochschild homology/. This section defines the preliminary necessary concepts
to develop the notion of Hochschild homology.

****** Opposite algebra.
The definition of an /opposite algebra/ is a trvial notion which will be crucial
to create the definition of a standard resolution of an algebra over a field.

#+begin_definition
If $A$ is an $R\text{-algebra}$, the *opposite algebra* of $A$, with a multiplication
given by yuxtaposition is $A^\ast$; an algebra with the same set of elements and where
the multiplication $\circ$ is defined as $x \circ y = yx$.
#+end_definition

****** Enveloping algebra.
#+begin_definition
Let $R$ be a $k\text{-algebra}$, the *enveloping algebra* of $R$ is the tensor
product $R^e = R \otimes R^{op}$, where the product is defined as

\[ (r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2) \otimes (s_2s_1).\]
#+end_definition

#+begin_theorem
Given any $k\text{-algebra}$, $R$, the following categories are isomorphic:

  - $(R;R)\text{-Mod}$
  - $R^e\text{-Mod}$
  - $\text{Mod-}R^e$
#+end_theorem
#+begin_proof
If $M$ is an $(R;R)\text{-module}$, we can provide it with $R^e\text{-module}$ structure
by defining $(r\otimes s)m = rms$. It is trivial to check that this structure is
compatible with our previously defined product, as

\[
(a\otimes b)(c \otimes d)m = acmdb = (ac \otimes bd)m.
\]

If $M$ is an $R^e\text{-module}$, we can provide it with $R;R\text{-module}$ structure
taking $rms = (r\otimes s) m$. Compatibility relation can be checked by the same
reasoning.
#+end_proof

****** Standard resolution.
#+begin_definition
Given $R$, a $k\text{-algebra}$ we define the *standard resolution* $(P_{\bullet},d_{\bullet})$ of $R$ in
$(R;R)\mathrm{-Mod}$ as

 - $P_n = R \otimes (R^{\otimes n}) \otimes R$
 - $d_{n} = \sum_{i=0}^n (-1)^id^i_n$

where

\[
d_n^i(a_0 \otimes \dots \otimes a_{n+1}) =
a_0 \otimes \dots \otimes a_ia_{i+1}\otimes \dots \otimes a_{n+1}
\]
#+end_definition

***** Hochschild homology
#+begin_definition
Given $R$, a $K\text{-algebra}$, and $M$, an $(R;R)\text{-module}$, we define:

  - The *Hochschild cohomology* of $R$ in $M$ as $HH^{\bullet}(R,M) = \operatorname{Ext}^\bullet_{R^e}(R,M)$.
  - The *Hochschild homology* of $R$ in $M$ as $HH_{\bullet}(R,M) = \operatorname{Tor}_\bullet^{R^e}(R,M)$.
#+end_definition

In order to compute the cohomology, we can take the following cochain
complex

\[
\mathrm{Hom}_K(K,M) \overset{b^0} \longrightarrow
\mathrm{Hom}_K(R,M) \overset{b^1} \longrightarrow
\mathrm{Hom}_K(R^{\otimes 2},M) \overset{b^2} \longrightarrow
\dots.
\]

where the $b^n$ are defined as

 - $b^0(m)(a) = am-ma$
 - $b^n = \sum^{n+1}_{i=0}(-1)^ib_i^n$

and the auxiliary morphisms $b_i^n$ are defined as

\[
b^n_i(f)(a_1\otimes \dots \otimes a_{n+1}) =
\left\{\begin{array}{ll} 
a_1f(a_2\otimes\dots\otimes a_{n+1})& \mbox{if } i=0  \\
f(a_1\otimes\dots\otimes a_ia_{i+1}\otimes\dots\otimes a_{n+1}}& \mbox{if } i=1,\dots,n \\
f(a_1\otimes\dots\otimes a_n)a_{n+1}& \mbox{if } i=n+1
\end{array}.
\right.
\]

*** Methods
Our methodology is based on the review of the basic bibliography of the
subject. This article is an attempt to collect all the needed
prerequisites to work with homology and cohomology theory and
ultimately to work with Hochschild homology and Koszul pairs.

Apart from the bibliographic review, we have developed materials for
future students interested in the subject.

***** Wikipedia articles
In order to achieve a higher level of understanding of the topic and
to provide future students with accesible resources, we have written
the following articles for the Spanish wikipedia; they are published
using a Creative Commons license.

 * [[https://es.wikipedia.org/wiki/Compleci%C3%B3n_(%C3%A1lgebra)][Complecin (lgebra)]]
 * [[https://es.wikipedia.org/wiki/Lema_de_escisi%C3%B3n][Lema de escisin]]
 * [[https://es.wikipedia.org/wiki/Lema_de_la_serpiente][Lema de la serpiente]]
 * [[https://es.wikipedia.org/wiki/Funtor_Tor][Funtor Tor]]
 * [[https://es.wikipedia.org/wiki/Homolog%25C3%25ADa_de_Hochschild][Homologa de Hochschild]]
 * [[https://es.wikipedia.org/wiki/Categor%25C3%25ADa_coma][Categora coma]]
 
***** Student-organized seminars
Two student-organized seminars have been held in the university. In
those seminars, the author has lectured about category theory; giving
a basic introduction to mathematics and computer science students.

*** Discussion
**** Koszul algebra
/Koszul rings/ will be a generalization of /Koszul algebras/. A pair of a
ring and its categorical dual, a coring; toghether with certain coherence
relations, will constitute our definition of a Koszul pair.

#+begin_definition
A graded algebra $A$ is a *Koszul algebra* over a field $k$ if
every graded module has a graded projective resolution
$P_{\bullet}$ where the projective module $P_j$ is generated by homogeneous
elements of degree $j$.
#+end_definition

***** Quadratic algebras
Koszul algebras are a particular case of quadratic algebras. We can describe
them in full generality with the following definition.

#+begin_definition
A graded algebra $A$ is a *quadratic algebra* if the natural
application from its tensor algebra $T(A) \to A$ is surjective
and its kernel $J_A$ is generated from $J_{A} \cap (A^{1} \otimes A^1)$. cite:polishchuk05
#+end_definition

In other words, a graded quadratic algebra is determined as the
quotient of a vector space $A_{1}$ by a subspace of homogeneous
quadratic relations $S \subset V \otimes V$ as

\[
A = T(V) / \left\langle S \right\rangle.
\]

#+begin_theorem
Every Koszul $R\text{-ring}$ is a quadratic algebra.
#+end_theorem

**** Almost-koszul pairs
Previous to the definition of Koszul pairs, we are going to define
/almost-koszul pairs/. Those will provide us with a weaker set of
requirements and we will be able to obtain a definition of Koszul
pairs suitable to every almost-koszul pair.

***** Graded rings
#+begin_definition 
A *graded ring* is a ring that can be written as a direct sum of
abelian groups

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.
#+end_definition

A *homogeneous element* is an element of any submodule $A_i$ of the
decomposition.

***** Koszul rings
#+begin_definition
A graded ring $A$ is a *Koszul ring* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.
cite:jarastefan10
#+end_definition

***** R-rings
#+begin_definition
An $R\text{-ring}$ is an associative and unital algebra. It is an associative and
unital ring $A$ together with a morphism $u : R \longrightarrow A$.
#+end_definition

A R-ring is *graded* if it is equipped with a decomposition

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

***** R-coring
Corings will be the categorical dual of rings. In order to define them, we
proceed by giving defitions of coalgebra and certain properties of this kind
of algebras. Those are also the dual notions to the preliminary definitions
we described at the start of this chapter.

#+begin_definition
A *coalgebra* over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$
#+end_definition

When writting in coalgebras, we will follow the *Sweedler
notation*. cite:underwood15_hopf

#+begin_definition
An $\mathbf{R\text{-coring}}$ is a /coassociative/ and /counital/ /coalgebra/. It is an 
$R\text{-bimodule}$ with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and  a /counit/
$\epsilon : C \longrightarrow R$.
#+end_definition

A $R\text{-coring}$ is *graded* if it is equipped with a decomposition 
$C = \bigoplus_{n \in \mathbb{N}} C_n$, such that

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}.\]

***** Almost-koszul pair
#+begin_definition
An *almost-Koszul pair* is a connected $R\text{-ring}$ and $R\text{-coring}$ $(A,C)$ 
with an isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$ that satisfies the relation

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0.\]
#+end_definition

Using Sweedler notation we can rewrite the condition as follows 


\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0,\]

for any $c \in C_2$.

**** Almost-koszul pair complexes
Six complexes will be associated to any given Koszul pair. Its
exactness will be related, i.e., if any one of them is exact, the six
complexes will be exact. This provides a definition of Koszul
pairs relying only on this kind of complexes.

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, if we define

\[
K^{-1}_l(A,C) = R
\quad\text{ and }\quad
K^n_l(A,C) = C \otimes A^n,
\]

and the differential maps

\[
d^n_l(c \otimes a) = \sum c_{(1,p-1)} \otimes \theta_{C,A}(c_{(2,1)})a,
\]

with the exceptional case $n = -1$, where we take $d^n_l$ to be the canonical
bimodule morphisms $R \to C \otimes A^0$, mapping $1 \mapsto 1 \otimes 1 \in C_0 \otimes A^0$. We will
also define the same notion on the opposite pair as

\[
K_r^{\ast}(A,C) = K^{\ast}_l(A^{op},C^{op}).
\]
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, we define

\[
K^{-1}(A,C) = C
\quad\text{ and }\quad
K^n(A,C) = C \otimes A^n\otimes C,
\]

and the differential relations given by $d^{-1} = \Delta$ and

\[
d^n = d^n_l \otimes I_C + (-1)^{n+1}I_C \otimes d^n_r.
\]
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, if we define

\[
K^r_{-1}(A,C) = R
\quad\text{ and }\quad
K^r_n(A,C) = C_n \otimes A,
\]

and the differential maps

\[
d_n^r(c \otimes a) = \sum c_{(1,n-1)} \otimes \theta_{C,A}(c_{(2,1)})a.
\]

Appliying the same construction to the opposite almost-Koszul pair
gives us the complex $K^l_{\ast}$.
#+end_definition

#+begin_definition
Let $(A,C)$ be an almost-Koszul pair, we define

\[
K_{-1}(A,C) = A
\quad\text{ and }\quad
K_n(A,C) = A \otimes C_n \otimes A,
\]

and the differential relations given by $d_0$, induced by multiplication,
and

\[
d_n^{l}(a \otimes c) = \sum a\theta_{C,A}(c_{(1,1)}) \otimes c_{(2,n-1)};
\]

defining $d_n = d_n^l \otimes I_A + (-1)^nI_A\otimes d_n^r$.
#+end_definition

**** Koszul pairs
#+begin_theorem
Given an almost-Koszul pair $(A,C)$, if one of these six complexes is
exact, all of them are exact, as it is showed in cite:jarastefan10.

 * $K^{l}_{\ast}(A,C)$.
 * $K^r_{\ast}(A,C)$.
 * $K_{\ast}(A,C)$.
 * $K^{\ast}_l(A,C)$.
 * $K_r^{\ast}(A,C)$.
 * $K^{\ast}(A,C)$.
#+end_theorem

#+begin_definition
An almost-Koszul pair $(A,C)$ is said to be *Koszul* if and only if the
previously discussed complexes are exact.
#+end_definition

*** Conclusions
Starting from a very basic undergraduate mathematical level, all the
necessary definitions of categories, chain complexes and homology have
been developed in this work. This constitutes a reference for students
interested on the specific field of Koszul pairs and sets the ground
for future developments and undergraduate and graduate-level research.

$\quad$

In particular, future work should be able to find new
characterizations of Koszul pairs in terms of homology and cohomology
apart from the known characterizations found on cite:jarastefan10.

*** References
bibliographystyle:unsrt
bibliography:math.bib
** TFG I: links and resources
*** Journal
**** June 2017
***** <2017-05-31 Wed>
****** created this file.
****** read MacLane chapter III.2.
***** <2017-06-01 Thu>
****** read https://golem.ph.utexas.edu/category/2006/08/cartesian_closed_categories_an_1.html
****** started reading chapter 4 on Lecture Notes on the lambda calculus by Selinger
****** superficial complete lecture of Selinger
***** <2017-06-02 Fri>
****** read https://bartoszmilewski.com/2016/11/21/monads-programmers-definition/
****** read multiple sections of MacLane
****** wrote a mikrokosmos section
***** <2017-06-03 Sat>
****** read MacLane. Yoneda Lemma
****** exercises from MacLane
***** <2017-06-04 Sun>
****** read I.1.1 to I.1.6 of Hott book
****** installed agda on emacs
***** <2017-06-05 Mon>
****** installed hott-library on agda
****** wrote simple proofs in agda
****** read I.1.10 and I.1.11 of Hott book
***** <2017-06-06 Tue>
****** installed [[https://proofgeneral.github.io/download/][Proofgeneral]] and [[https://coq.inria.fr/][Coq]]
****** completed first chapter exercises of Software Foundations
****** added 'tasty-hunit' tests to mikrokosmos
****** added travis-ci to mikrokosmos
***** <2017-06-07 Wed>
****** read MacLane: monads and algebras
***** <2017-06-08 Thu>
****** exercises from MacLane
***** <2017-06-09 Fri>
****** read Sheaves in geometry and logic
***** <2017-06-10 Sat>
****** applied to EUTypes 2017
***** <2017-06-11 Sun>
****** exercises from chapters 1 and 2 of software foundations
***** <2017-06-12 Mon>
****** created a specific ctlc.org file
****** rewrote tfg.org
Mikrokosmos won't solve the IO problem. If IO is needed,
it can be achieved via scripts.
***** <2017-06-13 Tue>
****** installed Why3
***** <2017-06-14 Wed>
****** installed docker container for Why3 and solvers
****** installed Coq-hott library
***** <2017-06-15 Thu>
****** wrote a jupyter kernel for mikrokosmos
***** <2017-06-16 Fri>
****** minor changes on mikrokosmos
****** wrote mikrokosmos user's guide
***** <2017-06-17 Sat>
****** wrote highlighter for Jupyter Notebook
****** solved minor problems on Jupyter output formatting
****** saw [[https://www.youtube.com/watch?v=21qPOReu4FI][Five Stages of Accepting Constructive Mathematics, by Andrej Bauer]]
****** wrote a section on simply typed lambda calculus
***** <2017-06-18 Sun>
****** started reading Types and programming languages
****** started following the agda tutorial
***** <2017-06-19 Mon>
****** wrote notes on the first lecture on HoTT.
****** wrote notes on the second lecture on HoTT.
***** <2017-06-20 Tue>
****** done homework 1 of the course on HoTT.
****** wrote notes on the third lecture on HoTT.
****** wrote notes on the fourth lecture on HoTT.
***** <2017-06-21 Wed>
****** wrote notes on the fifth lecture on HoTT.
***** <2017-06-22 Thu>
****** wrote notes on the sixth lecture on HoTT.
****** wrote notes on the seventh lecture on HoTT.
****** wrote notes on the eighth lecture on HoTT.
***** <2017-06-23 Fri>
****** wrote notes on the ninth lecture on HoTT.
****** wrote notes on the tenth lecture on HoTT.
****** wrote an org-mode template for the thesis.
***** <2017-06-24 Sat>
****** [[http://orgmode.org/cgit.cgi/org-mode.git/commit/?id=e903288e5080775cbd4d87c69deeba3268cda5c1][fixed bug]] in org-mode
***** <2017-06-25 Sun>
****** wrote notes on the eleventh lecture on HoTT.
****** wrote notes on the twelfth lecture on HoTT.
****** wrote notes on the thirteenth lecture on HoTT.
****** wrote notes on the fourteenth lecture on HoTT.
***** <2017-06-26 Mon>
****** wrote notes on the fiveteenth lecture on HoTT.
***** <2017-06-27 Tue>
****** [[https://math.stackexchange.com/questions/2337093/does-homotopy-type-theory-have-a-computational-interpretation][has HoTT a computational interpretation?]]
***** <2017-06-28 Wed>
***** <2017-06-29 Thu>
****** wrote hott code in agda
***** <2017-06-30 Fri>
****** wrote hott code in agda
**** July 2017
***** <2017-07-01 Sat>
***** <2017-07-02 Sun>
****** wrote hott code in agda
***** <2017-07-04 Tue>
****** wrote notes on the 16th lecture on HoTT.
***** <2017-07-05 Wed>
****** wrote notes on the 17th lecture on HoTT.
****** wrote notes on the 18th lecture on HoTT.
***** <2017-07-06 Thu>
****** wrote notes on the 19th lecture on HoTT.
****** wrote notes on the 20th lecture on HoTT.
***** <2017-07-07 Fri>
****** wrote notes on the 21th lecture on HoTT.
****** wrote notes on the 22th lecture on HoTT.
****** wrote notes on the 23th lecture on HoTT.
****** finished course on HoTT.
***** <2017-07-08 Sat>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-09 Sun>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-10 Mon>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-11 Tue>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-12 Wed>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-13 Thu>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-14 Fri>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-15 Sat>
****** EUTypes 2017. Ohrid, Macedonia.
***** <2017-07-16 Sun>
****** read about the continuum hypothesis
***** <2017-07-17 Mon>
****** solved a bug in the stack tool by updating.
****** mikrokosmos starts using GHC 8.0.2.
****** color and verbose options for mikrokosmos.
****** multiple line format on mikrokosmos.
***** <2017-07-18 Tue>
****** Ski abstraction on mikrokosmos.
***** <2017-07-19 Wed>
****** Ski option for the user.
****** pip-installable jupyter kernel.
***** <2017-07-20 Thu>
****** Closed multiple minor issues on mikrokosmos
***** <2017-07-21 Fri>
****** Read about algebraic Lawvere theories
****** Rewrote installation
****** Rewrote user's guide
****** Mikrokosmos tutorial: part 1
***** <2017-07-22 Sat>
****** Published mikrokosmos v0.3.0
****** Mikrokosmos tutorial: part 2
***** <2017-07-23 Sun>
****** Untyped lambda calculus
***** <2017-07-24 Mon>
****** Wrote: Church-Rosser theorem
****** Wrote: Programming in the untyped \lambda-calculus
***** <2017-07-25 Tue>
****** Types on mikrokosmos
****** Type unification algorithm
****** Type inference algorithm
***** <2017-07-26 Wed>
****** Type normalization algorithm
****** Update tutorial and user's guide
***** <2017-07-29 Sat>
****** Read about Topoi
***** <2017-07-30 Sun>
****** Rewrote STCL using only the implication
****** Wrote a section on Curry typing
***** <2017-07-31 Mon>
****** Wrote about the curry-howard correspondence
****** Implementing generalized STLC types on mikrokosmos
**** August 2017
***** <2017-08-01 Tue>
****** Wrote about the curry-howard correspondence
****** Wrote about natural deduction
***** <2017-08-02 Wed>
****** Refactored mikrokosmos code
****** Updated jupyter-kernel
****** Added unicode and agda output to the latex template
***** <2017-08-03 Thu>
****** updated user's guide
****** updated tutorial
****** wrote programming on STLC
***** <2017-08-04 Fri>
****** wrote about normalization and evaluation strategies
***** <2017-08-05 Sat>
****** wrote about categories
***** <2017-08-06 Sun>
****** tried (and failed) to create a debian package for mikrokosmos
***** <2017-08-07 Mon>
****** Wrote about basic category theory
***** <2017-08-08 Tue>
****** Heyting algebras
****** Minor changes to Mikrokosmos
***** <2017-08-09 Wed>
****** Russell's paradox in agda
***** <2017-08-12 Sat>
****** Wrote about Heyting algebras
***** <2017-08-13 Sun>
****** Talk on Categorical foundations by Awodey
***** <2017-08-14 Mon>
****** Notes on categorical foundations
****** Fix minor bugs on mikrokosmos
****** Use macros on latex
***** <2017-08-15 Tue>
****** Created server on Digital ocean
****** Created domain name on Namecheap
****** Created SSL certificate
****** Installed mikrokosmos in the server
****** Installed JupyterHub
****** GitHub OAuth
****** trymikrokosmos.me
***** <2017-08-16 Wed>
****** Wrote 7 tutorials on mikrokosmos
****** Updated libraries on trymikrokosmos.me
****** Minor additions to the category theory chapter
****** Wrote about SKI combinators
****** Wrote about evaluation and output in mikrokosmos
***** <2017-08-17 Thu>
****** Tested mikrokosmos under NixOS
***** <2017-08-18 Fri>
****** Wrote about pure type systems and the lambda cube
***** <2017-08-19 Sat>
****** Wrote about Haskell
****** Wrote about the lambda cube
***** <2017-08-20 Sun>
****** Algebraic theories
****** Models as functors
****** Closed multiple issues on Mikrokosmos
***** <2017-08-21 Mon>
****** Introduction to topos theory
****** Derivatives of regular types and zippers
***** <2017-08-23 Wed>
****** Read An introduction to topos theory.
***** <2017-08-24 Thu>
****** Wrote about dinatural transformations.
***** <2017-09-25 Mon>
***** <2017-09-26 Tue>
****** Experimenting with GHCJS
***** <2017-09-27 Wed>
****** MikrokosmosJS
***** <2017-09-28 Thu>
****** Codemirror pads for MikrokosmosJS
***** <2017-09-29 Fri>
****** Tutorials for mikrokosmos
****** Gentzen deduction trees
***** <2017-09-30 Sat>
****** Mikrokosmos 0.7.0
****** Update libraries
***** <2017-08-31 Thu>
****** Wrote tutorials for Mikrokosmos
**** September 2017
***** <2017-09-01 Fri>
****** JupyterHub server on iemath
****** Testing Mikrokosmos on NixOS
***** <2017-09-02 Sat>
****** Lawvere algebraic theories
***** <2017-09-03 Sun>
****** From sets to types to categories to sets
***** <2017-09-04 Mon>
****** Cartesian closed categories and lambda theories
***** <2017-09-05 Tue>
****** Meeting
****** Rewrote first sections on untyped lambda calculus
***** <2017-09-06 Wed>
****** Rewrote untyped lambda calculus
****** Added a section on SKI combinators
***** <2017-09-07 Thu>
***** <2017-09-08 Fri>
***** <2017-09-09 Sat>
***** <2017-09-10 Sun>
***** <2017-09-11 Mon>
****** Ends
****** 2-categories
***** <2017-09-16 Sat>

*** Notes
**** [[file:ctlc.org][Category theory and lambda-calculus]]
**** [[file:categoriesfortheworking.org][Categories for the working mathematician - MacLane]]
**** [[file:lecturesonthelambdacalculus.org][Lecture notes on the lambda calculus - Selinger]]
**** [[file:homotopytypetheory.org][Homotopy type theory - Univalent foundations]]
**** [[file:sheavesgeometrylogic.org][Sheaves in geometry and logic - MacLane]]
**** [[file:typesandprogramminglanguages.org][Types and programming languages - Pierce]]
**** DONE [[file:courseonhott.org][Course on Homotopy Type Theory - Robert Harper]]
**** [[file:introcategoricallogic.org][Introduction to categorical logic - Bauer, Awodey]]
*** Tasks
**** Write
***** Ideas
****** Syntax and semantics
****** Variable capture and deBruijn indices.
***** Mikrokosmos section
***** Untyped lambda calculus section
***** Type theory introduction
***** Category theory introduction
***** Wikipedia
****** Agda
**** Read
***** From sets to categories to types to sets
***** Elienberg categorical foundations
***** Extensionality on categories
Commutativity and efficiency

**** [#A] Mikrokosmos
Mikrokosmos is a lambda calculus interpreter.

***** TODO Implement type theory http://www.cse.chalmers.se/%7Ebengt/papers/GKminiTT.pdf
***** TODO Implement simply-typed lambda calculus with products and a terminal type
It is the language of CCCs.
It can be showed that it is strongly normalizable.

***** TODO Implement Hindley-Milner or System F
System F has no decidable inference, you have to write more.
Hindley-Milner does not allow for types on quantifiers.

System F and the Girard-Reynolds isomorphism seem like great ideas.

***** TODO [#C] Multiple lines on modules
Multiple line notation should be allowed by joining multiple lines whenever
they start with a <TAB> or a space.
***** TODO Write tests
***** TODO Should Multibimap be a package on its own?
***** Compile to categories
***** Seminars about mikrokosmos
***** Dependent types
http://math.andrej.com/2012/11/08/how-to-implement-dependent-type-theory-i/
***** Write a pygments lexer
http://pygments.org/docs/lexerdevelopment/

***** Emacs theme
***** Logo background should be a "cosmos" background
***** DONE [#A] Module system
The module system is being written.

I should first find every module I have to load and, only then,
load all of them in a single command.

Every module should have a list of DEPENDENCY directives.
***** DONE [#B] Jupyter kernel
[[https://ipython.org/ipython-doc/3/development/kernels.html][Making kernels for IPython]]
[[http://andrew.gibiansky.com/blog/ipython/ipython-kernels/]]
***** WONTFIX Change notation
In order to avoid confusions with types

#+BEGIN_SRC haskell
:load -- !load
qwer != asdf -- qwer ?= asdf
#+END_SRC

***** WONTFIX Use a .mikrokosmos config file
Is it really necessary?

***** WONTFIX Config files
A simply typed mikroskosmos would be great for writing configuration files.

***** WONTFIX compiling mikrokosmos
It could be compiled to C.

***** WONTFIX Write a compiler
Maybe a compiler would work better than an interpreter.

***** WONTFIX Optimizing mikrokosmos in Agda
It seems very difficult to write a mikrokosmos interpreter on Agda.

***** WONTFIX [#C] The IO problem
How to declare an imperative - Wadler

****** syscall proposal
******* Output
#+BEGIN_SRC 
#printNum (\s.\z.(s (s z)))
#+END_SRC

printNum.hs
#+BEGIN_SRC haskell
num :: Lambda -> Int
num Nil = 0
num (Lambda x s) = 1 + printnum s

main :: IO ()
main = do
  l <- read :: Lambda
  print $ printnum l
  return ()
#+END_SRC

******* Input
#+BEGIN_SRC
#readNum ()
#+END_SRC

****** syscall with literals
Add a "literal" type.

******* Output
#+BEGIN_SRC mikrokosmos
churchLiteral n = n (\k . syscall ("increment.sh" k)) "0"
printLiteral l = syscall2 ""
#+END_SRC

******* Input
It would use =$= as an antiliteral. Any string started on =$= would be interpreted as
a lambda term.

#+BEGIN_SRC mikrokosmos
readChurch = syscall "readChurch"
#+END_SRC

=readChurch= would return something as ="@(\s.\z.s (s (s z)))"=. Two literals applied one
over thw other would be reinterpreted as their concatenation.
**** [#C] Write articles
***** TODO Adjoint functors post
***** TODO Church-Rosser post
***** TODO Wikipedia article Church-Rosser
**** WONTFIX Ask for a type theory book on SO
**** WONTFIX Ask for a category theory + lambda calculus book on SO
*** Resources
**** Books on categories and types for the TFG
***** Books on category theory
****** [[http://www.maths.ed.ac.uk/~aar/papers/maclanecat.pdf][Categories for the working mathematician - Saunders Mac Lane]]
A complete course on category theory.

  * Category theory.
  * Monoidal categories.
  * 2-categories.

****** [[https://github.com/Mzk-Levi/texts/blob/master/Lambek%2520J.,%2520Scott%2520P.J.%2520Introduction%2520to%2520Higher%2520Order%2520Categorical%2520Logic.pdf][Introduction to Higher order categorical logic - Lambek]]
A course in categorical logic.

  * Cartesian closed categories.
  * Type theory and toposes.

****** [[https://s3.amazonaws.com/arena-attachments/325201/2ff932bf546d8985eb613fccf02b69c7.pdf][Conceptual Mathematics: a first introduction to categories - Lawvere]]
A course on category theory, oriented towards categorical logic.

  * Basic cateogory theory
  * Categorical logic, toposes

****** [[http://paultaylor.eu/prafm/][Practical foundations of Mathematics - Paul Taylor]]
A type-oriented foundation of mathematics.

  * Type theory.
  * Cartesian closed categories.
  * Algebra of dependent types.

****** [[http://tocs.ulb.tu-darmstadt.de/35821485.pdf][Sheaves in Geometry and Logic - MacLane, Moerdijk]]
A course on sheaves, topoi and logic. It assumes a categorical background.

  * Grothendieck topologies and sheaves.
  * Topoi and logic.
  * Classifying topoi.

****** [[http://www.mathematik.tu-darmstadt.de/~streicher/CTCL.pdf][Introduction to category theory and categorical logic - Thomas Streicher]]
Basic notions of category theory and a bit on \lambda-calculus,
cartesian-closed categories and toposes.

  * Basic category theory
  * Cartesian closed categories and \lambda-calculus
  * Logic of toposes
  
****** An introduction to topos theory - Kostecki
****** [[http://www.tac.mta.ca/tac/reprints/articles/12/tr12.pdf][Toposes, Triples and Theories - Barr & Wells]]
***** Books on \lambda-calculus
****** [[http://pages.di.unipi.it/ferrari/CORSI/PR2/HarperBook.pdf][Practical foundations for Programming Languages - Robert Harper]]
A complete course on types, syntax and programming languages.

  * Judgements and rules.
  * Levels of syntax.
  * Data types.
  * System F.
  * Types and propositions.
  * Laziness, paralellism and concurrency.

****** Types and programming languages - Benjamin C. Pierce
****** [[http://www.mscs.dal.ca/~selinger/papers/lambdanotes.pdf][Lecture notes on the lambda calculus - Peter Selinger]]
****** [[https://homotopytypetheory.org/book/][Homotopy Type Theory Book - The univalent foundations program]]
The foundational book on homotopy type theory.
****** [[http://pds14.egloos.com/pds/200901/16/93/Lambda-Calculus_and_Combinators.pdf][Lambda Calculus and Combinators. An Introduction - Hindley, Seldin]]
Basic introduction to the \lambda-calculus.

  * Combinatory logic.
  * Formal theories of \lambda-calculus.
  * Typing.
  * Models of \lambda-calculus.

****** [[http://www.cse.chalmers.se/research/group/logic/book/book.pdf][Programming in Martin-Lf's Type Theory - Nordstrm, Petersson]]
Martin-Lf type theory and how to write languages based on it.
Based on sets.

****** [[https://github.com/pigworker/CS410-14][CS410 Advanced Functional Programming - Connor McBride]]
A course on Agda.

  * Propositions as types.
  * Dependent types.
****** Software foundations - Benjamin C. 
**** Blog articles and web pages
***** [[https://hottheory.files.wordpress.com/2012/08/hott2.pdf][hott2.pdf]] - Master thesis on HoTT
***** [[https://en.wikipedia.org/wiki/Typed_lambda_calculus][Typed lambda calculus - Wikipedia]]
The kinds of typed lambda calculi.
http://homepages.inf.ed.ac.uk/wadler/papers/esslli/esslli-1.pdf

A typed lambda calculus in which the user can set the base types
and its constants. If we add products and a terminal type, this is
the language of cartesian closed categories; and a fragment of
intuitionistic logic called minimal logic.

More precisely, there exist functors between the category of Cartesian
closed categories, and the category of simply-typed lambda theories.

Not making assumptions about the type gives us something that behaves
like type variables.

***** https://github.com/Zepheus/SystemF
A SystemF implementation on Haskell following the B. Pierce's book.
***** [[https://ncatlab.org/homotopytypetheory/files/Joyal.pdf][Categorical Homotopy Type Theory - Joyal.pdf]]
***** [[https://homotopytypetheory.org/2011/04/23/running-circles-around-in-your-proof-assistant/][Running Circles Around (In) Your Proof Assistant; or, Quotients that Compute | Homotopy Type Theory]]
How to implement HIT on Agda using Licata's trick.
***** [[http://sweet.ua.pt/dirk/ct2015/slides/Guallart.pdf][Guallart.pdf]] A comparison between ITT and COC
It uses a categorical formulation of STLC similar to H-M.
***** [[http://www.cse.chalmers.se/research/group/logic/Types/tutorials.html][The Types Project]]
***** [[https://en.wikipedia.org/wiki/Intuitionistic_type_theory#Categorical_models_of_type_theory][Intuitionistic type theory - Wikipedia]] - Categorical models
***** [[https://www.microsoft.com/en-us/research/wp-content/uploads/1997/01/henk.pdf][The Henk intermediate language. core.dvi - henk.pdf]]
Based on the lambda cube with a single syntax for terms, types and kinds.
***** [[https://stackoverflow.com/questions/23995736/example-of-type-in-system-f-that-is-not-available-in-hindley-milner-type-inferen][Example of type in System F that is not available in Hindley Milner type inference - Stack Overflow]]
***** [[http://typessummerschool07.cs.unibo.it/courses/coquand-1.pdf][Models of type theory - Coquand]]
***** https://en.wikipedia.org/wiki/Pure_type_system
***** [[http://strictlypositive.org/calculus/][Differential Calculus with Datatypes]]
***** TODO [[http://people.inf.elte.hu/divip/AgdaTutorial/Index.html][Agda Tutorial]]
***** [[https://cs.stackexchange.com/questions/14674/intro-to-martin-l%C3%B6f-type-theory][logic - Intro to Martin-Lf type theory - Computer Science Stack Exchange]]

***** [[https://plato.stanford.edu/entries/type-theory-intuitionistic/][Intuitionistic Type Theory (Stanford Encyclopedia of Philosophy)]]
Intuitionistic type theory is thus a typed functional programming
language with the unusual property that all programs terminate.
***** DONE [[https://www.youtube.com/watch?v=21qPOReu4FI][Five Stages of Accepting Constructive Mathematics - Andrej Bauer - YouTube]]
"Taking the Principle of the Excluded Middle from the mathematician... 
is the same as ... prohibiting the boxer the use of his fists."
- /David Hilbert/

 * [[https://en.wikipedia.org/wiki/Brouwer%E2%80%93Hilbert_controversy][BrouwerHilbert controversy - Wikipedia]]

***** [[https://www.quora.com/What-is-the-best-textbook-for-Category-theory][What is the best textbook for category theory - Edward Kmett]]
***** DONE [[https://golem.ph.utexas.edu/category/2006/08/cartesian_closed_categories_an_1.html][CCCs and the -calculus | The n-Category Caf]] :math:
***** [[https://github.com/mattearnshaw/lawvere][mattearnshaw/lawvere: The collected works of F. W. Lawvere]] :logic:math:
***** [[https://www.cs.cmu.edu/~rwh/][Robert Harper's Home Page]] :math:logic:
***** [[http://www.jonmsterling.com/index.html][Notes from Jon Sterling Thought]] :math:logic:philosophy:
***** [[http://www2.tcs.ifi.lmu.de/~abel/MscThesisJoakimOhman.pdf][MscThesisJoakimOhman.pdf]] A logical relation for dependent type theory :mikrokosmos:types:logic:
Talks about identity types.
***** [[https://mathoverflow.net/questions/152497/formalizations-of-category-theory-in-proof-assistants][Formalizations of category theory in proof assistants - MathOverflow]] 
***** [[http://strictlypositive.org/Easy.pdf][Easy.pdf]] Simply Easy! - Conor McBride :mikrokosmos:math:
***** [[https://github.com/lambda-pi-plus/lambda-pi-plus][lambda-pi-plus: A simple Depdently-Typed Language for Research&Learning]] :mikrokosmos:math:
***** [[http://strictlypositive.org/Easy.pdf][Easy.pdf]] Implementation of dependent lambda calculus :math:logic:mikrokosmos:
***** [[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2007/EECS-2007-113.pdf][EECS-2007-113.pdf]] Adam Chipala - Implementing dependent types :types:math:logic:
***** [[http://math.andrej.com/2012/11/08/how-to-implement-dependent-type-theory-i/][How to implement dependent type theory I | Mathematics and Computation]] :math:types:
***** [[http://www.hedonisticlearning.com/posts/category-theory-syntactically.html][Category Theory, Syntactically ]] :math:logic:
***** [[https://github.com/Mzk-Levi/texts][Mzk-Levi/texts]] - Type theory and categorical logic texts :math:types:categories:
***** [[http://www.cs.ru.nl/B.Jacobs/CLT/bookinfo.html][Categorical Logic and Type Theory]] :math:categories:logic:
***** [[https://www.newton.ac.uk/event/bprw01][Computer-aided mathematical proofs]] :types:logic:math:
***** [[http://math.ucr.edu/home/baez/topos.html][Topos theory in a nutshell]]
***** [[http://www.logicmatters.net/tyl/][Logic matters]]
***** [[https://mathoverflow.net/questions/69251/is-mac-lane-still-the-best-place-to-learn-category-theory/70891#70891][Is MacLane still the best place to learn category theory?]]
***** Homotopy type theory
****** [[http://dlicata.web.wesleyan.edu/pubs/lb14cubical/lb14cubes-oxford.pdf][A cubical type theory]]
****** [[https://ncatlab.org/homotopytypetheory/files/AwodeyDMVrev.pdf][AwodeyDMVrev.pdf]] Cubical type theory
****** [[http://www.helsinki.fi/lc2015/materials/slides_awodey.pdf][slides_awodey.pdf]] Cubical Type theory
****** [[http://www.cse.chalmers.se/%7Ecoquand/cubicaltt.pdf][Cubical Type Theory - Coquand, Cohen]]
****** [[http://neil-strickland.staff.shef.ac.uk/formal/][Formalised mathematics]] in Agda
****** https://mathoverflow.net/questions/156238/function-extensionality-does-it-make-a-difference-why-would-one-keep-it-out-of/156295#156295
The conversation here between Sterling and Bauer is very interesting.
****** [[http://math.andrej.com/2013/08/28/the-elements-of-an-inductive-type/][The elements of an inductive type | Mathematics and Computation]]
****** [[https://github.com/HoTT/book/issues/460][Path induction again (sorry)  Issue #460  HoTT/book]]
****** [[https://www.youtube.com/watch?v=fJJ7NhkySXM][Homotopy Group - (1)Dan Licata, (2)Guillaume Brunerie, (3)Peter Lumsdaine - YouTube]]
****** [[https://homotopytypetheory.org/links/][Links | Homotopy Type Theory]]
****** [[https://agda.readthedocs.io/en/latest/language/cubical.html][Cubical Type Theory in Agda  Agda 2.6.0 documentation]]
****** [[http://www-sop.inria.fr/members/Anders.Mortberg/slides/TTT-cubicaltt.pdf][Cubical Type Theory: a constructive interpretation of the univalence axiom - TTT-cubicaltt.pdf]]
**** Articles
***** [[http://www.ams.org/notices/201309/rnoti-p1164.pdf][The Univalence Axiom in Homotopy Type Theory]] - Awodey
***** [[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.4309][CiteSeerX  Observational Equality, Now!]] - McBride, Altenkirch
***** [[http://www.cse.chalmers.se/~ulfn/papers/tphols09/tutorial.pdf][A brief overview of Agda]] - Ulf Norell
***** [[http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf][propositions-as-types.pdf]] Philip Wadler
***** TODO [[http://imps.mcmaster.ca/doc/seven-virtues.pdf][seven-virtues]] Seven virtues of type theory
***** TODO [[http://conal.net/papers/compiling-to-categories/compiling-to-categories.pdf][Compiling to categories]]
**** Mikrokosmos resources
***** [[http://www.madore.org/~david/computers/callcc.html][A page about call/cc]]
***** [[http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=3FF1F113BC01E491476F4F1930F838FE?doi=10.1.1.44.1497&rep=rep1&type=pdf][An untyped lambda calculus with IO]]

* Talks
** Course on HoTT - Robert Harper
*** Lecture 1: Intuitionistic Type Theory
**** Intuitionistic Type Theory (TT),
The *Intuitionistic Type Theory* is based on the work of Per
Martin-Lf on the 1970s.  It is an analysis and expansion of Brouwer's
intuitionism.

**** Intensional Type Theory (ITT)
The *Intensional Type Theory* will be our base theory. Other forms of
type theory are extensions of this one.

**** Extensional Type Theory (ETT)
The *Extensional Type Theory* has the core of ITT plus the principles
of equality reflection (ER) and uniqueness of the identity proofs
(UIP).

This is the intuitionistic theory of sets in which NuPRL is based.
It is a form of constructive set theory, developed by Bishop; where
types are treated as sets.

**** Homotopy Type Theory (HoTT)
The *Homotopy Type Theory* is an elaboration of ITT with higher
inductive types (HIT) and the univalence axiom (UA).

It is an intuitionistic theory of weak $\infty\text{-groupoids}$. Here types
are spaces in an abstract sense.
**** Brower's program
The *Brower's program* is a philosophy of mathematics based on the
following ideas
 
 1. mathematics is a human social activity. The focus is on the /language/
    as a tool for communication of mathematical concepts.

 2. the fundamental human capability is the understanding an execution
    of /algorithms/ for performing /constructions/. Proofs are forms
    of construction.

In this setting, the only way to describe infinite things is by
communicate them with an algorithm. 

***** Proof relevance
From the second point, arises the principle of *proof relevance*.
Proofs are mathematical objects that we can see an manipulate. In
other foundations of mathematics, only a limiting enumerable set of
formal proofs can be viewed as proofs.

***** Proof relevance in HoTT
In HoTT, our proofs will be paths in a space. This conception
will provide a synthetic way of working with homotopy which is a
cleaner, shorter and mechanizable way writting proofs.

***** Synthetic perspective in mechanized reasoning
Synthetic geometry is what Euclides did; analytic geometry is what
Descartes did. The traditional formulation of Homotopy Theory, using
euclidean spaces and topology, is an analytic one. Synthetic
formulations of Homotopy Theory are based on Quillen model categories or
HoTT.

This distinction of synthetic and analytical is due to Lawvere.

/Twelf vs Coq is another example/
**** Type Theory
Type theory is an analysis and codification of Brower's intuitionism
drawning on Gentzen's proof theory. Types classify the admisible
constructions. A type is defined by

 * *introduction rules*, showing how to make a construction.
 * *elimination rules*, showing how to use a construction.

linked by the *inversion principle*, or principle of conservation of
proofs; stating that the introduction is inverse to the elimination.
This inversion principle is the basis for the computational content
of our language.

**** Axiomatic freedom of constructive mathematics
In the Hilbert/Brouwer debate, Hilbert believed that Brouwer was negating
everything that has been done so far; but, as fewer assumptions lead to
stronger results, the exclusion of certain principles leads only to axiomatic
freedom.

For example, the law of excluded middle is not negated on constructive
mathematics, they are simply independent of it; but it can still be
taken as an hypothesis on certain subfields.

We can now include certain assumptions locally, and so, the
constructivity is not a limitation.
**** Computational aspect
Type theory acts as an unified theory of computation. Programming
languages and computation are particular manifestations of this
unified theory.

**** Computational trinitarianism

\[\begin{tikzcd}[row sep=huge, col sep=tiny]
& \begin{matrix}\text{Type}\\ \text{Theory}\end{matrix} \drar[to-to]\dlar[to-to] & \\
\text{Logic}\arrow[rr,to-to] & & \begin{matrix}\text{Category}\\ \text{Theory}\end{matrix}
\end{tikzcd}\]

There is a complete correspondence between the three theories.
**** Intuitionistic logic
*Intuitionistic logic* is based on the principles of intuitionism.
It has the following judgements

 1. $A$ is a proposition.
 2. $A$ is a true proposition, it has a proof.

We do not expect that a proposition is either provable or refutable.
We assume also /open-endedness/, we cannot write all the proofs in a
systematic way.

**** Negative fragment of intuitionistic propositional logic
We will write a grammar of proofs.

 * The trivially true proposition, this is the *truth-formation*
   rule

   \begin{prooftree}
   \RightLabel{(T-form)}
   \AxiomC{}
   \UnaryInfC{T prop}
   \end{prooftree}

   this trivially true proposition is true

   \begin{prooftree}
   \RightLabel{(T-intro)}
   \AxiomC{}
   \UnaryInfC{T true}
   \end{prooftree}

   but there is no truth elimination rule, as we are not using any
   information when we write this proposition.

 * Conjunction formation

   \begin{prooftree}
   \RightLabel{($\wedge$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\wedge$ B prop}
   \end{prooftree}

   conjunction introduction

   \begin{prooftree}
   \RightLabel{($\wedge$-intro)}
   \AxiomC{A true}
   \AxiomC{B true}
   \BinaryInfC{A $\wedge$ B true}
   \end{prooftree}
   
   we will use two elimination rules to extract the two pieces 
   of information that went into that fact.

   \begin{prooftree}
   \RightLabel{($\wedge$-elim$_1$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{A true}
   \RightLabel{($\wedge$-elim$_2$)}
   \AxiomC{A $\wedge$ B true}
   \UnaryInfC{B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}

 * Implication formation

   \begin{prooftree}
   \RightLabel{($\supset$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\supset$ B prop}
   \end{prooftree}

   and implication introduction, which uses only entailment

   \begin{prooftree}
   \RightLabel{($\supset$-intro)}
   \AxiomC{A true $\vdash$ B true}
   \UnaryInfC{A $\supset$ B true}
   \end{prooftree}

   in the Hilbert formulations of logic, we supress the difference
   between entailment and implication. The logical entailment is prior
   to the implication, it is a map of proofs; while the implication only
   captures that into the logic. The elimination rule is the modus ponens

   \begin{prooftree}
   \RightLabel{($\supset$-elim)}
   \AxiomC{A $\supset$ B true}
   \AxiomC{A true}
   \BinaryInfC{B true}
   \end{prooftree}

*** Lecture 2: Intuitionistic Propositional Logic
**** Negative fragment of intuitionistic propositional logic
We have talked about

 * the Gentzen principle of conservation of evidence.
 * the truth value.
 * the conjunction.
 * the implication.

Why are these "correct" rules? We are keeping a correspondence between
introduction and elimination rules; that is the beauty of the Gentzen
system and what gives rise to the computational interpretation.

These are not arbitrary rules, there is a coherence that is being kept.
**** Structural properties of entailment
The concept of *logical entailment* is a compound judgement. It express
the idea of a conclusion derived from a set of assumptions

\[\underbrace{
A_1 \text{ true},
A_2 \text{ true},
\dots,
A_n \text{ true}}_{\Gamma}
\vdash
A
\]

Logical entailment is a mapping between propositions.
The properties of logical entailment (aka hypothetical judgement) are
the following properties
 
 1. Reflexivity (R), $A \text{ true} \vdash A \text{ true}$.
 2. Transitivity (T),
    
    \begin{prooftree}
    \RightLabel{(T)}
    \AxiomC{$\Gamma_1 \vdash A$ true}
    \AxiomC{$\Gamma_2,A$ true $\vdash B$ true}
    \BinaryInfC{$\Gamma_1,\Gamma_{2} \vdash B$ true}
    \end{prooftree}

    in presence of the weakening, contraction, and exchange properties,
    this can be rewritten using only a $\Gamma$.

 3. Weakening (W),
    
    \begin{prooftree}
    \RightLabel{(W)}
    \AxiomC{$\Gamma$ $\vdash A$ true}
    \UnaryInfC{$\Gamma,B$ true $\vdash A$ true}
    \end{prooftree}

    where the two first properties are fundamental, and this third is
    not as fundamental. You can consider deniying this principle, and
    you will arrive at the notion of /relevant entitlement/, where every
    assumption has to be used in the entitlement.

 4. Contraction (C), 
    
    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma,A$ true,$A$ true $\vdash B$ true}
    \UnaryInfC{$\Gamma, A$ true $\vdash B$ true}
    \end{prooftree}

    in certain logics, we may will want to keep an accounting of
    how many times have we used a lemma; we will have to deny this
    property.

 5. Exchange (E), the order of the assumptions does not matter

    \begin{prooftree}
    \RightLabel{(C)}
    \AxiomC{$\Gamma \vdash A$ true}
    \UnaryInfC{$\pi(\Gamma) \vdash A$ true}
    \end{prooftree}

    where $\pi$ is any permutation.

When any of these properties fail, we talk of substructural entailment.

**** Local form
We are writing the rules in local form. They can be used in the same
way on the presence of assumptions. A $\Gamma$ could be added to all
the rules to obtain the global form. It is implied in our rules.

There are certain scenarios in which we will want $\Gamma$ to be explicitely
empty.

**** Order-theoretic formulation
Let us define $A \leq B$, an order on propositions, meaning that
$A \text{ true} \vdash B \text{ true}$.

***** Preorder
This is a preorder,

  * it is reflexive,

    \begin{prooftree}
    \RightLabel{($\leq$-refl)}
    \AxiomC{}
    \UnaryInfC{$A \leq A$}
    \end{prooftree}


  * it is transitive,

    \begin{prooftree}
    \RightLabel{($\leq$-trans)}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \leq C$}
    \end{prooftree}

  * we have a greatest, final element

    \begin{prooftree}
    \RightLabel{($\leq_\top$)}
    \AxiomC{}
    \UnaryInfC{$A \leq \top$}
    \end{prooftree}
   
  * we have meets given by conjunction. That is, there is a lower
    bound

    \begin{prooftree}
    \RightLabel{($\leq,\wedge_1$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq A$}
    \RightLabel{($\leq,\wedge_2$)}
    \AxiomC{}
    \UnaryInfC{$A \wedge B \leq B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

    which is also universal

    \begin{prooftree}
    \RightLabel{($\leq,\wedge$-bound)}
    \AxiomC{$C \leq A$}
    \AxiomC{$C \leq B$}
    \BinaryInfC{$C \leq A \wedge B$}
    \end{prooftree}

Those follow from the properties of entailment. We can draw those
properties with Hasse diagrams, where we can see a similarity with
a product diagram on category theory

\[\begin{tikzcd}[column sep=tiny]
& C \dar[dashed] \ar[ddr,bend left]\ar[ddl, bend right] & \\
& A \wedge B \drar\dlar & \\
A & & B &.
\end{tikzcd}\]

***** Antisymmetry and equivalence
We have now a lower semilattice. Sometimes, lower semilattices are
defined to be partial orders, where we have antisymmetry

    \begin{prooftree}
    \RightLabel{}
    \AxiomC{$A \leq B$}
    \AxiomC{$B \leq A$}
    \BinaryInfC{$A = B$}
    \end{prooftree}

but we are going to work without antisymmetry. We haven't talked yet
about equality, but we are going to introduce the univalent principle.
We could define $A \simeq B$ when $A \leq B$ and $B \leq A$, they are not equal,
but equivalent. We could also work with equivalence classes $[A]_{\simeq}$ here.
Univalence will imply the equality of equivalent propositions.

**** Positive fragment of IPL
Now we write the grammar of the positive fragment

 * The false proposition, this is the *false-formation* rule

   \begin{prooftree}
   \RightLabel{($\bot$-form)}
   \AxiomC{}
   \UnaryInfC{$\bot$ prop}
   \end{prooftree}

   there is no introduction rule, only an elimination rule

   \begin{prooftree}
   \RightLabel{($\bot$-elim)}
   \AxiomC{$\bot$ true}
   \UnaryInfC{A true}
   \end{prooftree}

   since there is no introduction rule and this never happens,
   this preserves the coherence principle.

 * Disjunction formation

   \begin{prooftree}
   \RightLabel{($\vee$-form)}
   \AxiomC{A prop}
   \AxiomC{B prop}
   \BinaryInfC{A $\vee$ B prop}
   \end{prooftree}

   disjunction introduction

   \begin{prooftree}
   \RightLabel{($\vee$-intro$_{1}$)}
   \AxiomC{A true}
   \UnaryInfC{A $\vee$ B true}
   \RightLabel{($\vee$-intro$_{2}$)}
   \AxiomC{B true}
   \UnaryInfC{A $\vee$ B true}
   \noLine
   \BinaryInfC{}
   \end{prooftree}
   
   we will use an elimination rule to extract the piece of
   of information that went into that fact as in

   \begin{prooftree}
   \RightLabel{($\vee$-elim)}
   \AxiomC{A $\vee$ B true}
   \AxiomC{A true $\vdash$ C true}
   \AxiomC{B true $\vdash$ C true}
   \TrinaryInfC{C true}
   \end{prooftree}

**** Order-theoretical properties
We have now a least or initial element,
 
    \begin{prooftree}
    \RightLabel{($\leq$-$\bot$)}
    \AxiomC{}
    \UnaryInfC{$\bot \leq A$}
    \end{prooftree}

and joins or upper bounds

    \begin{prooftree}
    \RightLabel{($\leq,\vee_1$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \RightLabel{($\leq,\vee_2$)}
    \AxiomC{}
    \UnaryInfC{$A \leq A \vee B$}
    \noLine
    \BinaryInfC{}
    \end{prooftree}

where the bound is the least upper bound

    \begin{prooftree}
    \RightLabel{($\leq,\vee$-bound)}
    \AxiomC{$A \leq C$}
    \AxiomC{$B \leq C$}
    \BinaryInfC{$A \vee B \leq C$}
    \end{prooftree}

Note that those bounds are unique up to equivalence, as they follow
also a categorical universal diagram, in this case, the coproduct
diagram

\[\begin{tikzcd}[column sep=tiny]
A \drar\ar[ddr, bend right] & & B \dlar\ar[ddl, bend left] \\
& A \vee B \dar[dashed] & \\
& C  & &.
\end{tikzcd}\]

This is a lattice, that has all finite meets and joins.

**** Order-theoretic formulation of the implication
We have an exponential $B^A$ whenever $A \supset B$, this is defined
as the property

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$A\wedge (A \supset B) \leq B$}
\end{prooftree}

and the exponential is the universal element with this property

\begin{prooftree}
\AxiomC{$A \wedge C \leq B$}
\UnaryInfC{$C \leq A \supset B$}
\end{prooftree}

**** Heyting algebra
A *Heyting algebra* is a lattice with exponentials.

***** Yoneda Lemma
The Yoneda Lemma on lattices says that

$a \leq b \iff \left(\forall x: x \leq a \implies x \leq b\right)$.

It is trivial by transitivity and identity. This is
an instance of a more general fact.
**** Negation
We define $\neg A := A \supset \bot$. It is the largest proposition inconsistent
with $A$, the largest proposition such that $A \wedge \neg A \leq \bot$.

**** Complement
We define $\overline{A}$ as the universal element with the property that $\top \leq A \vee \overline{A}$
and $\overline{A} \wedge A \leq \bot$.

We have a complement distributive algebra (a boolean algebra!) and such thing
has exponentials.

\begin{prooftree}
\AxiomC{$\top \leq A \vee C$}
\UnaryInfC{$\overline{A} \leq C$}
\end{prooftree}

**** Boolean algebra
A *boolean algebra* is a complemented distributive lattice. Therefore, it has
exponentials, defined as $B^A := \overline{A} \vee B$.

**** Completeness theorem
If $A \leq B$ in every Heyting algebra, it must be deducible that $A \vdash B$.
If something is valid in all models, in all Heyting algebras, it must be
provable.

This logic is complete for Heyting algebras, but it is not going to be
complete for boolean algebras. $A \vee \neg A$ is not going to be provable in
our logic.

***** Proof
If something is provable in every Heyting algebra, you can construct the
propositional *Lindenbaum algebra*; and this is used to show completenaess.
If $A \leq B$ holds in every Heyting algebra, then $A \text{ true} \vdash B \text{ true}$. We
need to interpret the propositions as elements on a Heyting algebra.

***** Converse
If something is provable, it holds in every Heyting algebra. 

**** Issue: negation and complement
In a boolean algebra, $A \vee \neg A \simeq \top$.

*** Lecture 3: Propositions as Types
**** Last week
Last week we saw IPL from a provability perspective. $A$ is true if it
has a proof, and $A$ is false if it has a refutation. We got the
structure of Heyting algebra (a lattice (partial order with all finite
meets and joins) and exponentials). Every Heyting algebra is
distributive. We defined the negation.

***** Soundness incompleteness result
$\Gamma \vdash A$ true iff $\Gamma^{\ast} \leq A^{\ast}$ in every Heyting algebra.

***** Boolean and Heyting algebras
Not every boolean algebra is a Heyting algebra, but every Heyting
algebra is a boolean algebra.

***** DeMorgan Duality
$\overline{A \wedge B} = \overline{A} \vee \overline{B}$ and $\overline{A \vee B} = \overline{A} \wedge \overline{B}$.

**** Claim
In IPL, not all instances of LEM are provable. We cannot prove
in general that $A \vee \neg A \text{ true}$.

***** Idea
The disjunction property says that if $A \vee B \text{ true}$, then $A$ true
or $B$ true. This would imply that LEM gives us a proof or a
refutation of every element.

**** There exists a Heyting algebra which is not a boolean algebra
We need only a countermodel, a Heyting algebra where $\top \leq A \vee \neg A$
does not hold. It will show that this is not provable in general
in IPL.

**** Decidable proposition
A proposition is *decidable* iff $A \vee \neg A \text{ true}$. There are decidable
propositions even if LEM does not hold.

***** Example
Two decidable propositions are $\bot$ and $\top$.

Equality on natural numbers will be decidable, but equality on reals
will not.
**** Stable proposition
A proposition is *stable* iff $(\neg \neg A) \supset A \text{ true}$.

**** Negation of the negation of LEM
We can prove $\neg \neg (A \vee \neg A)$. This proves that not every proposition
is stable as a corollary.

***** Proof
We will assume $\neg (A \vee \neg A)$ and arrive at a contradiction. If we
assume $A$, we have $A \vee \neg A$, and then a contradiction, so it must
be the case that $\neg A$. We know now that $A \vee \neg A$, arriving at a
contradiction.

**** Prove the disjunction property for IPL
We interpret the rules of IPL as an inductive definition of
the entailment relation.

We have finitary derivation trees of every $\Gamma \vdash A$.

***** Disjunction property: formal statement
If $\varnothing \vdash A \vee B \text{ true}$, then $\varnothing \vdash A \text{ true}$ or $\varnothing \vdash B \text{ true}$.

****** Counterexample if the context were not empty
If we take $A \vee B$ as an assumption, this would trivially
not hold.
***** Disjunction property: draft of a proof
We will use an induction on derivations. We examine all possible
derivations $\varnothing \vdash A \vee B \text{ true}$ and show that there are derivations of
$A$ or $B$ also.

The last step of a derivation of $A \vee B$ should be an introduction
$\vee-I_{1}$ or $\vee-I_2$; so there should be a derivation of $A$ or $B$ in
the previous step. The assumption rule is also not applicable.
Conjunction introduction is not applicable, and the same hold for
true introduction and implication introduction. Elimination rules
are our real problem here. For example, implication elimination should
be proved.

To prove this for the implication elimination rule, we suppose that
we have the derivations for $\vdash C$ and $C \vdash (A \vee B)$, and then we could
inline the first derivation using transitivity of entailment to get
a derivation of $\vdash A \vee B$. Note that this is not a complete proof! the
derivation of $C \supset (A \vee B)$ could have be done by other elimination
rules and we should prove that for them too.
**** Structural properties are admissible
*Weakening is admissible*, if $\Gamma \vdash_{IPL} B\text{ true}$, then $\Gamma,A \text{ true} \vdash_{IPL} B \text{ true}$.
If you give a derivation of the first, you can get a derivation of the
second one.

***** Why is weakening admissible
Because the rules are polymorphic! They do not depend of Gamma. We
could inductively weaken every step $\Gamma \mapsto \Gamma,A\text{ true}$, and then, reapplying
the rules, would give us the same conclusion.

***** Similarly
You could do exchange or contraction. But reflexivity is a primitive rule!
Transitivity for $\text{IPL}^{-}$ is homework.
***** We have now defined a good logic
It is not simply a bunch of rules, they follow a criteria. The
structural properties should hold. There are substructural logics,
but those are not our topic of interest.
**** Gentzen's insight
Our previous idea to prove the disjunction property uses crucially an
inversion principle between implication introduction and implication
elimination.

*ELIM is post-inverse to INTRO.*

We are saying something like the following for introductions, eliminations
and derivations.

 * $(\wedge E_1 \circ \wedge I)({\cal D}_1,{\cal D}_2) = {\cal D}_1$

This gives rise to a dynamics of proof! We do not only look at provability,
we look at the proofs per se.

**** II. Proof relevant logic
We will write a grammar of proofs. $M : A$ means that $M$ is a proof
of $A$. In correspondence with the assumptions, there is the concept
of variables

\[ x_1:A_1, \dots , x_n:A_n \vdash M : A.\]

Transitivity now reads as a substitution rule

\begin{prooftree}
\AxiomC{$\Gamma, x : A\vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$[N/x]M : B$}
\end{prooftree}

and reflexivity is only a use of a variable

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:A \vdash x : A$}
\end{prooftree}

We will write this derivations as mappings on a bicartesian closed category

\[M : A_1 \times \dots \times A_n \to A.
\]

Proof-relevant logic will give rise to Type Theory and Category Theory.
*** Lecture 4: Proof Reduction and Equivalence
We first saw logic from the point of view of provability. We are going
to look at the idea of logic with proofs. From the first, we got Heyting
Algebras; from the second, we are going to get bicartesian closed categories.

We going to define equivalence of proofs $M \equiv N : A$.

**** Proof terms
We will need a grammar of proofs to construct proof terms.
The structural properties are now properties for this grammar.

 * Reflexivity is now the introduction of a variable.
 * Transitivity is now the substitution of a variable.
 * Weakening is now the ability to discard variables.
 * Contraction is now a replication of variables.
 * Exchange is a permutation of variables.

**** Logic
Now the negative fragment of our logic can be written as

\begin{prooftree}
\RightLabel{$(\top_{I})$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge-I)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge_{E1})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) : A$}
\RightLabel{$(\wedge_{E2})$}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{snd}(M) : B$}
\noLine
\BinaryInfC{}
\end{prooftree}


\begin{prooftree}
\RightLabel{$(\supset_{I})$}
\AxiomC{$\Gamma, x:A \vdash M:B$}
\UnaryInfC{$\Gamma \vdash \lambda x . M : A \supset B$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\supset_{E})$}
\AxiomC{$\Gamma \vdash M . A \supset B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash M(N) : B$}
\end{prooftree}

**** Gentzen's Inversion principle
**** Definitional equality
In first order logic, no one draws a distinction between propositional
equality and definitional equality.

*Definitional equality* is the least congruence closed under the following
rules
 
 * it is a equivalence relation.
 * it is compatible with the rules.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M' : A \wedge B$}
\UnaryInfC{$\Gamma \vdash \text{fst}(M) \equiv \text{fst}(M') : A$}
\end{prooftree}

Now the inversion principle can be written on proof terms.
Simplifications such as $\text{fst}\left\langle M,N \right\rangle \equiv M$ are now useful if we
interpret this as a running program with proof dynamics.

Those are called Beta rules.
The inversion principle on conjunction is now

\begin{prooftree}
\RightLabel{$(\beta\wedge_1)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{fst}\left\langle M,N \right\rangle \equiv M : A$}
\RightLabel{$(\beta\wedge_2)$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : B$}
\BinaryInfC{$\Gamma \vdash \text{snd}\left\langle M,N \right\rangle \equiv N : B$}
\noLine
\BinaryInfC{}
\end{prooftree}

The inversion principle on implication is inlining

\begin{prooftree}
\RightLabel{$(\beta\supset_1)$}
\AxiomC{$\Gamma,x:A \vdash M : B$}
\AxiomC{$\Gamma \vdash N : A$}
\BinaryInfC{$\Gamma \vdash (\lambda x. M)(N) \equiv [N/x]M : B$}
\end{prooftree}

Now we can compute by calculation with closed terms written
as $M \equiv N$.

**** Gentzen's Unicity Principles
Those are $\eta$ rules.

\begin{prooftree}
\RightLabel{$(\eta\top)$}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle  \right\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\eta\wedge)$}
\AxiomC{$\Gamma\vdash M: A \wedge B$}
\UnaryInfC{$M \equiv \left\langle \text{fst}(M),\text{snd}(M) \right\rangle$}
\end{prooftree}

\begin{prooftree}
\RightLabel{$(\wedge\supset)$}
\AxiomC{$\Gamma\vdash M:A \supset B$}
\UnaryInfC{$\Gamma\vdash M \equiv \lambda x. Mx : A \supset B$}
\end{prooftree}

**** Propositions as types
The inversion and unicity principles will make a very strong
correspondence on categories.

\begin{tabular}{c|c|c|c}
Latticces & Propositions & Types & Categories \\
\hline
greatest & $\top$ & $1$ & final object \\
meets & $A \wedge B$ & $A \times B$ & finite products \\
exponential & $A \supset B$ & $A \to B$ & exponential \\
minimum & $\bot$ & $0$ & initial object \\
joins & $A \vee B$ & $A+B$ & coproducts
\end{tabular}

**** Category
A *category* is a generalized preoder with evidence.
The difference between preorder and partial order is
related to univalence

\begin{prooftree}
\AxiomC{$A \leq B$}
\AxiomC{$B \leq A$}
\BinaryInfC{$A \equiv B$}
\end{prooftree}

where this is an instance of univalence. 

In a category we have the structure of a preorder

 1) Reflexivity, $\mathrm{id} : A \to A$.
 2) Transitivity; if $f: A \to B$ and $g : B \to C$ then
    $g \circ f : A \to C$.

Those have to satisfy some coherence conditions, which are 
the following unit laws

 * $\mathrm{id_B}\circ f = f = f \circ \mathrm{id_A}$
 * $f \circ (g \circ h) = (f\circ g)\circ h$

The equality here is interesting. We could think of this structure
representing two paths and an homotopy between two paths on a 2-cell;
some kind of transformation. We are going to talk of a deformation
given by an associator

\[
\alpha : f \circ (g \circ h) \to (f \circ g) \circ h.
\]

And those notions of evidence (which act as natural transformations) need
also a notion of equivalence and a higher dimensional map between them. But 
this process could be repeated to infinity!

We are going to express the relation of types and terms in categorical terms.

**** Terminal object
Definition of final object

\begin{prooftree}
\AxiomC{$$}
\UnaryInfC{$\left\langle\right\rangle : A \to 1$}
\AxiomC{$M : A \to 1$}
\RightLabel{$(\eta{\top})$}
\UnaryInfC{$M = \left\langle  \right\rangle : 1$}
\noLine
\BinaryInfC{}
\end{prooftree}

this was, in our old notation, $A \vdash \left\langle  \right\rangle : 1 = \top$.

**** Product objects
There are maps

 1) $\mathrm{fst} : A \times B \to A$
 2) $\mathrm{snd} : A \times B \to A$

satisfying

\[\begin{tikzcd}[column sep=tiny]
& D \ar[bend left]{ddr}{M}\ar[swap,bend right]{ddl}{N}\dar[dashed]{\exists!} & \\
& A \times B \drar[swap]{\mathrm{fst}} \dlar{\mathrm{snd}} & \\
A && B
\end{tikzcd}\]

Pairing is the function taking two functions and returning
the function to the product

\begin{prooftree}
\AxiomC{$M : D \to A$}
\AxiomC{$N : D \to B$}
\BinaryInfC{$\left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

algebraically,

 * $\mathrm{fst}\circ \left\langle M,N \right\rangle = M : D \to A$
 * $\mathrm{snd}\circ \left\langle M,N \right\rangle = N : D \to B$

and there is a uniqueness condition; given

\begin{prooftree}
\RightLabel{$(\eta \times)$}
\AxiomC{$P : D \to A \times B$}
\AxiomC{$\mathrm{fst} \circ P = M$}
\AxiomC{$\mathrm{snd} \circ P = N$}
\TrinaryInfC{$P = \left\langle M,N \right\rangle : D \to A \times B$}
\end{prooftree}

the uniqueness can be seen as the existence of homotopy between
any two functions making the product diagram commute.

In particular, $\left\langle  \mathrm{fst}\circ P, \mathrm{snd} \circ P  \right\rangle = P$. Or we can say that $\left\langle \mathrm{fst}, \mathrm{snd} \right\rangle = \mathrm{id}$
or $\left\langle M,N \right\rangle \circ P = \left\langle M\circ P,N \circ P \right\rangle$.

Lawvere and Lambek first saw those connections on the 70s.

**** Exponentials
The exponential $B^A$, gives the application map with the universal
diagram

\[\begin{tikzcd}
C \dar[dashed,swap]{\exists! \lambda(h)} & 
C \times A \ar{dr}{h}\dar[dashed,swap]{\lambda(h) \times id_A} & \\
B^{A} & B^{A} \times A \rar[swap]{app} & B \\
\end{tikzcd}\]

If we write that on syntax, that is equal to

 * $app(\lambda(h) \times \mathrm{id}) = ap \circ \left\langle \lambda(h) \circ \mathrm{fst}, \mathrm{snd} \right\rangle = h$.
 * if there is any $g$ such that $ap \circ (g \times \mathrm{id}) = h$, then $g = \lambda(h)$.

We get the $\eta\text{-rule}$ of

\[
g = \lambda(\mathrm{ap} \circ (g \times \mathrm{id}))
  = \lambda(\mathrm{ap} \circ \left\langle g \circ \mathrm{fst}, \mathrm{snd} \right\rangle).
\]

The essence of all this is

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash h : B$}
\UnaryInfC{$\Gamma \vdash \lambda x. h: B^A$}
\end{prooftree}

**** DeBruijn indices
If we write contexts as $A_{n-1}\times \dots \times A_{1}$, and we refer to the
variables using $\mathrm{snd}(\mathrm{fst}(\mathrm{fst}\dots))$.

*** Lecture 5: Universal properties
In the previous weeks we talked about

 * logic via provability and truth.
 * the entailment relation.
 * an order theoretic interpretation.
 * a logic for proofs with proof terms.
 * a notion of equality for proofs.

**** Gentzen's inversion principle
Represented on the $\beta$ principles, rules such as

 * $\mathtt{fst} \left\langle M,N \right\rangle \equiv M$
 * $\mathtt{snd} \left\langle M,N \right\rangle \equiv N$
 * $(\lambda x. M)(N) \equiv [N/x]M$
 * $\mathtt{case}(\mathtt{inl}(M), x.P, y.Q) \equiv [M/x]P$
 * $\mathtt{case}(\mathtt{inr}(M), x.P, y.Q) \equiv [M/y]Q$

they act as rules for proof simplification and can be interpreted as
a dynamics for proofs. Proofs are programs.

**** Gentzen's unicity principles
Represented on $\eta$ principles.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \top$}
\UnaryInfC{$\Gamma \vdash M \equiv \langle\rangle : \top$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\UnaryInfC{$\Gamma \vdash M \equiv \left\langle \mathtt{fst}(M),\mathtt{snd}(M) \right\rangle : A \wedge B$}
\end{prooftree}

there is another way of saying this

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \wedge B$}
\AxiomC{$\Gamma \vdash \mathtt{fst}(M) \equiv P : A$}
\AxiomC{$\Gamma \vdash \mathtt{snd}(M) \equiv Q : B$}
\TrinaryInfC{$\Gamma \vdash M \equiv \left\langle P,Q \right\rangle : A \wedge B$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \supset B$}
\UnaryInfC{$\Gamma \vdash M \equiv \lambda x. M(x) : A \supset B$}
\end{prooftree}

**** Categorical interpretation
A derivation

\[
x_1:A_1,\dots,x_n:A_n \vdash M : A
\]

is interpreted as a morphism

\[
M : A_1 \times \dots \times A_n \to A\]
\[M \equiv N : A_1 \times \dots \times A_n \to A
\]

The product diagram relates

 * the existence with the introduction.
 * the uniqueness with the $\eta$ rules.
 * the commutativity with the $\beta$ rules.

**** Unicity principle for the disjunction [40:00]
It is more difficult to see how the disjunction property should be
written. An inspiration is the notion of Shannon expansion: the type
of booleans can be written as $\top \vee \top$; then $\mathtt{case}$ acts as a binary decision 
diagram. The Shannon expansion is a substitution using booleans where
 
 * $\mathtt{inl} \left\langle  \right\rangle \equiv true$
 * $\mathtt{inl} \left\langle  \right\rangle \equiv false$

then

\[
[M/x]P \equiv \text{ if } M \text{ then } [true/x]P \text{ else } [false/x]P.
\]

and, in particular,

\[
P \equiv \text{ if } x \text{ then } [true/x]P \text{ else } [false/x]P.
\]

The eta rule for disjunction is then

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A \vee B$}
\AxiomC{$\Gamma, z:A \vee B \vdash P : C$}
\BinaryInfC{$\Gamma \vdash [M/z]P \equiv \mathrm{case}(M; x : [\mathtt{inl}(x)/z]P; y : [\mathtt{inr}(y)/z]P) : C$}
\end{prooftree}

like a generalized Shannon expansion. As an special case, we
get that $M \equiv \mathtt{case}(M, x . \mathtt{inl}(x), y . \mathtt{inr}(y))$.

**** Remark
We could have defined the relationship on variables $x \equiv \left\langle \mathtt{fst}(x), \mathtt{snd}(x) \right\rangle$, but
to derive the general rule from there, we would have needed another property
to get a correct substitution rule.

**** Coproduct
We write the coproduct as $A + B$, and its diagram as

\[\begin{tikzcd}[column sep=tiny]
& C  & \\
& A+B  \uar[dashed]{\exists! \left\{ P,Q \right\}}  & \\
A\ar[bend left]{uur}{P}       \urar[swap]{\mathtt{inl}} &&
B\ar[swap,bend right]{uul}{Q} \ular{\mathtt{inr}}
\end{tikzcd}\]

where

\[
\left\{ P,Q \right\} \equiv \mathtt{case} ( - , x.P, y.Q) 
\]

And the unicity simply says that

\begin{prooftree}
\AxiomC{$\Gamma, x:A \vdash [ \mathtt{inl}(x)/z ]M \equiv P : C$}
\AxiomC{$\Gamma, y:B \vdash [ \mathtt{inr}(y)/z ]M \equiv Q : C$}
\BinaryInfC{$\Gamma, z : A+B \vdash M \equiv \mathtt{case}(z,x:P,y:Q) : C$}
\end{prooftree}

This is an induction principle. We can caracterize the behaviour of $M$ simply
by giving its behaviour on the $\mathtt{inl}$ and the $\mathtt{inr}$.
**** Beta/eta rules
The beta rules are analytic judgements. Self-evident.
The eta rules are synthetic judgements. They require proof.

The beta rules correspond to definitional equality and the 
eta rules correspond to propositional equality; it will be
expressed typically by a type. The definitional equality, on
the other hand, is simply a judgement and it is also called
a judgmental equality.
*** Lecture 6: Dependency, families of types
So far, we have seen a propositions/types correspondence.
We will add a type of natural numbers, and look for its correspondence
in intuitionistic logic.

**** Gdel's T
We will call Gdel's T to the system we have developed so far plus
a natural numbers type. This is not exactly Gdel's T in the literature,
where it is defined only with function types.

\begin{prooftree}
\RightLabel{(Nat$_{I-0}$)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash 0 : Nat$}
\RightLabel{(Nat$_{I-S}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\UnaryInfC{$\Gamma \vdash s(M) : Nat$}
\noLine
\BinaryInfC{}
\end{prooftree}

The elimination form is just definition by recursion

\begin{prooftree}
\RightLabel{(Nat$_{E}$)}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma \vdash P : A$}
\AxiomC{$\Gamma, x:A \vdash Q:A$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}(P,x.Q)(M) : A$}
\end{prooftree}

We need now two beta rules to comply with the inversion principle.

 * $\mathtt{rec}(P,Q)(0) \equiv P$
 * $\mathtt{rec}(P,Q)(s(M)) \equiv [ \mathrm{rec}(P,Q)(M)/x ]Q$

so, if $\overline{n} = s(\dots s(0)\dots)$, $\mathtt{rec}(P,Q)(\overline{n}) \equiv Q(Q(\dots (Q(P))\dots)$.

There is also a eta rule, that was not considered by Gdel at the moment.
Suppose an $M$ acting the same way on the $0$ and the $s$, then it is the
recursor.

\begin{prooftree}
\AxiomC{$\Gamma,z : Nat \vdash M : A$}
\AxiomC{$\Gamma \vdash [0/z] M \equiv P:A$}
\AxiomC{$\Gamma, z:Nat \vdash [ S(z)/z ]M \equiv [M/x]Q$}
\TrinaryInfC{$\Gamma,z:Nat \vdash M \equiv \mathtt{rec}(P,Q)(z)$}
\end{prooftree}

***** Special case on the recursor
Plugging naturals on the recursor

$z : Nat \vdash \mathtt{rec}(0,y.s(y))(z) \equiv z : Nat$

***** Commuting conversion

$\Gamma, z:Nat \vdash [ \mathtt{rec}(0,y.s(y))(z)/z  ]M \equiv \mathtt{rec}([0/z]M, y.[s(y)/z]M)(z)$

**** Natural numbers object in a category
The natural numbers object is the universal object in the following
diagram

\[\begin{tikzcd}[column sep=huge]
1 \rar{0}\drar[swap]{P} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \rar{s}\dar[dashed]{\exists! \mathtt{rec}(P,Q)} &
\mathbb{N} \dar[dashed]{\exists! \mathtt{rec}(P,Q)} \\
&
A &
A \rar[swap]{Q}&
A
\end{tikzcd}\]

**** Reorging the NNO into an initial algebra
This is equivalent to this universality property

\[\begin{tikzcd}[column sep=60pt]
1+\mathbb{N} \dar[swap]{\left\{ 0,s \right\}} \rar[dashed]{ id + \mathtt{rec}(P,Q) } & 
1+A \dar{\left\{ P,Q \right\}} \\
\mathbb{N} \rar[dashed]{\mathtt{rec}(P,Q)}  & 
A
\end{tikzcd}\]

where $f+g : A+B \to A'+B'$ is defined componentwise on the coproduct.

**** Initial algebras
This is an instance of a more general phenomenon, where a functor $F$ satisfies
the diagram with the initial object $I$.

\[\begin{tikzcd}
F(I)\rar{F(!)} \dar[swap]{i} & F(A) \dar{f} \\
I\rar{(!)} & A
\end{tikzcd}\]

This is called an *initial algebra*.

**** Defining addition
We can define addition on the second argument

$\mathtt{plus} := \lambda x. \lambda y. \mathtt{rec}(x;z.s(z))(y)$

and we can check that $\mathtt{plus}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$. But we also can
define addition on the first $\mathtt{q}:= \lambda x.\lambda y. \mathtt{p}\ y\ x$, and this also
implements addition: $\mathtt{q}\ \overline{m}\ \overline{n} \equiv \overline{m+n}$.

Be we cannot prove

\[
x:Nat, y:Nat \vdash \mathtt{p}\ x\ y \equiv \mathtt{q}\ x\ y  \equiv \mathtt{p}\ y\ x
\]

as these are NOT definitionally equal! It can be proved that it is
not provable using only beta rules. This would require a proof by
induction: to show something for all the numerals is the same thing
as to show it for any numeral variables.

**** Extensional and intensional equality
Those are *extensionally* equal, but they are not intensionally equal
(definitional equality). They represent a different algorithm. In the
*sense of Frege*, they have the same reference, but not the same sense.
They have the same IO but different algorithms.

 * Extensional equality is analytic, it does not require proof.
 * Intensional equality is synthetic, does requires proof.

Extensional equality on $(\mathbb{N}\to \mathbb{N})\to(\mathbb{N}\to \mathbb{N})$ has a high quantifier
complexity. A bunch of nested forall and exist.

**** Extensional equality
Intensional equality is an inductive defined judgment, whereas
Extensional equality is a proposition such as

\[ \mathtt{p}\ x\ y =_{Nat} \mathtt{q}\ x\ y
\]

that is an atomic proposition. By the propositions as types
principle, extensional equality is a family of types.

\[
x: Nat, y:Nat \vdash x = y \text{ type}
\]

sometimes $x=y$ is written as $Id_{Nat}(x,y)$. It is a propositional
function or a binary relation.

This family can be instantiated by substitution

\[
Id_{Nat}(M,N) \text{ type}
\]

whenever $M,N:Nat$.

**** Example of extensional equality
We can define the finite sequence of naturals of length $x:Nat$

\[
x : Nat \vdash Seq(x) \text{ type.}
\]

In this case, $Seq(p\ \overline{m}\ \overline{n}) \equiv Seq(q\ \overline{m}\ \overline{n})$ because of the fact that
$p\ \overline{m}\ \overline{n} \equiv q\ \overline{m}\ \overline{n}$. But

\[
x:Nat, y:Nat \vdash Seq(p\ x\ y) \not\equiv Seq(q\ x\ y)
\]

will not be definitionally equal. But they are isomorphic! In some
sense, they should be equivalent. $A \simeq B$ should mean that for some
$f,g$, we should get

\[\begin{aligned}
\alpha :&\quad g \circ f = \mathrm{id} \\
\beta :&\quad f \circ g = \mathrm{id}
\end{aligned}\]

but again, we are we meaning here by equality? In this case we are
talking about propositional equality. There should be transformations
$\alpha,\beta$ between the compositions and the identities.

**** Univalence axiom
In some sense, we expect them to be equal. Univalence says that $A=B \iff A \simeq B$.
There will be an equivalence between those two types.
**** Setup for dependent types
Context/closed types. We have judgements
 
 * $\Gamma \text{ ctx}$
 * $\Gamma \equiv \Gamma'$

Open types/families

 * $\Gamma \vdash A \text{ type}$
 * $\Gamma : A \equiv A'$

Elements of types

 * $\Gamma \vdash M : A$
 * $\Gamma \vdash M \equiv M' : A$

We will have a notion of empty context and the notion of adding anything
to a context

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \text{ ctx}$}
\AxiomC{$\Gamma \text{ ctx}$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A \text{ ctx}$}
\noLine
\BinaryInfC{}
\end{prooftree}

and the equality

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\cdot \equiv \cdot$}
\AxiomC{$\Gamma \equiv \Gamma'$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma, x:A \equiv \Gamma, x:A'$}
\noLine
\BinaryInfC{}
\end{prooftree}

we can take variables

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma,x:A,\Delta \vdash x :A $}
\end{prooftree}

here it is necessary a weakening rule

\begin{prooftree}
\AxiomC{$\Gamma,\Delta \vdash J$}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\BinaryInfC{$\Gamma, x:A, \Delta \vdash J$}
\end{prooftree}

and a substitution

\begin{prooftree}
\RightLabel{(substitution/transitivity)}
\AxiomC{$\Gamma, x:A, \Delta \vdash J$}
\AxiomC{$\Gamma \vdash M:A$}
\BinaryInfC{$\Gamma [M/x]\Delta \vdash [M/x]J$}
\end{prooftree}

and the principle of functionality

\begin{prooftree}
\AxiomC{$\Gamma, x:A, \Delta \vdash N:B$}
\AxiomC{$\Gamma\vdash M\equiv M' :A$}
\BinaryInfC{$\Gamma [M/x] \Delta \vdash [M/x]N \equiv [M'/x]N : [M/x]B$}
\end{prooftree}

another simpler rule is

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M:A'$}
\end{prooftree}

and similarly

\begin{prooftree}
\AxiomC{$\Gamma \vdash M \equiv M':A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M\equiv M':A'$}
\end{prooftree}

All this is written on the section 2 of the appendix of HoTT.

***** Exercise
Consider exchange and contraction
**** Formation rules
The identity type is constructed as

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash N:A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

iterated identity types can be defined $Id_{Id_A(M,N)}$ to any dimension.
The introduction rule should be

\begin{prooftree}
\RightLabel{(Id-I)}
\AxiomC{$\Gamma \vdash M:A$}
\UnaryInfC{$\Gamma \vdash \mathrm{refl}(M) : Id_A(M,M)$}
\end{prooftree}

being a witness of the fact that $M$ is equal to itself.
*** Lecture 7: Dependent Types
**** Last week
The basic judgements are

 1) $\Gamma \text{ ctx}$
 2) $\Gamma \equiv \Gamma'$
 3) $\Gamma \vdash A \text{ type}$
 4) $\Gamma \vdash A \equiv A'$
 5) $\Gamma \vdash M:A$
 6) $\Gamma \vdash M \equiv M' :A$

and they follow structural properties. For example, typing respect definitional
equivalence

\begin{prooftree}
\AxiomC{$\Gamma \vdash M:A$}
\AxiomC{$\Gamma \vdash A \equiv A'$}
\BinaryInfC{$\Gamma \vdash M : A'$}
\end{prooftree}

We left open the exact formulation.

***** Example
An example of dependent type is $x : Nat \vdash Seq(x) \text{ text}$.

\begin{prooftree}
\AxiomC{$M \equiv M' : Nat$}
\UnaryInfC{$Seq(M) \equiv Seq(M')$}
\end{prooftree}

But we do not get $x,y : Nat \not\vdash Seq(x+y) \equiv Seq(y+x)$. The
reason is that $x + y \not\equiv y + x$, they are only intensionally equivalent.
To apply $\eta$ you need to establish an invariant about a candidate $M$,
and the $\eta$ rule would not be enough to write a proof of induction of
that fact. We do not want an induction eta-rule.

**** Proof-relevance
An element $P : Id_A(M,N)$ can be seen as

 1) a proof that $M$ is $N$.
 2) an identification of $M$ with $N$.
 3) a path from $M$ to $N$.

This $x =_A y$ is called propositional equality.

**** Generalization to dependent types
We will review the initial structure of types to generalize the
propositional negative connectives to their dependent forms.
For example, $A \times B$ will generalize to a sigma type $\sum_{x:A}B_x$;
and $A \supset B$ generalizes to $\prod_{x:A}B_{x}$.

\[
\prod_{x:Nat} \sum_{y:Nat} Id_{Nat}(y, \mathtt{succ}(x))
\]

They will represent logical conectives as

\[
\forall x:Nat. \exists y:Nat.\quad y = \mathtt{succ}(x).
\]

**** Pi Types
Formation rules

\begin{prooftree}
\RightLabel{($\pi$-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x : A \vdash B_x \text{ type}$}
\BinaryInfC{$\Gamma \vdash \prod_{x:A}B_{x} \text{ type}$}
\end{prooftree}

introductory rules

\begin{prooftree}
\RightLabel{($\pi$-I)}
\AxiomC{$\Gamma, x:A \vdash M_{x} : B_{x}$}
\UnaryInfC{$\Gamma \vdash \lambda x. M_x : \prod_{x:A}B_{x}$}
\end{prooftree}

elimination rules

\begin{prooftree}
\RightLabel{($\pi$-E)}
\AxiomC{$\Gamma \vdash M : \prod_{x:A}B_x$}
\AxiomC{$\Gamma \vdash N:A$}
\BinaryInfC{$\Gamma \vdash MN : [N/x]B$}
\end{prooftree}

There is a beta-rule

\[
(\lambda x.M)N \equiv [N/x]M
\]

and an eta-rule

\[
(\lambda x.M x)\equiv M.
\]
**** Particular case
$A \supset B$ is a particular case of a pi-type where $B$ does
not depends on $A$.

**** Sigma type
***** Formation

\begin{prooftree}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash B_{x} \text{ type}$}
\BinaryInfC{$\Gamma \vdash \sum_{x:A}B_x \text{ type}$}
\end{prooftree}

***** Introduction
This is constructive existence, you are required to show evidence
of a particular case where it does hold

\begin{prooftree}
\AxiomC{$\Gamma \vdash M :A $}
\AxiomC{$\Gamma \vdash N : [M/x]B$}
\BinaryInfC{$\Gamma \vdash \left\langle M,N \right\rangle : \sum_{x:A} B_x$}
\end{prooftree}

***** Particular case
The product of types is a particular case where $B_x$ is
independent from $x:A$.

***** Elimination
Will not be the same as in the HoTT book.

\begin{prooftree}
\RightLabel{($\Sigma_{E_1}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{fst}(M) : A$}
\RightLabel{($\Sigma_{E_2}$)}
\AxiomC{$\Gamma \vdash M : \sum_{x:A} B_x$}
\UnaryInfC{$\Gamma \vdash \mathtt{snd}(M) : [ \mathtt{fst}(M)/x]B_x$}
\noLine
\BinaryInfC{}
\end{prooftree}

***** Beta/eta rules
Beta rules

 * $\mathtt{fst}\left\langle M,N \right\rangle \equiv N$,
 * $\mathtt{snd}\left\langle M,N \right\rangle \equiv N$

and an eta-rule

 * $\left\langle \mathtt{fst}(M), \mathtt{snd}(M) \right\rangle \equiv M$.
 
**** Constructive logic
Can be seen as a refinment of classical logic, not as anything opposite
to it.
**** Positive fragment
In the positive fragment, we have $(0,A+B,Nat,\dots)$. But are not
going to change the types. Issue: the positive elims reach into
arbitrary types.

For example, the elim of $+$ was

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma,x:A \vdash N:C$}
\AxiomC{$\Gamma, y:B \vdash P:C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case}(M,x.N,y.P) : C$}
\end{prooftree}

but here there is no dependency. $C$ captures the join point of two
branches; or proof by cases.

***** Example: induction
Let $2 := 1 + 1$, $tt := \mathtt{inl}\langle\rangle$ and $ff := \mathtt{inr}\langle\rangle$. We define

\[ \mathtt{if}(M,N,P) := \mathtt{case}(M,-.N,-.P)
\]

and we want to prove that every element of $2$ is one of those

\[
\prod_{x:2} \left( Id_2(x, \mathtt{tt}) + Id_2(x, \mathtt{ff}) \right).
\]

We have to prove both

 * $Id_2(\mathtt{tt}, \mathtt{tt}) + Id_2(\mathtt{tt}, \mathtt{ff})$
 * $Id_2(\mathtt{ff}, \mathtt{tt}) + Id_2(\mathtt{ff}, \mathtt{ff})$

So we use

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A + B$}
\AxiomC{$\Gamma, z:A+B \vdash C_{z}$ type}
\AxiomC{$\Gamma, x:A \vdash N: [\mathtt{inl}(x)/z] C$}
\noLine
\UnaryInfC{$\Gamma, y:B \vdash P: [\mathtt{inr}(y)/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{case} [z.C] (M;x.N;y.P) : [M/z]C$}
\end{prooftree}

where $[z.C]$ is called the *motive* (term by Connor McBride). In this
particular case

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : 2$}
\AxiomC{$\Gamma, z:2 \vdash C_{z}$ type}
\AxiomC{$\Gamma\vdash N: [\mathtt{tt}/z] C$}
\noLine
\UnaryInfC{$\Gamma\vdash P: [\mathtt{ff}/z] C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{if}(M;N;P) : [M/z]C$}
\end{prooftree}

This is a rule of induction.

***** Example
We have the expression

$\mathtt{if}(M,17, \mathtt{tt}) : \mathtt{if} (M,Nat,2)$

but, it is a well-typed expression? not yet. We cannot type
those as types.

**** Induction on naturals
\begin{prooftree}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma, z:Nat \vdash C \text{ type}$} 
\AxiomC{$\Gamma \vdash N : [0/z]C$}
\noLine
\UnaryInfC{$\Gamma,x:Nat, y:[x/z]C \vdash P:[s(x)/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{rec}[z.C](M,N;x,y.P) : [M/z]C$}
\end{prooftree}

with the two beta rules

 * $\mathtt{rec}[z.C](0,N; x,y.P) \equiv N$
 * $\mathtt{rec}[z.C](s(M), N; x,y.P) \equiv [M, \mathtt{rec}[z.C](M,N;x,y.P)/x,y]P$

It has an eta rule which is not useful.

***** Exercise

$\prod_{x:Nat} \left(Id(s(x),0) \to \bot\right)$

we will use

\[
\lambda x. \mathtt{rec}[-](x; -,-)
\]

***** Hard exercise
We cannot solve this yet

$\prod_{x,y : Nat} (Id_{Nat}(sx,sy) \to Id_{Nat}(x,y))$
**** The other form of product types, sigma variant
Idea: elimination as pattern-matching.

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \Sigma_{x:A}B_x$}
\AxiomC{$\Gamma, z : \Sigma_{x:A}B_x \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A, y:B \vdash P : [\langle x,y \rangle/z]C$}
\TrinaryInfC{$\Gamma \vdash \mathtt{split}[z.C](M;x,y.P) : [M/z]C$}
\end{prooftree}

the beta rule is

 * $\mathtt{split}[z.C](\left\langle M_1,M_2 \right\rangle; x,y.P) \equiv [M_1,M_2/x,y]P$

and the eta rule is similar to previous $\eta$ rules. Anything like split is split.

***** Exercise
Define =split= from fst,snd.
Define =fst=, =snd= from split. (Not yet)
*** Lecture 8: Identity types
**** Polarity
Negative and positive fragments. The difference here is
if the type is based on the elimination or the introduction
rule; the other part of the rule is determined by this first
rule. In category theory, it corresponds to the universal
property mapping /in/ or /out/ the definition of the type.

\begin{tabular}{c|cc}
            & negative    & positive     \\
\hline
type theory & elimination & introduction \\
category theory & UP mapping in & UP mapping out
\end{tabular}

For example, $A\times B$ is /negative/. We write the elimination rule:
given a product, we have =fst= and =snd=. The introduction rule is
a pair, needing an $A$ and a $B$.
**** Last week
Dependent formulations of 

 1) negatives $\Pi,\Sigma$.
 2) positives, the type does not change, but the elimination forms do;
    they become induction principles

Elim for the booleans is an example of branching. Today

 * identity types
 * universes
 * ITT. Limitations and peculiarities

**** Identity types
They have this rule of formation

\begin{prooftree}
\RightLabel{(Id-F)}
\AxiomC{$\Gamma \vdash A \text{ type}$}
\AxiomC{$\Gamma \vdash M : A$}
\AxiomC{$\Gamma \vdash N : A$}
\TrinaryInfC{$\Gamma \vdash Id_A(M,N) \text{ type}$}
\end{prooftree}

if we read this type propositionally, this is the type of proofs of
equality between $M$ and $N$. As a notation we use $M =_A N$.

\begin{prooftree}
\RightLabel{(Id-T)}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash \mathtt{refl}_A(M) : Id_A(M,M)$}
\end{prooftree}

In ITT, this would be the only intro rule. We can think of $Id$ as an
inductively generated family of types. 

**** Elimination rule for identity types
The elimination rule would then work as

\begin{prooftree}
\RightLabel{(Id-E)}
\AxiomC{$\Gamma \vdash P: Id_{A}(M,N)$}
\AxiomC{$\Gamma, x:A, y:A, z:Id_A(x,y) \vdash C \text{ type}$}
\AxiomC{$\Gamma, x:A \vdash Q: [x,x,\mathtt{refl}(x)/x,y,z]C$}
\TrinaryInfC{$\Gamma \vdash J[x,y,z.C](P;x.Q) : [M,N,P/x,y,z]C$}
\end{prooftree}

This principle is called *path induction*, where a path is an element
of the identity type. The beta rule is then

 * $J[x,y,z.C]( \mathtt{refl}(M), x.Q) \equiv [M/x]Q : [M,M, \mathtt{refl}(M)/x,y,z]C$

This $J$ is the computational content of the proofs by path induction.
**** Equivalence relation of identity
The identity type should be an equivalence relation

 1) it is reflexive by definition, $Id_A(M,M) \text{ true}$.
 2) it is symmetric showing that there is a function

    \[ \mathtt{sym}_A : \prod_{x,y:A}Id_A(x,y) \to Id_A(y,x)
    \]

 3) it is transitive with

    \[ \mathtt{trans}_A:
    \prod_{x,y,z:A} Id_A(x,y) \to Id_A(y,z) \to Id_A(x,z)
    \]

To define symmetry, we will take

\[ \mathtt{sym}_A :=
\lambda x,y:A.\quad \lambda z:Id_A(x,y).\quad
J[x,y, - : Id_A(y,x)}](z;x. \mathtt{refl}_A(x))
\]

Note that $\mathtt{sym}(M)(M)(\mathtt{refl}(M)) \equiv \mathtt{refl}(M)$ due to the beta rule for $J$.

To define transitivity 

\[ \mathtt{trans}_A :=
\lambda m,n,p. \ \lambda u{:}Id_A(m,n).\ \lambda v{:} Id_A(n,p).\  
(J[x,y, -:Id_A(y,p) \to Id(x,p) ](u; x.\lambda w.w))(v)
\]

# It would be better to stop using lambdas for the parameters and
# write the arguments as arguments.

Note that, in particular, $\mathtt{trans}(M)(M)(P)(\mathtt{refl_A(M)})(Q) \equiv Q$.

***** Exercise
Find two other proofs, not definitionally equivalent, of transitivity.
Hint: double induction.
**** Simple functionality
Suposse $x:A\vdash F:B$ where $A,B$ are types. We have $F\colon A \to B$.
We would like to have a way to prove that maps preserve equality

\[
x,y{:}A, u{:}Id_A(x,y) \vdash Id_B(Fx,Fy)
\]

We will define $\mathtt{ap}\ F\ u$, also called $F(|u|)$; the functorial action

\[ \mathtt{ap}\ F\ u = 
J[x,y, -:Id_B(Fx,Fy)](u, x. \mathtt{refl}_B(F\ x))
\]

**** Transportation property
Suposse $x:A \vdash B \text{ type}$, two pictures are useful

 1) Assigning $a{:}A \mapsto B[a]$ should be functorial.
 2) $\int_{A} B$ should have a display map with fibers sending elements
    on $B[a]$ to $a$.

In some sense, $a = a'$ must imply $B[a] \simeq B[a']$. Transportation could
be thought as functionality for families.

We would want to have 

\[
m,m':A, u:Id_A(m,m'), v : [m/x]B \vdash \mathtt{tr}[x.B](u)(v) : [m'/x]B
\]

the notation for $\mathtt{tr}[x.B](u)(v)$ is $u_{\ast}(v)$.

# Diagram of the lifting property [1:19:50]

This should be defined using path induction

\[ \mathtt{tr}[x.B](u)(v) :=
J\Big[x,y, -:[x/z]B \to [y/z]B\Big](u; z. \lambda w.w)(v)
\]

**** Exercise
Find a map 

\[
x,y{:}Nat \vdash  -{:} Seq(x+y) \to Seq(y+x)
\]

To do this we need

 1) to find a path $x,y{:} Nat \vdash -{:}x+y =_{Nat} y+x$.
 2) transport along that path.
*** Lecture 9: Universes
**** Last week
Maps preserve proofs of identity (functionality)

 * if $F \colon A \to B$ and $p : Id_A(a,a')$, then $\mathtt{ap}\ f\ p : Id_B(f(a),f(a'))$.
   If $a = a'$ is true, $f(a) = f(a')$ is true.

The transportation creates isomorphisms between families of types.

 * If $x:A\vdash B$ is a type and $p : Id_A(a,a')$, then
   $\mathtt{tr}[x.B](p) : B[a] \to B[a']$. This is family functionality.
   If $a=a'$, then $B[a] \iff B[a']$.
**** Universes and large elims
Last notion on ITT.

***** Example
We defined $\mathtt{if}(M,N;P) : B[M]$, and we would want to write things like
$\mathtt{if}(M;17;\mathtt{tt}) : \mathtt{if}(M; Nat,Bool)$; a type depending on a boolean. But we cannot
write it because those are types instead of terms.

***** Large eliminations (ad hoc)
We simply introduce a new type

\begin{prooftree}
\AxiomC{$M:Bool$}
\AxiomC{$A$ type}
\AxiomC{$B$ type}
\TrinaryInfC{$IF(M,A,B)$ type}
\end{prooftree}

where

 * $IF(\mathtt{tt},A,B) \equiv A$
 * $IF(\mathtt{ff},A,B) \equiv B$

Those are called *large eliminations*.

***** Universes of types
A *universe* is a type of types.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U}$ type}
\end{prooftree}

\begin{prooftree}
\AxiomC{}
\UnaryInfC{${\cal U} \equiv {\cal U}$}
\end{prooftree}

where the introduction rules are the previous formation rules.
For example,

\begin{prooftree}
\RightLabel{(UI-Id)}
\AxiomC{$A: {\cal U}$}
\AxiomC{$M,N:A$}
\BinaryInfC{$Id_A(M,N) : {\cal U}$}
\end{prooftree}

The universe should be closed to type formation, for example, closed
to pi-types, sigma-types, 0, 1, sum of two types...

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}$}
\end{prooftree}

But we do NOT postulate that ${\cal U} : {\cal U}$. Its formation rule is the unique
formation rule that is not translated. In other way, the Burali-Forte
Paradox could be reproduced.

***** Solving the problem with universes
Now, we could form $\mathtt{if}(M,Nat,Bool) : {\cal U}$; except we should define some
elimination rules.

Universes allow us to prove

 * injectivity of succ.
 * define =fst=, =snd= from =split=.

If we were to have large elims, we could write things like $\mathtt{If}(M,U,U\to U)$; but
not with the universal type, where is not true that $U : U$.

**** Hierarchy of universes
To solve previous problems, we could write a cumulative hierarchy of
universes. We have a family of rules

\begin{prooftree}
\RightLabel{(U-I)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i : {\cal U}_{i+1}$}
\RightLabel{(U-$\equiv$)}
\AxiomC{$$}
\UnaryInfC{${\cal U}_i \equiv {\cal U}_{i}$}
\noLine\BinaryInfC{}
\end{prooftree}

defining ${\cal U}_1,{\cal U}_2,\dots$ with a trivial definitional equality and closure
properties for every universe, for example

\begin{prooftree}
\AxiomC{$A : {\cal U}_i$}
\AxiomC{$x:A \vdash B:{\cal U}_i$}
\BinaryInfC{$\prod_{x:A} B:{\cal U}_i$}
\end{prooftree}

and the *principle of cumulativity*

\begin{prooftree}
\RightLabel{(cumulativity)}
\AxiomC{$A:{\cal U}_i$}
\UnaryInfC{$A : {\cal U}_{i+1}$}
\RightLabel{(cumulativity-$\equiv$)}
\AxiomC{$A \equiv B : {\cal U}_{i}$}
\UnaryInfC{$A \equiv B : {\cal U}_{i+1}$}
\noLine\BinaryInfC{}
\end{prooftree}

This architecture is forced on us by the Burali-Forte paradox. This
corresponds to the idea of inaccesible cardinals; to a size hierarchy.
**** Dimension
There will be another different notion (on a different axis) than
size (universes). Dimensions are new in HoTT.

**** Formation rules in HoTT
In the HoTT book, formation rules are written as introductions to
the universal type

\begin{prooftree}
\AxiomC{$A : {\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$\prod_{x:A} B : {\cal U}$}
\end{prooftree}

This uses *typical ambiguity*, ${\cal U}$ can be ${\cal U}_i$. The type inference algorithms
of proof assistants solve these constraints, specifying the level in which
we are working. Is a kind of Universe Polymorphism: it let you pretend
${\cal U} : {\cal U}$.

It is very difficult to write something where it is not possible to get an
error at the time of inferring universes. The Burali-Forte paradox cannot be
written in this setting.

**** ITT
At this point, we have introduced ITT with Nats, Sigma, Pi, Identity and
Universes. [Martin-Lf 73]

***** Theorem of Choice in ITT
When $C$ is a total relation, we can pick up a canonical representative of
the elements to which $x$ is related to.

\[
\left(\prod_{x:A} \sum_{y:B} C(x,y)\right) \to \sum_{f:A\to B}\prod_{x:A} C(x,f(x))
\]

where $f$ is called the choice function.

In set theory, this is indepent of the axioms of sets; but in type
theory, it is a theorem because of proof-relevance.

\[
\lambda F.\ 
\left\langle \lambda x. \mathtt{fst}(F(x)) , \lambda x. \mathtt{snd}(F(x)) \right\rangle
\]

where $\mathtt{snd}(F(x)) = C(x, \mathtt{fst}(F(x)))$. 

***** Axiom of choice on sets
How about translating this proof to set theory? We would need for the proof
to be a parametrized object! Proof relevance is key to prove the theorem of
choice. If we cannot look inside the first proof, we could not prove the
theorem.

**** Martin-Lof theorem
If $p:Id_A(M,N)$ for any closed $M,N,A$; without hypothesis (a theorem),
then $M \equiv N : A$.

***** Example
If we have that 

$A = Nat \to Nat \to Nat$
$M = \lambda x. \lambda y.\ x+y$
$N = \lambda x. \lambda y.\ y+x$
$M \not\equiv N$

There is no proof $p : Id(M,N)$, no term of that type. Yet, given $x,y,z: Nat$,
there exists a proof of $p : Id(x+y,y+x)$. The axiom of extensionality fails
here. It is NOT true that

\begin{prooftree}
\AxiomC{$x : A \vdash p:Id_{B}(fx,gx)$}
\UnaryInfC{\vdash -:Id$_{A\to B}(f,g)$}
\end{prooftree}

So the ordinary notion of function is not true here anymore. We cannot
even prove that $\lambda x.fx = \lambda x.gx$. This is a weakness of ITT.

***** Function extensionality as an axiom
If we introduce extensionality as an axiom, we would have introduced another
intro for identity types, and $J$ should have to be redefined.

In HoTT, we can construct this from the axioms, and this makes very difficult
the task of giving it a meaningful computational interpretation.

**** Extensional theory of types (ETT)
In ETT (Extensional here has another meaning), the only identifications are
=refl=. We have the principle of *identity reflection*

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$M \equiv N : A$}
\end{prooftree}

and the only possible proof of identity is =refl=

\begin{prooftree}
\AxiomC{$p : Id_{A}(M,N)$}
\UnaryInfC{$p \equiv \mathtt{refl}(M): Id_A(M,N)$}
\end{prooftree}

In this case, the problem is solved. $Id_B(fx,gx)$ gives us $fx \equiv gx$,
so $\lambda x. fx \equiv \lambda x. gx$, and by eta-reduction, $f \equiv g$. This implies function
extensionality and obviates the need for a rule of transport, we can in fact
show that $B[a] \equiv B[a']$. NuPRL was based on ETT, Coq is based on ITT.

**** The disadvantage of ETT
$M:A$ is decidable (not feasible) in ITT, while $M : A$ is undecidable in ETT.
We need arbitrary theorem proving to decide the equality on ETT. It is instead
decidable if a derivation is a valid one.

*** Lecture 10: Groupoid structure of types
**** Last week
We considered ITT vs ETT. ETT has advantages

 * in ETT, there is no necessity for transport.
 * ETT is similar to standard mathematics, in that there is "just
   equality".
 * function extensionality is implied from the rules.

And disadvantages

 * type checking is no longer decidable; judgmental equality
   is not decidible and it involves proof search and arbitrary theorem
   proving.

A *setoid* in ITT is a set with a given equivalence relation chosen to
have properties like function extensionality. So, the alternative to ETT
is to work with setoids on ITT.

Types are (limited to) sets (aka hsets). The reason why ETT looks like standard
mathematics is because we are working with Sets, where the only paths/identifications
are reflexivities. A sufficient condition for being discrete is decibility of equality.

**** Groupoids
Types in ITT, in contrast, are more general. They are $\infty\text{-groupoids}$, 
and they have richer path structure. Paths can be composed

 * $p : Id_A(a,b)$
 * $q : Id_A(b,c)$

When ITT was introduced, it had power to use gropoids. At the very
beginning, no one realized this feature. ETT works for set-level 
mathematics and it is easier.

***** Strict/weak refl
In ETT we can have two views of refl. NuPRL uses strict sets.

***** HoTT
ITT + axioms introducing new paths. Examples of new types are the
interval.

\[\begin{tikzcd}
I : & \underset{0}\cdot \rar[no head] & \underset{1}\cdot 
\end{tikzcd}\]

which is different from boolean types in that it has a nontrivial path

\[\begin{tikzcd}
Bool : & \underset{0}\cdot & \underset{1}\cdot 
\end{tikzcd}\]

There elements $0,1 : I$ and $seg : \mathrm{Id}_I(0,1)$. The booleans have a mapping
out property where a function $f : Bool \to A$ is defined by

 * $f(0) : A$
 * $f(1) :A$

on intervals, to create a function $f : I \to A$, you must also specify what the
function does on the segment

 * $f(\mathtt{seg}) : f(0) = f(1)$

just intuitively, we want some free structure on the data defining the type,
so that if we want to map out a type, we are required to define how to get
from a type to another on all constructors. $f : I \to A$, for example, picks
a path in $A$.
**** How does J deal with new paths?
Where do you get off adding axioms to type theory? In type theory, 
we have introductions, eliminations, and the Gentzen's inversion/unicity
principle gives us computation by beta rules. Everything has a beta-normal
form.

But when we add axioms, we get into trouble. What should we do on these cases

 * $J[\ ](\mathtt{seg}, x.Q) \equiv ?$
 * $J[\ ](\lambda x.p, y.Q) \equiv ?$

the principal problem with HoTT is how to recover constructivity/computation on
HoTT. We can here express non set-level math. If every equalities are decidable,
we have to be working with sets.

**** I. types are infinite-groupoids
Types are $\infty\text{-groupoids}$. 

Recall that $id_A(M) := \mathtt{refl}_A(M) : Id_A(M,M)$ and that
$p: Id_A(M,N) \vdash p^{-1} : Id_A(N,M)$ was defined by $J$. We also
had composition of paths (transitivity). =trans(p,q)= is defined
by $J$; so we have an equivalence relation.

We have to write code to prove that this is, in fact, an equivalence
relation. Those paths follow the groupoid laws.

***** Groupoid laws
In a groupoid, these laws has to be satisfied

  * $p \cdot p^{-1} \equiv \mathrm{id}$, could be an option, but we usually will accept
    equality on a weaker sense $p \cdot p^{-1} =_{\mathrm{Id}_A(M,N)} \mathrm{id}$.

So we would have elements giving us

  * $\mathtt{unitr} : Id_{Id_A(M,N)}(pp^{-1}, \mathrm{id}(M))$
  * $\mathtt{unitl} : p^{-1}p = \mathrm{id}(N)$
  * $\mathrm{idr} : p \cdot \mathrm{id}(N) = p$
  * $\mathrm{idl} : \mathrm{id}(M) \cdot p = p$

And associativity

  * $\mathtt{assoc} : (p \cdot q) \cdot r = p \cdot ( q \cdot r)$

All of those paths are definible from $J$, they are implicit on the
structure of types and they are called higher-coherences. If we consider only
paths from $M$ to $M$, we would get a higher-group.

***** Defining groupoid laws from J
The groupoid laws can be proven from J.

**** II. Maps are functors
If $f : A \to B$ and $p: M = M'$, we get $\mathrm{ap}_f(p) : fM = fM'$. 
That is the principle of equality functionality. This is written using
$J$ again. We know that $\mathrm{ap}(\mathtt{refl}(M)) \equiv \mathtt{refl}(f(M))$. $\mathtt{ap}$ preserves
identities in this sense. Does it preserve all the groupoid structure?

We can prove that $\mathtt{ap}$ preserves all the structure, it gives us a principle
of *equality functoriality*; it is functorial.

*** Lecture 11: Functoriality
**** Last week
It is a generalization of the structure given by the equivalence
relation on paths. Path satisfy the groupoid laws with the
concatenation of paths. The data associated to every path can be
thought as a higher dimensional path.

For $f : A \to B$, we have

\[ \mathtt{ap}_f : Id(M,N) \to Id(fM, fN)
\]

and it is a functorial application, respecting the groupoid structure
due to the eta-rules for $J$ as

 * $ap(id) = id$
 * $ap(p^{-1}) = ap(p)^{-1}$
 * $ap(p\cdot q) = ap(p) \cdot ap(q)$

and having also that $ap_{id} = id$ and $ap_{f \circ g} = ap_g \circ ap_f$. Suppose $f : \prod_{x{:}A}B_x$,
we would like to have the path

\[ Id_A(M,N) \to Id_B(fM,fN)
\]

but $fM : [M/x]B$ and $fN:[N/x]B$ are not of the same type! But we could use
the transport property to get $p_{\ast} : [M/x]B \to [N/x]B$. If we apply the transport
property to the inversed path, we get the inverted path $B[N] \to B[M]$. We would
get different proofs of the lemma if we use $p_{\ast}$ or $p_{\ast}^{-1}$.

**** Path-over-path
The lemma we want to do is

\[
M =_A N \longrightarrow f(M) =_p^{x:B_{x}} f(N)
\]

this is a notation that says that $f(M)$ and $f(N)$ are correlated by
$p$ on the fiber $x:B_x$. We will be able to send $p$ to a
path-over-path $q : f(M) =_p^{x:B_x} f(N)$.

#+begin_definition
Given $x : A \vdash B : {\cal U}_x$ and $p : M =_A N$,

\[
\Big(Q =_p^{x:B} R \Big)
:=
\Big(p_{\ast} Q =_{[N/x]B} R\Big)
\]
#+end_definition

It is possible to prove a lot of lemmas about this type. We can
state reflexivity, symmetry properties and so on.
**** Equivalence of types: motivation
Equivalence vs definitional and propositional equality of types as
elements of the universe.

 * In an informal treatment of classical logic, we mix $\iff$ and $=$.
   Nothing can distinghish between them. In classical logic there are
   only two propositions, so it is difficult to distingish.
 * Equality should be the relationship respected by everything inside
   the language.
 * But when we are working on a proof relevance setting, there could
   be many different proofs of two propositions, and two implications
   do not have to be inverses!
 * Isomorphisms of sets work on a similar way. It is not important to
   distinghish between two isomorphic sets given any isomorphism $f,f^{-1}$.

We could write bijections like $\omega = \omega^2$, but there are
contexts where we want to make a difference between the two. Set theory
allows us to ask nonsensical things like $0 \in 1$.

The condition of bijection on types can be translated as a function
$f : A \to B$ with a $g : B \to A$ such that

In ITT, let's suppose a set of functions $N \to N$ and a non-trivial 
bijection to itself.

 * $F(f) = f'$ and $G(f') = f$
 * $F(g) = g'$ and $G(g') = g$

but what do those equalities mean? 

 * $F(f)(x) = f'(x)$ and $G(f)(y) = f(y)$ would be an interpretation.
   Those would be extensionally equal, but different functions.

The notion of bijection is not very useful when working on higher-order
types.
**** Equivalence on types involving a universe
The elements of ${\cal U}$ have structure, each one of them is a groupoid.
The idea of bijection $FG(A) = A$ is not workable; we are interested
in nontrivial isomorphisms, in an equivalence rather than equality
$FG(A) \simeq A$.

This is similar to isomorphisms and equivalence of categories. We want
$FG(A) \cong A$, we do not need $FG(A) = A$. Equivalence is isomorphism up
to isomorphism.

And when we have a universe of universes, the same question repeats
itself. We need another level of comparison now. We would get the
higher-group structure of a type.

Isomorphism here is not a proposition but a structure.
**** Equivalence
Given $f : A \to B$, a quasiinverse of $f$ is given by
$(g,\alpha,\beta)$ such that

 * $g : B \to A$
 * $\alpha : \prod_{a:A} g(f(a)) =_A a$
 * $\beta : \prod_{b:B} f(g(b)) =_B b$

The type of *quasiinverses* is

\[
QI(f)_{A\to B} := \sum_{g : B \to A} 
\left(
\left(\prod_{a:A} g(f(a)) = a\right)
\times
\left(\prod_{b:B} f(g(b)) = b\right)
\right)
\]

***** Another version
In ITT, this is different from

 * $\alpha' : g \circ f = id_A$
 * $\beta' : f \circ g = id_B$

this uses two paths instead of two homotopies.
Function extensionality is now

\[
(f =_{A \to B} g) \simeq
\left( \prod_{a:A}f(a)=_B g(a) \right)
\]

saying that every homotopy defines an equation. Those
two types of proofs are equivalent.

**** Univalence axiom
There is an equivalence between equivalence and equality.

\[
(A \simeq B) \simeq (A = B)
\]

Equivalences are given by

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g = id_B \times g \circ f = id_A \right)  \times \text{ some coherence condition }
\]

to avoid the function extensionality issue, we can write
homotopies instead

\[
\sum_{f : A \to B} \sum_{g : B \to A} 
\left( f \circ g \sim id_B \times g \circ f \sim id_A \right) \times \text{ some coherence condition }
\]

but we are going to have function extensionality.
*** Lecture 12: Equivalence of Types
**** Equivalence of types
We write the equivalence of $A \simeq B$. We say that $f : A \to B$ 
is an *equivalence* if there exists

\[
\left( \sum_{g:B\to A} f \circ g \sim id_B \right) \times
\left( \sum_{h:B\to A} h \circ f \sim id_A \right)
\]

the type of equivalences is

\[
A \simeq B := \sum_{f:A\to B} \mathrm{isequiv}(f)
\]

**** Elements of the equivalence
An equivalence is defined whenever those functions
exist

 1. $f : A \to B$
 2. $g:B\to A$
 3. $\alpha: \prod_{y:B} f(g(y)) =_B y$
 4. $h : B\to A$
 5. $\beta : \prod_{x:A} h(f(x)) =_A x$

**** Quasiinverse
Quasiinverses are defined as

\[ \mathrm{quasiinverse}(f) :=
\sum_{g:B\to A} f\circ g \sim id_B \times g \circ f \sim id_{A}
\]

There are three important properties

 1. $qinv(f) \to isequiv(f)$
 2. $isequiv(f) \to qinv(f)$
 3. $isequiv(f)$ expresses an HPROP, it has at most one proof up
    to higher homotopy.

we can transform the data from a quasiinverse to a equivalence.
from  $H : f \sim_{A \to B} g$ we get $\prod_{x:A} Id_B(f x, gx)$. $H$ is functorial in
$x:A$; in the sense that this diagram commutes for any $p : a = a'$

\[\begin{tikzcd}
f(a)\rar[no head]{H(a)} \dar[swap,no head]{ap_f(p)} & g(a) \dar[no head]{ap_g(p)} \\
f(a')\rar[no head]{H(a')} & g(a')
\end{tikzcd}\]

Homotopy is natural (or /polymorphic/) in $x$.

**** Funtion extensionality

 1) definable if $\mathtt{happly}: f =_{A \to B} g \to f \sim g$.
 2) the axiom of funtion extensionality says that the
    above map is an equivalence.

In the presence of function extensionality, we could write $\alpha$
and $\beta$ as $f \circ g \sim id$ and $h \circ f \sim id$. Once you
have function extensionality, you can write the homotopy as
an equality

 * $\prod_{y:B} f(g(y)) = y$
 * by definition of homotopy, $f\circ g \sim id$
 * by function extensionality, $f \circ g = id_{B}$

**** Exercises

 1) $id : A \to A$ is an equivalence, give the four parts of the
    equivalence.
 2) if $f$ is an equivalence, $f^{-1}$, given by the quasiinverse, is
    an equivalence.
 3) if $f$ and $g$ are equivalences, then so is $g \circ f: A \to C$.

**** Structure of paths in types
For example, if we take $Id_{A \times B}(-,-)$, the identity type seems invariant
to the way the type has been constructed; but a structure can be deduced
from the types.

There is a function $f$ with the type $Id_{A \times B}(x,y) \to Id_A(\pi_1x, \pi_2y) \times Id_B( \pi_2x, \pi_2y)$
that we can define as

\[
f := \lambda p. \left\langle \mathrm{ap}_{\pi_1}(p), \mathrm{ap}_{\pi_2}(p) \right\rangle
\]

And we can prove that $f$ is an equivalence

\[
Id_A(x,y) \simeq Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x, \pi_2y)
\]

because it suffices to exhibit a quasiinverse for $f$.

 * $g : Id_A(\pi_1x,\pi_1y) \times Id_B(\pi_2x,\pi_2y) \to Id_{A \times B}(x,y)$
 * $\alpha : g(f(p)) =_{Id_{A\times B}(x,y)} p$
 * $\beta : f(g(q)) =_{Id_A(-,-) \times Id_B(-,-)} q$

we use pattern matching

\[
g := \lambda (p,q). ap^2_{pair}\ p\ q
\]

where $pair = \lambda x,y. (x,y)$, and $ap^2_f\ p\ q : Id(f x y, f x' y')$ where
$p: Id(x,x')$ and $q : Id(y,y')$.
**** Products
We need to show the following for the quasi-inverse

 * $\eta :\prod_p (ap^2_{pair} \left(ap_{\pi_1}(p), ap_{\pi_2}(p)) = p\right)$
 * $\beta_1 : \prod_p\prod_q ap_{\pi_1}(ap^2_{pair}\ p\ q) = p$
 * $\beta_2 : \prod_p\prod_q ap_{\pi_2}(ap^2_{pair}\ p\ q) = p$

We need by path induction $x : A \times B \vdash - : ap^2_{pair}\ (ap_{\pi_1}(refl(x))\ ap_{\pi_2}(refl(x)) = refl(x)$

 * $ap_{\pi_1}(refl(x)) \equiv refl(\pi_1(x))$
 * $ap_{\pi_2}(refl(x)) \equiv refl(\pi_2(x))$

Note that the type checking will depend on the computation rules, and
this is antimodular. If you change anything on the code, everything that
relies on it could break.

 * $ap^2_{pair}\ (refl(\pi_1 x))\ (refl(\pi_2 x)) \equiv refl(\pi_1(x),\pi_2(x)) \equiv refl(x)$
**** Nullary case

\[
Id_{1}(x,y) \simeq 1
\]

**** Coproducts
In coproducts, we would like to prove that

 * $Id_{A+B}(inl(a),inl(a')) \simeq Id_A(a,a')$
 * $Id_{A+B}(inr(b),inr(b')) \simeq Id_B(b,b')$
 * $Id_{A+B}(inl(a),inr(b)) \simeq 0$
 * $Id_{A+B}(inr(b),inl(a)) \simeq 0$

If we were to find a map from

 * $x : Id_{A+B}(inl(a),inl(a')) \vdash -:Id_A(a,a')$

using path induction on $p$, we would have to find a motive $C = ?$
and the conclusion should be $C(inl(a),inl(a'), p)$, where $J[C](p,\dots)$
would be the induction on paths. But how do we get rid of the $inl$?
We should define a motive as

\[
D(u,v) = Id_{A}(outl(u), outl(u))
\]

but there are not $outl$ functions! We want the motive to be

\[
F : (A+B) \times (A+B) \to {\cal U}
\]

such that
 
 * $F(inl(a),inl(a')) \equiv Id_A(a,a')$
 * $F(inr(b),inl(b')) \equiv Id_A(b,b')$
 * $F(inl(-),inr(-)) \equiv 0$
 * $F(inr(-),inr(-)) \equiv 0$

Exercise: define such an $F$ by double induction.

The critical lemma is $x : A+B \vdash -:F(x,x)$, which we need to
use path induction.

\[ \mathtt{case}[z.F(z,z)](x; m:A. refl(m) ; n:B. refl(n) ) : F(x,x)
\]

where $[inl(m)/z]F(z,z) \equiv F(inl(n),inl(n))$.
*** Lecture 13: Path structure of Types
**** Last week
We characterized paths in coproducts.

***** Lemma
$x : A +B \vdash -:F(x,x)$

we use induction on $x$

 * $a:A \vdash refl(a) : F(inl(a),inl(a))$
 * $b:B \vdash refl(b) : F(inr(b),inr(b))$

what we want to define a quasiinverse 

\[
f : \prod_{x,x' : A+B} Id_A(x,x') \to F(x,x')
\]

\begin{aligned}
f := \lambda x. \lambda x'. \mathtt{case}(x;\ a:A.\ \mathtt{case}( & \\
& x'; a':A. \lambda p:Id_A(inl(a),inl(a')) . J[F](p; z.F(z,z), \\
& \dots )
\end{aligned}

***** Quasiinverse
Now we have to define

\[
g : \prod_{x,x':A+B} F(x,x') \to Id_{A+B}(x,x')
\]

as

\[
g := \lambda x,x',z:F(x,x')\ \text{cases on }\ x\ x'
\]

and now we want to show

 * $z:F(x,x') \vdash \alpha(z) : f(g(z)) = z$
 * $z:Id_{A+B}(x,x') \vdash \beta(z) : g(f(z)) = z$

**** Positive types
We work with coproducts as examples of positive types. We will
characterize $Id_0(-,-)$ and the path structure of $\mathbb{S}^1$.

\[
Id_{s'}(b,b) = \Omega_b(S') \simeq \mathbb{Z}
\]

We are doing synthetic homotopy theory.

**** Characterizing paths on identity types
Given a type $A$, we consider $Id_{Id_{\dots_A}}(-,-)$. We cannot say much, because
it includes as special cases the spheres $\Omega(S^n)$.

If $f : A \to B$ is an equivalence, then so is $ap_f : a =_A a' \to f(a) = f(a')$.
What we have is $f : A \to B$, so $\alpha : \prod_{a:A}f^{-1}(f(a)) =_A a$ and $\beta : \prod_{b:B}f^{-1}(f(b)) =_B b$.
because it has quasiinverses. To prove this, we define

\[ ap^{-1}_f := \alpha(a)^{-1} \cdot ap_{f^{-1}} \cdot \alpha(a')
\]

now we need

 * $\alpha' : \prod_{p:a =_A a'} ap^{-1}_f(ap_f(p)) =_{a = a'} p$
 * $\beta' : \prod_{q:f(a) =_B f(a')} ap_f(ap_{f}^{-1}(q)) =_{f(a) = f(a')} q$

and both can be proved by path induction.
**** Identity types are homs in an (infinite,1)-category
The type $Id_A(x,y)$ is similar to $Hom_A(x,y)$. $Id_A(-,-)$ is a family
of types, and hence a fibration.

We look at the transport/fibration properties taking
the notation $E(x,y) := Id(x,y)$

  1) fix $x_{0}:A$, consider $\lambda y:A.E(x_0,y)$,

     \[
     tr[y.E(x_0,y)](q) : E(x_0,y) \to E[x_0,y']
     \]

     it maps $p:E(x_0,y) \mapsto p \cdot q$

  2) fix $y_0 : A$, consider $x . E(x,y_0)$,

     \[
     tr[x.E(x,y_0)](p) : E(x,y_0) \to E(x',y_0)
     \]

     mapping $q \mapsto p^{-1}\cdot q$.

  3) for $p : x = x'$, $q : E(x,x)$; $tr[x.E(x,x)](p) : q \mapsto p^{-1} \cdot q \cdot p$.

It can be checked by path induction. This show that they behave like
Hom's and that they exhibit the infinity-groupoid structure.
**** Recall: identity elimination rule
The idea is that, in ITT, this can be thought of as an induction
principle arising from taking the Id to be the least reflexive
relation, because the only introduction rule says so; and the 
elimination works as that.

\begin{prooftree}
\AxiomC{$\Gamma \vdash p:Id_A(M,N)$}
\noLine
\UnaryInfC{$\Gamma,x:A,y:A,z:Id(x,y) \vdash F : {\cal U}$}
\AxiomC{$\Gamma, x:A \vdash q : F(x,x,refl) $}
\BinaryInfC{$\Gamma \vdash J[F](p,x.q) : F(M,N,p)$}
\end{prooftree}

For doing set-level mathematics, this works. In HoTT, we interpret the
identities as paths in $A$, not as inductive types. We conclude things
about non-trivial paths only reasoning about reflexivity!
*** Lecture 14: Identity elimination
**** Last week exercise
If $ - : qinv(f)$, then $-: ap_f$.

 1) $ap_f^{-1} = ap_{f^{-1}}$
 2) $\alpha : \prod_{p : a=_A a'} \dots$
 3) $\beta : \prod_{q : f(a) = (a')} ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$

the (2) is proved by path induction, but (3) is not so easy. If we use
path induction there, we will get $F[f(a),f(a'),q]$ as motive, which should
be then $ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q$. Recall that, for coproducts,

 * $F[inl(a),inl(a')] \equiv (a = a')$

but here, we cannot do that, we would need to define it such that
$F[f(a),f(a'),q] =_{{\cal U}} \left(ap_f(\alpha(a)^{-1} \cdot ap_{f^{-1}}(Q) \cdot \alpha(a')) = q\right)$. If $M:A$ and
$p : A =_{{\cal U}} A'$, then $p_{\ast}(M) : A'$. So you use the fact that

 * $f^{-1}(f(a)) =_A a$, and
 * $(f^{-1},\alpha,\beta) : qinv(f)$.
**** Justifying the J operator
The J operator has different meanings in ITT and HoTT

 1. In ITT, J expresses an induction principle on proofs of identity,
    of which there is exactly one.

 2. In HoTT (or ITT + FUNEXT), the situation is less clear,

    \[J[\ ](refl(M), x.Q) \equiv [M/x]Q\]
    
    but then, we have the problem

    \[J[\ ](funext(H); x.Q) \equiv ?
    \]

    where the Gentzen's principle does not hold. How should apply
    $J$ with the Univalence Axiom or to other defined equalities?

    * $J[\ ](UA(E), x.id) \equiv ?$
    * $J[\ ](seg, x.id) \equiv ?$
    * $J[\ ](loop, x.id) \equiv ?$

 3. In ETT, it does not work like this. Equality reflection allows us
    to replace to equalities; we do not need J at all. We get FUNEXT
    without special arrangement. It has a computational interpretation.
    You end using a theory of realizability.

 4. In OTT, we can have FUNEXT without special arrangement. It has a
    computational interpretation.

In HoTT, we give up on computation; but maybe we can recover one. We
justify the theory by interpretation into the classical ZF using
simplicial sets.
**** Solving (partially) the problem
Idea: have $x:A \vdash Q : C[x,x,refl(x)]$ where the motif
$x:A,y:A,z: x=y \vdash C : {\cal U}$. We want to get $- : C[M,N,P]$ 
where $M,M':A,P: M=M'$. This is what the J-rule is saying. 

We know that $[M/x]Q : C[M,M,refl(M)$, and $Q$ depends functorially
on $x$. The logic in HoTT is integrated with the whole structure of
maps. There is a continuous dependency from $Q$ to $A$. So we also
know that $[P/x]Q : [M/x]Q =_p^{C(-,-,refl(-))} [N/x]Q$ (in an abuse of language)
and $ - : p_\ast [M/x]Q =_{C(M',M',refl(M'))} [M'/x]Q$.

Since $refl(M) : M = M and $p : M = M'$, now it suffices to find
$\alpha : refl(M) =^{Id(-,-)}_{(refl(M),p)} p$, wich is to say that

\[
\alpha : \left\langle refl(M),p \right\rangle(refl(M)) = p
\]

the triple $(refl,p,\alpha)$ would take $C(M,M,refl(M))$ into $C(M,M',p)$.

\[ tr[x.Id(x,x)](p)(q) = p^{-1}\cdot q \cdot p\]

it works choosing $refl_{Id_{A}(M,M')}(p)$. $C$ does the work! A priori, $C$ respects
whatever it is that $Id$ internalizes!

**** The identity type
The equality is respected by all the theory, that is why the identity
type has those special properties. In HoTT, $Id$ internalizes homotopy
equivalence, and, by univalence, everything respects homotopy
equivalence. In contrast, in ITT, $Id$ internalizes definitional
equality.

The identity type does not define homotopy equivalence, it only 
internalizes the notion.
**** Homotopy types
The slogan is that Homotopy (Type Theory) is (Homotopy Type) Theory.
# As que debe traducirse por teora de tipos homotpicos o
# por teora de tipos homotpica.

#+begin_definition
A type $A$ is a *set*, aka 0-type, iff for all $p,q : x =_{A} y$, we have
that $p=q$.
#+end_definition

\[ \mathrm{isSet}(A) :=
\prod_{x,y:A}\prod_{p,q: x=y} p = q
\]

it is a discrete groupoid up to higher homotopy. The only paths are
the reflexivities, but up to higher-homotopy! There can be other loops,
but they are homotopic to the reflexivity.

You can form a type theory there every type is a set.
*** Lecture 15: Sets and propositions
**** Last week
We saw a justification for the J-rule and the interaction with
the functioriality of $C$ and the inductive analysis of J.

**** The Interval Type
Formation rule

\begin{prooftree}
\RightLabel{$(I-F)$}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash I : {\cal U}$}
\end{prooftree}

Introduction rules

\begin{prooftree}
\RightLabel{(iI0)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  0 : I$}
\RightLabel{(iI1)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash  1 : I$}
\noLine
\BinaryInfC{}
\end{prooftree}

And another introduction rule

\begin{prooftree}
\RightLabel{(iIseg)}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash seg : Id_I(0,1)$}
\end{prooftree}

This is an inductive definition of the type. The type should be
freely generated by these constructors.

\begin{prooftree}
\AxiomC{$\Gamma, x:I \vdash C[x] : {\cal U}$}
\AxiomC{$\Gamma \vdash M_0 : C[0]$}
\noLine
\UnaryInfC{$\Gamma \vdash M_1 : C[1]$}
\AxiomC{$\Gamma \vdash p : M_0 =_{seg}^{x:C} M_1$}
\TrinaryInfC{$\Gamma, x:I \vdash \mathrm{rec}_I[x.C](x;M_0,M_1 )  : C[x]$}
\end{prooftree}

where it is defined as

 * $rec[x.C](0;M_0,M_1, -) \equiv M_0 : C[0]$
 * $rec[x.C](1;M_0,M_1, -) \equiv M_1 : C[1]$
 * $dap(\lambda x . rec[x.C](0;M_0,M_1,p)) \equiv p : M_0 =^{x:C}_{seg} M_1$

the $dap$ map should be functorial

\[ dap : \prod_f \prod_{x:A}B \longrightarrow \prod_{p:Id(x,y)} Id(fx,fy)
\]

**** The total path space of a type
The total path space are the morphisms from the interval

\[
\sum_{x:A}\sum_{y:A} Id(x,y) \simeq (I \to A)
\]

***** Proof
The rec function goes from left to right

$\lambda x,y,p. \lambda t. rec[-:A](t;x,y,p)$

And the description of the path goes the other way

\[ \lambda h. (h(0),h(1), ap(seg)).
\]

**** Conclusion on the total path space
A path between functions is an homotopy, a path between
every pair of points

\begin{align*}
\int Id_{A \to B} &
\simeq I \to (A \to B) \\&
\simeq (I \times A) \to B \\&
\simeq (A \times I) \to B \\&
\simeq A \to (I \to B) \\&
\simeq A \to \int Id_{B}
\end{align*}

Function extensionality says that

\[
Id(f,g) \simeq \prod_{x:A}Id_{A \to B}(fx,gx)
\]

which can be proved by definition and taking the right-to-left
direction as an axiom.
**** Sets
A type is a set if it is homotopically discrete.

\[
\mathrm{isSet}(A) \equiv \prod_{x,y:A}\prod_{p,q : x=y} p=q
\]

up to higher homotopy, the only equality is reflexivity.
Pure ITT is a theory of sets. All of the constructs of ITT
preserve the property of being a set

 1) $1$ is a set.
 2) if $A,B$ are sets, $A \times B$ is a set.
 3) if $A,B[x:A]$ are sets, $\sum_{x:A} B$ is a set.
 4) if $A,B$ are sets, $A+B$ is a set.
 5) $Nat$ is a set.
 6) if $A,B$ are sets, $A \to B$ is a set.
 7) if $A,B[x:A]$ are sets, $\prod_{x:A} B$ is a set.

In the NPS book, they use the terminology =Sets=.
**** Problems interpreting ITT as a theory of sets
Why are the identities sets? Why is the universe a set?

ETT is also a set theory, and it is easier to work with it. In
ITT, we have to pay the price of higher dimensionality without
using it.

**** Is universe a set?
Are the elements of ${\cal U}$ codes (names of types) or types? We can
introduce the elements of ${\cal U}$ inductively. The codes will form a
set.

NuPRL and HoTT take the elements to be types; but NPS take the
elements to be codes and to form a set, using ITT as a set theory.
*** Lecture 16: ITT
All of the basic constructs of ITT preserve the relation of being a Set.
Up to higher homotopy, there is at most one proof of equality of any two
elements.

${\cal U}$ is rigged to be a set and it is a set of codes; an inductively defined
set.

**** The identity type is a set
$Id_A(x,y)$ is a set if $A$ is a set

***** Proof
Assume that $A$ is a set

\[
H : \prod_{x,y:A}\prod_{p,q:Id_A(x,y)}Id_{Id_A(x,y)}(p,q)
\]

and we want to show that $Id(x,y)$ is a set. Assume $u,v : A$,
$r,s:Id(u,v)$ and $\alpha,\beta : Id(r,s)$. We have to show that

\[
Id_{Id_{Id_A(u,v)}(r,s)}(\alpha,\beta)
\]

We specialize $H' := H(u)(v)(r) : \prod_{q:Id_A(u,v)} Id(r,q)$; and we are going
to exploit the functoriality of $H'$. So

\[ apd_{H'} : \prod_{q,q': Id_A(u,v)} \prod_{\gamma : Id(q,q')} Id(\gamma_{\ast}(H'(q)),H'(q')
\]

being a path-over scenario. Here,

\[
apd_{H'}(r,s,\alpha) : Id(\alpha_{\ast}(H'(r)), H'(s))
\]

and, similarly

\[
apd_{H'}(r,s,\beta) : Id(\beta_{\ast}(H'(r)), H'(s)).
\]

So, we can conclude that I can get an element of the identity
$Id(\alpha_{\ast}(H'(r)), \beta_{\ast}(H'(r)))$. What this is telling us is that, by
post-composition given by transport in the identity, $Id(H'(r)\alpha, H'(r)\beta)$.

We have that $H'(r)\cdot \alpha = H'(r)\cdot \beta$, so I can multiply by the inverses
to get

\[
H'(r)^{-1}H'(r)\alpha = H'(r)^{-1}H'(r)\beta
\]

and then $\alpha = \beta$. We have used here the groupoid structure.
**** ETT
ETT is also a set theory because ITT is a set theory. ETT is easier to
use when working with sets than ITT. HoTT adds the univalence axiom
and Higher Inductive Types. Here, homotopy can be thought as a branch
of logic. 

**** ITT+UA
But ITT+UA is *not* a set theory; not all types are sets! In particular,
${\cal U}$ is a proper groupoid; there are non-trivial paths between elements.

For example, we will show two non-related paths between $1+1=2$ and
$2 = 1+1$. We know that

\[ UA: (A = B) \simeq (A \simeq B)
\]

and we are going to use it to create two different paths.

 * $ud(id)$
 * $ud(not)$

and $id \neq not : 2 \to 2$ by function extensionality; they are two different
equivalences. We also have $refl(tt) : tt =_2 tt$; and by transport if the
two paths were the same up to higher homotopy, $tr('') : ff = tt$, which is 
falsable.

**** H-props
Start with $n \geq -2$. 

#+begin_definition
A type $A$ is an *h-prop* or prop iff

\[ \mathrm{IsProp(A)} :\equiv
\prod_{x,y:A} Id(x,y)
\]
#+end_definition

It is a subsingleton and it has at most one element up to higher
homotopy. The problem with this naming is that this collides with
the idea that propositions are types! It is better to call them
*h-props* instead of *props*.

The truth of these propositions is proof-irrelevant for types that
are called h-props.

***** Example: NuPRL and Markov's principle
In NuPRL, the types were specifications, and proofs where programs.
If we want to look for a zero on a sequence

\[s : \left( \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but here there is a solution in constant time! The $i$ is part of the
specification, we provided too much information on the input. The
problem here is proof-relevance. How could we suppress this information
in a type?

The first idea is an observation by *Brower*: we can change the specification
to use double negation

\[s : \left(\neg\neg \sum_{t:Nat\to Nat}\sum_{i:Nat} t(i) = 0 \right)
\to 
\left(\sum_{i : [0..|s|-1]} s(i) = 0\right)
\]

but now, should a while terminate? *Markov's principle* says that, if you
can prove that a machine can't fail to halt, then it must halt. This is a
very contentfull statement in a constructivist setting. This is a very
strong axiom, the characteristic of the Russian school of constructivism.
(Markov, Kolmogorov).

***** Double negation and computational content
In NuPRL, we do not have Markov's principle. We would change $Nat \to Nat$ to
$FinSeq(k)$ in order to have a bound. Double negation kill computational,
proof relevant content.

#+begin_proposition
For any $A$, $\mathrm{IsProp}(\neg \neg A)$.
#+end_proposition

It has a simple proof.

***** Gdel's double negation translation
The idea of Gdel was to embed classical into constructive logic.
Here, classical logic is just a particular case of constructive
logic. This is called /squashing/

 * $\|1\| = 1$
 * $\|A \wedge B\| = \|A\| \wedge \|B\|$
 * $\|0\| = 0$
 * $\|A \vee B\| = \neg\neg(\|A\| \vee \|B\|)$

For implication, we have to choices

 * if we only want to just squash, $\|A \supset B\| = \|A\|\supset \|B\|$, suffices.
 * but if we want to recover classical logic, $\|A\| \supset (\neg\neg \|B\|)$.

Classical logic is constructive + double negation elimination; the
notion of $\neg\neg A \supset A$.

 * with the first option, $\|\neg\neg A \supset A\| = \neg\neg A \supset A$.
 * with the second one, $\|\neg\neg A \supset A\| = \neg\neg A \supset \neg\neg A$, which is true!

This is called the CTS transform for compilers. Where $\neg A$ is interpreted
as a countinuation for compilers. This is the type of a continuation

\[
(\|A\| \times (\|B\| \to 0)) \to 0
\]

With this technique, classical logic can be recovered from the constructivistic
logic.

**** Propositional truncation
We will abstract the idea of squasing into truncation; the idea is
to quotient by the full relation. You take a type and a relation where
you quotient by all the relationships. The notion of subsingleton is
also useful to do proof-irrelevance.

The idea of a subquotient does not work well with set theories. In
HoTT we will use the idea of a quotient.

**** Hedberg's theorem
A type with decidable equality is a set.

If $\prod_{x,y:A} Id(x,y) \vee \neg Id(x,y)$, then $isSet(A)$.

***** Corollary
Classical logic destroy the higher-homotopy structure! If you
postulate excluded-middle, everything is now gone.

***** Proof
 1) Decidable equality implies stable equality.

    \[
   \neg \neg Id(x,y) \to Id(x,y)
   \]

 2) Stability implies sethood.
*** Lecture 17: Hedbergs theorem, truncation
**** Last week
A type is a set if any two proofs of equality are equal. In other
words, if the equality is a proposition. A proposition is a type such
that any two elements of it are equal.

**** The negations are propositions
The negation of any type is a proposition.

***** Proof
If $x,y : A \to \bot$, then $x = y$, as we have function extensionality;
and given any $a : A$, we could use ex falso quodlibet, $\mathtt{abort}(xa) : xa = ya$.
# Check this line on agda with hott

**** Hedberg's theorem
A type with decidable equality is a set. Decidable equality
can be written as

\[
\prod_{x,y : A} Id(x,y) \vee \neg Id(x,y)
\]

and a type is a set if

\[
\prod_{x,y: A} \prod_{p,q : x=y} p = q.
\]

***** Proof 1: Decidable equality implies Stable equality
Stable equality, by definition, is

\[
\prod_{x,y : A} \neg \neg Id(x,y) \to Id(x,y).
\]

In general, what we know is that if $A \vee \neg A$, then $\neg\neg A \to A$. This
is only an instance of that.

***** Proof 2: Stable equality implies Sethood
Suppose that the equality on $A$ is stable, $h :\prod_{x,y: A} \neg \neg (x = y) \to (x = y)$.
It suffices to show that every $p : x = x$ is $p = \mathtt{refl}$. We can apply the
path to get, by transport

\[
p_{\ast}(h(x)(x)) =_{\neg\neg x = x \to x = x} h(x)(x)
\]

so we know that, for any $r: \neg\neg (x = x)$, we know that

\[
p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r).
\]

And Lemma 2.9.6 from HoTT book is a technical result, saying that

\[
h(x)(x)(r)(p) = h(x)(x)(p_\ast r)= p_{\ast}(h(x)(x)) (r) =_{x = x} h(x)(x)(r) = h(x)(x)(r),
\]

where we use that negated types are propositions.

***** Example: N is a set
By double induction, we can show the decidability of equality on this
type.
**** Every proposition is a set
In general, we will get that any n-type is a n+1-type. If
$\prod_{x,y : A} x = y$, then $\prod_{x,y:A}\prod_{p,q:x=y} p = q$. Suppose a function given
with $f : \prod_{x,y:A} x = y$; then we can fix $x_0:A$ and let $g(y) \equiv f(x_0)(y)$.

By functioriality, if we have $p : y = y'$, then $apd(p) : p_{\ast}(g(y)) = g(y')$.
And if $q : y = y'$ and $q = g(y^{-1})g(y')$, so $p = q$.

**** The statement of anything being a proposition or a set is a proposition

 * $isProp(isProp(A))$
 * $isProp(isSet(A))$

In the book, there is a chapter on when is a proposition an equivalence of
two types. $isProp(isEquiv(A)(B))$? In the case of the definition by quasiinverses,
it is not a proposition. A function can has many quasiinverses.

***** First proof
Given $f,g : isProp(A)$, we will show that they are equal. It suffices to show that
$x,y:A \vdash - : f(x)(y) =_{x=y} g(x)(y)$. Since $isProp(A)$ implies $isSet(A)$, the desired
equation holds.

***** Second proof
We can use a similar argument.
**** Propositional truncation, aka "squashing"
When we worked in the Godel double negation translation,

\[
\|A \to B\| = \|A\| \to \neg\neg \|B\|
\]

A more abstract notion of truncation is do the squashing and not to
worry about recovering classical logic. What you do is to introduce
the type $\|A\|_{-1}$ of a truncation of $A$. It has the introduction form

\begin{prooftree}
\RightLabel{($\|\cdot\|$-I)}
\AxiomC{$M:A$}
\UnaryInfC{$|M| : \|A\|$}
\end{prooftree}

and the rule that any two elements are going to be the same up to higher
homotopies

\begin{prooftree}
\AxiomC{$M:A$}
\AxiomC{$N:A$}
\BinaryInfC{$- : Id_{\|A\|}(|M|,|N|)$}
\end{prooftree}

This is the quotient of $A$ by the full relation. The elimination form has
to be, then

\begin{prooftree}
\RightLabel{$\|\cdot\|$ - E}
\AxiomC{$M : \|A\|$}
\AxiomC{$x : A \vdash N : B$}
\AxiomC{$p : isProp(B)$}
\TrinaryInfC{$\mathtt{trunc}(M, x.N, p):B$}
\end{prooftree}

the requirement of $B$ to be a proposition, ensures that N's behaviour is
independent of the choice of representative of the suplied equivalence
class. We could relax the condition to a weaker one requiring only this.
**** Contractibility
A type is contractible if it has an element and every other element is
equal to it

\[
isContr(A) = \sum_{x:A}\prod_{y:A} x=y
\]

***** Lemma

\[
isProp(A) \iff
\prod_{x,y:A} isContr(x=y)
\]

**** n-types
Something is a -2type iff it is contractible. And something is an
n+1-type iff for all $x,y$, $x=y$ is a n-type.

 * A proposition is a -1 type
 * A set is a 0 type
 * A groupoid is a type
 * A 2-groupoid is a 2-type
 * and so on

Any n-type is also an n+1-type. It is a *cumulative hierarchy*.

**** Not any type is an n-type
Not any type is an n-type for some n! There are types with a higher structure
up to infinity.

*** Lecture 18: Homotopy n-types, contractability
**** Last week
We defined contractability using centers of contraction.
It expresses the idea of unique existence $\exists!$. It is sometimes
written as $\Sigma!$.

Something is contractible if it is a proposition and it has
one element.

**** Fact of contractability
If you fix any point $a : A$; you can consider the neighborhood of $A$
and we can consider the star of $A$ and that is contractible.
We can prove that

\[
isContr\left(\sum_{x:A} a = x\right)
\]

given $a : A$.
**** The special case of the propositional truncation
We are going to call propositional truncation as -1-truncation.
We can write it as $\|A\|_{-1}$. It will be useful to define other
truncations. The idea is to have

\[
isProp(\|A\|)
\]

for any $A : {\cal U}$. That is to say that the equality type of this type
is contractible as

\[
\prod_{x,y:\|A\|} isContr(x = y).
\]

The intuition is that

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : A$}
\UnaryInfC{$\Gamma \vdash |M| : \|A\| $}
\end{prooftree}

and in the elimination rule, we should prevent proofs for depending on
the witness of the inhabitation.

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x : \|A\|, y: \|A\| \vdash \mathtt{squash}(x,y) : x = y$}
\end{prooftree}

The eliminator was defined as

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \|A\|$}
\AxiomC{$\Gamma, x : A\vdash N : B$}
\AxiomC{$\Gamma \vdash p : isProp(B)$}
\TrinaryInfC{$\Gamma \vdash elim[B](M,x.N,p) : B$}
\end{prooftree}

by using that $B$ was a proposition, we were sure that the result did not
depend on the representative of $A$.

**** Gentzen and squash
Squash is another case of a new primitive equality. By Gentzen's principle,
we would need a beta and an eta rule

 * $elim[B](|M|; x.N, p) \equiv [M/x]N : B$

we would like to have a rule such as

 * $ap(\lambda z. elim[B](z;x.N,p))(squash(|M|,|N|)) \equiv (|M| =|N|)$

this is problematic. (?) If you are using a $J$ and the argument is a
squash, what should that be definitionally equal to?
**** Revisit the axiom of choice
The Axiom of Choice $AC_{\infty}$ has a formulation as

\[
\prod_{A : {\cal U}}
\prod_{B : A \to {\cal U}}
\prod_{C : \prod_{x:A} B \to {\cal U}}
\left(
\prod_{x:A}\sum_{y:B_x} C(x,y)
\overset{\simeq}\longrightarrow
\sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x))
\right)
\]

and we can check in fact that this is a definable *equivalence*. It is
not an axiom! it is a theorem. The theorem of choice. We use crucially
the proof relevance to prove it.

***** Proof
From left to right

\[
\lambda F. \left(
 \lambda x. \mathtt{fst}(F x),
 \lambda x. \mathtt{snd}(F x)
\right)
\]

and from right to left

\[
\lambda \left\langle f,g\right\rangle . \lambda x .(f x, gx)
\]

and those are mutually inverses. We will need eta rules for products and
eta rules for sums.
***** It is a theorem
It is not saying exactly what the axixom of choice says usually.
**** Versions of the axiom of choice
If we use propositional truncations we get the actual axiom of choice,
that we will call $AC_{-1}$.

\begin{aligned}
AC_{-1} : 
  \prod_{A :{\cal U}} isSet(A) \to 
  \prod_{B : A \to {\cal U}} \prod_{x : A} isSet(B(x)) \to
  \prod_{C : \prod_{x:A} B \to {\cal U}} \prod_{x:A} \prod_{y:B} isProp(C(x,y)) \to \\
  \left(
    \left( \prod_{x:A} \| \sum_{y:B} C(x,y) \| \right) \to
    \left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\|
  \right)
\end{aligned}

And this is *not* a theorem. We are using truncation and this is expressing the idea
that there is no functional dependency but we can, nevertheless, build a function.

***** NuPRL
Using squashing, we can express this also on the NuPRL system.
***** Expressivity
The constructive setting is more expressive than the classical one. We can choose,
by introducing identifications, to work on the classical setting.
***** Restatement
If we use the equivalence from before, we can write that

\[
\left\| \sum_{f : \prod_{x:A} B} \prod_{x:A} C(x,f(x)) \right\| \simeq
\left\| \prod_{x:A}\sum_{y:B} C(x,y)  \right\|
\]

and that means that we can restate the axiom of choice using

\[
    \left( \prod_{x:A} \left\| \sum_{y:B} C(x,y) \right\| \right) \to
    \left\| \prod_{x : A} \sum_{y:B} C(x,y) \right\|
\]

instead. And we can reduce this to a simpler form as

\[
\prod_{x:X}\|Y(x)\| \to
\left\| \prod_{x:A} Y(x)  \right\|
\]

which can be read as "the product of a family of inhabited sets
is an inhabited set". This is also an equivalence.

This version of the axiom of choice is false if $X$ is not constrained
to be a set.
**** Quasiinverses
Recall that a quasiinverse was

\[ \mathtt{qinv}( f : A \to B) :\equiv
  \sum_{g : B\to A} f \circ g \sim id \times g \circ f \sim id
\]

in the presence of function extensionality, we can replace $\sim$ with
$=$. We will show that $qinv$ is not necessarily a -1-type (a proposition).

***** Characterization of quasiinverses
If $f : A \to B$ and $e : qinv(f)$ then 

\[
qinv(f) \simeq \prod_{x:A} x = x
\]

sometimes we write $x =_{A} x \equiv \Omega(A,x)$. This uses univalence.

***** Existence of a not-proposition
There is a type $X$ such that

\[
\prod_{x : X} x=_Xx
\]

is not a proposition. An example of this is $X = \pi(\mathbb{S}) \simeq \mathbb{Z}$, which
will be a set. Another one is $X = K(G,1)$, a space with its fundamental
group being $G$.

As a corollary, $qinv(f)$ need not be a proposition.

**** A good definition of equivalence
The criterion is that it should be a proposition, so the quasiinverses
definition does not qualify. We create new definitions

 * $isContr(f)$
 * $isBiequiv(f)$, we have a left inverse and a right inverse.
 * $isHalfAdjoint(f)$, defined by quasiinverses plus a coherence condition.

all these definitions are equivalent. And these are all propositions.

**** Contractability definition of equivalence
For $f : A \to B$,

\[
isContr(f) :\equiv
\prod_{y:B} isContr(fibers_f(y))
\]

where

\[
fibers_f(y) \equiv \sum_{x:A} f(x) = y
\]

the things that are sent by $f$ to $y$. The total "sum of fibers" is
the total $A$.

***** Voevodsky's definition of equivalence
The definition can be stated as that exists a unique

\[
\prod_{y:B}\sum_{z: fib_f(y)} \prod_{z' : fib_f(y)} z = z'
\]

so the function is a bijection up to homotopy.
*** Lecture 19: Inductive types I
**** Last week
We suppose that we had a quasiinverse for $f$ given by an inverse,
and two proofs of the inverse, $\left\langle g_0,\alpha_0,\beta_0 \right\rangle$. The claim was that

\[
qinv(f) \simeq \prod_{x:A} x = x
\]

in the presence of FUNEXT, this is equivalent to the fact that
$id = id$. The type of quasiinverses is

\[
\sum_{g : B \to A}\sum_{\alpha : g \circ f = id} \sum_{\beta : f \circ g = id} 1
\]

and a similar type is contractible

\[
\sum_{g : B \to A} \sum_{\beta : f \circ g = id} 1
\]

with center $(g_0,\beta_0)$. This says that $f$ has exactly one right inverse.
If we consider $(g_1,b_1) : \sum_{g : B \to A}\sum_{\beta : f \circ g = id} 1$, we have to show that
$p : g_1 = g_0$ and then, by transport $- : \beta_0 = \beta_1$.
**** Biinverse
If we use the definition of biinverses

\[
binv(f) :\equiv
\left(\sum_{r : B \to A} f \circ r = id\right) \times
\left( \sum_{l:B \to A} l \circ f = id \right)
\]

as both factors are contractible, the type is contractible. This
definition is related to the half-adjoint definition. $f$ is
bijective up to homotopy if this holds.

It is reasonable to speak of $biinv(f)$ true as it were a proposition.
**** Inductive types (the nat case)
Reconsider Nat in simple types. We had introductory rules

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma \vdash 0 : Nat$}
\AxiomC{$\Gamma \vdash M : Nat$}
\UnaryInfC{$\Gamma \vdash succ(M) : Nat$}
\noLine
\BinaryInfC{}
\end{prooftree}

elimination rules

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : Nat$}
\AxiomC{$\Gamma \vdash M_{0} : A$}
\AxiomC{$\Gamma, x:A \vdash M_1 : A$}
\TrinaryInfC{$\Gamma \vdash rec[A](M,M_0,x.M_1) : A$}
\end{prooftree}

with beta-like rules (inversion principle), which can be
expressed as a commutative diagram

 * $rec[A](0,M_0; x.M_1) \equiv M_0$
 * $rec[A](succ(M);M_0,x.M_1) \equiv [rec[A](M,M_0,x.M_1)/x]M_0 : A$
 
and an eta-like rule (unicity principle), which is the
unicity of the diagram

\begin{prooftree}
\AxiomC{$[0/x]N \equiv M_{0}$}
\AxiomC{$z : Nat \vdash [succ(z)/x]N \equiv [[z/x]N/x]M_{1}:A$}
\BinaryInfC{$\Gamma, x:Nat \vdash N \equiv rec[A](x,M_0,x.M_1)$}
\end{prooftree}
**** Local definition
We could write the introductions as

 * $\vdash 0 : Nat$
 * $x : Nat \vdash succ(x) : Nat$

and the global version works on a suitable theory. We could write
them even as

 * $0 : 1 \to Nat$
 * $succ : Nat \to Nat$

and in a suitable theory, we can derive the rules from the constants.
Note that those two notations are NOT the same thing!

We could write also the induction as an element of a function type

\begin{prooftree}
\AxiomC{$\Gamma \vdash M_{0} : A$}
\AxiomC{$\Gamma, x:A \vdash M_1 : A$}
\BinaryInfC{$\Gamma, z:Nat \vdash rec[A](M_0, x.M_1)(z) : A$}
\end{prooftree}
**** Nat-algebras
We can write this as a single function

\[
z : 1 + Nat \vdash case\{-.0 ; x.succ(x)\}(z) : Nat
\]

we can write this as

\[
z : 1 + Nat \vdash \{0,succ\}(z) : Nat
\]

This notation uses eta/beta properties of coproducts and
products to get its etea/beta properties. Any mapping
$\alpha : 1 + Nat \to Nat$ is called a *Nat-algebra*. More generally,
a Nat-algebra is $\alpha : 1 + A \to A$. 

A *Nat-algebra category* is defined by the idea that if we have
two Nat-algebras, we can define a mapping between them as

\[\begin{tikzcd}
1+A\dar{\alpha}\rar{1+h} & 1+B\dar{\beta} \\
A\rar{h} & B
\end{tikzcd}\]

and we call this a Nat-homomorphism. The previous definition of the
naturals is in fact the initial object in the category on
nat-homomorphisms. This is an initial algebra, there is a unique
morphism from this algebra to all the others; and this morphism is
precisely the recursor. Any other morphism is unique up to higher
homotopy to the other morphism (eta-rule).

There are implicit uses of the Yoneda Lemma here.
**** F-algebra
Given a functor $F$ on some category, we are going to define a
F-algebra. The particular case of Nat is $F(X) = 1 + X$.

\[\begin{tikzcd}
F(A)\dar{\alpha}\rar{F(h)} & F(B)\dar{\beta} \\
A\rar{h} & B
\end{tikzcd}\]

**** F-coalgebra
We can define coalgebras and study the final objects on coalgebra
categories. The unique function to a final coalgebra is a corecursor.

***** Exercise
What is the final coalgebra for Nat? $F(X) = 1+X$.

**** Lambek's lemma
If $i : F(I) \to I$ is an initial F-algebra, then $i$ is an
isomorphism; and then, $F(I) \cong I$.

This is called a *fixed point*.

***** Proof
If we have an algebra, we also have $FI$ as an algebra

\[\begin{tikzcd}
FI  \rar[dashed]{F!}\dar{i} & FFI \dar{Fi} \\
I  \rar[dashed]{!} & FI
\end{tikzcd}\]

we use that the first one is initial. And we also have

\[\begin{tikzcd}
FI \rar{i}\dar[dashed]{F!}\ar[dd,bend right,swap,"Id"] & 
I \dar[dashed]{!}\ar[dd,bend left,"Id"] \\
FFI  \rar{Fi}\dar{Fi} & FI \dar{i} \\
FI  \rar{i} & FI
\end{tikzcd}\]

so we know that $i \circ ! = id$ and $!\circ i = F(i \circ !) = id$.
***** CoLambek
If we have a final coalgebra it is also an isomorphism.
*** Lecture 20: Inductive types II
**** Last week
We reexamined Nat as an inductive type. We claim that $1+Nat \to Nat$
is initial in the category of Nat-algebras. Any other Nat-algebra can
be written as $\alpha = \left\langle \alpha_0,\alpha_{1} \right\rangle$; and the function from the initial algebra
is simply the recursor $rec[A](\alpha_0,x.\alpha_1)$.

**** Nats Inside type theory
A Nat-algebra would be

\[
NatAlg :\equiv
  \sum_{A : {\cal U}} 1+A \to A \simeq
  \sum_{A : {\cal U}} A \times (A \to A)
\]

and a Nat-homomorphism is

\[
NatHom(\alpha,\beta) :\equiv
  \sum_{h : A \to B} \beta \circ (1+h) = h \circ \alpha
\]

then $\nu :\equiv \left\langle Nat, \{0,succ\} \right\rangle$ is a Nat-algebra an we can prove that this is
in fact initial, which is to say that

\[
NatHom(\nu,\alpha) \text{ is contractible}
\]

Two terminologically different traditions collide here, so we are using
them both.
**** Derivation of mathematical induction
The recursor for the naturals is

\begin{prooftree}
\AxiomC{$M_{0}:A$}
\AxiomC{$x.A \vdash M_1:A$}
\BinaryInfC{$x:Nat \vdash rec[A](M_0;x.M_1) : A$}
\end{prooftree}

with its beta and eta rules. In HoTT, we take the eta rules
to be not definitional equalities $\equiv$ but propositional equalities $=$.

**** The principle of induction
The induction principle says that, given,

 * $x : Nat \vdash P(x) : {\cal U}$
 * $M_0 : P(0)$
 * $x:Nat, y:P(x) \vdash M_1 : P(succ(x))$

we have

 * $z:Nat \vdash ind[x.P](M_0,x.y.M_1)(z) : P(z)$

and the beta and eta rules are similar to those of the recursor.
But, with respect to what equality?
**** Idea
Consider $\int P :\equiv \sum_{x:Nat} P(x)$, we define an auxiliary function

 * $i :\equiv \lambda z:Nat.\  rec[\int P](\left\langle 0,M_0 \right\rangle; \left\langle x,y \right\rangle.\left\langle succ(x), M_1 \right\rangle)(z)$
 * $i0 \equiv \left\langle 0,M_0 \right\rangle$
 * $i(succ(M)) \equiv \left\langle succ(fst(M)), [snd(iM)/y]M_1 \right\rangle$

***** Kleene discovered how to define the predecessor

**** Lambek inside type theory
We can define functors up to higher homotopy. When we apply Lambek, we
get a fixed point $FI \cong I$ up to isomorphism.

***** Not functors
There are cases where, if we define things like $F X =X \to X$, we get a 
*non-algebraic* datatype. There is a way of solving this equations using
fixpoint induction.

***** Nat+
We could define a final coalgebra as

\[
Nat^+ \to 1 + Nat^{+}
\]

and we could think of this loosely as $Nat \cup \{\infty\}$.
 
**** Positive and negative types
Positive types correspond to inductive types and negative types
correspond to coinductive types. Negative types are limits, and
positive types are colimits.
**** Brower ordinals (aka W types)
Well-founded trees or preorders. The ordinals codify what transfinite
induction is.

***** Brower ordinals
Nodes labeled as

 - $0$                   z

 - $1 = sup(0)$          s -> z

 - $2 = sup(1)$          s -> s -> z

 - ...

 - $\omega = sup(0,1\dots)$     w -> z
                         \-> s -> z
                          \-> s -> s -> z
                           \-> ...

***** Well-founded
There is no infinite descendent branches, there may be as many width
branches as we want.

The right definition is that "The principle of transfinite induction is
valid". Is something holds for all predecessors.

**** Formation rule for W-types
Given a type of node sorts, $A$, 

\begin{prooftree}
\AxiomC{$A:{\cal U}$}
\AxiomC{$x:A \vdash B:{\cal U}$}
\BinaryInfC{$W_{x:A}B : {\cal U}$}
\end{prooftree}

given $x:A \vdash B(x)$ is the branching factor; the index type for
the predecessors. 

***** Example
As an example, $A :\equiv 1+1 = [Z,S]$ is an enumeration type, and
you define $B$ by case analysis.

 * $B(Z) :\equiv \bot : {\cal U}$
 * $B(S) :\equiv 1 : {\cal U}$

and $Nat$ will be $W_{x:A}B$.

**** Introduction rule for W-types

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$x:B(a) \vdash w(x) : W_{x:A}$}
\BinaryInfC{$sup[a](x.w) : W_{x:A}B$}
\end{prooftree}

***** Example

 * $0 :\equiv sup[z](x.abort(x))$
 * $1 :\equiv sup[s](-.0)$

**** Elimination rule, non-dependent form

\begin{prooftree}
\AxiomC{$\Gamma,\ a:A,\ p:B(a) \to W_{x:A}B,\ r:B(a) \to C \vdash M:C$}
\UnaryInfC{$z: W_{x:A}B \vdash  wrec[c](  a,p,r.M     )(z)      :C$}
\end{prooftree}

and we are going to have a beta rule

 * $wrec[c]( a,p,r.M )(sup[a](w)) \equiv [a,w,\lambda z. wrec[c](a,p,r.M) /a,p,r] M$

and the eta rule says that it is the only such thing.

***** Polynomial functors
The W types determine polynomial functors over certain classes.

\[
F(x) :\equiv \sum_{a:A}B(a) \to X
\]

in the case of naturals, it is $(1\to X)\times (X\to X)$.

**** Transfinite induction - dependent elimination rule

\begin{prooftree}
\AxiomC{$\Gamma,z: W_{x:A} B \vdash P:{\cal U}$}
\noLine\UnaryInfC{$\Gamma,a:A, p:B(a) \to W_{x:A}B, h:\prod_{b:B(a)}P(p(b)) \vdash M : P(sup[a](p))$}
\UnaryInfC{$\Gamma,z:W_{x:A}B \vdash wind[x.P](  ): P(z)$}
\end{prooftree}

**** Exercise: Invent the M type, dual to the W type
*** Lecture 21: Higher inductive types I
**** Last week: lower inductive types
Well-founded trees $W_{x:A} B$ with an elimination rule based on
transfinite induction. It can be characterized as the homotopy
initial algebras for polynomial functors.

The universal property is here propositional.

**** Higher inductive types
The idea is to take some type of free structure using inductive
definitions with equational laws. It is a similar idea to the
presentation of algebraic structures using generatos and relations.
This will be a 0-type concept; but higher inductive types must be
more general than that.

They are relevant because of

 1. full higher-dimensional structure or path structure.
 2. proof-relevance means generators and relations are the same thing.

Informally, we are building the free infinity groupoid on the structure
we are building.

**** Current status of HoTT
HoTT is ITT + UA + HIT. The Univalence Axiom is a matter of mathematical
efficiency; and the HIT is a matter of expressiveness on higher types.

HITs are not yet fully worked out.
**** Example: interval
We can write the interval using inductive definitions

 * $0 : I$, a 0-cell.
 * $1 : I$, a 0 cell.
 * $seg : Id_I(0,1)$, a 1-cell.

This definition implies the existence of other paths. For example,
$seg^{-1} : Id(1,0)$ or $refl(0) : Id(0,0)$. Moreover, they are significant
and they induce even higher paths.

It is an open problem what is implied for a given inductive
definition.

**** Recursor
An inductive definition induces a recursor; a function from an
initial object on a given category.

In the example, given any "interval algebra", we have a function
from the interval to it

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$b:B$}
\AxiomC{$\beta : a=_Ab$}
\TrinaryInfC{$z:I \vdash rec[A](a,b,\beta)(z):A$}
\end{prooftree}

the Gentzen's inversion principle holds as

 * $rec[A](a,b,\beta)(0) \equiv a : A$
 * $rec[A](a,b,\beta)(1) \equiv b : A$
 * $ap_{rec[A](a,b,\beta)}(seg) = \beta : a =_{A} b$

we could think of the first two cases as an $ap$ on 0-types. Note that
the third case uses a propositional equality; $ap$ is a defined
function! we cannot define what its behaviour should be.
**** Induction
The induction can be written as

\begin{prooftree}
\AxiomC{$z: I \vdash A(z) : {\cal U}$}
\AxiomC{$a_0 : A(0)$}
\noLine\UnaryInfC{$a_1 : A(1)$}
\noLine\UnaryInfC{$p : a_0 =_{seg}^{z.A} a_1$}
\BinaryInfC{$z:I \vdash ind[z.A](a_0,a_1,p) : A(z)$}
\end{prooftree}

where we are using a transportation to have that

\[
trans[z.A](seg)(a_0) =_{A(1)} a_1
\]

And now we expect the following equations to hold

 * $ind[z.A](a_0,a_1,p)(0) \equiv a_0 : A(0)$
 * $ind[z.A](a_0,a_1,p)(1) \equiv a_1 : A(1)$
 * $ap_{ind[z.A](a_0,a_1,p)}(seg) = p$ true.

and there is also a unicity condition
**** Example: circle
The circle $\mathbb{S}^1$ is a type given by the higher inductive definition

 * $base : \mathbb{S}^{1}$, a 0-cell
 * $loop : Id(base,base)$, a 1-cell

This definition induces loops such as $loop \cdot loop : Id(base,base)$ or
$loop^{-1} : Id(base,base)$. Those will form the integers; a set-level
group.

***** Recursor
It is defined as

\begin{prooftree}
\AxiomC{$a_0 : A$}
\AxiomC{$l : a_0 =_A a_0$}
\BinaryInfC{$z : \mathbb{S}^1 \vdash rec[A](a_0,l)(z) : A$}
\end{prooftree}

where

 * $rec[A](a_0,l)(base) \equiv a_0 : A$
 * $ap_{rec[A](a_0,l)}(loop) = l$ true

and we can have the unicity

 * $z : \mathbb{S}^1\vdash P : {\cal U}$
 * $b : P(base)$
 * $l : b =^{z.P}_{loop} b$, so this is preserved going around the loop
**** Recall: the interval
The interval characterizes the total path space of $A$

\[
I \to A \simeq
\int Id_A :\equiv \sum_{x,y:A} Id(x,y)
\]

the identifications are paths. The usual way to do this in Topology is
similar. Here,

\[ \mathbb{S}^{1} \to A \simeq
\int \Omega_A := \sum_{x:A}Id(x,x)
\]

is the loop space.

 1) define $f : (\mathbb{S}^1 \to A) \to \int \Omega_A$ by $\lambda g. \left\langle g(base), ap_g(loop) \right\rangle$.
 2) we show that $\prod_{l : \int \Omega_A} fib(l)$ is contractible

**** Suspension: circle
Another picture of $\mathbb{S}^1$ could use two poles and two
meridians. This is called $Susp(2)$.

 * $N : \mathbb{S}^1$
 * $S :\ \mathbb{S}^1$
 * $mer : 2 \to (N = S)$

and we can check that this is equivalent to the previous
definition.

**** Suspensions
We define $Susp(A)$ as two zero cells

 * $N : Susp(A)$
 * $S : Susp(A)$

and the meridians

 * $mer : A \to (N = S)$

***** Example: susp^2 is the sphere
$Susp^2(2)$ has two meridians associated with N and S and also two
higher-order paths W E associated with the two meridians on
$Susp(2)$.

We will prove that this is the sphere.

**** Suspensions in type theory
We can define the introduction

\begin{prooftree}
\AxiomC{$x:A\vdash m(x) : n =_{B} s$}
\AxiomC{$n:B$}
\noLine\UnaryInfC{$s:B$}
\BinaryInfC{$z:Susp(A) \vdash rec[B](n,s,x.m):B$}
\end{prooftree}

with the beta and eta usual rules.
*** Lecture 22: Higher inductive types II
**** Last week
We defined suspensions

 * $N : Susp(A)$
 * $S : Susp(A)$
 * $merid : \prod_{x:A} N =_{Susp(A)} S$

We defined functorial mappings from the suspension of a type
to another type.

**** Iterated suspension
It can be showed that

$\mathbb{S}^1 \simeq Susp(2)$

by defining an invertible function between them.

**** Pointed types
A point is preserved up to homotopy by mappings

\[
X \multimap Y := \sum_{f:X\to Y} f(x_0) = y_0
\]

**** Characterization of suspensions
Suspensions follow a kind of adjunction with the loop space

\[
(Susp(A) \multimap B) \simeq (A \to \Omega(B))
\]

**** Pushouts
Generally used for amalgamation properties and quotients. In classical
set theory. They are the dual of pullbacks, the constrained subset of
a product.

We glue two sets in a way that a deisgnated subset of the two sets is
regarded as the same; as $A \sqcup^{C} B$, where $C$ is the diagram for the 
considered subset. The coproduct is the special case where $C = \varnothing$.

***** Denotational semantics
In denotational semantics, we want to form the disjoint union of two
types with common elements.

***** In sets
In sets, pushouts do always exist.

**** Pushouts as HIT
We define the inclusions

 * $inl : A \to A \sqcup^C B$
 * $inr : B \to A \sqcup^C B$

and a glue term

 * $glue : \prod_{c:C} inl(f(c)) = inr(g(c))$

***** Universal constructions

\begin{prooftree}
\AxiomC{$x:A \vdash l:D$}
\noLine\UnaryInfC{$y:B \vdash r:D$}
\AxiomC{$u:C \vdash q: [f(u)/x]l = [g(u)/x]r$}
\BinaryInfC{$z: A \sqcup^C B \vdash rec[D](x.l,y.r;u.q) : D$}
\end{prooftree}

with the usual beta/eta rules.

***** Suspension
In particular,

$Susp(A) := 1 \sqcup^{A} 1$
*** Lecture 23: Pushouts
**** Last week
Pushouts as HITs.

**** Quotients as HITs
We can define the expected quotients

 * $a:A \vdash q(a) : A/R$
 * $a,b:A, r:R(a,b) \vdash wd(a,b,r) : q(a) = q(b)$

and a truncation rule

 * $x,y:A/R, p,q:x=y \vdash tr(x,y,p,q):p=q$

so that $A/R$ is a set.

***** Example: Integers as formal differences of naturals

**** Truncations as HITs
The propositional truncation $\|A\|_{-1}$ can be defined as a type
with an induction principle.

***** Induction on integers

**** Fundamental group of S1

\[
\pi_1(\mathbb{S}^1) \simeq \mathbb{Z}
\]

we can show that $\Omega(\mathbb{S}^1,base) \simeq \mathbb{Z}$.

***** Proof
In the proof, we define the winding function from the loop
space to the integers. We then use induction on $\mathbb{Z}$.
*** Exercises
**** Homework 1: Heyting algebra and IPL [5/6]
***** DONE Task 1
#+begin_statement
Show that $A \wedge (B \vee C) \leq (A \wedge B) \vee (A \wedge C)$ in any Heyting algebra.
Hint: use the Yoneda Lemma.
#+end_statement

The Yoneda Lemma in this setting says that the statement is equivalent
to say that, for all $D$, if $(A \wedge B) \vee (A \wedge C) \leq D$, then $A \wedge (B \vee C) \leq D$.
In this case we have

 * $A \wedge B \leq D$
 * $A \wedge C \leq D$

and crucially using the definition of exponential

 * $B \wedge C \leq B,C \leq A \supset D$.

***** DONE Task 2
#+begin_statement
Show that in any Heyting algebra, $A \supset \bot$ is one of the largest elements
inconsistent with $A$, and is equivalent to any largest inconsistent one.
#+end_statement

By definition, $A \wedge (A \supset \bot) \leq \bot$, and for any other element $C$ such that
$A \wedge C \leq \bot$, $C \leq (A \supset \bot)$. Any other largest inconsistent element should
satisfy $(A \supset \bot) \leq C$.

***** DONE Task 3
#+begin_statement
Show that, in any Boolean algebra (complemented distributive lattice),
$\overline{A} \vee B$ is a valid implementation of $A \supset B$. That is, it satisfies all
properties of $A \supset B$.
#+end_statement

We know that

\[
A \wedge (\overline{A}\vee B) \leq 
(A \wedge \overline{A}) \vee (A \wedge B) \leq
(A \wedge B) \leq B
\]

and if $A \wedge C \leq B$, then

\[
C \leq
C \wedge (A \vee \overline{A}) \leq
B \vee (C \wedge \overline{A}) \leq \overline{A} \vee B.
\]
***** TODO Task 4
#+begin_statement
Show that IPL is transitive, which is to say ...
#+end_statement

***** DONE Task 5
#+begin_statement
Show that for any Heyting algebra and any evaluation function on
atoms, if $\Gamma \vdash P$ true then $\Gamma^+\leq P^{\ast}$. You only have to consider the
cases in which the last rule applied is $(\supset I)$ or $(\supset E)$.
#+end_statement

  * In the first case, $(\supset I)$, we know that $\Gamma, A \vdash B$. By induction,
    we know that $\Gamma^{+} \wedge A^{\ast} \leq B^{\ast}$, and then $\Gamma^{ +} \leq (A^{\ast} \supset B^{\ast})$.
  * In the second case, we know by induction that $\Gamma^{ +} \leq A^{\ast} \supset B^{\ast}$ and
    $\Gamma^{+} \leq A^{\ast}$, so $\Gamma^{ +} \leq A^{\ast} \wedge (A^{\ast} \supset B^{\ast}) \leq B^{\ast}$.

***** DONE Task 6
#+begin_statement
Consider the Lindembaum algebra of IPL where the elements are all
propositions in IPL (with the translation $(-)^{\ast}$ being the identity function) 
and the relationship $\leq$ is defined by provability in IPL. That is, $A\leq B$ 
iff $A \text{ true} \vdash B\text{ true}$. Show that this is a Heyting algebra. You only have to
prove the transitivity. You may assume weakening and exchange of IPL,
or cite previous tasks as lemmas.
#+end_statement

If $A \leq B$ and $B \leq C$, we know that, by weakening, $A \text{ true},B \text{ true} \vdash C \text{ true}$.
We now can apply transitivity to $A \text{ true} \vdash B \text{ true}$ and the previous formula
to obtain $A \text{ true} \vdash C \text{ true}$.
**** Homework 2: Kindom of Kittens [0/7]
***** TODO Task 1
#+begin_statement
Weite down a suitable morphism in terms of the primitive constructs and
the morphisms immediately available in each subtask. The primitive
constructs include $\mathrm{id}$, $f \circ g$, $\left\langle f,g \right\rangle$, $\mathtt{fst}$, $\mathtt{snd}$, $\mathtt{inl}$, $\mathtt{inr}$, $\left\{ f,g \right\}$, $\lambda(f)$ and $\mathtt{map}$.

 * *Reflexivity*, write down a morphism from $\Gamma^+ \times P^{\ast}$ to $P^{\ast}$.
 * *Contraction*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of
   a morphism $f \colon (\Gamma^{ +}\times P^{\ast})\times P^{\ast} \to Q^{\ast}$.
 * *Weakening*, write down a morphism from $\Gamma^{ +} \times P^{\ast}$ to $Q^{\ast}$ in terms of a
   morphism $f \colon \Gamma^{ +} \to Q^{\ast}$.
 * *Exchange*, write down a morphism from $(\Gamma^{ +}\times Q^{\ast}) \times P^{\ast}$ to $R^{\ast}$ in terms
   of a morphism $f \colon (\Gamma^{ +}\times P^{\ast}) \times Q^{\ast} \to R^{\ast}$.
 * *Substitution*, write down a morphism from $\Gamma^{ +}$ to $Q^{\ast}$ in terms of two 
   morphisms $f \colon \Gamma^{ +}\to P^{\ast}$ and $g\colon \Gamma^{ +}\times P^{\ast} \to Q^{\ast}$.
#+end_statement

***** TODO Task 2
***** TODO Task 3
***** TODO Bonus Task 1
***** TODO Task 4
***** TODO Task 5
***** TODO Task 
*** Bibliography
 * Awodey, Category theory.
 * Programming in Martin-Lf Type theory.
 * Homotopy Type Theory book.
** Category theory foundations - Steve Awodey
Following this [[https://www.youtube.com/playlist?list=PLGCr8P_YncjVjwAxrifKgcQYtbZ3zuPlb][video series]].

*** Category theory foundations 1.0
Category theory is the abstract algebra of abstract functions.

**** Functions on sets
In set theory, a function $f \colon A \to B$ is a subset of the cartesian
product $f \subset A \times B$, such that for all $a \in A$, there exists a unique
$b \in B$ such that $f(a) = b$.

Composition of functions is distributive and it has an identity.
Categories arise as an abstraction of this setting.

**** Definition of category
A category is defined by a class of objects and a class of arrows.
A distributive composition with identity. The axioms of a category
are the distributivity and the identity as a neutral element.
**** Isomorphisms
**** Examples
***** Finite categories
***** Posets
***** Monoids
***** Category of all posets
***** Relations on sets
***** Category of proofs
The objects are logic formulas and arrows are deductions on the formal
system, from the assumptions to the conclusions, that can be composed.
*** Category theory foundations 1.1
**** Constructions on categories
***** Product category
***** Arrow category
${\cal C}^{\to}$, where objects are arrows on ${\cal C}$ and arrows
are commutative squares.
***** Slice category
****** Cat, the category of categories
**** Functors
Preserve all the structure of a category.

***** Exponential functor on sets
Fix an object $A$, then $B \mapsto B^{A}$ is a functor on sets.

**** Duality
***** Contravariant functors
****** Example: Hom-Functors
**** Hom-sets
Assuming ${\cal C}$ small, $\mathrm{hom}(A,B)$ is the set of arrows from $A$ to $B$. If we fix $A$,
we get a functor $\mathrm{hom}(A,-)$; if we fix $B$, we get a contravariant functor $\mathrm{hom}(-,B)$.

*** Category theory foundations 1.2
**** Representable functors
A functor is representable if it can be written as an hom-set.

The currying of the $Hom$ functor is the Yoneda embedding. (!)

*** Category theory foundations 2.0
**** Universal mappings
***** Products (MacLane, 1949)
Products on categories, on posets...
***** Coproducts and duality
***** Exponentials
Suppose we have all products. An exponential for $A,B$ is
an object $B^{A}$ such that

\[\begin{tikzcd}
B^{A} & B^{A} \rar{e} \times A & B \\
X \uar[dashed]{\exists! f} & X \times A \uar{f \times 1} \urar[swap]{g} &
\end{tikzcd}\]

*** Category theory foundations 2.1
In groups, the homomorphisms are not an exponential. Groupoids are!
They form a cartesian closed category.

**** Cartesian closed category
A category is *cartesian closed* if it has

  * all products.
  * all exponentials.
  * the terminal object.
 
**** Adjunction Product-Exponential
Observe that the universal mapping property of the exponent
implies that every time we have a map like $X \times A \to B$,
we can define $X \to B^{A}$. It exactly says that the two functors
are adjoints.

**** Universal properties as rules of inference
Universal properties are like rules of inference

  * Product

    \begin{prooftree}
    \AxiomC{$X \to A$}
    \AxiomC{$X \to B$}
    \BinaryInfC{$X \to A \times  B$}
    \end{prooftree}

  * Coproduct

    \begin{prooftree}
    \AxiomC{$A \to X$}
    \AxiomC{$B \to X$}
    \BinaryInfC{$A + B \to X$}
    \end{prooftree}

  * Exponential

    \begin{prooftree}
    \AxiomC{$X \times A \to B$}
    \UnaryInfC{$X \to B^A$}
    \end{prooftree}

In the case where $X=1$, we get a particular case of the inference rules.

**** Exponentials in a poset
Exponentials in a poset are implications on intuitionistic
propositional calculus. Rules of logic can be written as universal
properties.

***** Proof relation
A natural deduction logic is a category where deductions are morphisms
and propositions are objects. We can prove the adjunction on the rules.

***** Category of proofs
If we take the category of proofs, we get the lambda calculus.
This is a richer structure.

This is called *category of types* or *category of proofs*.

*** Category theory foundations 2.2
**** Category of types on \lambda-calculus is CCC
To make this a CCC, we need to identify certain proofs. We have to identify
some proofs to make this a CCC

  * $\mathrm{fst}(a,b) = a$
  * $\mathrm{snd}(a,b) = b$
  * $(\lambda x.b)a = b[a/x]$

This is simplification of proofs. 

**** Theory in the \lambda-calculus
We have some basic types $A,B,\dots$, basic terms $a:X,b:Y,\dots$ and equations
between terms of the same type. That defines a theory.

You could formulate the theory of groups or any algebraic theory in
this way as a lambda theory. The theory of the reflexive domain is an
example of higher order theory that can be formulated as a lambda theory.

We can then define a model of such a theory in a CCC as an assignment of
objects to basic types and morphisms as functions.

  * $\llbracket A \rrbracket \in {\cal C}$, for any basic type
  * $\bbk{a} \colon 1 \to \bbk{X}$, for any basic term

and it can be extended to all terms as

  * $\bbk{t} \colon 1 \to A$, for any term $t \colon A$,
  * in particular, $f \colon A \to B$, $\bbk{f} \colon \bbk{A} \to \bbk{B}$.

That is, you can interpret this on any algebraic theory and a model of that
theory will arise.

**** Completeness theorem of CCC for \lambda-calculus
For any theory $\mathbb{T}$ in \lambda-calculus

  1) for any closed terms $a,b\colon X$, $\mathbb{T} \vdash a = b$ if and only if $\bbk{a} = \bbk{b}$ in
     any CCC.
  2) there exists a closed term $t : X$ if and only if in every $\mathbb{T}$ model of in 
     a CCC, $1 \to \bbk{X}$.


This says that lambda calculus is really equivalent to the notion of a CCC.
\[
\lambda^{x,\to} \simeq CCC
\]

Propositional logic itself is exactly equivalent to the notion of a CCC Poset.
If we add the disjunction, we get a Heyting algebra.

Kripke models are a specialization to some special cartesian closed categories.

*** Category theory foundations 3.0
**** Arithmetic on a Cartesian Closed Category
All the usual arithmetic can be expressed on cartesian closed categories.
**** Lambda calculus with sums on a CCC
Lambda calculus with sums can be expressed on a CCC with coproducts and
you can use it to prove equations on a CCC because of its soundness.
**** Natural transformation
Represents the concept of a morphism independent of the choice
of objects. This is the notion of parametricity or uniformity.
***** Definition of natural transformation
***** Example of naturality: sets through time
Discrete time parametrized on the natural numbers. A function
between two sets through time should be a natural transformation
between the indexed family of sets.

If we see $\omega$ as the natural preorder, the category of sets through
time is $\mathtt{Set}^{\omega}$, the category of functors from $\omega$ to $\mathtt{Set}$.

**** Definition of functor categories
***** Functor categories make Cat a CCC
***** Example: the arrow category
Can be seen as a functor category from a category with only
one morphism to the base category.
***** Example: product category
$\mathbb{C}^2 \cong \mathbb{C} \times \mathbb{C}$ where $2$ is a discrete category of two objects.
***** Example: graph category
***** Example: simplicial sets
*** Category theory foundations 3.1
**** The Yoneda embedding
Presheaves of the form $\mathtt{Sets}^{{\cal C}^{op}}$. If we assume ${\cal C}$ locally small, the functor
hom can be defined. The functor $\mathrm{Hom}$ can be curried to get a functor
$y \colon {\cal C} \to \mathtt{Sets}^{{\cal C}^{op}}$.

This functor takes a morphism to a natural transformation between two functors.
**** Yoneda Lemma
Given any $c \in {\cal C}$ and $F \colon {\cal C}^{op}\to \mathtt{Sets}$, there is an isomorphism
\[
\mathrm{Hom}(yC,F) \cong FC.
\]

***** Proof of the Yoneda Lemma

***** Corollary
The isomorphism is natural on both arguments.

***** Utility of Yoneda
The category $\mathtt{Sets}^{{\cal C}^{op}}$ is a topos, has a nice logical structure; while the
category was ${\cal C}$ any category. If the Yoneda embedding preserves the structure,
that gives us a nice structure on ${\cal C}$.

**** Examples of usage of the Yoneda Lemma
***** Product
Propositionally, the universal mapping property of the product
can be written as

\begin{prooftree}
\AxiomC{$X \to A$}
\AxiomC{$X \to B$}
\doubleLine
\BinaryInfC{$X \to A \times  B$}
\end{prooftree}

but this rule of inference goes both ways. And this is also a
bijection between the two sides;

\[
\mathrm{hom}(X,A) \times \mathrm{hom}(X,B) \cong \mathrm{hom}(X, A \times B).
\]

***** Example
Consider $\mathrm{hom}(X,-)$ and apply it to the product diagram.
We get

\[\begin{tikzcd}
& \mathrm{hom}(X,A \times B) \drar\dlar\dar[dashed]{\cong} & \\
\mathrm{hom}(X,A) & \mathrm{hom}(X,A) \times \mathrm{hom}(X,B) \lar{\pi}\rar{\pi} & \mathrm{hom}(X,B)
\end{tikzcd}\]

The universal properties can be expressed using hom-sets.

***** Claim
$yC \cong yD \implies C \cong D$

We can prove some equations using this technique.

\[
y({\cal C}^{A+B}) \cong y({\cal C}^A \times {\cal C}^B)
\]

****** Proof
$\mathrm{hom}(X\times (A+B), C) \cong \mathrm{hom}(X \times A,C) \times \mathrm{hom}(X \times B,C)$

This reduces the proof of ${\cal C}^{A+B} \cong {\cal C}^A \times {\cal C}^B$ to a much simpler algebraic
manipulation.

*** Category theory foundations 3.2
**** Laws in any CCC
Products distribute over coproducts. Exponentials make products distribute
over coproducts.

***** Proof
Using Yoneda.

***** Yoneda embedding preserves all the cartesian closed structure

*** Category theory foundations 4.0
**** Sets^C^op is a cartesian closed category
They are some kind of "variable sets"; sets that vary on a parameter
coming from the index category. These things have products and coproducts
defined pointwise. Exponentials could be also defined pointwise, but it has
a covariant and a contravariant component, so it is not useful to get a
definition of exponentials on morphisms. This does not work for exponentials.

**** Yoneda to the rescue
We are trying to define a functor $B^A(X)$. If it exists, it has to be like
\[
B^A(X) \cong \mathrm{hom}(yX,B^{A}) \cong \mathrm{hom}(yX \times A, B).
\]

If we take this as the definition, $\mathrm{hom}(y- \times A,B)$ is a contravariant
function.

***** Corollary
As a corollary, $y \colon {\cal C} \to \mathtt{Set}^{{\cal C}^{op}}$ preserves CC structure.

****** Proof
We can prove using Yoneda lemma that $y(B^A) = y(B)^{y(A)}$.

**** Completeness of \lambda-calculus
Every cartesian closed category can be embedded into a $\mathtt{Sets}^{{\cal C}^{op}}$.

#+begin_theorem
Completeness of \lambda-calculus with respect to variable sets.
Given any \lambda theory $\mathbb{T}$, and $s,t {:} X$
\[
\mathbb{T} \vdash s=t \iff \text{ for any interpretation}, \bbk{s} = \bbk{t}
\]

There is a $t \colon X$ iff in every model $\bbk{t} \colon 1 \to \bbk{X}$.
#+end_theorem

**** Awodey's Theorem
Kripke completeness.

#+begin_theorem
The same thing happens to respect to $\mathtt{Sets}^{P}$, where $P$ is a poset.
#+end_theorem

**** Adjointness
The following are examples of adjoints

  1. Products
  2. Exponentials
  3. Coproduct
  4. Induction
  5. Recursion
  6. Natural numbers
  7. Inductively defined types
  8. Logical connectives
  9. Quantifiers
  10. Sigma and Pi types

***** Product-exponential
The functors $F(X) = X \times A$ and $G(X) = Y^{A}$ are adjoints. There is a natural
isomorphism between $\mathrm{hom}(X \times A,Y) \cong \mathrm{hom}(X,Y^{A})$.

***** Product-diagonal
\[
\mathtt{hom}((X,X), (A,B)) \cong \mathtt{hom}(X,A \times B)
\]

***** Chain of adjoints

\[ + \dashv \Delta \dashv \times \dashv \mathrm{exp}
\]

*** Category theory foundations 4.1
**** Uniqueness of adjoints
Every universal property and every adjoint determine an object up
to isomorphism. Adjoints are unique up to isomorphism.

***** Proof of the uniqueness of adjoints
Using the Yoneda Lemma

**** Unit and counit of and adjunction
***** Example: product-exponent
Evaluation is the counit.
***** Example: diagonal-product
The diagonal map is the unit.
**** Example: adjoints in logic
In Propositional calculus, conjunction is an adjoint.
Entailment is reflexive and transitive, so proofs form a category.

\begin{prooftree}
\AxiomC{$\theta \vdash \varphi$}
\AxiomC{$\theta \vdash \rho$}
\doubleLine
\BinaryInfC{$\theta \vdash \varphi \times \rho$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\varphi \vdash \theta$}
\AxiomC{$\rho \vdash \theta$}
\doubleLine
\BinaryInfC{$\rho + \varphi \vdash \theta$}
\end{prooftree}

Terminal and initial objects can be written as adjoints. Implications
can be written as adjoints. This work is due to Lawvere. 

/Adjointness in Foundations/, W. Lawvere.

**** Example: quantifiers
We will write formulas with individual variables; and we build up formulas
involving some variables in the usual way. We have a deduction system with
entailment and rules of inference.

There is an operation of adding a new variable to a context. If I have,
\[
x_1,\dots,x_n \vdash \varphi(x_1,\dots,x_n),
\]

I can get
\[
x_1,\dots,x_n,y \vdash \varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y).
\]


This operation has adjoints. Its right adjoint is $\ast \vdash \forall$

\begin{prooftree}
\AxiomC{$^{y\text{ in context}}\varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y)$}
\doubleLine
\UnaryInfC{$\varphi(x_1,\dots,x_n) \vdash \forall_y \psi(x_1,\dots,x_n,y)$} 
\end{prooftree}

and its left adjoint is $\exists \vdash \ast$

\begin{prooftree}
\AxiomC{$\varphi(x_1,\dots,x_n,y) \vdash ^{y\text{ in context}}\psi(x_1,\dots,x_n)$}
\doubleLine
\UnaryInfC{$\exists_y\varphi(x_1,\dots,x_n) \vdash \psi(x_1,\dots,x_n,y)$} 
\end{prooftree}

Unit and counit look like provable formulas.

**** Proof theory of first order logic
The proof theory of propositional logic was the lambda calculus. The proof
theory of first order logic is dependent type theory (??).

***** Propositional logic

\begin{tabular}{c|c|c}
Propositional logic & Provability & Proof/type theory \\
\hline
Logical Point of view & Intuitionistic PL $\wedge,\vee$ & STLC with simple types $\times,+$ \\
CT & Poset CCC / Heyting algebra & CCC with sums \\
\hline
& Poset & Category
\end{tabular}

***** First order logic

\begin{tabular}{c|cc}
FOL & Provability & Proof/type theory \\
\hline
Logic & Intuitionistic FOL $\forall,\exists$ & Dependent Type theory $\Pi,\Sigma$ \\
CT & Heyting category & Locally cartesian closed category \\
\hline
& Poset & Category
\end{tabular}

A locally cartesian closed category is a category such that any slice is CCC.

***** Yoneda and CCC
If ${\cal C}$ is a CCC, the Yoneda embedding is also cartesian closed. It preserves the
interpretation of dependent type structure of a category.

We have the same Kripke completeness theorem for the full system of Martin-Lof
type theory.

** The formation of swarms as a consesus problem - Ulrich Krause
Estructuras complejas globales emergiendo de interacciones locales.
We will use topology instead of differential equations.

*** Model
Ensemble of birds in $\mathbb{R}^{d}$. Others $d$ different than 3 are allowed.
Position $x_i$ and velocity $v_i$ of each bird. The align by averaging.

\[
v_i = \sum_{j \in N} a_{ij}(t) v_i(t)
\]

The coefficients $a_{ij}$ model intensity of interactions; they depend
on the time. The set of seen birds is

S\[
S(i,t) = \left\{ j \in N \mid a_{ij}(t) > 0 \right\}
\]

**** Swarm formation
A swarm can be formed if

\[
\lim_t v_{i}(t) = v
\]

*** Swarm formation - theorem 1
**** Two assumptions
 * Structure not too loose.
 * Interaction does not decay too fast.
*** Swarm formation 2
Interaction only at certain points of time.

**** Core of a stochastic matrix
If $A$ has positive diagonal, $\mathrm{cor}(A) \neq \varnothing \iff A^k$ is scrambling;
we call these matrices *coherent*.

New conditions

 * structure of matrix not too loose;
 * intensity of interaction decays not too fast;
 * intensity of interaction decays slowly.

That can be interpreted as

 * every bird sees itself,
 * there is a sight chain to a leader.

*** Flight formations
**** V-formation and echelon
A leader is the only one in the core
**** Other possible cores: sterling clouds
Loops in the sight chain; connected loops.

***** Systematic account of flight formations?
Graphs changing in time.

***** Computer simulations?

*** Sight cones / cones of vision
Given by direction of flight. Non-convex cones would be also an
option.

**** Farkas lemma
**** Helly's theorem
*** Models of intensity of interaction
Cucker-Smale model of bird flocking.
** Profunctor Optics - Bartosz Milewski
#+BEGIN_SRC haskell
type Lens s t a b  = forall p. Strong p => p a b -> p s t
type Prism s t a b = forall p. Choice p => p a b -> p s t

class Profunctor p => Strong p where
  first' :: p a b -> p (a,c) (b,c)

class Profunctor p => Choice p where
  left' :: p a b -> p (Either a c) (Either b c)

class Profunctor p where
  dimap :: (a -> b) -> (c -> d) -> (p b c -> p a d)
#+END_SRC

A profunctor is a bifunctor of the form ${\cal C}^{op} \times {\cal C} \to \mathsf{Set}$.
In principle, we are not constrained to a single category,
the important notion is that the functor must be contravariant
on the first argument and covariant on the second.

#+BEGIN_SRC haskell
type f ~> g = forall x. f x -> g x
#+END_SRC

Parametricity implies naturality (?).

We have defined natural transformations as polymorphic functions.
Is this equivalent to the usual definition of natural transformation using naturality squares?

But the usual definition of natural transformations talks about naturality squares
and naturlity conditions. Are these two definitions equivalent?

Is this equivalent to the usual definition of natural transformation?
That is, does every polymorphic function satisfy the naturality condition?


*** Yoneda Lemma
#+BEGIN_SRC haskell
type Reader a x = a -> x
type Yo f a = Functor f => Reader a ~> f
-- Yo f a ~ f a
-- forall x. (a -> x) -> f x -> f a

toYo :: Functor f => f a -> Yo f a
toYo fa = \atox -> fmap atox fa

fromYo :: Functor f => Yo f a -> f a
fromYo alpha = alpha id
#+END_SRC

The Yoneda embedding

#+BEGIN_SRC haskell
forall x. (a -> x) -> (b -> x) ~ (b -> a)
#+END_SRC
** Monad transformers - Snoyman
Concurrency with IO a and IO b.

** Mikrokosmos - Mario Romn
*** Clculo lambda sin tipos
Una expresin lambda es

 * una variable,
 * una aplicacin de dos expresiones $M\ N$,
 * una abstraccin $(\lambda x.M)$, donde $M$ es un trmino que depende de $x$.

Una abstraccin aplicada a otro trmino se puede reducir como

\[
(\lambda x.M)\ N \longrightarrow_{\beta} M[N/x]
\]

y las aplicaciones asocian a izquierda: $M\ N\ P$ se lee como $(M\ N)\ P$
en vez de $M\ (N\ P)$.

\[

\]

*** El intrprete
Podis instalarlo desde github si tenis Haskell y si no, podis usarlo
directamente desde la pgina web

 * https://github.com/m42/mikrokosmos
 * https://m42.github.io/mikrokosmos/tutorial.html

En Mikrokosmos, las lambdas se escriben como una *barra invertida*, y
el programa responde con la expresin lambda y una lista de posibles
nombres que tiene esa expresin.

#+BEGIN_SRC haskell
mikro> (\x.x)
a.a  I, ifelse, id
#+END_SRC

Para ver cmo funciona, se pueden probar algunas expresiones aritmticas
simples

#+BEGIN_SRC haskell
mult 2 3
plus 3 4
and true false
sum (take 5 naturals)
#+END_SRC

Caractersticas:
 
 * los argumentos van separados por espacios,
 * se entiende asociatividad a izquierda, y
 * se permite aplicacin parcial.

Es un pequeo lenguaje de programacin y est completamente basado en el 
clculo lambda. Quiero explicaros cmo se puede obtener un lenguaje de
programacin desde el clculo lambda.

*** Primeras definiciones
Vamos a usar clculo lambda. Las expresiones lambdas se leen
como 

#+BEGIN_SRC haskell
(\x.\y.plus x y)
plus 3 4
(\e.plus e e) 3
#+END_SRC

Diciendo: esta es una funcin que toma =x= e =y= y devuelve =x+y=.
Lo que vamos a aprender es cmo funcionan por dentro los nmeros
o la funcin =plus=.

La funcin *identidad* y la funcin *constantemente*.

#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x

id id
id const
id 3
id 5
const 4 2
const 4 3
const 4 (id (const id id))

devuelvecuatro = const 4
devuelvecuatro 5
#+END_SRC

*** Tcnica de Church
Queremos usar estructuras de datos. Tenemos primero que escribir
la estructura de datos como constructores y hacer depender de ellos
a los trminos.

#+BEGIN_SRC haskell
true = \t.\f.t
false = \t.\f.f

0 = \s.\z.z
1 = \s.\z.s z

cons = \h.\t.\c.\n.c h (t c n)
nil = \c.\n.n
#+END_SRC

*** Librera
**** Bsica
#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x
compose = \g.\f.\x.g (f x)
#+END_SRC

**** Booleanos
#+BEGIN_SRC haskell
true = \x.\y.x
false = \x.\y.y

not = \p.p false true

and = \p.\q.p q false
and = \p.\q.p q p

or = \p.\q.p true q
or = \p.\q.p p q
#+END_SRC

**** Aritmtica bsica
#+BEGIN_SRC haskell
0 = \f.\x.x
succ = \n.\f.\x.f (n f x)

plus = \m.\n.n succ m
plus = \m.\n.(\f.\x.n f (m f x))

mult = \m.\n.compose m n
mult = \m.\n.\f.\x.m (n f) x

iseven = \n.n not true
iszero = \n.n (const false) true
#+END_SRC

**** Tuplas
#+BEGIN_SRC haskell
tuple = \x.\y.\z.z x y

first = \p.p true
second = \p.p false

pred = \n.first (n (\t.tuple (first t) (succ (first t))) (tuple 0 0))
minus = \m.\n.n pred m
leq = \m.\n.iszero (minus m n)
geq = \m.\n.iszero (minus n m)
#+END_SRC

**** Listas
#+BEGIN_SRC haskell
nil = \c.\n.n
cons = \h.\l.(\c.\n.c h (l c n))

fold = \o.\n.\l.l o n

sum = fold plus 0
prod = fold mult 1
all = fold and true
any = fold or false
length = fold (\h.\t.)

map = \f.fold (\h.\t.cons (f h) t) nil
filter = \p.fold (\h.t.(p h) (cons h t) t) nil

head = fold const nil
tail = \l.first (l (\a.\t.tuple (second t) (cons a (second t))) (tuple nil nil))
take = \n.\l.first (n (\t.tuple (cons (head (second t)) (first t)) (tail (second t))) (tuple nil l))
#+END_SRC

**** rboles
#+BEGIN_SRC haskell
nil = \d.\n.n
node = \x.\l.\r.\d.\n.(d x (l d n) (r d n))
#+END_SRC

**** Recursin
#+BEGIN_SRC haskell
omega := (\x.x x)(\x.x x)
fix := (\f.(\x.f (x x)) (\x.\f (x x)))

fact := fix (\f.\n.iszero n 1 (mult n (f (pred n))))
fib :=  fix (\f.\n.iszero n 1 (plus (f (pred n)) (f (pred (pred n)))))

infinity := fix succ
naturals := fix (compose (cons 0) (map succ))
#+END_SRC

**** Tipos
#+BEGIN_SRC haskell

#+END_SRC
** Seemengly impossible functional programs - Escard
#+BEGIN_SRC haskell :results output
data Bit = I | O deriving (Eq)
type Nats = Integer
type Cantor = Nats -> Bit

(#) :: Bit -> Cantor -> Cantor
x # a = \i -> if i == 0 then x else a(i-1)

forsome :: (Cantor -> Bit) -> Bit
find :: (Cantor -> Bit) -> Bit
forsome = undefined
find = undefined

main :: IO ()
main = putStrLn "hello!"
#+END_SRC

** EUTypes Summer School
*** Introduction to type theory
**** Bibliography
HP. Barendregt. Lambda calculus: syntax and semantics.
F. Cardone, JR. Hindley. History of lambda-calculus and combinatory logic.
Statman. Lambda calculus with types.
Benjamin Pierce. Types and programming languages.
JL Krivine. Lambda calculus, types and models.

**** Introduction to type theory I
***** Introduction
****** Gentzen
Gentzen: natural deduction/sequent calculus/axiomatic system.
****** Functions
We can give multiple notions of function

 * functions as black boxes.
 * set-theoretical definition.

We can define a domain and codomain for functions. This notion leads
to the notion of the type of a function.

***** Untyped lambda calculus
****** Informal syntax
Lambda terms are divided in

 * variables, which can be bound or free. There is a countable set of
   variables.
 * application of terms, function application.
 * lambda-abstractions, function generation by binding a variable.

An example is $\lambda x. x+42$. We see the application as left-associative.

\[
M ::= x \mid MM \mid \lambda x.M
\]

****** Examples
Those are examples of lambda combinators.
 
 * $I = \lambda x.x$
 * $K = \lambda xy. x$
 * $\Delta = \lambda x . xx$
 * $Y = \lambda f.(\lambda x. f(xx))(\lambda x. f(xx))$
 * $\Omega = (\lambda x.xx)(\lambda x.xx)$.

****** Free variables and closed terms
We define the set of free variables recursively. A closed term or
*combinator* has no free variables.

****** \alpha-conversion
Renaming of bound variables. This could also be done by using *De
Bruijn* notation. We apply the Barendregt's convention of renaming
variables that would be bound after a \beta-reduction.

\[
\lambda x.M \longrightarrow_{\alpha} \lambda y.M[y/x]
\]

****** \beta-reduction
It represents function application of functions in lambda calculus.

\[
(\lambda x.M)N \longrightarrow_{\beta} M[N/x]
\]

******* Substitution as a meta notion
Substitution is an implicit meta notion that can be defined
recursively over terms

 * $x[M/x] := M$
 * $\dots$

****** \eta-conversion
It represents function extensionality

\[
\lambda x.(Mx) \longrightarrow_{\eta} M
\]

****** Normal form
A term is in *normal form* if beta-reduction cannot be applied.
For example

 * $I$ is in normal form.
 * 4$KI(KII)$ is strongly normalizing (SN) to $I$.
 * $KI\Omega$ normalizing term.
 * $Y$ is only *head-normalizable*, or solvable.

Evaluation order is important; $KI\Omega$ stops or enters an infinite loop
depending on the evaluation order; this is a normalizing but not strongly
normalizing term.

****** Confluence and the Church-Rosser theorem
If $M \to N$ and $M \to P$, then there exists $S$ such that $N \longrightarrow S$
and $P \longrightarrow S$. The proof is not trivial.

******* Corollaries
The order of applied reductions is arbitrary. The Normal form is
unique if it exists.

****** Normalisation therem
A term is in head-normal form if its head is a lambda abstraction.
A term is in normal form if there are no $\beta$ nor $\eta$ redexes.

The normalisation theorem says that the leftmost strategy results
in the normal form of $M$ if and only if it has a normal form.

****** Fixed-point theorem
There is a fixed point combinator

\[
Y \equiv \lambda f. (\lambda x.f(xx))(\lambda x.f(xx))
\]

such that $\forall F. YF \equiv F(YF)$.

****** Church encoding
Logic and arithmetic can be encoded in lambda calculus via
Church numerals.

\[
n :\equiv \lambda fx. f^n x
\]

****** Expressiveness of lambda calculus
In the 1930s

 * Kleene: it is equivalent to recursive funtions.
 * Church
 * Curry

***** Typed lambda calculus
***** Intersection types
**** Introduction to type theory II
***** Disadvantages of untyped lambda calculus

 * There exist lambda terms without normal form.
 * Meaningless expressions.

This motivates two typing paradigms

 * Implicit type assignment: lambda calculus with types.
 * Explicit type assignment: typed lambda calculus.
***** Sintatic definition of typed lambda calculus
Type assignments $M : \sigma$, declarations $x : \sigma$ and environments
$\Gamma = \left\{ x_1:\sigma_1,\dots, x_s:\sigma_s \right\}$. With rules

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:\sigma \vdash x:\sigma$ }
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash N : \sigma$}
\BinaryInfC{$\Gamma \vdash \lambda x . M : \sigma \to \tau$ } 
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, x:\sigma\vdash y:\tau$}
\UnaryInfC{$\Gamma \vdash \lambda x.y : \sigma \to \tau$}
\end{prooftree}

It can be defined as a natural deduction system with introduction
and elimination rules.

***** Typing example
There are non-typable normal forms.

 * $I : \sigma \to \sigma$
 * $K : \sigma \to \tau \to \sigma$
 * $\Delta$, $Y$ or $\Omega$ can not be typed

***** Type preservation
If $M \longrightarrow P$ and $M:\sigma$, then $P:\sigma$.

***** Generation and substitution lemmas
If $\Gamma \vdash \lambda x. M: \varphi$, then $\varphi = \sigma \to \tau$ and $\Gamma, x:\sigma \vdash M : \tau$.
If $\Gamma, x:\sigma \vdash M : \tau$ and $\Gamma \vdash N:\tau$, then $\Gamma \vdash M[x/N]:\tau$.

***** Strong normalization
If $M : \sigma$, then $M$ is strongly normalizing. This was proven by
Tait in 1967.
***** Typability and inhabitation
Questions on lambda calculus

 * *Typability:* iven a term, find a type for it.
 * *Inhavitation:* given a type, construct a term of that type.
 * *Type checking:* check the type of a term.

Typability is decidable in simply typed lambda calculus. It is
decidable in second order lambda calculus with the Hindley-Milner
algoritm.

Inhabitation is equivalent to the intuitionistic logic of Gentzen's
natural deduction. The rules of typed lambda calculus are the rules
of natural deduction if we do not use the terms.

***** Curry-Howard correspondence
A formula is provable in IL iff it is inhabited in simply-typed lambda
calculus. This is also the language of Cartesian Closed Categories
(Lambek, 1970).

BHK interpretation of logical connectives is formalized by the 
Curry-Howard correspondence.

***** Consistency/Completeness/Decidability
Intuitionistic propositional logic (IL) is consistent, complete and
decidable. Due to Curry-Howard, inhabitation is decidable in STLC.
***** Lambda cube
If any $M$ is typable, $M$ is strongly normalizing.
The [[https://en.wikipedia.org/wiki/Lambda_cube][lambda cube]] represent multiple type systems.

\[\begin{tikzcd}
& & & \\
\lambda 2 & & \lambda P2 & \\
& \lambda & & \\
\lambda_{\to}& & & & \\
\end{tikzcd}\]
***** Intersection types
In our current system, $\Delta$ is not typeable. We are going to introduce
intersection types with elimination rules

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \sigma$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \tau$}
\end{prooftree}

and a introduction rule

\begin{prooftree}
\AxiomC{$M:\sigma$}
\AxiomC{$M:\tau$}
\BinaryInfC{$M:\sigma\cap\tau$}
\end{prooftree}

In general, the Curry-Howard correspondance is lost here. We create
a new system $\lambda\cap$, but in this system, $\sigma \to \tau \to \sigma \cap \tau$ is provable while
it is not inhabited.

****** Now self application is typable
The self application can be of type $\lambda x.xx :((\sigma \to \tau) \cap \sigma) \to \tau$.

***** Characterization of strong normalization on intersection types
A term is typable iff it is strongly normalizing.

For example, $KI\Omega$ is not typable, even if $I$ is.

***** Typability and inhabitation are undecidable with intersection types
***** Models of lambda-calculus
We can prove completeness of type assignment. It is a theorem that

\[
\Gamma \vdash M:\sigma \iff \Gamma \models M : \sigma
\]
**** Pure type systems I
*alx@minuw.edu.pl*

***** Simple type systems
Differences between logics and type systems:

 * focus on computation instead of consistency.
 * it is meaningful to have two assumptions of the same type.
 * it is meaningful to use wh same assumption twice.

Combinatory logic, with combinators S,K, defines /minimal logic/.
With them, deduction theorem is provable. But we can add other
combinators such as B,C or W.
***** More complex type systems
We can add polymorphism with type variables. We get SystemF (aka
$\lambda 2$). We need more complex typing rules and beta reduction for types.
$\lambda P$ was proposed by deBruijn, Harper, Longo and Moggi.

***** Properties of interest of a pure type system

 1. Church-Rosser property. Values are computed deterministically.
 2. Subject reduction property. Types are invariants of the reduction.
 3. Strong normalisation property. Computation terminates.

Those properties prove consistency of the logical system.
***** Examples of PTSs
$\lambda_{\to}, \lambda 2, \lambda P, \lambda \omega, \lambda C, \lambda \ast, \lambda U$

***** Lemmas for PTSs
****** Free variables
****** Transitivity of contexts
****** Substitution
****** Weakening
****** Generation lemma
****** Condensing lemma
***** Properties of PTSs
****** Church-Rosser property
There is a PTS extended with a number of axioms which does not have
the Church-Rosser property.

****** Geuvers theorem
All functional strongly normalizing PTSs have the Church-Rosser
property.

****** Functionality
A PTS (S,A,R) is functional when A is a function from S to S and
R is a function from $S \times S$ to $S$.

****** Uniqueness of types lemma
**** Pure type systems II
***** The type inhabitation problem
*** Dependently typed programming
**** Milner's coincidence
Milner's Coincidence on Hindley-Milner's type systems

|-----------------------+--------------------------------------|
| Terms                 | Types                                |
|-----------------------+--------------------------------------|
| what we write         | we don't write these                 |
| what we read          | invisible (except errors)            |
| what gets compiled    | what gets erased                     |
| non dependent \lambda | polymorphism over types with \Lambda |
|-----------------------+--------------------------------------|

In the late 90s, this was the accepted unquestioned way of thinking
about types.
*** Homotopy type theory
The Tao of Types - Thorsten Altenkirch

 - A topological model of HoTT.

**** HoTT 1
There are multiple implementations of type theory (Coq, Agda, ...)

***** Extensionality vs intensionality
***** Set theory vs type theory
In set theory, we would write $3 \in \mathbb{N}$, and this is a proposition of the
language; we can write things like $x \in A \longrightarrow x \in B$. In type theory,
$3 : \mathbb{N}$ is instead a judgement. Statements such as $\mathbb{B}\cap \mathbb{N}$ are intensional:
they depend on the encoding.

Sometimes, we want to talk about intensional properties

***** Univalence
Two types in a one-to-one correspondence are equal.

***** Propositions as types explanation/Curry-Howard equivalence
****** Example
We will prove that $P \times Q \to R \iff P \to (Q \to R)$. We will define two
functions from and to the types

#+BEGIN_SRC haskell
f :: ((a,b) -> c) -> (a -> b -> c)
f h x y = h (x,y)

g :: (a -> b -> c) -> ((a,b) -> c)
g h (x,y) = h x y
#+END_SRC

these are curry/uncurry functions.

***** Products and sums
Products are created as

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$b:B$}
\BinaryInfC{$(a,b) : A \times B$}
\end{prooftree}

and sums as

\begin{prooftree}
\AxiomC{$a:A$}
\UnaryInfC{$left(a) : A +B$}
\AxiomC{$b:B$}
\UnaryInfC{$right(b):A+B$}
\noLine
\BinaryInfC{}
\end{prooftree}
 
***** Definitional equality
Equality given by the definition of the terms. These equalities are
static.

$\equiv$
***** Recursor
The recursor is a non-dependent eliminator. It gives us the ability
of doing pattern-matching on types. For example, if we want to define
a function from a pair type using the recursor for the product

\[ \mathtt{rec}^{\times} :
(A \to B \to C) \to (A \times B) \to C
\]

or a recursor for the sum type

\[ \mathtt{rec}^+ :
(A \to C) \to (B \to C) \to (A + B \to C)
\]

the recursor for the empty type

\[ \mathrm{rec}^\bot : \bot \to C
\]

is implemented without using anything because of the nature of the
empty type.
**** HoTT 2
***** What is a type?
We allow the following judgements,

 * $a:A$, type declarations.
 * $a \equiv_{A} b$, definitional equality.

and we define a universe of types ${\cal U}$, a type whose elements are types.

****** Is type a type?
If we set $Type : Type$, we can encode a version of Russell's paradox
using trees of types. Being of a type is a judgement, so we can not
encode the traditional Russell paradox.

****** Type universes
We are going to use type universes $Type_0: Type_1: Type_2 : \dots$,
constructing a *predicative* hierarchy. It is a cumulative hierarchy,
where we can lift a type $A : Type_{i}$ to $\lceil A\rceil : Type_{i+1}$ and any function
$A \to B$ to $\lceil A\rceil \to \lceil B\rceil$. 

***** Dependent types
A *dependent type* depends on a term. An example is $Fin : \mathbb{N} \to Type$.
Another example is $Vec : Type \to \mathbb{N} \to Type$ or $Prime : \mathbb{N} \to Type$.
***** Pi-types
Pi types are a generalization of function types allowing the codomain
to depend on the domain.

****** Example: zeroes

\[
zeroes : \prod_{n:\mathbb{N}} Vec\ \mathbb{N}\ n
\]

where

\[
zeroes\ n = (0,0,\dots,0)
\]

****** Example: theorems on naturals

\[
pluszero : \prod_{n : \mathbb{N}} n+0 =_{\mathbb{N}} n
\]

***** Sigma-types
Sigma tupes generalize product types to the case where the type of
second depends on the first. They work as dependent pairs.

****** Example: lists

\[
\sum_{n:\mathbb{N}} Vec\ A\ n
\]

***** Particular cases
The function type is a particular case of a pi-type, while the 
product type is a particular case of a sigma-type.

 * $\prod_{a:A} B \text{ is } A \to B$
 * $\sum_{a:A} B \text{ is } A \times B$

***** Example of predicate logic
We have the following logic equivalence in predicate logic

\[
\left(\sum_{x:A}  P\ x\right)\to Q \iff \prod_{x:A} P\ x \to Q
\]

and the proof is similar to that of $((P,Q) \to R) \to (P \to Q \to R)$.
Yesterday we talked only about propositional logic.
***** Numerical interpretation
If $f : n \to \mathbb{N}$, and we take $\overline{n}$ to be a type with $n$ elements

\[
\sum_{i:\overline{n}} \overline{f(i)}
=
\overline{\sum_{i=0}^{n-1} f(i)
\]

and the same is true for pi-types, they are related to a product.
***** Sum as a sigma type
We can define $A + B$ using $\sum_{x:2}\text{if x then } A \text{ else } B$; and the same trick
can be used for products, taking $A \times B$ to be $\prod_{x:2}\text{if x then } A \text{ else } B$.

\[\begin{tikzcd}
    & $\sum$ &          & $\prod$ &       \\
$+$  &        & $\times$ &         & $\to$
\end{tikzcd}\]

***** Eliminators of dependent types
The eliminator of the sum type is

\[
R^+ : (A \to B) \to (A \to C) \to A + B \to C
\]

and we can define a dependent version of the eliminator

\[
R^+ : \left( \prod_{x:A} C(inl(x)) \right) \to 
\left(\prod_{y:B} C(inr(y))\right) \to
\prod_{z: A+B} C(z)
\]

of which the first is a particular case.
**** HoTT 3
***** Intensional equality
***** Uniqueness of equality proofs

\[
uep : \prod_{x,y:A}\prod_{p,q: x=y} p=q
\]

****** Proof and the need for K
It has been proved that this does not depend on J using
countermodels. We need to add another eliminator called K.
If we have

\[
C : \prod_{x:A} x =x \to Type
\]

then

\[
K_C : \prod_{x:A} C\ x\ (refl\ x) \to \prod_{x:A}\prod_{p:x=x} C\ x\ p
\]

****** What can we proof without K?
The groupoid structure of paths can be proven wihtout K.

\[
\prod_{x,y:A}\prod_{p : x=y}
trans\ p\ refl = p
\]

***** Extensionality
We need extensionality to prove

\[
\lambda x. x+0 = \lambda x.0+x
\]

using that $f x = g x$ for all $x$ implies $f = g$.

****** Product
The equality of a product is the product of two equalities;
the equality of a coproduct is a coproduct, and so on.

****** Equality of types
Equivalence or isomorphism of types can be defined with two
mutually inverse functions between them. They give us a one-to-one
correspondence between types. This is written as $A \simeq B$.

We would need

\[
\eta : \prod_{x:A} g(f(x)) = x
\]

and

\[
\varepsilon : \prod_{y:B} f(g(y)) = y
\]

We could use J to prove

\[
\prod_{A,B: {\cal U}} A=B \to A \simeq B
\]

but this is not provable.

****** Automorphisms of Bool
There are two proofs of equality of Bool to Bool.

There are two ways of proving $f(g(f(x))) = f(x)$ with the previous
definition.

We fix that with

\[
\tau : \prod_{x:A} f(\eta (x)) = \varepsilon f(x)
\]

****** Definition of equivalence
This definition of isomorphism 

\[
isequiv(f) = \prod_{b:B} iscontractible \left( \sum_{a:A} f(a) = b \right)
\]

is equivalent to our previous definition of equivalence.
****** Isomorphisms and equivalence
There are more isomorphisms than equivalences, but for every
isomorphism, we can build an equivalence

\[
A \simeq B \iff A\cong B
\]

The previous definition of univalence was unsound because it
made isomorphisms and equivalences equal.
**** HoTT 4
***** What is a proposition?
***** Axiom of choice
Diaconescu; from the set-theoretical axiom of choice, we get that,
for all propositions the LEM holds, $\prod_{P:Prop} P \vee \neg P$.
***** Sets and propositions

\[ \mathtt{isSet}\ A \equiv
\prod_{x,y:A} \mathtt{isProp}(x =_{A} y)
\]

$Type_0$ is an example of something that is not a set. There are two
different proofs of the equality $Bool = Bool$.

***** n-Types

\[
isntype(A) \equiv
\prod_{x,y:A} is(n-1)type(x = y)
\]

An n-type is also an (n+1)-type.

|  -2 | Contractible type |
|  -1 | Proposition       |
|   0 | Set               |
|   1 | Groupoid          |
|   2 | 2-Groupoid        |
| ... | ...               |

The sphere $\mathbb{S}^2$ is not an n-type for any n.

***** Hedberg's theorem
Given $A:Type$ with decidable equality

\[
d : \forall x,y : A.\quad x=y \vee x \neq y
\]

it is a set, $\mathtt{isSet}(A)$.
**** HoTT 5
***** Negative translation of classical logic

 * $A \vee B \mapsto \neg (\neg P \wedge \neg Q)$
 * $\exists_{x:A}B(x) \mapsto \neg \prod_{x:A} \neg B(x)$

** Affine group schemes seminar
*** I. lgebras de Hopf
**** 1. Definiciones
***** lgebra de Hopf
Un *lgebra de Hopf* es una bilgebra (lgebra y colgebra) con un 
antiautomorfismo llamado /antpoda/.

****** Explcitamente
Tenemos $(H, m, \eta, \Delta, \varepsilon, S)$ como componentes del lgebra de Hopf sobre
un cuerpo $k$, donde:

 - $H$ es el lgebra.
 - $m : H \otimes H \to H$ es el producto.
 - $\eta : k \to H$ es la unidad.
 - $\Delta : H \to H \otimes H$ es la comultiplicacin.
 - $\varepsilon : H \to k$ es la counidad.
 - $S : H \to H$ la antpoda.

Bajo ciertas condiciones de compatibilidad.

***** Group-like elements
Elementos no nulos cumpliendo $\Delta(x) = x \otimes x$. Forman un grupo con la inversa
dada por la antpoda.

*** II. Introduction to affine group schemes
**** 1. Definition and examples
***** Affine group scheme
An *affine group scheme* over $k$ is a representable functor $\mathtt{Alg}_k \to \mathtt{Grp}$.
More precisely, the composition of the functor with $\mathtt{Grp}\to\mathtt{Set}$ is
representable.

***** Connection with affine algebraic varieties
If $V$ is an affine algebraic variety, the we can define the corresponding
affine scheme as $Alg_k(K[V], -)$, where $K[V]$ is the coordinate algebra.

***** Algebraic affine scheme
An affine scheme is said to be *algebraic* if its representing object is
finitely generated as a k-algebra.

*** III. Esquemas diagonalizables y constantes
**** 1. Introduccin
***** lgebra grupo
Dado un grupo $G$ y un cuerpo $k$, el lgebra grupo $k[G]$ est formada como el
espacio vectorial libre sobre $G$ con el producto que induce el grupo.

****** Estructura de lgebra de Hopf
Este lgebra tiene estructura de lgebra de Hopf si extendemos linealmente
las siguientes aplicaciones:

  - $\Delta(x) = x \otimes x$
  - $\varepsilon(x) = 1$
  - $S(x) = x^{-1}$
** The Catsters
*** Adjunctions
Serie de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][vdeos]] sobre funtores adjuntos.

**** Adjuntions 1
Tenemos varias nociones de igualdad entre categoras.

#+begin_definition
*Isomorfismo de categoras*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C = GF$ y $FG = 1_D$.
#+end_definition

#+begin_definition
*Equivalencia de categoras*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C \cong GF$ y $FG \cong 1_D$. Entendiendo la isomorfa en la 
categora de funtores, es decir, una [[https://ncatlab.org/nlab/show/natural+isomorphism][isomorfa natural]].
#+end_definition

#+begin_definition
*Adjuncin*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que tenemos transformaciones naturales $1_C \overset{\eta}\Longrightarrow GF$ y 
$FG \overset{\epsilon}\Longrightarrow 1_D$ que cumplen las dos identidades triangulares siguientes:
 
\[ \begin{tikzcd}
F \arrow{r}{\eta} \arrow{dr}{id} & FGF \arrow{d}{\epsilon} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta} \arrow{dr}{id} & GFG \arrow{d}{\epsilon} \\
 & G
\end{tikzcd}
\]
#+end_definition

En este caso escribimos $F \dashv G$, y $F$ es funtor adjunto de $G$.

**** Adjuntions 2
Damos una definicin equivalente de funtores adjuntos.

#+begin_definition
*Adjuncin*. Una adjuncin es un isomorfismo natural:

\[Hom_D(FX,Y) \cong Hom_C(X,GY)\]

Natural sobre $X$ fijado cualquier $Y$ y natural sobre $Y$ fijado 
cualquier $X$. Entendiendo que usamos los funtores contravariantes $Hom(F-,Y)$,
$Hom(-,GY)$ por un lado y los funtores covariantes $Hom(FX,-)$ y $Hom(X,G-)$;
que nos dan los siguientes cuadrados de naturalidad:

\[ \begin{tikzcd}
Hom_D(FX',Y) \arrow{d}[swap]{Hom_D(Ff,Y)} \arrow{r}{\alpha_{X'}} & Hom_C(X',GY) \arrow{d}{Hom_C(f,GY)}\\
Hom_D(FX, Y) \arrow{r}{\alpha_{X}}& Hom_C(X,GY)
\end{tikzcd}
\] 

\[ \begin{tikzcd}
Hom_D(FX,Y) \arrow{d}[swap]{Hom_D(FX,g)} \arrow{r}{\beta_{Y}} & Hom_C(X,GY) \arrow{d}{Hom_C(X,Gf)}\\
Hom_D(FX,Y') \arrow{r}{\beta_{Y'}}& Hom_C(X,GY')
\end{tikzcd}
\] 
#+end_definition

Esta definicin es equivalente intuitivamente a la anterior porque
podemos crear $\eta$ y $\epsilon$ desde las identidades usando las
siguientes transformaciones naturales:

\[Hom_D(FX,FX) \cong Hom_C(X,GFX)\]

\[Hom_D(FGY,Y) \cong Hom_C(GY,GY)\]

**** Adjuntions 3
Podemos presentar ejemplos de adjunciones.
Los *funtores libres y de olvido* suelen ser adjuntos. Entre $Set$ y $Monoid$ tenemos:

\[ \begin{tikzcd}
{Set} \arrow[bend left]{r}{Free} & {Monoid} \arrow[bend left]{l}{Forget}
\end{tikzcd}
\]

Con la adjuncin $Free \dashv Forget$. 

#+begin_theorem
*Mnada de una adjuncin*. Cada adjuncin da lugar a una mnada.
#+end_theorem

Tenemos un funtor $T = GF : {\cal C}  \longrightarrow {\cal C}$. Podemos definir la unidad de
la mnada como la unidad de la adjuncin $\eta : 1_C \Longrightarrow T$ y la
multiplicacin podemos definirla usando $id \ast \epsilon \ast id : GFGF \Longrightarrow GF$.

Ahora debemos comprobar que cumple los axiomas de mnada. El primero
se obtiene directamente desde los tringulos de la adjuncin:

\[ \begin{tikzcd}
T \arrow{r}{T\eta} \arrow{dr}{id} & T^2 \arrow{d}{\mu} \\
 & T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GF \arrow{r}{GF\eta} \arrow{dr}{id} & GFGF \arrow{d}{G \epsilon F} \\
 & GF
\end{tikzcd}   
\]

Donde el segundo es resultado de aplicar el funtor $G$ a uno de los tringulos conmutativos
de la adjuncin. Comprobamos el segundo axioma:

\[ \begin{tikzcd}
T^2 \arrow{d}{\mu} & T \arrow{dl}{id} \arrow{l}[swap]{\eta T} \\
T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GFGF \arrow{d}{G \epsilon F} & GF \arrow{dl}{id} \arrow{l}[swap]{\eta GF} \\
GF
\end{tikzcd}   
\]

Donde tenemos el resultado de aplicar $F$ por la derecha al otro tringulo conmutativo.

Y finalmente el axioma de conmutatividad de la mnada se comprueba como:

\[ \begin{tikzcd}
T^3 \arrow{d}{T \mu} \arrow{r}{\mu T} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd} \]  \[ \begin{tikzcd}
GFGFGF \arrow{d}{GFG \epsilon F} \arrow{r}{G \epsilon FGF} & GFGF \arrow{d}{G\epsilon F} \\
GFGF \arrow{r}{G \epsilon F} & GF
\end{tikzcd} \] 

Donde el segundo diagrama se obtiene desde la naturalidad de $\epsilon$ aplicando funtores.

**** Adjuntions 4
Vamos a probar la igualdad entre las dos definiciones de adjuncin.
Supongamos primero que tenemos el isomorfismo natural entre los dos 
conjuntos de morfismos, es decir, tenemos:

\[ (-) : Hom_D(FX,Y) \cong Hom_C(X,GY) \]

Si tomamos ahora los dos cuadrados naturales que tenamos por este 
isomorfismo y tomamos en ellos los casos particulares $Y = FX$ primero,
y $X = GY$ despus:

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{\_ \circ Ff} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{\_\circ f}\\
Hom_D(FX', FX) \arrow{r}{(-)}& Hom_C(X',GFX)
\end{tikzcd}
\]

Si tomamos la identidad $1_{FX}$ y llamamos $\eta_X = \overline{1_{FX}}$, tenemos que
\(\eta \circ f = \overline{Ff}\). Ahora, si damos la vuelta al isomorfismo $(-)$ en este 
diagrama a la vez que hacemos $X = GY$:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{\_ \circ Ff}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{\_\circ f}\\
Hom_D(FGY',Y) & Hom_C(GY',GY) \arrow{l}[swap]{(-)}
\end{tikzcd}
\]

Volviendo a tomar la identidad $1_{GY}$ y llamando $\epsilon_Y = \overline{1_{GY}}$, tenemos
$\epsilon \circ Ff = \overline{f}$.

Ahora tomamos el segundo cuadrado natural, y repetimos el mismo
proceso.

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{g \circ \_} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{Gg\circ \_}\\
Hom_D(FX,FX') \arrow{r}{(-)}& Hom_C(X,GFX')
\end{tikzcd}
\] 

Obteniendo desde la identidad en $FX$ la ecuacin $\overline{g} = Gg \circ \eta$. Y volviendo
a dar la vuelta a los isomorfimos llegamos a:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{g \circ \_}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{Gg \circ \_}\\
Hom_D(FGY,Y') & \arrow{l}[swap]{(-)} Hom_C(GY,GY')
\end{tikzcd}
\]

Obteniendo finalmente $\overline{Gg} = g \circ \epsilon$. De este proceso hemos obtenido finalmente
las siguientes ecuaciones:

\[ \begin{aligned}
\eta \circ f &= \overline{Ff} \\
\epsilon \circ Ff &= \overline{f} \\
Gg \circ \eta &= \overline{g} \\
g \circ  \epsilon &= \overline{Gg} 
\end{aligned} \]

Con ellas podemos probar la naturalidad de $\eta$ y la naturalidad de
$\epsilon$:

\[ \begin{tikzcd}
GFX  \arrow{r}{GFf} & GFY \\
X \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & Y \arrow{u}{\eta_Y}
\end{tikzcd}
\]   \[ \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}
\]

Ya que $\eta \circ f = \overline{Ff} = GFf \circ \eta$ y $f \circ \epsilon = \overline{Gf} = \epsilon \circ FGf$. Y adems podemos probar
los dos tringulos de naturalidad.

\[ \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}
\]

Teniendo finalmente que:

\[ \begin{aligned}
\epsilon \circ F\eta &= \overline{\eta} = 1 \\
G\epsilon \circ \eta &= \overline{\epsilon} = 1
\end{aligned} \]

El otro sentido de la demostracin se tiene llegando primero a las
cuatro ecuaciones, y usndolas para definir el isomorfismo
$(-)$. Falta entonces demostrar su naturalidad.

** Harpreet Bedi's channel
*** Sheaves and coho
**** Preseaves and sheaves
***** Preseaf definition
#+begin_definition
*Preseaf*. A preseaf ${\cal F}$ of abelian groups on a topological space $X$ consists of:

- For each open set $U$, an abelian group ${\cal F}(U)$, whose elements are called 
  *sections*.
- For each inclusion $V \subseteq U$, a *restriction map*, homomorphism of the form:
  
 
\[p_{U,V} : {\cal F}(U) \longrightarrow {\cal F}(V)\]

such that $p_{U,W} = p_{V,W} \circ p_{U,V}$.
#+end_definition

We can write the restriction of an element $u \in U$ to a set $V \subseteq U$ as
$u|_V = p_{U,V}(u)$.

***** Sheaf definition
 #+begin_definition
 *Gluability axiom*. Given $U = \bigcup U_i$ with sections $s_i \in {\cal F}(U_i)$, if we have:

 \[ s_\alpha|_{U_\alpha \cap U_\beta} = s_\beta|_{U_\alpha \cap U_\beta} \]

 then there exists $s \in {\cal F}(U)$ such that $s|_U_\alpha = s_\alpha$.
 #+end_definition
 #+begin_definition
 *Uniqueness axiom*. Given $U = \bigcup U_i$ with sections $s,t \in {\cal F}(U)$ such that:

 \[\forall U_\alpha:\ s|_U_\alpha = t|_U_\alpha\]

 then $s=t$.
 #+end_definition
 #+begin_definition
 *Sheaves*. A presheaf satisfiying gluability and uniqueness.
 #+end_definition
*** Homological Algebra
**** 2. Chain Complex and Homology
**** 4. Homology Theorem
***** Setting
Given a SES of chain complexes $0 \longrightarrow {\cal A}
\longrightarrow{\cal B}
\longrightarrow{\cal C}
\longrightarrow 0$, we have a long exact
sequence like:

\[ \begin{tikzcd}
 & \dots\rar & H_{n+1}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_{n+1}} \\
H_{n}({\cal A})\rar & H_{n}({\cal B}) \rar & H_{n}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_n}\\
H_{n-1}({\cal A})\rar & \dots & 
\end{tikzcd} \]

***** Naturality
When we have two SES of chain complexes:

\[ \begin{tikzcd}
0 \rar & {\cal A}\rar\dar & {\cal B}\rar\dar & {\cal C}\rar\dar & 0 \\
0 \rar & {\cal A}'\rar & {\cal B}'\rar & {\cal C}'\rar & 0 \\
\end{tikzcd} \]

where it hols for every $n$ that:

\[ \begin{tikzcd}
H_n({\cal C}) \rar\dar & H_{n-1}({\cal A})\dar \\
H_n({\cal C}') \rar & H_{n-1}({\cal A}')
\end{tikzcd} \]

**** 8. Proj, inj and flat modules
***** Definitions
An R-module $D$ is:

 1. *Projective* if $Hom(D, -)$ is exact.
 2. *Injective* if $Hom(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.

***** Considerations
We know that $Hom(D,-)$ and $Hom(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ surjective induces
   $Hom(D,B) \longrightarrow Hom(D,C)$ surjective.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ surjective induces
   $Hom(B,D) \longrightarrow Hom(A,D)$ surjective.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ injective induces 
   $D\otimes A \longrightarrow D \otimes B$ injective.

**** 9. Resolutions: projective, injective and flat
***** Definitions
****** Resolutions
Resolutions are *exact sequences*.

****** Projective resolution
A resolution, with $d_i$ maps:

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where $P_i$ is projective.

****** Injective resolution
A resolution:

\[0 \longrightarrow M \longrightarrow E_0\longrightarrow E_1
\longrightarrow E_2 \longrightarrow \dots\]

where $E_i$ is injective.

****** Flat resolution
A resolution:

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.

***** How to form a resolution
It is important to notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as follows:

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

**** TODO 10. Homotopic projective resolutions
***** Extending a morphism
Given two projective resolutions of two $R$ modules, $A$ and $A'$, and a morphism
between them, $f$. We can extend it to $f_n \in Hom(P_n,P_n')$.

\[ \begin{tikzcd}
\dots\rar & P_{n+1}\rar & P_n\rar& \dots
 \rar & P_1\rar{d_1} & P_0\rar{d_0}& A \dar{f} \rar& 0 \\
\dots\rar & P_{n+1}'\rar & P_n'\rar&\dots
 \rar & P_1'\rar{d_1} & P_0'\rar{d_0'}& A' \rar& 0 \\
\end{tikzcd} \]

****** Extending the morphism, base case
We use that $P_0$ is projective to construct:

\[ \begin{tikzcd}
     & P_0 \arrow[ddl,"f_0",dashed,swap] \dar\\
     & A \dar{f} \\
P_0' \rar[two heads] & A'
\end{tikzcd} \]

****** Extending the morphism, inductive case
We are going to show that $f_n(\im d_{n+1}) \subset \im d_{n+1}' = \ker d_n'$. That is, 
$d_n' \circ f_n \circ d_{n+1} = 0$. And that follows from diagram chasing. We use
again the projectivity of $P_{n+1}$.

\[ \begin{tikzcd}
     & P_{n_+1} \arrow[ddl,"f_{n+1}",dashed,swap] \dar\\
     & \im d_{n+1} \dar{f_n} \\
P_{n+1}' \rar[two heads] & \im d_{n+1}'
\end{tikzcd} \]

***** TODO Homotopic resolutions
**** 11. Derived functors Ext and Tor
***** Right derived functors
Let $F$ be additive, covariant and left-exact. Let 
$0 \longrightarrow M \longrightarrow E^\bullet$ be an injective resolution with $M$ deleted; then $F(E^\bullet)$ 
is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E_i) \longrightarrow F(E_{i+1})\}}
{\im\{ F(E_{i-1}) \longrightarrow F(E_i)\}}\]

That is, if we take the injective resolution:

\[ 0 \longrightarrow M \longrightarrow E_0 \longrightarrow E_1 
\longrightarrow \dots\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology:

\[ 0 \longrightarrow F(E_0) \longrightarrow F(E_1)
\longrightarrow F(E_2) \longrightarrow \dots\]

***** Left derived functors
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the injective resolution:

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

**** 12. Computations of some standard Ext and Tor examples
**** 13. Long Exact Sequence for Tor
*** Algebraic Geometry
**** 1. Intro to Algebraic Geometry

** Fields lectures
http://www.fields.utoronto.ca/video-archive//event/2012/2016

*** [May 16] Michael Shulman: synthetic homotopy theory
It shows a proof of the equality between integers and the foundamental
group of the circle.

**** Introduction: type theory
Homotopy type theory is a variation on ML-TT with Higher inductive
types and univalence. In type theory we have

 - types,
 - terms,
 - type constructors, like Pi or Sigma,
 - several universes

From the homotopic point of view, we think of types as spaces or
groupoids. A type family is a homotopy-theoretic fibration: if
we have $B : A \to {\cal U}$, $B(x)$ is the fiber over $x : A$.

**** Identity types
Identity types provide the groupoid structure to a type. Equalities
are paths between two points of a type.

 - Leibniz/Lawvere/Martin-Lof notion. The family of equality types for
   any given type is freely generated by the reflexivity path.

***** Why does this work? How can exist non-trivial paths?
The space of paths with a fixed endpoint is contractible. There are no
paths but reflexivity. Every path can be retracted back to
reflexivity.  You can use the Yoneda lemma here; the hom functor is
determined by the identity map.

***** Homotopy structure
Any type has an internal homotopy structure

**** Observational/definitional/cubicaal approach
The meaning of the identity type is defined recursively on the
structure of the type A. For example, if we have a product type,
two pairs are equal if their components are equal.

We have operations of transport defined in terms of the structure of
the type.

**** n-types & propositions
We regard types as representing propositions, things that we can prove;
and elements of a type are their proofs.

 - A type is a proposition if every two elements of that type are
   propositionally equal.

Note that propositional equalities have nothing to do with these mere
propositions.

***** Propositional truncation
A type such that every map from a type factors uniquely throught its
propositional truncation.
**** Synthetic homotopy theory
Synthetic homotopy theory is the study in HoTT of properties of types
that traditionally belong to homotopy spaces. We view types as spaces
and we try to apply ideas from homotopy theory.

For example, we classically define the homotopy group of a space as a
map from the sphere to a space.

We can define the loop space of a type. If we iterate over this, we get
higher homotopy groups. The zero truncation of these types gives us the
homotopy paths.

***** Traditional vs synthetic
Traditional

 - spaces are sets of points,

Synthetic

 - spaces are fundamental notions,
 - paths are fundamental notions.

Synthetic homotopy theory models other homotopy theories, things like
higher toposes are expected to be models of this theory.

**** Our tools: HITs and univalence
HITs give us a way to construct spaces in type theory.

In classical homotopy theory we have cell-complexes and we use them to
build complicated spaces. A higher inductive is a cell-complex what an
inductive type is a 0-dimensional cell-complex.

The circle can be constructed directly as a HIT.

We can prove that
\[
\Omega(\mathbb{S}^1, \mathrm{base}) = \mathbb{Z},
\]
by defining a map from the integers to the paths, $n \mapsto \mathrm{loop}^n$.

We need the UA in order to create the converse function.
*** [May 19] Thorsten Altenkirch: why does homotopy type theory matter?

 * *Realist* foundation of mathematics. Mathematical objects are real
   things instead of constructed notions. We use sets.

 * *Constructivist* foundation of mathematics. We are not basing this
   in real objects, we are only communicating ideas. Type theory can be
   thought of as an implementation of constructivism.

   * We can reason about propositions.
   * We use types instead of sets.

We can translate propositions as types, and this is not a sintactic
trick but a new way of understanding a proposition. If we use types
instead of sets, we have to introduce types and terms from that type
at the same time. There is no way to reference untyped objects.

\[
\mathtt{Bool} \cong \mathtt{Prop},
\]

if and only if the LEM holds.

**** What has homotopy theory ever done for us?
In Martin-Lf first version, membership was impredicative. Then he
introduced extensional type theory; and then later he introduced
intensional type theory.

 - Programming in Martin-Lof's type theory, Nordstrm.

In intensional type theory, two objects are equal only if they are
defined the same way; that is a problem. These two functions

 - $\lambda x.x + 0$,
 - $\lambda x.0+x$, 

for example, are not equal.

**** Setoids
Setoids are a way to solve the problem with intensional type theory.
A setoid is a type with some equivalence relation. From any two
setoids $A,B$, we can define a new setoid $A \to B$ whose functions
must preserve the equivalence relation. That is, we can translate the
usual type constructors into setoid constructors.

**** TODO Setoid interpretation
** ZFC - Pablo Baeyens
# Estos apuntes han sido tomados durante el seminario de Pablo
# Baeyens para LibreIM sobre ZFC. El artculo que acompaa a
# este seminario puede leerse en
#
#  http://tux.ugr.es/libreim/blog/2017/03/25/zfc/
#
# Estos apuntes estn licenciados bajo CC-BY-SA.
Utilizando lgica de primer orden.

\[
\wedge, \implies, \iff, \forall, \exists
\]

Adems de:

- Un conjunto infinito numerable de variables: $x_1,x_2,\dots$
- Slo puede cuantificarse sobre variables.
- Reglas para frmulas bien formadas.

Smbolos propios de la teora de conjuntos:

- $=, \in$

Se usa internamente la axiomtica de la lgica de primer orden.

*** Axiomas de la igualdad
La igualdad es relacin de equivalencia. Es

 1. Reflexiva, $\forall x: x=x$.
 2. Transitiva, $\forall x,y,z: x=y \wedge x=y \implies x=z$.
 3. Simtrica, $\forall x,y : x=y \iff y=x$.
 4. Sustitucin, $\forall x,y: x=y \implies \varphi \iff \varphi'$ donde $\varphi'$ sale de sustituir $x$.

*** Nmeros como conjuntos
Algunas teoras consideran elementos que no tienen elementos dentro.
En nuestro caso usaremos conjuntos para representar todos los objetos
matemticos.

**** Nmeros naturales
Definimos:

 - $0 = \varnothing$
 - $S(x) = x \cup \{x\}$

**** Otra construccin posible
Definiendo:

 - $\varnothing$
 - $S(x) = \{x\}$

**** Construccin de funciones
Para definir una funcin, usamos su grfico:

\[\{(a,b) \in A \times B \mid f(a) = b\}\]

*** Restricciones
No podemos hablar todava del conjunto de todos los conjuntos. Dentro
de ZFC no podemos hablar de cosas como $Obj(\mathtt{Set})$.

*** Axiomas de la teora de conjuntos
Tomamos como ciertos:

**** 0. Axioma de existencia
$\exists x : x=x$

**** 1. Axioma de extensionalidad
$\forall x,y:(\forall z: z\in x \implies z \in y) \implies x = y$

De paso definimos la inclusin:

\[
x \subseteq y := \forall z: z\in x \implies z \in y
\]

Y este axioma es equivalente a la antisimetra de la inclusin.

**** 2. Axioma de comprensin
Exigiendo que $A$ no aparezca como variable libre en $\varphi$.

\[
\forall A: \exists B: \forall z:\left( \varphi(z) \vee z \in A\right) \iff z \in B
\]

Puede usarse para demostrar que existe el conjunto vaco. O que
no existe el conjunto universal.

***** Paradoja de Russell
Supongamos el universal $U$. Podramos definir:

\[
R = \{x \in U \mid x \notin x\}
\]

Tanto $R \in R$ como $R \notin R$. Para evitarla podramos haber usado
estratificacin.

***** El nmero de axiomas es numerable
Las frmulas son sucesiones finitas de los smbolos que hemos usado
antes. Al haber una cantidad numerable de smbolos, las frmulas son
numerables, y los axiomas que se generan en este esquema lo son.

***** NBG
En la teora axiomtica de Von-Neumann se usa un nmero finito de
axiomas.

***** Diferencia de conjuntos
\[A-B = \{x \in A \mid x \notin B\}\]

***** Interseccin de conjuntos
Ntese que todava no podemos definir la unin arbitraria.

\[
\bigcap {\cal F} = \{x \in A \mid \forall y \in {\cal F} x \in y\}
\]

**** 3. Axioma del par
Dados dos conjuntos, tenemos uno que los contiene a los dos:

\[
\forall a,b : \exists z:
(a\in z \vee b \in z)
\]

***** Naturales
Con este axioma podemos construir los naturales en su segunda 
construccin.

***** Hay conjuntos no vacos
Hasta ahora, los axiomas eran consistentes con que slo existiera
el conjunto vaco.

***** Pares ordenados
Definimos un par ordenado:

\[
(a,b) := \{a , \{a,b\}\}
\]

**** 4. Axioma de la unin
Para una coleccin de conjuntos, crearemos una unin:

\[
\forall {\cal F}: \exists A: \forall Y,x: (x \in Y \wedge Y \in {\cal F}) \implies x \in A
\]

**** 5. Axioma del infinito
Construye directamente los nmeros naturales:

\[
\exists I: \varnothing \in I \wedge \forall x: x\in I \implies S(x) \in I \longrightarrow \exists \mathbb{N}
\]

Lleva a la existencia de cardinales grandes.

***** Finitud
Hasta ahora, podramos trabajar suponiendo todos los conjuntos finitos.

**** 6. Axioma del conjunto potencia
Existencia del conjunto potencia:

\[
\forall x: \exists y: \forall z: z \subseteq x \implies z \in y
\]

***** Producto cartesiano
Podemos definir el producto cartesiano de $A,B$. Tenemos que todos los
elementos $a\in A,b \in B$ llevan a $\{a,b\} \in {\cal P}(A,B)$.

\[
A \times B = \{ x \in {\cal P}{\cal P}(A \cup B) \mid x = (a,b), a \in A, b \in B\}
\]

Ntese que as slo hemos creado el producto cartesiano finito.

***** Funciones
Con el producto cartesiano, podemos pasar a ver las funciones como su
grfico.
**** 7. Axioma de reemplazamiento
Con estos seis axiomas, que constituyen la teora de Zermelo, no
podemos definir el conjunto con:

\[
\mathbb{N}, {\cal P}\mathbb{N}, {\cal P}{\cal P}\mathbb{N}, \dots
\]

Un predicado funcional es una frmula con variables libres $\varphi(x,y)$ 
que se comporta como una funcin:

\[
\forall x: \exists! y: \varphi(x,y)
\]

Tenemos entonces:

\[
\forall z: \exists \omega: \forall x,y: (x \in z \wedge \varphi(x,y) \implies y \in \omega)
\]

***** Definiendo el conjunto de potencias
Usando la funcin $n \mapsto {\cal P}^n(\mathbb{N})$.

***** Definiendo la imagen por un funcional
Definimos $\{x \in A \mid \phi(x)\}$ partiendo en el caso de que exista y 
de que no.

***** No existe el conjunto de todos los conjuntos.
Si existiera, podramos usar todas las topologas triviales y desde ah
el conjunto universal.
**** 8. Axioma de eleccin
Para cualquier familia de conjuntos sin ninguno vaco,

\[
\forall {\cal F} : 
\left(
\forall x \in {\cal F} :\varnothing \neq x
\implies 
\exists f : {\cal F} \to \bigcup {\cal F}: f(a) \in A
\right)
\]

Siendo $f$ una funcin.

**** 9. Axioma de fundacin
Para cualquier conjunto no vaco:

\[
\forall x: (x \neq \varnothing \implies \exists y: y \in x \wedge x \cap y = \varnothing)
\]
** Working group on Univalent Foundations - Michael Shulman

Categories can have an internal language or internal logic.

| Type theory    | Categories                                                            |
|----------------+-----------------------------------------------------------------------|
| Extensional TT | 1-categories (toposes, pretoposes, sheaves, realizability, gluing...) |
| Homotopy TT    | (,1)-categories, model categories, -toposes                         |

The first example is the simplicial model of type theory.

*** Type-theoretic fibration category
Two classes of examples

 1. Simplicial sets
 2. Sintactic category of a type theory

It should have

 * a terminal object,
 * fibrations (Kan fibrations, display maps) closed under composition and pullback.

Given a fibration $g \colon A \twoheadrightarrow B$, the pullback functor ${\cal C}/B \to {\cal C}/A$ has a right adjoint
taking fibrations to fibrations. (Pullback preserves acyclic cofibrations)

**** Weak factorization system
Two classes of maps $({\cal L}, {\cal R})$ and every morphism factors
as something in ${\cal L}$ and something in ${\cal R}$. Every square

\[\begin{tikzcd}
\cdot \rar{} \dar[swap]{{\cal L}} & \cdot \dar{{\cal R}} \\
\cdot\rar{} \urar[dashed] & \cdot 
\end{tikzcd}\]

factors as shown.
** Oregon Programming Languages Summer School 2017
*** Programming Languages Background 1
A programming language is defined by

 * *statics*, how it is written;
 * *dynamics*, how it is executed;

and they should be coherent in some way.

**** Statics
 1. Concrete syntax. Linear representations, usually. Psycology of
    programming languages determines how they are written.
 2. Abstract syntax.
 3. Context-sensitive conditions and well-formation.

The practical foundation are ABT (abstract binding trees); the syntax
is generated by operators with arguments.

[7:27]
** School on Univalent Mathematics - Birmingham
*** Spartan type theory - Andrej Bauer
*** Univalent foundations - Martin Escardo
*** Semantics for type theory - Helfer
# Notes on paper.

**** Formal languages and semantics
Traditional definition of formal languages. An alphabet and rules to
inductively construct words. We call $L$ the set of valid strings.

***** Example: boolean algebra
 * symbols $\Sigma = \left\{ p_1,\dots,p_n, \wedge,\neg,\implies,(,),\top,\bot,\dots \right\}$ 
   atomic propositions and logical symbols.
 * valid strings are defined inductively as
   * singletons $p_i$, $\top$ or $\bot$
   * connectors: if $a, b$ are valid, so are $a \wedge b, a \vee b, \neg a, \dots$

***** Semantics
The semantics assigns to each string a number $0$ or $1$,

\[
s \colon L \to \left\{ 0,1 \right\}
\]

and this evaluation will depend on the evaluation of atomic propositions.
If we call $\Omega = \left\{ p_1,\dots,p_n \right\}$, it depends on a valuation $v \colon \Omega \to \left\{ 0,1 \right\}$.
Connectives are interpreted naturally.

***** Observation
Sometimes $s_v(a) = s_v(b)$ regardless of $v$; in particular, $s_v(a) = 1$ regardless
of $v$ for some formulae (tautologies and absurds).

\[
s_v(A \wedge B) = s_v(B \wedge A)
\]

**** Simply typed lambda calculus
***** Definition
Taking a inductively defined set of types

 * given type $I$
 * function types $\alpha \to \beta$

The set $\Sigma$ of symbols has countably many variables of each type and the symbols of
lambda calculus $(,),\lambda, O,+,r$. We call a pair $<s,\alpha>$ a typed string; the set of
valid strings is our set of valid strings; we write $s : \alpha$ instead of $<s,\alpha> \in L$.

We have

 * $0 : I$
 * $^+ \colon I \to I$
 * $r \colon I \to (I \to I) \to I \to I$

and the usual typing rules for application and abstraction

 * if $s : \alpha, l : \alpha \to \beta$ then $sl : \beta$,
 * if $s : \beta$ and $x$ var of type $\beta$, $\lambda x.s \colon \alpha \to \beta$.

***** Semantics
We associate a set to each type, with $M(I) := \mathbb{N}$ and $M(\alpha \to \beta) := M(\beta)^{M(\alpha)}$;
and to each constant a correspondant element on the set, for example,
$M(r)$ is the unique function defined by induction.

Based on this, we construct an interpretation for each lambda term with
$M(s) \in M(\alpha)$. We give first an interpretation of variables $v = (v_{\alpha})_{\alpha \in Tp}$.
Application is interpreted as application of functions and abstraction
is interpreted as the interpretation of the body of the lambda under
a valuation that takes the bounded variable to the argument.

We can define a set of free variables of a string. Note that an
interpretation $M_{v}(x)$ with a valuation $v$ only depends on the
values of $v$ for the elements of $FV(x)$.

***** Observations
We have alpha-equivalence, beta-reduction and eta-reduction
inside the interpretation.

**** Semantics of MLTT
***** Set-theoretical semantics
It is more difficult to write a complete formalization of mltt.

We want to interpret $x_1:A_1,\dots,x_n:A_n \vdash A\ \mathrm{type}$ after interpreting

$A_1,\dots,A_n$ as sets. The interpretation will be a tuple
\[
a = \left\langle a_1,\dots,a_n \right\rangle
\]
where $a_i \in M(A_i)$, this is called the *realization of the context*.

To create an element $x_1:A_1,\dots,x_n:A_n \vdash t : A$ we should get
$M_v(t) \in M_v(A)$. We want an interpretation such that for every
definitional equality $A \equiv B$, we have the same sets $M_v(A) = M_v(B)$.

\[
M(s = t) = \left\{ \ast \right\} \mbox{ if } M(s)=M(t) \mbox{, and } \varnothing \mbox{ otherwise}
\]

But these semantics satisfy UIP.
***** Topological semantics
We interpret each type as a topological space; and each function type
as the set of continuous functions. We use simplicial sets in MLTT.

UIP does not hold under this interpretation.
*** Set-level mathematics - Helfer
**** Motivation
Given $X$ topological space, we say it is n-truncated if

\[
\pi_m(X) = 0 \text{ for all } m > n.
\]

 1) We know from homotopy theory that if $X$ is n-truncated, the
    space of paths between any two points is (n-1)-truncated.

 2) If $X$ is 0-truncated, it is homotopy equivalent to a discrete
    space; that is, a set.

A similar phenomenon occurs in category theory; a category has
objects, morphisms between them, morphisms between morphisms and so
on. The connection between categories and homotopical spaces is known
as the *[[https://ncatlab.org/nlab/show/homotopy+hypothesis][homotopy hypothesis]]*.

There are some definitions of -groupoids for which the homotopy
hypothesis is a proven theorem.

**** H-levels
\[
\mathsf{isofhlevel} : \mathbb{N} \to {\cal U} \to {\cal U}
\]

defined as

 * $\mathsf{isoflevel}(0,X) :\equiv \mathsf{iscontr}(X)$
 * $\mathsf{isoflevel}(S(n),X) :\equiv \prod_{x,x' : X} \mathsf{isofhlevel}(n,x=x')$

***** Sets
A set is a type of h-level 2.

 * Dependent pair of sets is a set.
 * Binary product of sets is a set.
 * Dependent function from a set to a family of sets is a set.
 * Function space to a set is a set.

**** How to show that something is not a set
***** Decidable types
A type $A$ is *decidable* if $A + \neg A$.

A type $A$ has *decidable path-equality* if all path types are
decidable

\[
\prod_{x,x' : A} (x = x') + \neg (x = x')
\]

***** Hedberg's theorem
Any type with decidable equality is a set.

***** Are all types sets?
 * In spartan type theory, there are types that cannot be shown to be
   sets. It is consistent with spartan type theory to assume that all
   types are sets.
 * In univalent type theory, some types are not sets.

***** Another set

\[
\mathsf{hProp} :\equiv \sum_{X:U} \mathsf{isaprop}(X)
\]

is a set. This can be generalized: the type of types of n-level is
of (n+1)-level.

***** The universe is not a set
The booleans have a non-trivial automorphism.

***** Sets and propositions

\[
\mathsf{isInjective}(f) :\equiv \prod_{x,x' : X}f(x) = f(x') \to x = x'
\]

is a proposition when $X,Y$ as sets.

**** Set-level quotient
***** Quotient
A map compatible with a relation is a map from the quotient;
the equivalence is given by precomposition with the projection.

\[
\sum_{f \colon X \to Y} \mathsf{isCompatible}(f) \simeq X/R \to Y
\]

***** Subtype
A subtype of a type is a map from the subtype to hProp.
# Note that this definition is similar to that of the dependent sum.

****** The type of binary relations is a set

***** Defining quotients
Equivalence classes

\[
\mathsf{iseqclass}(A) = \| \mathsf{carrier}(A) \| \times 
\left( \prod_{x,y:A} Rxy \to Ax \to Ay \right)
\times 
\left( \prod_{x,y:A} Ax \to Ay \to Rxy \right)
\]

Quotients

\[
X/R :\equiv \sum_{A : X \to \mathsf{hProp}} \mathsf{iseqclass}(A)
\]

**** Set-level mathematics
***** Groups in type theory
We want the proofs of the axioms of a group to be elements of a
proposition; having this, any two groups with the same data are
equivalent.

A group isomorphism is a bijective function compatible with the
group structure; we can show that the type of equality between
of groups is the type of isomorphisms.

# Identity is isomorphism for groups!  Transport along the path given
# by univalence for a equivalence is conjugation by that equivalence.
*** Category theory - Lumsdaine
Definition of a category in the univalent setting is different than
that from a classical setting. What works the same in this
formulation and what works differently?

**** Difference
***** Definition
A *category* consists of 

 * a type of objects $\mathrm{ob}({\cal C})$;
 * for each pair of objects, a set of morphisms $\mathrm{hom}(a,b)$;

and the axioms, with are all about morphisms and they behave well with
objects not being a set.

****** Terminology
This is terminology in UniMath, in the HoTT book this is called
*precategory*. A precategory here would be just types
$\mathsf{hom}(x,y)$ but this is not discussed in the HoTT book.

****** Set-category
A set category is a category where $\mathrm{ob}({\cal C})$ is a set.

****** Carrier set
It is useful to take the carrier to be a set; in other case, we
would get a more general algebraic structure where equalities do
not work as well as in the particular case.

***** Examples
****** Sets
Sets is a category in the way we expect; but it is *not* a set
category; the set of h-sets is not an h-set. This is why we don't
want to take set-categories as our definition.

****** Simplicial set
$\Delta$ can be constructed with objects $\mathbb{N}$ and maps $m \to n$ 
as order-preserving maps $f \colon [m] \to [n]$. It is a set
category.

Small cats, combinatorially constructed ones, are set-cats in
practice.

***** Univalent categories and Rezk completion
A category is *univalent* if the canonical map (defined with identity)
$x = y \to \mathrm{Iso}(x,y)$ is an equivalence for each pair $x,y$. This is like
an internal version of univalence.

This is called /saturated category/ in the HoTT book.

****** Example: sets
Sets is univalent. Most categories in practice are univalent.
Tops, Grps, and algebraic constructions in general. Products of
univalent categories and algebras for a monad in a univalent
category are univalent.

/Heuristic:/ if the category is "the category of its objects" it will
be univalent.

****** Counterexample
The homotopy category of topological spaces where

 * objects are topological spaces,
 * and maps are continuous maps up to homotopy.

There are non-equal objects here that are homotopically-equal. It is not
the category of topological spaces but a category of homotopy types, and
we are using topological spaces only as representatives.

****** Counterexample
A preorder (category where each hom-set is a prop) is univalent iff
$\mathrm{ob}({\cal C})$ is a set and $x \leq y, y \leq x$ implies $x = y$.

****** Fact: categories have an univalent completion operation
The *Rezk completion* (Ahrens, Kapulkin, Shulman) is a sort of
univalent completion.

\[\begin{tikzcd}
& RC({\cal C}) \drar[dashed] & \\
{\cal C} \ar{rr} \urar & & {\cal E}
\end{tikzcd}\]

Given any univalent ${\cal E}$, any map factors through the completion.
The functor ${\cal C} \to RC({\cal C})$ is fully faithfull and essentially surjective.

**** What works the same?
Most things that don't mention equality of objects; modulo being
careful about existence vs chosen structure and not having the
axiom of choice.

***** Example: having products
If they exist, they are unique up to isomorphism.

***** In univalent categories
In an univalent category, they are actually unique! existence
of products is equivalent to chosen products and this is a
proposition.

***** Unimath

- Functors, natural transformations.
- Monads.
- Functor categories.
- Colimits, limits.

**** What works a little differently?
***** Displayed categories
Examples of equality on objects

 * *fibrations of categories*; for example, if ${\cal C}$ has pullbacks, the
   arrow category ${\cal C}^{\to}$ with the projection to the second object is a
   fibration.

   Typically, fibers are

   \[
   \mathrm{ob}({\cal E}) :\equiv \sum_{x : {\cal E}} \text{objects of ${\cal E}$ over ${\cal C}$}
   \]

***** Definition of displayed category
A displayed category over ${\cal C}$ has

 - for $c : \mathrm{ob}({\cal C})$, a type $\mathrm{ob}_c({\cal D})$;
 - for 

   \[\begin{tikzcd}
   d' & d \\
   c'\rar{f} & c
   \end{tikzcd}\]
 
   a set $\mathrm{hom}(d',d)$.

They 

***** Utility of displayed categories
Useful for building up categories of multi-component structures and
reasoning about them one cat at a time.

***** Example: groups
Groups are a displayed category over sets. The objects are group
structures over set; and the $\mathrm{hom}(g,g')$ is a function
between the sets together with the assumption that it preserves the
structure.
***** !
**** What works very differently?
Unexplored territory

***** 2-categories, higher categories
In univalent categories, we don't have enough strict 2-categories; in
particular, the category Cat is not a strict 2-category in the univalent
setting.
*** How to implement type theory in an hour - Andrej Bauer

 * Unicode input
 * Pretty printing
 * Loading filesv
 
**** Type checking
Bidirectional type checking.

**** Equality of types
Not every theory has an algorithm checking equality of types.

 -> We use an algorithm due to Bob Harper.
    It uses the extensionality rules to check for equality of terms.

     * Every two elements of the unit are equal.
     * We can apply a judgmental eta rule with a fresh variable.

    We have *extensional rules* for free.

It does not work with primitive symbols. Then we switch to normalization
phase and structurally compare the two weak normal form of the types.
*** Future of unimath - Ahrens
*** Presentations
**** Nominal sets
***** First definition
Given a set with decidable equality (eg. naturals), $X$ is
a nominal set...

\[
\forall x \in X, \exists A \subset \mathbb{N}, \forall u \in \mathrm{Perm}(\mathbb{N}), u|_{A} = \mathrm{id}: u(x) = x
\]
***** Presheaf definition
et $N$ be the subcategory of finite subsets of $\mathbb{N}$,
morphisms injections. A nominal set is a functor $\mathbb{N} \to \mathrm{Set}$.


